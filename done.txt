I0109 14:38:01.787251  4932 caffe.cpp:112] Use CPU.
I0109 14:38:02.016176  4932 caffe.cpp:120] Swtiching to GPU 0
I0109 14:38:02.016535  4932 caffe.cpp:174] Starting Optimization
I0109 14:38:02.016592  4932 solver.cpp:34] Initializing solver from parameters: 
test_iter: 950
test_interval: 1000
base_lr: 0.0001
display: 20
max_iter: 80000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot_prefix: "/home/hadoop/whx/tsncaffe/mywork/ucf101/snapshot/ucf101_split1_tsn_flow_bn_inception"
solver_mode: GPU
debug_info: false
net: "/home/hadoop/whx/tsncaffe/mywork/ucf101/tsn_bn_inception_flow_train_val.prototxt"
test_initialization: true
average_loss: 20
stepvalue: 10000
stepvalue: 20000
stepvalue: 30000
stepvalue: 50000
clip_gradients: 20
iter_size: 1
richness: 10000
I0109 14:38:02.016616  4932 solver.cpp:75] Creating training net from net file: /home/hadoop/whx/tsncaffe/mywork/ucf101/tsn_bn_inception_flow_train_val.prototxt
I0109 14:38:02.021952  4932 net.cpp:334] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0109 14:38:02.022084  4932 net.cpp:334] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I0109 14:38:02.024097  4932 net.cpp:46] Initializing net from parameters: 
name: "BN-Inception"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "VideoData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 128
    fix_crop: true
    multi_scale: true
    scale_ratios: 1
    scale_ratios: 0.875
    scale_ratios: 0.75
    max_distort: 1
    is_flow: true
    more_fix_crop: true
  }
  video_data_param {
    source: "/home/hadoop/whx/dataset/ucf101/train_flow_split1.txt"
    batch_size: 24
    shuffle: true
    new_length: 5
    num_segments: 3
    modality: FLOW
    name_pattern: "flow_%c_%04d.jpg"
  }
}
layer {
  name: "data_reshape"
  type: "Reshape"
  bottom: "data"
  top: "data_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 10
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "conv1/7x7_s2"
  type: "Convolution"
  bottom: "data_reshape"
  top: "conv1/7x7_s2"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/7x7_s2_bn"
  type: "BN"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: false
    engine: CAFFE
  }
}
layer {
  name: "conv1/relu_7x7"
  type: "ReLU"
  bottom: "conv1/7x7_s2_bn"
  top: "conv1/7x7_s2_bn"
}
layer {
  name: "pool1/3x3_s2"
  type: "Pooling"
  bottom: "conv1/7x7_s2_bn"
  top: "pool1/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2/3x3_reduce"
  type: "Convolution"
  bottom: "pool1/3x3_s2"
  top: "conv2/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/3x3_reduce_bn"
  type: "BN"
  bottom: "conv2/3x3_reduce"
  top: "conv2/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "conv2/relu_3x3_reduce"
  type: "ReLU"
  bottom: "conv2/3x3_reduce_bn"
  top: "conv2/3x3_reduce_bn"
}
layer {
  name: "conv2/3x3"
  type: "Convolution"
  bottom: "conv2/3x3_reduce_bn"
  top: "conv2/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/3x3_bn"
  type: "BN"
  bottom: "conv2/3x3"
  top: "conv2/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "conv2/relu_3x3"
  type: "ReLU"
  bottom: "conv2/3x3_bn"
  top: "conv2/3x3_bn"
}
layer {
  name: "pool2/3x3_s2"
  type: "Pooling"
  bottom: "conv2/3x3_bn"
  top: "pool2/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "pool2/3x3_s2"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1_bn"
  type: "BN"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_1x1"
  type: "ReLU"
  bottom: "inception_3a/1x1_bn"
  top: "inception_3a/1x1_bn"
}
layer {
  name: "inception_3a/3x3_reduce"
  type: "Convolution"
  bottom: "pool2/3x3_s2"
  top: "inception_3a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/3x3_reduce_bn"
  top: "inception_3a/3x3_reduce_bn"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_3a/3x3_reduce_bn"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3_bn"
  type: "BN"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_3x3"
  type: "ReLU"
  bottom: "inception_3a/3x3_bn"
  top: "inception_3a/3x3_bn"
}
layer {
  name: "inception_3a/double_3x3_reduce"
  type: "Convolution"
  bottom: "pool2/3x3_s2"
  top: "inception_3a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3a/double_3x3_reduce"
  top: "inception_3a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/double_3x3_reduce_bn"
  top: "inception_3a/double_3x3_reduce_bn"
}
layer {
  name: "inception_3a/double_3x3_1"
  type: "Convolution"
  bottom: "inception_3a/double_3x3_reduce_bn"
  top: "inception_3a/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_3a/double_3x3_1"
  top: "inception_3a/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_3a/double_3x3_1_bn"
  top: "inception_3a/double_3x3_1_bn"
}
layer {
  name: "inception_3a/double_3x3_2"
  type: "Convolution"
  bottom: "inception_3a/double_3x3_1_bn"
  top: "inception_3a/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_3a/double_3x3_2"
  top: "inception_3a/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_3a/double_3x3_2_bn"
  top: "inception_3a/double_3x3_2_bn"
}
layer {
  name: "inception_3a/pool"
  type: "Pooling"
  bottom: "pool2/3x3_s2"
  top: "inception_3a/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_3a/pool_proj"
  type: "Convolution"
  bottom: "inception_3a/pool"
  top: "inception_3a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/pool_proj_bn"
  type: "BN"
  bottom: "inception_3a/pool_proj"
  top: "inception_3a/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3a/pool_proj_bn"
  top: "inception_3a/pool_proj_bn"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1_bn"
  bottom: "inception_3a/3x3_bn"
  bottom: "inception_3a/double_3x3_2_bn"
  bottom: "inception_3a/pool_proj_bn"
  top: "inception_3a/output"
}
layer {
  name: "inception_3b/1x1"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "inception_3b/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/1x1_bn"
  type: "BN"
  bottom: "inception_3b/1x1"
  top: "inception_3b/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_1x1"
  type: "ReLU"
  bottom: "inception_3b/1x1_bn"
  top: "inception_3b/1x1_bn"
}
layer {
  name: "inception_3b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "inception_3b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3b/3x3_reduce"
  top: "inception_3b/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3b/3x3_reduce_bn"
  top: "inception_3b/3x3_reduce_bn"
}
layer {
  name: "inception_3b/3x3"
  type: "Convolution"
  bottom: "inception_3b/3x3_reduce_bn"
  top: "inception_3b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/3x3_bn"
  type: "BN"
  bottom: "inception_3b/3x3"
  top: "inception_3b/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_3x3"
  type: "ReLU"
  bottom: "inception_3b/3x3_bn"
  top: "inception_3b/3x3_bn"
}
layer {
  name: "inception_3b/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "inception_3b/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3b/double_3x3_reduce"
  top: "inception_3b/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3b/double_3x3_reduce_bn"
  top: "inception_3b/double_3x3_reduce_bn"
}
layer {
  name: "inception_3b/double_3x3_1"
  type: "Convolution"
  bottom: "inception_3b/double_3x3_reduce_bn"
  top: "inception_3b/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_3b/double_3x3_1"
  top: "inception_3b/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_3b/double_3x3_1_bn"
  top: "inception_3b/double_3x3_1_bn"
}
layer {
  name: "inception_3b/double_3x3_2"
  type: "Convolution"
  bottom: "inception_3b/double_3x3_1_bn"
  top: "inception_3b/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_3b/double_3x3_2"
  top: "inception_3b/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_3b/double_3x3_2_bn"
  top: "inception_3b/double_3x3_2_bn"
}
layer {
  name: "inception_3b/pool"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "inception_3b/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_3b/pool_proj"
  type: "Convolution"
  bottom: "inception_3b/pool"
  top: "inception_3b/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/pool_proj_bn"
  type: "BN"
  bottom: "inception_3b/pool_proj"
  top: "inception_3b/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3b/pool_proj_bn"
  top: "inception_3b/pool_proj_bn"
}
layer {
  name: "inception_3b/output"
  type: "Concat"
  bottom: "inception_3b/1x1_bn"
  bottom: "inception_3b/3x3_bn"
  bottom: "inception_3b/double_3x3_2_bn"
  bottom: "inception_3b/pool_proj_bn"
  top: "inception_3b/output"
}
layer {
  name: "inception_3c/3x3_reduce"
  type: "Convolution"
  bottom: "inception_3b/output"
  top: "inception_3c/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3c/3x3_reduce"
  top: "inception_3c/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3c/3x3_reduce_bn"
  top: "inception_3c/3x3_reduce_bn"
}
layer {
  name: "inception_3c/3x3"
  type: "Convolution"
  bottom: "inception_3c/3x3_reduce_bn"
  top: "inception_3c/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/3x3_bn"
  type: "BN"
  bottom: "inception_3c/3x3"
  top: "inception_3c/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_3x3"
  type: "ReLU"
  bottom: "inception_3c/3x3_bn"
  top: "inception_3c/3x3_bn"
}
layer {
  name: "inception_3c/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_3b/output"
  top: "inception_3c/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3c/double_3x3_reduce"
  top: "inception_3c/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3c/double_3x3_reduce_bn"
  top: "inception_3c/double_3x3_reduce_bn"
}
layer {
  name: "inception_3c/double_3x3_1"
  type: "Convolution"
  bottom: "inception_3c/double_3x3_reduce_bn"
  top: "inception_3c/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_3c/double_3x3_1"
  top: "inception_3c/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_3c/double_3x3_1_bn"
  top: "inception_3c/double_3x3_1_bn"
}
layer {
  name: "inception_3c/double_3x3_2"
  type: "Convolution"
  bottom: "inception_3c/double_3x3_1_bn"
  top: "inception_3c/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_3c/double_3x3_2"
  top: "inception_3c/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_3c/double_3x3_2_bn"
  top: "inception_3c/double_3x3_2_bn"
}
layer {
  name: "inception_3c/pool"
  type: "Pooling"
  bottom: "inception_3b/output"
  top: "inception_3c/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "inception_3c/output"
  type: "Concat"
  bottom: "inception_3c/3x3_bn"
  bottom: "inception_3c/double_3x3_2_bn"
  bottom: "inception_3c/pool"
  top: "inception_3c/output"
}
layer {
  name: "inception_4a/1x1"
  type: "Convolution"
  bottom: "inception_3c/output"
  top: "inception_4a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 224
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/1x1_bn"
  type: "BN"
  bottom: "inception_4a/1x1"
  top: "inception_4a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_1x1"
  type: "ReLU"
  bottom: "inception_4a/1x1_bn"
  top: "inception_4a/1x1_bn"
}
layer {
  name: "inception_4a/3x3_reduce"
  type: "Convolution"
  bottom: "inception_3c/output"
  top: "inception_4a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_4a/3x3_reduce"
  top: "inception_4a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4a/3x3_reduce_bn"
  top: "inception_4a/3x3_reduce_bn"
}
layer {
  name: "inception_4a/3x3"
  type: "Convolution"
  bottom: "inception_4a/3x3_reduce_bn"
  top: "inception_4a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/3x3_bn"
  type: "BN"
  bottom: "inception_4a/3x3"
  top: "inception_4a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_3x3"
  type: "ReLU"
  bottom: "inception_4a/3x3_bn"
  top: "inception_4a/3x3_bn"
}
layer {
  name: "inception_4a/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_3c/output"
  top: "inception_4a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_4a/double_3x3_reduce"
  top: "inception_4a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4a/double_3x3_reduce_bn"
  top: "inception_4a/double_3x3_reduce_bn"
}
layer {
  name: "inception_4a/double_3x3_1"
  type: "Convolution"
  bottom: "inception_4a/double_3x3_reduce_bn"
  top: "inception_4a/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_4a/double_3x3_1"
  top: "inception_4a/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_4a/double_3x3_1_bn"
  top: "inception_4a/double_3x3_1_bn"
}
layer {
  name: "inception_4a/double_3x3_2"
  type: "Convolution"
  bottom: "inception_4a/double_3x3_1_bn"
  top: "inception_4a/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_4a/double_3x3_2"
  top: "inception_4a/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_4a/double_3x3_2_bn"
  top: "inception_4a/double_3x3_2_bn"
}
layer {
  name: "inception_4a/pool"
  type: "Pooling"
  bottom: "inception_3c/output"
  top: "inception_4a/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4a/pool_proj"
  type: "Convolution"
  bottom: "inception_4a/pool"
  top: "inception_4a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/pool_proj_bn"
  type: "BN"
  bottom: "inception_4a/pool_proj"
  top: "inception_4a/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4a/pool_proj_bn"
  top: "inception_4a/pool_proj_bn"
}
layer {
  name: "inception_4a/output"
  type: "Concat"
  bottom: "inception_4a/1x1_b
I0109 14:38:02.025002  4932 layer_factory.hpp:74] Creating layer data
I0109 14:38:02.025020  4932 net.cpp:96] Creating Layer data
I0109 14:38:02.025027  4932 net.cpp:415] data -> data
I0109 14:38:02.025048  4932 net.cpp:415] data -> label
I0109 14:38:02.025058  4932 net.cpp:160] Setting up data
I0109 14:38:02.025408  4932 video_data_layer.cpp:34] Opening file: /home/hadoop/whx/dataset/ucf101/train_flow_split1.txt
I0109 14:38:02.030411  4932 video_data_layer.cpp:50] A total of 9537 videos.
I0109 14:38:03.724882  4932 video_data_layer.cpp:89] output data size: 24,30,224,224
I0109 14:38:03.740986  4932 net.cpp:167] Top shape: 24 30 224 224 (36126720)
I0109 14:38:03.741016  4932 net.cpp:167] Top shape: 24 1 1 1 (24)
I0109 14:38:03.741024  4932 layer_factory.hpp:74] Creating layer data_reshape
I0109 14:38:03.741037  4932 net.cpp:96] Creating Layer data_reshape
I0109 14:38:03.741042  4932 net.cpp:459] data_reshape <- data
I0109 14:38:03.741051  4932 net.cpp:415] data_reshape -> data_reshape
I0109 14:38:03.741065  4932 net.cpp:160] Setting up data_reshape
I0109 14:38:03.741080  4932 net.cpp:167] Top shape: 72 10 224 224 (36126720)
I0109 14:38:03.741084  4932 layer_factory.hpp:74] Creating layer conv1/7x7_s2
I0109 14:38:03.741101  4932 net.cpp:96] Creating Layer conv1/7x7_s2
I0109 14:38:03.741106  4932 net.cpp:459] conv1/7x7_s2 <- data_reshape
I0109 14:38:03.741111  4932 net.cpp:415] conv1/7x7_s2 -> conv1/7x7_s2
I0109 14:38:03.741119  4932 net.cpp:160] Setting up conv1/7x7_s2
I0109 14:38:03.741291  4932 net.cpp:167] Top shape: 72 64 112 112 (57802752)
I0109 14:38:03.741307  4932 layer_factory.hpp:74] Creating layer conv1/7x7_s2_bn
I0109 14:38:03.741318  4932 layer_factory.cpp:177] Layer conv1/7x7_s2_bn is using CAFFE engine.
I0109 14:38:03.741325  4932 net.cpp:96] Creating Layer conv1/7x7_s2_bn
I0109 14:38:03.741328  4932 net.cpp:459] conv1/7x7_s2_bn <- conv1/7x7_s2
I0109 14:38:03.741334  4932 net.cpp:415] conv1/7x7_s2_bn -> conv1/7x7_s2_bn
I0109 14:38:03.741341  4932 net.cpp:160] Setting up conv1/7x7_s2_bn
I0109 14:38:03.741363  4932 net.cpp:167] Top shape: 72 64 112 112 (57802752)
I0109 14:38:03.741371  4932 layer_factory.hpp:74] Creating layer conv1/relu_7x7
I0109 14:38:03.741377  4932 net.cpp:96] Creating Layer conv1/relu_7x7
I0109 14:38:03.741381  4932 net.cpp:459] conv1/relu_7x7 <- conv1/7x7_s2_bn
I0109 14:38:03.741386  4932 net.cpp:404] conv1/relu_7x7 -> conv1/7x7_s2_bn (in-place)
I0109 14:38:03.741390  4932 net.cpp:160] Setting up conv1/relu_7x7
I0109 14:38:03.741395  4932 net.cpp:167] Top shape: 72 64 112 112 (57802752)
I0109 14:38:03.741399  4932 layer_factory.hpp:74] Creating layer pool1/3x3_s2
I0109 14:38:03.741405  4932 net.cpp:96] Creating Layer pool1/3x3_s2
I0109 14:38:03.741407  4932 net.cpp:459] pool1/3x3_s2 <- conv1/7x7_s2_bn
I0109 14:38:03.741411  4932 net.cpp:415] pool1/3x3_s2 -> pool1/3x3_s2
I0109 14:38:03.741417  4932 net.cpp:160] Setting up pool1/3x3_s2
I0109 14:38:03.741427  4932 net.cpp:167] Top shape: 72 64 56 56 (14450688)
I0109 14:38:03.741431  4932 layer_factory.hpp:74] Creating layer conv2/3x3_reduce
I0109 14:38:03.741438  4932 net.cpp:96] Creating Layer conv2/3x3_reduce
I0109 14:38:03.741441  4932 net.cpp:459] conv2/3x3_reduce <- pool1/3x3_s2
I0109 14:38:03.741446  4932 net.cpp:415] conv2/3x3_reduce -> conv2/3x3_reduce
I0109 14:38:03.741451  4932 net.cpp:160] Setting up conv2/3x3_reduce
I0109 14:38:03.741480  4932 net.cpp:167] Top shape: 72 64 56 56 (14450688)
I0109 14:38:03.741487  4932 layer_factory.hpp:74] Creating layer conv2/3x3_reduce_bn
I0109 14:38:03.741489  4932 layer_factory.cpp:177] Layer conv2/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.741495  4932 net.cpp:96] Creating Layer conv2/3x3_reduce_bn
I0109 14:38:03.741498  4932 net.cpp:459] conv2/3x3_reduce_bn <- conv2/3x3_reduce
I0109 14:38:03.741503  4932 net.cpp:415] conv2/3x3_reduce_bn -> conv2/3x3_reduce_bn
I0109 14:38:03.741508  4932 net.cpp:160] Setting up conv2/3x3_reduce_bn
I0109 14:38:03.741520  4932 net.cpp:167] Top shape: 72 64 56 56 (14450688)
I0109 14:38:03.741528  4932 layer_factory.hpp:74] Creating layer conv2/relu_3x3_reduce
I0109 14:38:03.741533  4932 net.cpp:96] Creating Layer conv2/relu_3x3_reduce
I0109 14:38:03.741536  4932 net.cpp:459] conv2/relu_3x3_reduce <- conv2/3x3_reduce_bn
I0109 14:38:03.741540  4932 net.cpp:404] conv2/relu_3x3_reduce -> conv2/3x3_reduce_bn (in-place)
I0109 14:38:03.741545  4932 net.cpp:160] Setting up conv2/relu_3x3_reduce
I0109 14:38:03.741549  4932 net.cpp:167] Top shape: 72 64 56 56 (14450688)
I0109 14:38:03.741552  4932 layer_factory.hpp:74] Creating layer conv2/3x3
I0109 14:38:03.741559  4932 net.cpp:96] Creating Layer conv2/3x3
I0109 14:38:03.741561  4932 net.cpp:459] conv2/3x3 <- conv2/3x3_reduce_bn
I0109 14:38:03.741566  4932 net.cpp:415] conv2/3x3 -> conv2/3x3
I0109 14:38:03.741572  4932 net.cpp:160] Setting up conv2/3x3
I0109 14:38:03.742053  4932 net.cpp:167] Top shape: 72 192 56 56 (43352064)
I0109 14:38:03.742058  4932 layer_factory.hpp:74] Creating layer conv2/3x3_bn
I0109 14:38:03.742063  4932 layer_factory.cpp:177] Layer conv2/3x3_bn is using CAFFE engine.
I0109 14:38:03.742067  4932 net.cpp:96] Creating Layer conv2/3x3_bn
I0109 14:38:03.742071  4932 net.cpp:459] conv2/3x3_bn <- conv2/3x3
I0109 14:38:03.742076  4932 net.cpp:415] conv2/3x3_bn -> conv2/3x3_bn
I0109 14:38:03.742081  4932 net.cpp:160] Setting up conv2/3x3_bn
I0109 14:38:03.742094  4932 net.cpp:167] Top shape: 72 192 56 56 (43352064)
I0109 14:38:03.742101  4932 layer_factory.hpp:74] Creating layer conv2/relu_3x3
I0109 14:38:03.742106  4932 net.cpp:96] Creating Layer conv2/relu_3x3
I0109 14:38:03.742110  4932 net.cpp:459] conv2/relu_3x3 <- conv2/3x3_bn
I0109 14:38:03.742120  4932 net.cpp:404] conv2/relu_3x3 -> conv2/3x3_bn (in-place)
I0109 14:38:03.742130  4932 net.cpp:160] Setting up conv2/relu_3x3
I0109 14:38:03.742135  4932 net.cpp:167] Top shape: 72 192 56 56 (43352064)
I0109 14:38:03.742137  4932 layer_factory.hpp:74] Creating layer pool2/3x3_s2
I0109 14:38:03.742142  4932 net.cpp:96] Creating Layer pool2/3x3_s2
I0109 14:38:03.742146  4932 net.cpp:459] pool2/3x3_s2 <- conv2/3x3_bn
I0109 14:38:03.742151  4932 net.cpp:415] pool2/3x3_s2 -> pool2/3x3_s2
I0109 14:38:03.742156  4932 net.cpp:160] Setting up pool2/3x3_s2
I0109 14:38:03.742161  4932 net.cpp:167] Top shape: 72 192 28 28 (10838016)
I0109 14:38:03.742164  4932 layer_factory.hpp:74] Creating layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0109 14:38:03.742169  4932 net.cpp:96] Creating Layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0109 14:38:03.742172  4932 net.cpp:459] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2
I0109 14:38:03.742177  4932 net.cpp:415] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0109 14:38:03.742182  4932 net.cpp:415] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0109 14:38:03.742187  4932 net.cpp:415] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0109 14:38:03.742192  4932 net.cpp:415] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0109 14:38:03.742197  4932 net.cpp:160] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split
I0109 14:38:03.742202  4932 net.cpp:167] Top shape: 72 192 28 28 (10838016)
I0109 14:38:03.742205  4932 net.cpp:167] Top shape: 72 192 28 28 (10838016)
I0109 14:38:03.742209  4932 net.cpp:167] Top shape: 72 192 28 28 (10838016)
I0109 14:38:03.742213  4932 net.cpp:167] Top shape: 72 192 28 28 (10838016)
I0109 14:38:03.742216  4932 layer_factory.hpp:74] Creating layer inception_3a/1x1
I0109 14:38:03.742223  4932 net.cpp:96] Creating Layer inception_3a/1x1
I0109 14:38:03.742225  4932 net.cpp:459] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0109 14:38:03.742230  4932 net.cpp:415] inception_3a/1x1 -> inception_3a/1x1
I0109 14:38:03.742235  4932 net.cpp:160] Setting up inception_3a/1x1
I0109 14:38:03.742297  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742303  4932 layer_factory.hpp:74] Creating layer inception_3a/1x1_bn
I0109 14:38:03.742307  4932 layer_factory.cpp:177] Layer inception_3a/1x1_bn is using CAFFE engine.
I0109 14:38:03.742312  4932 net.cpp:96] Creating Layer inception_3a/1x1_bn
I0109 14:38:03.742316  4932 net.cpp:459] inception_3a/1x1_bn <- inception_3a/1x1
I0109 14:38:03.742321  4932 net.cpp:415] inception_3a/1x1_bn -> inception_3a/1x1_bn
I0109 14:38:03.742327  4932 net.cpp:160] Setting up inception_3a/1x1_bn
I0109 14:38:03.742338  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742344  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_1x1
I0109 14:38:03.742350  4932 net.cpp:96] Creating Layer inception_3a/relu_1x1
I0109 14:38:03.742353  4932 net.cpp:459] inception_3a/relu_1x1 <- inception_3a/1x1_bn
I0109 14:38:03.742358  4932 net.cpp:404] inception_3a/relu_1x1 -> inception_3a/1x1_bn (in-place)
I0109 14:38:03.742362  4932 net.cpp:160] Setting up inception_3a/relu_1x1
I0109 14:38:03.742367  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742369  4932 layer_factory.hpp:74] Creating layer inception_3a/3x3_reduce
I0109 14:38:03.742375  4932 net.cpp:96] Creating Layer inception_3a/3x3_reduce
I0109 14:38:03.742378  4932 net.cpp:459] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0109 14:38:03.742383  4932 net.cpp:415] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I0109 14:38:03.742388  4932 net.cpp:160] Setting up inception_3a/3x3_reduce
I0109 14:38:03.742449  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742455  4932 layer_factory.hpp:74] Creating layer inception_3a/3x3_reduce_bn
I0109 14:38:03.742458  4932 layer_factory.cpp:177] Layer inception_3a/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.742463  4932 net.cpp:96] Creating Layer inception_3a/3x3_reduce_bn
I0109 14:38:03.742470  4932 net.cpp:459] inception_3a/3x3_reduce_bn <- inception_3a/3x3_reduce
I0109 14:38:03.742480  4932 net.cpp:415] inception_3a/3x3_reduce_bn -> inception_3a/3x3_reduce_bn
I0109 14:38:03.742485  4932 net.cpp:160] Setting up inception_3a/3x3_reduce_bn
I0109 14:38:03.742496  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742502  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_3x3_reduce
I0109 14:38:03.742507  4932 net.cpp:96] Creating Layer inception_3a/relu_3x3_reduce
I0109 14:38:03.742511  4932 net.cpp:459] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce_bn
I0109 14:38:03.742514  4932 net.cpp:404] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce_bn (in-place)
I0109 14:38:03.742519  4932 net.cpp:160] Setting up inception_3a/relu_3x3_reduce
I0109 14:38:03.742523  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742527  4932 layer_factory.hpp:74] Creating layer inception_3a/3x3
I0109 14:38:03.742532  4932 net.cpp:96] Creating Layer inception_3a/3x3
I0109 14:38:03.742535  4932 net.cpp:459] inception_3a/3x3 <- inception_3a/3x3_reduce_bn
I0109 14:38:03.742540  4932 net.cpp:415] inception_3a/3x3 -> inception_3a/3x3
I0109 14:38:03.742545  4932 net.cpp:160] Setting up inception_3a/3x3
I0109 14:38:03.742712  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742717  4932 layer_factory.hpp:74] Creating layer inception_3a/3x3_bn
I0109 14:38:03.742720  4932 layer_factory.cpp:177] Layer inception_3a/3x3_bn is using CAFFE engine.
I0109 14:38:03.742727  4932 net.cpp:96] Creating Layer inception_3a/3x3_bn
I0109 14:38:03.742729  4932 net.cpp:459] inception_3a/3x3_bn <- inception_3a/3x3
I0109 14:38:03.742734  4932 net.cpp:415] inception_3a/3x3_bn -> inception_3a/3x3_bn
I0109 14:38:03.742740  4932 net.cpp:160] Setting up inception_3a/3x3_bn
I0109 14:38:03.742750  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742759  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_3x3
I0109 14:38:03.742764  4932 net.cpp:96] Creating Layer inception_3a/relu_3x3
I0109 14:38:03.742768  4932 net.cpp:459] inception_3a/relu_3x3 <- inception_3a/3x3_bn
I0109 14:38:03.742772  4932 net.cpp:404] inception_3a/relu_3x3 -> inception_3a/3x3_bn (in-place)
I0109 14:38:03.742776  4932 net.cpp:160] Setting up inception_3a/relu_3x3
I0109 14:38:03.742780  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742784  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_reduce
I0109 14:38:03.742789  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_reduce
I0109 14:38:03.742792  4932 net.cpp:459] inception_3a/double_3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0109 14:38:03.742799  4932 net.cpp:415] inception_3a/double_3x3_reduce -> inception_3a/double_3x3_reduce
I0109 14:38:03.742804  4932 net.cpp:160] Setting up inception_3a/double_3x3_reduce
I0109 14:38:03.742864  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742871  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_reduce_bn
I0109 14:38:03.742873  4932 layer_factory.cpp:177] Layer inception_3a/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.742879  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_reduce_bn
I0109 14:38:03.742882  4932 net.cpp:459] inception_3a/double_3x3_reduce_bn <- inception_3a/double_3x3_reduce
I0109 14:38:03.742887  4932 net.cpp:415] inception_3a/double_3x3_reduce_bn -> inception_3a/double_3x3_reduce_bn
I0109 14:38:03.742892  4932 net.cpp:160] Setting up inception_3a/double_3x3_reduce_bn
I0109 14:38:03.742903  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742909  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_reduce
I0109 14:38:03.742914  4932 net.cpp:96] Creating Layer inception_3a/relu_double_3x3_reduce
I0109 14:38:03.742918  4932 net.cpp:459] inception_3a/relu_double_3x3_reduce <- inception_3a/double_3x3_reduce_bn
I0109 14:38:03.742921  4932 net.cpp:404] inception_3a/relu_double_3x3_reduce -> inception_3a/double_3x3_reduce_bn (in-place)
I0109 14:38:03.742928  4932 net.cpp:160] Setting up inception_3a/relu_double_3x3_reduce
I0109 14:38:03.742936  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.742939  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_1
I0109 14:38:03.742944  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_1
I0109 14:38:03.742949  4932 net.cpp:459] inception_3a/double_3x3_1 <- inception_3a/double_3x3_reduce_bn
I0109 14:38:03.742954  4932 net.cpp:415] inception_3a/double_3x3_1 -> inception_3a/double_3x3_1
I0109 14:38:03.742959  4932 net.cpp:160] Setting up inception_3a/double_3x3_1
I0109 14:38:03.743203  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.743209  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_1_bn
I0109 14:38:03.743212  4932 layer_factory.cpp:177] Layer inception_3a/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.743217  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_1_bn
I0109 14:38:03.743221  4932 net.cpp:459] inception_3a/double_3x3_1_bn <- inception_3a/double_3x3_1
I0109 14:38:03.743227  4932 net.cpp:415] inception_3a/double_3x3_1_bn -> inception_3a/double_3x3_1_bn
I0109 14:38:03.743232  4932 net.cpp:160] Setting up inception_3a/double_3x3_1_bn
I0109 14:38:03.743242  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.743248  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_1
I0109 14:38:03.743253  4932 net.cpp:96] Creating Layer inception_3a/relu_double_3x3_1
I0109 14:38:03.743257  4932 net.cpp:459] inception_3a/relu_double_3x3_1 <- inception_3a/double_3x3_1_bn
I0109 14:38:03.743260  4932 net.cpp:404] inception_3a/relu_double_3x3_1 -> inception_3a/double_3x3_1_bn (in-place)
I0109 14:38:03.743265  4932 net.cpp:160] Setting up inception_3a/relu_double_3x3_1
I0109 14:38:03.743269  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.743273  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_2
I0109 14:38:03.743278  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_2
I0109 14:38:03.743280  4932 net.cpp:459] inception_3a/double_3x3_2 <- inception_3a/double_3x3_1_bn
I0109 14:38:03.743285  4932 net.cpp:415] inception_3a/double_3x3_2 -> inception_3a/double_3x3_2
I0109 14:38:03.743290  4932 net.cpp:160] Setting up inception_3a/double_3x3_2
I0109 14:38:03.743652  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.743659  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_2_bn
I0109 14:38:03.743661  4932 layer_factory.cpp:177] Layer inception_3a/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.743667  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_2_bn
I0109 14:38:03.743670  4932 net.cpp:459] inception_3a/double_3x3_2_bn <- inception_3a/double_3x3_2
I0109 14:38:03.743675  4932 net.cpp:415] inception_3a/double_3x3_2_bn -> inception_3a/double_3x3_2_bn
I0109 14:38:03.743680  4932 net.cpp:160] Setting up inception_3a/double_3x3_2_bn
I0109 14:38:03.743690  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.743697  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_2
I0109 14:38:03.743701  4932 net.cpp:96] Creating Layer inception_3a/relu_double_3x3_2
I0109 14:38:03.743705  4932 net.cpp:459] inception_3a/relu_double_3x3_2 <- inception_3a/double_3x3_2_bn
I0109 14:38:03.743710  4932 net.cpp:404] inception_3a/relu_double_3x3_2 -> inception_3a/double_3x3_2_bn (in-place)
I0109 14:38:03.743713  4932 net.cpp:160] Setting up inception_3a/relu_double_3x3_2
I0109 14:38:03.743716  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.743721  4932 layer_factory.hpp:74] Creating layer inception_3a/pool
I0109 14:38:03.743726  4932 net.cpp:96] Creating Layer inception_3a/pool
I0109 14:38:03.743731  4932 net.cpp:459] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0109 14:38:03.743734  4932 net.cpp:415] inception_3a/pool -> inception_3a/pool
I0109 14:38:03.743739  4932 net.cpp:160] Setting up inception_3a/pool
I0109 14:38:03.743744  4932 net.cpp:167] Top shape: 72 192 28 28 (10838016)
I0109 14:38:03.743751  4932 layer_factory.hpp:74] Creating layer inception_3a/pool_proj
I0109 14:38:03.743759  4932 net.cpp:96] Creating Layer inception_3a/pool_proj
I0109 14:38:03.743763  4932 net.cpp:459] inception_3a/pool_proj <- inception_3a/pool
I0109 14:38:03.743767  4932 net.cpp:415] inception_3a/pool_proj -> inception_3a/pool_proj
I0109 14:38:03.743773  4932 net.cpp:160] Setting up inception_3a/pool_proj
I0109 14:38:03.743808  4932 net.cpp:167] Top shape: 72 32 28 28 (1806336)
I0109 14:38:03.743813  4932 layer_factory.hpp:74] Creating layer inception_3a/pool_proj_bn
I0109 14:38:03.743818  4932 layer_factory.cpp:177] Layer inception_3a/pool_proj_bn is using CAFFE engine.
I0109 14:38:03.743823  4932 net.cpp:96] Creating Layer inception_3a/pool_proj_bn
I0109 14:38:03.743825  4932 net.cpp:459] inception_3a/pool_proj_bn <- inception_3a/pool_proj
I0109 14:38:03.743830  4932 net.cpp:415] inception_3a/pool_proj_bn -> inception_3a/pool_proj_bn
I0109 14:38:03.743835  4932 net.cpp:160] Setting up inception_3a/pool_proj_bn
I0109 14:38:03.743845  4932 net.cpp:167] Top shape: 72 32 28 28 (1806336)
I0109 14:38:03.743852  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_pool_proj
I0109 14:38:03.743857  4932 net.cpp:96] Creating Layer inception_3a/relu_pool_proj
I0109 14:38:03.743860  4932 net.cpp:459] inception_3a/relu_pool_proj <- inception_3a/pool_proj_bn
I0109 14:38:03.743865  4932 net.cpp:404] inception_3a/relu_pool_proj -> inception_3a/pool_proj_bn (in-place)
I0109 14:38:03.743870  4932 net.cpp:160] Setting up inception_3a/relu_pool_proj
I0109 14:38:03.743873  4932 net.cpp:167] Top shape: 72 32 28 28 (1806336)
I0109 14:38:03.743876  4932 layer_factory.hpp:74] Creating layer inception_3a/output
I0109 14:38:03.743882  4932 net.cpp:96] Creating Layer inception_3a/output
I0109 14:38:03.743885  4932 net.cpp:459] inception_3a/output <- inception_3a/1x1_bn
I0109 14:38:03.743890  4932 net.cpp:459] inception_3a/output <- inception_3a/3x3_bn
I0109 14:38:03.743892  4932 net.cpp:459] inception_3a/output <- inception_3a/double_3x3_2_bn
I0109 14:38:03.743896  4932 net.cpp:459] inception_3a/output <- inception_3a/pool_proj_bn
I0109 14:38:03.743901  4932 net.cpp:415] inception_3a/output -> inception_3a/output
I0109 14:38:03.743906  4932 net.cpp:160] Setting up inception_3a/output
I0109 14:38:03.743911  4932 net.cpp:167] Top shape: 72 256 28 28 (14450688)
I0109 14:38:03.743914  4932 layer_factory.hpp:74] Creating layer inception_3a/output_inception_3a/output_0_split
I0109 14:38:03.743919  4932 net.cpp:96] Creating Layer inception_3a/output_inception_3a/output_0_split
I0109 14:38:03.743922  4932 net.cpp:459] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0109 14:38:03.743927  4932 net.cpp:415] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0109 14:38:03.743932  4932 net.cpp:415] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0109 14:38:03.743939  4932 net.cpp:415] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I0109 14:38:03.743945  4932 net.cpp:415] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3
I0109 14:38:03.743949  4932 net.cpp:160] Setting up inception_3a/output_inception_3a/output_0_split
I0109 14:38:03.743954  4932 net.cpp:167] Top shape: 72 256 28 28 (14450688)
I0109 14:38:03.743959  4932 net.cpp:167] Top shape: 72 256 28 28 (14450688)
I0109 14:38:03.743963  4932 net.cpp:167] Top shape: 72 256 28 28 (14450688)
I0109 14:38:03.743966  4932 net.cpp:167] Top shape: 72 256 28 28 (14450688)
I0109 14:38:03.743970  4932 layer_factory.hpp:74] Creating layer inception_3b/1x1
I0109 14:38:03.743975  4932 net.cpp:96] Creating Layer inception_3b/1x1
I0109 14:38:03.743978  4932 net.cpp:459] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0
I0109 14:38:03.743984  4932 net.cpp:415] inception_3b/1x1 -> inception_3b/1x1
I0109 14:38:03.743989  4932 net.cpp:160] Setting up inception_3b/1x1
I0109 14:38:03.744071  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744081  4932 layer_factory.hpp:74] Creating layer inception_3b/1x1_bn
I0109 14:38:03.744084  4932 layer_factory.cpp:177] Layer inception_3b/1x1_bn is using CAFFE engine.
I0109 14:38:03.744089  4932 net.cpp:96] Creating Layer inception_3b/1x1_bn
I0109 14:38:03.744093  4932 net.cpp:459] inception_3b/1x1_bn <- inception_3b/1x1
I0109 14:38:03.744098  4932 net.cpp:415] inception_3b/1x1_bn -> inception_3b/1x1_bn
I0109 14:38:03.744103  4932 net.cpp:160] Setting up inception_3b/1x1_bn
I0109 14:38:03.744122  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744133  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_1x1
I0109 14:38:03.744138  4932 net.cpp:96] Creating Layer inception_3b/relu_1x1
I0109 14:38:03.744141  4932 net.cpp:459] inception_3b/relu_1x1 <- inception_3b/1x1_bn
I0109 14:38:03.744146  4932 net.cpp:404] inception_3b/relu_1x1 -> inception_3b/1x1_bn (in-place)
I0109 14:38:03.744150  4932 net.cpp:160] Setting up inception_3b/relu_1x1
I0109 14:38:03.744154  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744158  4932 layer_factory.hpp:74] Creating layer inception_3b/3x3_reduce
I0109 14:38:03.744163  4932 net.cpp:96] Creating Layer inception_3b/3x3_reduce
I0109 14:38:03.744168  4932 net.cpp:459] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I0109 14:38:03.744173  4932 net.cpp:415] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I0109 14:38:03.744177  4932 net.cpp:160] Setting up inception_3b/3x3_reduce
I0109 14:38:03.744257  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744263  4932 layer_factory.hpp:74] Creating layer inception_3b/3x3_reduce_bn
I0109 14:38:03.744266  4932 layer_factory.cpp:177] Layer inception_3b/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.744272  4932 net.cpp:96] Creating Layer inception_3b/3x3_reduce_bn
I0109 14:38:03.744277  4932 net.cpp:459] inception_3b/3x3_reduce_bn <- inception_3b/3x3_reduce
I0109 14:38:03.744282  4932 net.cpp:415] inception_3b/3x3_reduce_bn -> inception_3b/3x3_reduce_bn
I0109 14:38:03.744287  4932 net.cpp:160] Setting up inception_3b/3x3_reduce_bn
I0109 14:38:03.744297  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744303  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_3x3_reduce
I0109 14:38:03.744308  4932 net.cpp:96] Creating Layer inception_3b/relu_3x3_reduce
I0109 14:38:03.744312  4932 net.cpp:459] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce_bn
I0109 14:38:03.744316  4932 net.cpp:404] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce_bn (in-place)
I0109 14:38:03.744320  4932 net.cpp:160] Setting up inception_3b/relu_3x3_reduce
I0109 14:38:03.744324  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744328  4932 layer_factory.hpp:74] Creating layer inception_3b/3x3
I0109 14:38:03.744333  4932 net.cpp:96] Creating Layer inception_3b/3x3
I0109 14:38:03.744336  4932 net.cpp:459] inception_3b/3x3 <- inception_3b/3x3_reduce_bn
I0109 14:38:03.744341  4932 net.cpp:415] inception_3b/3x3 -> inception_3b/3x3
I0109 14:38:03.744346  4932 net.cpp:160] Setting up inception_3b/3x3
I0109 14:38:03.744590  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.744596  4932 layer_factory.hpp:74] Creating layer inception_3b/3x3_bn
I0109 14:38:03.744601  4932 layer_factory.cpp:177] Layer inception_3b/3x3_bn is using CAFFE engine.
I0109 14:38:03.744606  4932 net.cpp:96] Creating Layer inception_3b/3x3_bn
I0109 14:38:03.744608  4932 net.cpp:459] inception_3b/3x3_bn <- inception_3b/3x3
I0109 14:38:03.744613  4932 net.cpp:415] inception_3b/3x3_bn -> inception_3b/3x3_bn
I0109 14:38:03.744618  4932 net.cpp:160] Setting up inception_3b/3x3_bn
I0109 14:38:03.744629  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.744637  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_3x3
I0109 14:38:03.744640  4932 net.cpp:96] Creating Layer inception_3b/relu_3x3
I0109 14:38:03.744644  4932 net.cpp:459] inception_3b/relu_3x3 <- inception_3b/3x3_bn
I0109 14:38:03.744650  4932 net.cpp:404] inception_3b/relu_3x3 -> inception_3b/3x3_bn (in-place)
I0109 14:38:03.744659  4932 net.cpp:160] Setting up inception_3b/relu_3x3
I0109 14:38:03.744663  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.744666  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_reduce
I0109 14:38:03.744671  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_reduce
I0109 14:38:03.744675  4932 net.cpp:459] inception_3b/double_3x3_reduce <- inception_3a/output_inception_3a/output_0_split_2
I0109 14:38:03.744680  4932 net.cpp:415] inception_3b/double_3x3_reduce -> inception_3b/double_3x3_reduce
I0109 14:38:03.744685  4932 net.cpp:160] Setting up inception_3b/double_3x3_reduce
I0109 14:38:03.744765  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744771  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_reduce_bn
I0109 14:38:03.744773  4932 layer_factory.cpp:177] Layer inception_3b/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.744779  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_reduce_bn
I0109 14:38:03.744782  4932 net.cpp:459] inception_3b/double_3x3_reduce_bn <- inception_3b/double_3x3_reduce
I0109 14:38:03.744787  4932 net.cpp:415] inception_3b/double_3x3_reduce_bn -> inception_3b/double_3x3_reduce_bn
I0109 14:38:03.744792  4932 net.cpp:160] Setting up inception_3b/double_3x3_reduce_bn
I0109 14:38:03.744802  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744809  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_reduce
I0109 14:38:03.744814  4932 net.cpp:96] Creating Layer inception_3b/relu_double_3x3_reduce
I0109 14:38:03.744817  4932 net.cpp:459] inception_3b/relu_double_3x3_reduce <- inception_3b/double_3x3_reduce_bn
I0109 14:38:03.744822  4932 net.cpp:404] inception_3b/relu_double_3x3_reduce -> inception_3b/double_3x3_reduce_bn (in-place)
I0109 14:38:03.744825  4932 net.cpp:160] Setting up inception_3b/relu_double_3x3_reduce
I0109 14:38:03.744829  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.744832  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_1
I0109 14:38:03.744838  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_1
I0109 14:38:03.744841  4932 net.cpp:459] inception_3b/double_3x3_1 <- inception_3b/double_3x3_reduce_bn
I0109 14:38:03.744846  4932 net.cpp:415] inception_3b/double_3x3_1 -> inception_3b/double_3x3_1
I0109 14:38:03.744850  4932 net.cpp:160] Setting up inception_3b/double_3x3_1
I0109 14:38:03.745095  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.745100  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_1_bn
I0109 14:38:03.745105  4932 layer_factory.cpp:177] Layer inception_3b/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.745110  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_1_bn
I0109 14:38:03.745112  4932 net.cpp:459] inception_3b/double_3x3_1_bn <- inception_3b/double_3x3_1
I0109 14:38:03.745118  4932 net.cpp:415] inception_3b/double_3x3_1_bn -> inception_3b/double_3x3_1_bn
I0109 14:38:03.745123  4932 net.cpp:160] Setting up inception_3b/double_3x3_1_bn
I0109 14:38:03.745133  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.745139  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_1
I0109 14:38:03.745144  4932 net.cpp:96] Creating Layer inception_3b/relu_double_3x3_1
I0109 14:38:03.745148  4932 net.cpp:459] inception_3b/relu_double_3x3_1 <- inception_3b/double_3x3_1_bn
I0109 14:38:03.745152  4932 net.cpp:404] inception_3b/relu_double_3x3_1 -> inception_3b/double_3x3_1_bn (in-place)
I0109 14:38:03.745157  4932 net.cpp:160] Setting up inception_3b/relu_double_3x3_1
I0109 14:38:03.745160  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.745163  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_2
I0109 14:38:03.745169  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_2
I0109 14:38:03.745172  4932 net.cpp:459] inception_3b/double_3x3_2 <- inception_3b/double_3x3_1_bn
I0109 14:38:03.745179  4932 net.cpp:415] inception_3b/double_3x3_2 -> inception_3b/double_3x3_2
I0109 14:38:03.745188  4932 net.cpp:160] Setting up inception_3b/double_3x3_2
I0109 14:38:03.745549  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.745556  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_2_bn
I0109 14:38:03.745559  4932 layer_factory.cpp:177] Layer inception_3b/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.745565  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_2_bn
I0109 14:38:03.745568  4932 net.cpp:459] inception_3b/double_3x3_2_bn <- inception_3b/double_3x3_2
I0109 14:38:03.745573  4932 net.cpp:415] inception_3b/double_3x3_2_bn -> inception_3b/double_3x3_2_bn
I0109 14:38:03.745579  4932 net.cpp:160] Setting up inception_3b/double_3x3_2_bn
I0109 14:38:03.745589  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.745595  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_2
I0109 14:38:03.745600  4932 net.cpp:96] Creating Layer inception_3b/relu_double_3x3_2
I0109 14:38:03.745604  4932 net.cpp:459] inception_3b/relu_double_3x3_2 <- inception_3b/double_3x3_2_bn
I0109 14:38:03.745609  4932 net.cpp:404] inception_3b/relu_double_3x3_2 -> inception_3b/double_3x3_2_bn (in-place)
I0109 14:38:03.745612  4932 net.cpp:160] Setting up inception_3b/relu_double_3x3_2
I0109 14:38:03.745616  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.745620  4932 layer_factory.hpp:74] Creating layer inception_3b/pool
I0109 14:38:03.745625  4932 net.cpp:96] Creating Layer inception_3b/pool
I0109 14:38:03.745627  4932 net.cpp:459] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3
I0109 14:38:03.745632  4932 net.cpp:415] inception_3b/pool -> inception_3b/pool
I0109 14:38:03.745637  4932 net.cpp:160] Setting up inception_3b/pool
I0109 14:38:03.745642  4932 net.cpp:167] Top shape: 72 256 28 28 (14450688)
I0109 14:38:03.745645  4932 layer_factory.hpp:74] Creating layer inception_3b/pool_proj
I0109 14:38:03.745651  4932 net.cpp:96] Creating Layer inception_3b/pool_proj
I0109 14:38:03.745654  4932 net.cpp:459] inception_3b/pool_proj <- inception_3b/pool
I0109 14:38:03.745659  4932 net.cpp:415] inception_3b/pool_proj -> inception_3b/pool_proj
I0109 14:38:03.745664  4932 net.cpp:160] Setting up inception_3b/pool_proj
I0109 14:38:03.745743  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.745748  4932 layer_factory.hpp:74] Creating layer inception_3b/pool_proj_bn
I0109 14:38:03.745753  4932 layer_factory.cpp:177] Layer inception_3b/pool_proj_bn is using CAFFE engine.
I0109 14:38:03.745757  4932 net.cpp:96] Creating Layer inception_3b/pool_proj_bn
I0109 14:38:03.745760  4932 net.cpp:459] inception_3b/pool_proj_bn <- inception_3b/pool_proj
I0109 14:38:03.745765  4932 net.cpp:415] inception_3b/pool_proj_bn -> inception_3b/pool_proj_bn
I0109 14:38:03.745770  4932 net.cpp:160] Setting up inception_3b/pool_proj_bn
I0109 14:38:03.745780  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.745787  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_pool_proj
I0109 14:38:03.745791  4932 net.cpp:96] Creating Layer inception_3b/relu_pool_proj
I0109 14:38:03.745795  4932 net.cpp:459] inception_3b/relu_pool_proj <- inception_3b/pool_proj_bn
I0109 14:38:03.745800  4932 net.cpp:404] inception_3b/relu_pool_proj -> inception_3b/pool_proj_bn (in-place)
I0109 14:38:03.745803  4932 net.cpp:160] Setting up inception_3b/relu_pool_proj
I0109 14:38:03.745807  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.745810  4932 layer_factory.hpp:74] Creating layer inception_3b/output
I0109 14:38:03.745815  4932 net.cpp:96] Creating Layer inception_3b/output
I0109 14:38:03.745818  4932 net.cpp:459] inception_3b/output <- inception_3b/1x1_bn
I0109 14:38:03.745822  4932 net.cpp:459] inception_3b/output <- inception_3b/3x3_bn
I0109 14:38:03.745826  4932 net.cpp:459] inception_3b/output <- inception_3b/double_3x3_2_bn
I0109 14:38:03.745829  4932 net.cpp:459] inception_3b/output <- inception_3b/pool_proj_bn
I0109 14:38:03.745836  4932 net.cpp:415] inception_3b/output -> inception_3b/output
I0109 14:38:03.745844  4932 net.cpp:160] Setting up inception_3b/output
I0109 14:38:03.745849  4932 net.cpp:167] Top shape: 72 320 28 28 (18063360)
I0109 14:38:03.745853  4932 layer_factory.hpp:74] Creating layer inception_3b/output_inception_3b/output_0_split
I0109 14:38:03.745858  4932 net.cpp:96] Creating Layer inception_3b/output_inception_3b/output_0_split
I0109 14:38:03.745862  4932 net.cpp:459] inception_3b/output_inception_3b/output_0_split <- inception_3b/output
I0109 14:38:03.745867  4932 net.cpp:415] inception_3b/output_inception_3b/output_0_split -> inception_3b/output_inception_3b/output_0_split_0
I0109 14:38:03.745870  4932 net.cpp:415] inception_3b/output_inception_3b/output_0_split -> inception_3b/output_inception_3b/output_0_split_1
I0109 14:38:03.745875  4932 net.cpp:415] inception_3b/output_inception_3b/output_0_split -> inception_3b/output_inception_3b/output_0_split_2
I0109 14:38:03.745880  4932 net.cpp:160] Setting up inception_3b/output_inception_3b/output_0_split
I0109 14:38:03.745885  4932 net.cpp:167] Top shape: 72 320 28 28 (18063360)
I0109 14:38:03.745889  4932 net.cpp:167] Top shape: 72 320 28 28 (18063360)
I0109 14:38:03.745893  4932 net.cpp:167] Top shape: 72 320 28 28 (18063360)
I0109 14:38:03.745896  4932 layer_factory.hpp:74] Creating layer inception_3c/3x3_reduce
I0109 14:38:03.745901  4932 net.cpp:96] Creating Layer inception_3c/3x3_reduce
I0109 14:38:03.745904  4932 net.cpp:459] inception_3c/3x3_reduce <- inception_3b/output_inception_3b/output_0_split_0
I0109 14:38:03.745910  4932 net.cpp:415] inception_3c/3x3_reduce -> inception_3c/3x3_reduce
I0109 14:38:03.745915  4932 net.cpp:160] Setting up inception_3c/3x3_reduce
I0109 14:38:03.746111  4932 net.cpp:167] Top shape: 72 128 28 28 (7225344)
I0109 14:38:03.746120  4932 layer_factory.hpp:74] Creating layer inception_3c/3x3_reduce_bn
I0109 14:38:03.746126  4932 layer_factory.cpp:177] Layer inception_3c/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.746132  4932 net.cpp:96] Creating Layer inception_3c/3x3_reduce_bn
I0109 14:38:03.746136  4932 net.cpp:459] inception_3c/3x3_reduce_bn <- inception_3c/3x3_reduce
I0109 14:38:03.746141  4932 net.cpp:415] inception_3c/3x3_reduce_bn -> inception_3c/3x3_reduce_bn
I0109 14:38:03.746146  4932 net.cpp:160] Setting up inception_3c/3x3_reduce_bn
I0109 14:38:03.746157  4932 net.cpp:167] Top shape: 72 128 28 28 (7225344)
I0109 14:38:03.746165  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_3x3_reduce
I0109 14:38:03.746172  4932 net.cpp:96] Creating Layer inception_3c/relu_3x3_reduce
I0109 14:38:03.746176  4932 net.cpp:459] inception_3c/relu_3x3_reduce <- inception_3c/3x3_reduce_bn
I0109 14:38:03.746181  4932 net.cpp:404] inception_3c/relu_3x3_reduce -> inception_3c/3x3_reduce_bn (in-place)
I0109 14:38:03.746186  4932 net.cpp:160] Setting up inception_3c/relu_3x3_reduce
I0109 14:38:03.746189  4932 net.cpp:167] Top shape: 72 128 28 28 (7225344)
I0109 14:38:03.746193  4932 layer_factory.hpp:74] Creating layer inception_3c/3x3
I0109 14:38:03.746201  4932 net.cpp:96] Creating Layer inception_3c/3x3
I0109 14:38:03.746207  4932 net.cpp:459] inception_3c/3x3 <- inception_3c/3x3_reduce_bn
I0109 14:38:03.746212  4932 net.cpp:415] inception_3c/3x3 -> inception_3c/3x3
I0109 14:38:03.746217  4932 net.cpp:160] Setting up inception_3c/3x3
I0109 14:38:03.747007  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.747014  4932 layer_factory.hpp:74] Creating layer inception_3c/3x3_bn
I0109 14:38:03.747017  4932 layer_factory.cpp:177] Layer inception_3c/3x3_bn is using CAFFE engine.
I0109 14:38:03.747022  4932 net.cpp:96] Creating Layer inception_3c/3x3_bn
I0109 14:38:03.747026  4932 net.cpp:459] inception_3c/3x3_bn <- inception_3c/3x3
I0109 14:38:03.747031  4932 net.cpp:415] inception_3c/3x3_bn -> inception_3c/3x3_bn
I0109 14:38:03.747036  4932 net.cpp:160] Setting up inception_3c/3x3_bn
I0109 14:38:03.747047  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.747056  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_3x3
I0109 14:38:03.747066  4932 net.cpp:96] Creating Layer inception_3c/relu_3x3
I0109 14:38:03.747068  4932 net.cpp:459] inception_3c/relu_3x3 <- inception_3c/3x3_bn
I0109 14:38:03.747073  4932 net.cpp:404] inception_3c/relu_3x3 -> inception_3c/3x3_bn (in-place)
I0109 14:38:03.747078  4932 net.cpp:160] Setting up inception_3c/relu_3x3
I0109 14:38:03.747082  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.747086  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_reduce
I0109 14:38:03.747090  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_reduce
I0109 14:38:03.747093  4932 net.cpp:459] inception_3c/double_3x3_reduce <- inception_3b/output_inception_3b/output_0_split_1
I0109 14:38:03.747098  4932 net.cpp:415] inception_3c/double_3x3_reduce -> inception_3c/double_3x3_reduce
I0109 14:38:03.747103  4932 net.cpp:160] Setting up inception_3c/double_3x3_reduce
I0109 14:38:03.747200  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.747206  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_reduce_bn
I0109 14:38:03.747210  4932 layer_factory.cpp:177] Layer inception_3c/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.747215  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_reduce_bn
I0109 14:38:03.747218  4932 net.cpp:459] inception_3c/double_3x3_reduce_bn <- inception_3c/double_3x3_reduce
I0109 14:38:03.747223  4932 net.cpp:415] inception_3c/double_3x3_reduce_bn -> inception_3c/double_3x3_reduce_bn
I0109 14:38:03.747228  4932 net.cpp:160] Setting up inception_3c/double_3x3_reduce_bn
I0109 14:38:03.747239  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.747246  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_double_3x3_reduce
I0109 14:38:03.747251  4932 net.cpp:96] Creating Layer inception_3c/relu_double_3x3_reduce
I0109 14:38:03.747254  4932 net.cpp:459] inception_3c/relu_double_3x3_reduce <- inception_3c/double_3x3_reduce_bn
I0109 14:38:03.747258  4932 net.cpp:404] inception_3c/relu_double_3x3_reduce -> inception_3c/double_3x3_reduce_bn (in-place)
I0109 14:38:03.747262  4932 net.cpp:160] Setting up inception_3c/relu_double_3x3_reduce
I0109 14:38:03.747267  4932 net.cpp:167] Top shape: 72 64 28 28 (3612672)
I0109 14:38:03.747270  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_1
I0109 14:38:03.747275  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_1
I0109 14:38:03.747278  4932 net.cpp:459] inception_3c/double_3x3_1 <- inception_3c/double_3x3_reduce_bn
I0109 14:38:03.747283  4932 net.cpp:415] inception_3c/double_3x3_1 -> inception_3c/double_3x3_1
I0109 14:38:03.747288  4932 net.cpp:160] Setting up inception_3c/double_3x3_1
I0109 14:38:03.747532  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.747539  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_1_bn
I0109 14:38:03.747542  4932 layer_factory.cpp:177] Layer inception_3c/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.747547  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_1_bn
I0109 14:38:03.747550  4932 net.cpp:459] inception_3c/double_3x3_1_bn <- inception_3c/double_3x3_1
I0109 14:38:03.747555  4932 net.cpp:415] inception_3c/double_3x3_1_bn -> inception_3c/double_3x3_1_bn
I0109 14:38:03.747560  4932 net.cpp:160] Setting up inception_3c/double_3x3_1_bn
I0109 14:38:03.747570  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.747576  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_double_3x3_1
I0109 14:38:03.747581  4932 net.cpp:96] Creating Layer inception_3c/relu_double_3x3_1
I0109 14:38:03.747584  4932 net.cpp:459] inception_3c/relu_double_3x3_1 <- inception_3c/double_3x3_1_bn
I0109 14:38:03.747589  4932 net.cpp:404] inception_3c/relu_double_3x3_1 -> inception_3c/double_3x3_1_bn (in-place)
I0109 14:38:03.747593  4932 net.cpp:160] Setting up inception_3c/relu_double_3x3_1
I0109 14:38:03.747597  4932 net.cpp:167] Top shape: 72 96 28 28 (5419008)
I0109 14:38:03.747601  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_2
I0109 14:38:03.747611  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_2
I0109 14:38:03.747615  4932 net.cpp:459] inception_3c/double_3x3_2 <- inception_3c/double_3x3_1_bn
I0109 14:38:03.747620  4932 net.cpp:415] inception_3c/double_3x3_2 -> inception_3c/double_3x3_2
I0109 14:38:03.747625  4932 net.cpp:160] Setting up inception_3c/double_3x3_2
I0109 14:38:03.748026  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.748034  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_2_bn
I0109 14:38:03.748036  4932 layer_factory.cpp:177] Layer inception_3c/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.748042  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_2_bn
I0109 14:38:03.748046  4932 net.cpp:459] inception_3c/double_3x3_2_bn <- inception_3c/double_3x3_2
I0109 14:38:03.748052  4932 net.cpp:415] inception_3c/double_3x3_2_bn -> inception_3c/double_3x3_2_bn
I0109 14:38:03.748059  4932 net.cpp:160] Setting up inception_3c/double_3x3_2_bn
I0109 14:38:03.748070  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.748083  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_double_3x3_2
I0109 14:38:03.748088  4932 net.cpp:96] Creating Layer inception_3c/relu_double_3x3_2
I0109 14:38:03.748091  4932 net.cpp:459] inception_3c/relu_double_3x3_2 <- inception_3c/double_3x3_2_bn
I0109 14:38:03.748095  4932 net.cpp:404] inception_3c/relu_double_3x3_2 -> inception_3c/double_3x3_2_bn (in-place)
I0109 14:38:03.748100  4932 net.cpp:160] Setting up inception_3c/relu_double_3x3_2
I0109 14:38:03.748105  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.748111  4932 layer_factory.hpp:74] Creating layer inception_3c/pool
I0109 14:38:03.748117  4932 net.cpp:96] Creating Layer inception_3c/pool
I0109 14:38:03.748121  4932 net.cpp:459] inception_3c/pool <- inception_3b/output_inception_3b/output_0_split_2
I0109 14:38:03.748126  4932 net.cpp:415] inception_3c/pool -> inception_3c/pool
I0109 14:38:03.748134  4932 net.cpp:160] Setting up inception_3c/pool
I0109 14:38:03.748142  4932 net.cpp:167] Top shape: 72 320 14 14 (4515840)
I0109 14:38:03.748144  4932 layer_factory.hpp:74] Creating layer inception_3c/output
I0109 14:38:03.748150  4932 net.cpp:96] Creating Layer inception_3c/output
I0109 14:38:03.748153  4932 net.cpp:459] inception_3c/output <- inception_3c/3x3_bn
I0109 14:38:03.748157  4932 net.cpp:459] inception_3c/output <- inception_3c/double_3x3_2_bn
I0109 14:38:03.748162  4932 net.cpp:459] inception_3c/output <- inception_3c/pool
I0109 14:38:03.748165  4932 net.cpp:415] inception_3c/output -> inception_3c/output
I0109 14:38:03.748170  4932 net.cpp:160] Setting up inception_3c/output
I0109 14:38:03.748175  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.748178  4932 layer_factory.hpp:74] Creating layer inception_3c/output_inception_3c/output_0_split
I0109 14:38:03.748183  4932 net.cpp:96] Creating Layer inception_3c/output_inception_3c/output_0_split
I0109 14:38:03.748186  4932 net.cpp:459] inception_3c/output_inception_3c/output_0_split <- inception_3c/output
I0109 14:38:03.748190  4932 net.cpp:415] inception_3c/output_inception_3c/output_0_split -> inception_3c/output_inception_3c/output_0_split_0
I0109 14:38:03.748195  4932 net.cpp:415] inception_3c/output_inception_3c/output_0_split -> inception_3c/output_inception_3c/output_0_split_1
I0109 14:38:03.748201  4932 net.cpp:415] inception_3c/output_inception_3c/output_0_split -> inception_3c/output_inception_3c/output_0_split_2
I0109 14:38:03.748208  4932 net.cpp:415] inception_3c/output_inception_3c/output_0_split -> inception_3c/output_inception_3c/output_0_split_3
I0109 14:38:03.748211  4932 net.cpp:160] Setting up inception_3c/output_inception_3c/output_0_split
I0109 14:38:03.748216  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.748220  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.748224  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.748229  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.748234  4932 layer_factory.hpp:74] Creating layer inception_4a/1x1
I0109 14:38:03.748245  4932 net.cpp:96] Creating Layer inception_4a/1x1
I0109 14:38:03.748248  4932 net.cpp:459] inception_4a/1x1 <- inception_3c/output_inception_3c/output_0_split_0
I0109 14:38:03.748252  4932 net.cpp:415] inception_4a/1x1 -> inception_4a/1x1
I0109 14:38:03.748257  4932 net.cpp:160] Setting up inception_4a/1x1
I0109 14:38:03.748893  4932 net.cpp:167] Top shape: 72 224 14 14 (3161088)
I0109 14:38:03.748901  4932 layer_factory.hpp:74] Creating layer inception_4a/1x1_bn
I0109 14:38:03.748904  4932 layer_factory.cpp:177] Layer inception_4a/1x1_bn is using CAFFE engine.
I0109 14:38:03.748909  4932 net.cpp:96] Creating Layer inception_4a/1x1_bn
I0109 14:38:03.748914  4932 net.cpp:459] inception_4a/1x1_bn <- inception_4a/1x1
I0109 14:38:03.748919  4932 net.cpp:415] inception_4a/1x1_bn -> inception_4a/1x1_bn
I0109 14:38:03.748924  4932 net.cpp:160] Setting up inception_4a/1x1_bn
I0109 14:38:03.748936  4932 net.cpp:167] Top shape: 72 224 14 14 (3161088)
I0109 14:38:03.748944  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_1x1
I0109 14:38:03.748949  4932 net.cpp:96] Creating Layer inception_4a/relu_1x1
I0109 14:38:03.748951  4932 net.cpp:459] inception_4a/relu_1x1 <- inception_4a/1x1_bn
I0109 14:38:03.748955  4932 net.cpp:404] inception_4a/relu_1x1 -> inception_4a/1x1_bn (in-place)
I0109 14:38:03.748960  4932 net.cpp:160] Setting up inception_4a/relu_1x1
I0109 14:38:03.748965  4932 net.cpp:167] Top shape: 72 224 14 14 (3161088)
I0109 14:38:03.748967  4932 layer_factory.hpp:74] Creating layer inception_4a/3x3_reduce
I0109 14:38:03.748973  4932 net.cpp:96] Creating Layer inception_4a/3x3_reduce
I0109 14:38:03.748977  4932 net.cpp:459] inception_4a/3x3_reduce <- inception_3c/output_inception_3c/output_0_split_1
I0109 14:38:03.748981  4932 net.cpp:415] inception_4a/3x3_reduce -> inception_4a/3x3_reduce
I0109 14:38:03.748986  4932 net.cpp:160] Setting up inception_4a/3x3_reduce
I0109 14:38:03.749173  4932 net.cpp:167] Top shape: 72 64 14 14 (903168)
I0109 14:38:03.749181  4932 layer_factory.hpp:74] Creating layer inception_4a/3x3_reduce_bn
I0109 14:38:03.749183  4932 layer_factory.cpp:177] Layer inception_4a/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.749189  4932 net.cpp:96] Creating Layer inception_4a/3x3_reduce_bn
I0109 14:38:03.749193  4932 net.cpp:459] inception_4a/3x3_reduce_bn <- inception_4a/3x3_reduce
I0109 14:38:03.749197  4932 net.cpp:415] inception_4a/3x3_reduce_bn -> inception_4a/3x3_reduce_bn
I0109 14:38:03.749202  4932 net.cpp:160] Setting up inception_4a/3x3_reduce_bn
I0109 14:38:03.749213  4932 net.cpp:167] Top shape: 72 64 14 14 (903168)
I0109 14:38:03.749219  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_3x3_reduce
I0109 14:38:03.749224  4932 net.cpp:96] Creating Layer inception_4a/relu_3x3_reduce
I0109 14:38:03.749228  4932 net.cpp:459] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce_bn
I0109 14:38:03.749233  4932 net.cpp:404] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce_bn (in-place)
I0109 14:38:03.749236  4932 net.cpp:160] Setting up inception_4a/relu_3x3_reduce
I0109 14:38:03.749240  4932 net.cpp:167] Top shape: 72 64 14 14 (903168)
I0109 14:38:03.749243  4932 layer_factory.hpp:74] Creating layer inception_4a/3x3
I0109 14:38:03.749249  4932 net.cpp:96] Creating Layer inception_4a/3x3
I0109 14:38:03.749253  4932 net.cpp:459] inception_4a/3x3 <- inception_4a/3x3_reduce_bn
I0109 14:38:03.749258  4932 net.cpp:415] inception_4a/3x3 -> inception_4a/3x3
I0109 14:38:03.749263  4932 net.cpp:160] Setting up inception_4a/3x3
I0109 14:38:03.749541  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.749547  4932 layer_factory.hpp:74] Creating layer inception_4a/3x3_bn
I0109 14:38:03.749550  4932 layer_factory.cpp:177] Layer inception_4a/3x3_bn is using CAFFE engine.
I0109 14:38:03.749555  4932 net.cpp:96] Creating Layer inception_4a/3x3_bn
I0109 14:38:03.749558  4932 net.cpp:459] inception_4a/3x3_bn <- inception_4a/3x3
I0109 14:38:03.749564  4932 net.cpp:415] inception_4a/3x3_bn -> inception_4a/3x3_bn
I0109 14:38:03.749575  4932 net.cpp:160] Setting up inception_4a/3x3_bn
I0109 14:38:03.749588  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.749593  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_3x3
I0109 14:38:03.749598  4932 net.cpp:96] Creating Layer inception_4a/relu_3x3
I0109 14:38:03.749601  4932 net.cpp:459] inception_4a/relu_3x3 <- inception_4a/3x3_bn
I0109 14:38:03.749605  4932 net.cpp:404] inception_4a/relu_3x3 -> inception_4a/3x3_bn (in-place)
I0109 14:38:03.749610  4932 net.cpp:160] Setting up inception_4a/relu_3x3
I0109 14:38:03.749614  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.749617  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_reduce
I0109 14:38:03.749625  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_reduce
I0109 14:38:03.749631  4932 net.cpp:459] inception_4a/double_3x3_reduce <- inception_3c/output_inception_3c/output_0_split_2
I0109 14:38:03.749639  4932 net.cpp:415] inception_4a/double_3x3_reduce -> inception_4a/double_3x3_reduce
I0109 14:38:03.749644  4932 net.cpp:160] Setting up inception_4a/double_3x3_reduce
I0109 14:38:03.749928  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.749936  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_reduce_bn
I0109 14:38:03.749939  4932 layer_factory.cpp:177] Layer inception_4a/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.749945  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_reduce_bn
I0109 14:38:03.749949  4932 net.cpp:459] inception_4a/double_3x3_reduce_bn <- inception_4a/double_3x3_reduce
I0109 14:38:03.749954  4932 net.cpp:415] inception_4a/double_3x3_reduce_bn -> inception_4a/double_3x3_reduce_bn
I0109 14:38:03.749960  4932 net.cpp:160] Setting up inception_4a/double_3x3_reduce_bn
I0109 14:38:03.749972  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.749979  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_double_3x3_reduce
I0109 14:38:03.749984  4932 net.cpp:96] Creating Layer inception_4a/relu_double_3x3_reduce
I0109 14:38:03.749987  4932 net.cpp:459] inception_4a/relu_double_3x3_reduce <- inception_4a/double_3x3_reduce_bn
I0109 14:38:03.749991  4932 net.cpp:404] inception_4a/relu_double_3x3_reduce -> inception_4a/double_3x3_reduce_bn (in-place)
I0109 14:38:03.749995  4932 net.cpp:160] Setting up inception_4a/relu_double_3x3_reduce
I0109 14:38:03.750000  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.750002  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_1
I0109 14:38:03.750008  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_1
I0109 14:38:03.750011  4932 net.cpp:459] inception_4a/double_3x3_1 <- inception_4a/double_3x3_reduce_bn
I0109 14:38:03.750016  4932 net.cpp:415] inception_4a/double_3x3_1 -> inception_4a/double_3x3_1
I0109 14:38:03.750021  4932 net.cpp:160] Setting up inception_4a/double_3x3_1
I0109 14:38:03.750567  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.750574  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_1_bn
I0109 14:38:03.750577  4932 layer_factory.cpp:177] Layer inception_4a/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.750583  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_1_bn
I0109 14:38:03.750586  4932 net.cpp:459] inception_4a/double_3x3_1_bn <- inception_4a/double_3x3_1
I0109 14:38:03.750591  4932 net.cpp:415] inception_4a/double_3x3_1_bn -> inception_4a/double_3x3_1_bn
I0109 14:38:03.750597  4932 net.cpp:160] Setting up inception_4a/double_3x3_1_bn
I0109 14:38:03.750608  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.750615  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_double_3x3_1
I0109 14:38:03.750619  4932 net.cpp:96] Creating Layer inception_4a/relu_double_3x3_1
I0109 14:38:03.750623  4932 net.cpp:459] inception_4a/relu_double_3x3_1 <- inception_4a/double_3x3_1_bn
I0109 14:38:03.750627  4932 net.cpp:404] inception_4a/relu_double_3x3_1 -> inception_4a/double_3x3_1_bn (in-place)
I0109 14:38:03.750633  4932 net.cpp:160] Setting up inception_4a/relu_double_3x3_1
I0109 14:38:03.750641  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.750644  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_2
I0109 14:38:03.750649  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_2
I0109 14:38:03.750653  4932 net.cpp:459] inception_4a/double_3x3_2 <- inception_4a/double_3x3_1_bn
I0109 14:38:03.750658  4932 net.cpp:415] inception_4a/double_3x3_2 -> inception_4a/double_3x3_2
I0109 14:38:03.750663  4932 net.cpp:160] Setting up inception_4a/double_3x3_2
I0109 14:38:03.751381  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.751387  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_2_bn
I0109 14:38:03.751391  4932 layer_factory.cpp:177] Layer inception_4a/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.751396  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_2_bn
I0109 14:38:03.751400  4932 net.cpp:459] inception_4a/double_3x3_2_bn <- inception_4a/double_3x3_2
I0109 14:38:03.751405  4932 net.cpp:415] inception_4a/double_3x3_2_bn -> inception_4a/double_3x3_2_bn
I0109 14:38:03.751410  4932 net.cpp:160] Setting up inception_4a/double_3x3_2_bn
I0109 14:38:03.751421  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.751428  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_double_3x3_2
I0109 14:38:03.751433  4932 net.cpp:96] Creating Layer inception_4a/relu_double_3x3_2
I0109 14:38:03.751436  4932 net.cpp:459] inception_4a/relu_double_3x3_2 <- inception_4a/double_3x3_2_bn
I0109 14:38:03.751441  4932 net.cpp:404] inception_4a/relu_double_3x3_2 -> inception_4a/double_3x3_2_bn (in-place)
I0109 14:38:03.751444  4932 net.cpp:160] Setting up inception_4a/relu_double_3x3_2
I0109 14:38:03.751448  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.751451  4932 layer_factory.hpp:74] Creating layer inception_4a/pool
I0109 14:38:03.751456  4932 net.cpp:96] Creating Layer inception_4a/pool
I0109 14:38:03.751461  4932 net.cpp:459] inception_4a/pool <- inception_3c/output_inception_3c/output_0_split_3
I0109 14:38:03.751466  4932 net.cpp:415] inception_4a/pool -> inception_4a/pool
I0109 14:38:03.751469  4932 net.cpp:160] Setting up inception_4a/pool
I0109 14:38:03.751474  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.751478  4932 layer_factory.hpp:74] Creating layer inception_4a/pool_proj
I0109 14:38:03.751483  4932 net.cpp:96] Creating Layer inception_4a/pool_proj
I0109 14:38:03.751487  4932 net.cpp:459] inception_4a/pool_proj <- inception_4a/pool
I0109 14:38:03.751492  4932 net.cpp:415] inception_4a/pool_proj -> inception_4a/pool_proj
I0109 14:38:03.751497  4932 net.cpp:160] Setting up inception_4a/pool_proj
I0109 14:38:03.751857  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.751863  4932 layer_factory.hpp:74] Creating layer inception_4a/pool_proj_bn
I0109 14:38:03.751866  4932 layer_factory.cpp:177] Layer inception_4a/pool_proj_bn is using CAFFE engine.
I0109 14:38:03.751873  4932 net.cpp:96] Creating Layer inception_4a/pool_proj_bn
I0109 14:38:03.751875  4932 net.cpp:459] inception_4a/pool_proj_bn <- inception_4a/pool_proj
I0109 14:38:03.751881  4932 net.cpp:415] inception_4a/pool_proj_bn -> inception_4a/pool_proj_bn
I0109 14:38:03.751886  4932 net.cpp:160] Setting up inception_4a/pool_proj_bn
I0109 14:38:03.751898  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.751904  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_pool_proj
I0109 14:38:03.751909  4932 net.cpp:96] Creating Layer inception_4a/relu_pool_proj
I0109 14:38:03.751911  4932 net.cpp:459] inception_4a/relu_pool_proj <- inception_4a/pool_proj_bn
I0109 14:38:03.751915  4932 net.cpp:404] inception_4a/relu_pool_proj -> inception_4a/pool_proj_bn (in-place)
I0109 14:38:03.751920  4932 net.cpp:160] Setting up inception_4a/relu_pool_proj
I0109 14:38:03.751924  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.751927  4932 layer_factory.hpp:74] Creating layer inception_4a/output
I0109 14:38:03.751935  4932 net.cpp:96] Creating Layer inception_4a/output
I0109 14:38:03.751940  4932 net.cpp:459] inception_4a/output <- inception_4a/1x1_bn
I0109 14:38:03.751945  4932 net.cpp:459] inception_4a/output <- inception_4a/3x3_bn
I0109 14:38:03.751948  4932 net.cpp:459] inception_4a/output <- inception_4a/double_3x3_2_bn
I0109 14:38:03.751951  4932 net.cpp:459] inception_4a/output <- inception_4a/pool_proj_bn
I0109 14:38:03.751956  4932 net.cpp:415] inception_4a/output -> inception_4a/output
I0109 14:38:03.751961  4932 net.cpp:160] Setting up inception_4a/output
I0109 14:38:03.751966  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.751971  4932 layer_factory.hpp:74] Creating layer inception_4a/output_inception_4a/output_0_split
I0109 14:38:03.751974  4932 net.cpp:96] Creating Layer inception_4a/output_inception_4a/output_0_split
I0109 14:38:03.751977  4932 net.cpp:459] inception_4a/output_inception_4a/output_0_split <- inception_4a/output
I0109 14:38:03.751982  4932 net.cpp:415] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0
I0109 14:38:03.751987  4932 net.cpp:415] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1
I0109 14:38:03.751993  4932 net.cpp:415] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2
I0109 14:38:03.751998  4932 net.cpp:415] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3
I0109 14:38:03.752002  4932 net.cpp:160] Setting up inception_4a/output_inception_4a/output_0_split
I0109 14:38:03.752007  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.752012  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.752015  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.752018  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.752022  4932 layer_factory.hpp:74] Creating layer inception_4b/1x1
I0109 14:38:03.752028  4932 net.cpp:96] Creating Layer inception_4b/1x1
I0109 14:38:03.752032  4932 net.cpp:459] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_0
I0109 14:38:03.752037  4932 net.cpp:415] inception_4b/1x1 -> inception_4b/1x1
I0109 14:38:03.752041  4932 net.cpp:160] Setting up inception_4b/1x1
I0109 14:38:03.752585  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.752593  4932 layer_factory.hpp:74] Creating layer inception_4b/1x1_bn
I0109 14:38:03.752596  4932 layer_factory.cpp:177] Layer inception_4b/1x1_bn is using CAFFE engine.
I0109 14:38:03.752601  4932 net.cpp:96] Creating Layer inception_4b/1x1_bn
I0109 14:38:03.752605  4932 net.cpp:459] inception_4b/1x1_bn <- inception_4b/1x1
I0109 14:38:03.752610  4932 net.cpp:415] inception_4b/1x1_bn -> inception_4b/1x1_bn
I0109 14:38:03.752616  4932 net.cpp:160] Setting up inception_4b/1x1_bn
I0109 14:38:03.752629  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.752635  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_1x1
I0109 14:38:03.752640  4932 net.cpp:96] Creating Layer inception_4b/relu_1x1
I0109 14:38:03.752642  4932 net.cpp:459] inception_4b/relu_1x1 <- inception_4b/1x1_bn
I0109 14:38:03.752647  4932 net.cpp:404] inception_4b/relu_1x1 -> inception_4b/1x1_bn (in-place)
I0109 14:38:03.752652  4932 net.cpp:160] Setting up inception_4b/relu_1x1
I0109 14:38:03.752656  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.752660  4932 layer_factory.hpp:74] Creating layer inception_4b/3x3_reduce
I0109 14:38:03.752665  4932 net.cpp:96] Creating Layer inception_4b/3x3_reduce
I0109 14:38:03.752667  4932 net.cpp:459] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_1
I0109 14:38:03.752673  4932 net.cpp:415] inception_4b/3x3_reduce -> inception_4b/3x3_reduce
I0109 14:38:03.752678  4932 net.cpp:160] Setting up inception_4b/3x3_reduce
I0109 14:38:03.752954  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.752961  4932 layer_factory.hpp:74] Creating layer inception_4b/3x3_reduce_bn
I0109 14:38:03.752971  4932 layer_factory.cpp:177] Layer inception_4b/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.752977  4932 net.cpp:96] Creating Layer inception_4b/3x3_reduce_bn
I0109 14:38:03.752981  4932 net.cpp:459] inception_4b/3x3_reduce_bn <- inception_4b/3x3_reduce
I0109 14:38:03.752985  4932 net.cpp:415] inception_4b/3x3_reduce_bn -> inception_4b/3x3_reduce_bn
I0109 14:38:03.752991  4932 net.cpp:160] Setting up inception_4b/3x3_reduce_bn
I0109 14:38:03.753002  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.753008  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_3x3_reduce
I0109 14:38:03.753013  4932 net.cpp:96] Creating Layer inception_4b/relu_3x3_reduce
I0109 14:38:03.753016  4932 net.cpp:459] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce_bn
I0109 14:38:03.753021  4932 net.cpp:404] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce_bn (in-place)
I0109 14:38:03.753026  4932 net.cpp:160] Setting up inception_4b/relu_3x3_reduce
I0109 14:38:03.753031  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.753033  4932 layer_factory.hpp:74] Creating layer inception_4b/3x3
I0109 14:38:03.753038  4932 net.cpp:96] Creating Layer inception_4b/3x3
I0109 14:38:03.753042  4932 net.cpp:459] inception_4b/3x3 <- inception_4b/3x3_reduce_bn
I0109 14:38:03.753047  4932 net.cpp:415] inception_4b/3x3 -> inception_4b/3x3
I0109 14:38:03.753053  4932 net.cpp:160] Setting up inception_4b/3x3
I0109 14:38:03.753597  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.753604  4932 layer_factory.hpp:74] Creating layer inception_4b/3x3_bn
I0109 14:38:03.753607  4932 layer_factory.cpp:177] Layer inception_4b/3x3_bn is using CAFFE engine.
I0109 14:38:03.753612  4932 net.cpp:96] Creating Layer inception_4b/3x3_bn
I0109 14:38:03.753615  4932 net.cpp:459] inception_4b/3x3_bn <- inception_4b/3x3
I0109 14:38:03.753621  4932 net.cpp:415] inception_4b/3x3_bn -> inception_4b/3x3_bn
I0109 14:38:03.753626  4932 net.cpp:160] Setting up inception_4b/3x3_bn
I0109 14:38:03.753638  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.753644  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_3x3
I0109 14:38:03.753649  4932 net.cpp:96] Creating Layer inception_4b/relu_3x3
I0109 14:38:03.753653  4932 net.cpp:459] inception_4b/relu_3x3 <- inception_4b/3x3_bn
I0109 14:38:03.753659  4932 net.cpp:404] inception_4b/relu_3x3 -> inception_4b/3x3_bn (in-place)
I0109 14:38:03.753662  4932 net.cpp:160] Setting up inception_4b/relu_3x3
I0109 14:38:03.753666  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.753669  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_reduce
I0109 14:38:03.753674  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_reduce
I0109 14:38:03.753679  4932 net.cpp:459] inception_4b/double_3x3_reduce <- inception_4a/output_inception_4a/output_0_split_2
I0109 14:38:03.753684  4932 net.cpp:415] inception_4b/double_3x3_reduce -> inception_4b/double_3x3_reduce
I0109 14:38:03.753689  4932 net.cpp:160] Setting up inception_4b/double_3x3_reduce
I0109 14:38:03.753962  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.753970  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_reduce_bn
I0109 14:38:03.753974  4932 layer_factory.cpp:177] Layer inception_4b/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.753978  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_reduce_bn
I0109 14:38:03.753983  4932 net.cpp:459] inception_4b/double_3x3_reduce_bn <- inception_4b/double_3x3_reduce
I0109 14:38:03.753988  4932 net.cpp:415] inception_4b/double_3x3_reduce_bn -> inception_4b/double_3x3_reduce_bn
I0109 14:38:03.753993  4932 net.cpp:160] Setting up inception_4b/double_3x3_reduce_bn
I0109 14:38:03.754004  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.754010  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_double_3x3_reduce
I0109 14:38:03.754016  4932 net.cpp:96] Creating Layer inception_4b/relu_double_3x3_reduce
I0109 14:38:03.754021  4932 net.cpp:459] inception_4b/relu_double_3x3_reduce <- inception_4b/double_3x3_reduce_bn
I0109 14:38:03.754029  4932 net.cpp:404] inception_4b/relu_double_3x3_reduce -> inception_4b/double_3x3_reduce_bn (in-place)
I0109 14:38:03.754034  4932 net.cpp:160] Setting up inception_4b/relu_double_3x3_reduce
I0109 14:38:03.754039  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.754042  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_1
I0109 14:38:03.754047  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_1
I0109 14:38:03.754050  4932 net.cpp:459] inception_4b/double_3x3_1 <- inception_4b/double_3x3_reduce_bn
I0109 14:38:03.754055  4932 net.cpp:415] inception_4b/double_3x3_1 -> inception_4b/double_3x3_1
I0109 14:38:03.754060  4932 net.cpp:160] Setting up inception_4b/double_3x3_1
I0109 14:38:03.754600  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.754606  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_1_bn
I0109 14:38:03.754609  4932 layer_factory.cpp:177] Layer inception_4b/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.754616  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_1_bn
I0109 14:38:03.754621  4932 net.cpp:459] inception_4b/double_3x3_1_bn <- inception_4b/double_3x3_1
I0109 14:38:03.754631  4932 net.cpp:415] inception_4b/double_3x3_1_bn -> inception_4b/double_3x3_1_bn
I0109 14:38:03.754637  4932 net.cpp:160] Setting up inception_4b/double_3x3_1_bn
I0109 14:38:03.754650  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.754657  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_double_3x3_1
I0109 14:38:03.754662  4932 net.cpp:96] Creating Layer inception_4b/relu_double_3x3_1
I0109 14:38:03.754664  4932 net.cpp:459] inception_4b/relu_double_3x3_1 <- inception_4b/double_3x3_1_bn
I0109 14:38:03.754668  4932 net.cpp:404] inception_4b/relu_double_3x3_1 -> inception_4b/double_3x3_1_bn (in-place)
I0109 14:38:03.754673  4932 net.cpp:160] Setting up inception_4b/relu_double_3x3_1
I0109 14:38:03.754676  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.754679  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_2
I0109 14:38:03.754686  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_2
I0109 14:38:03.754689  4932 net.cpp:459] inception_4b/double_3x3_2 <- inception_4b/double_3x3_1_bn
I0109 14:38:03.754694  4932 net.cpp:415] inception_4b/double_3x3_2 -> inception_4b/double_3x3_2
I0109 14:38:03.754699  4932 net.cpp:160] Setting up inception_4b/double_3x3_2
I0109 14:38:03.755411  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.755417  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_2_bn
I0109 14:38:03.755421  4932 layer_factory.cpp:177] Layer inception_4b/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.755426  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_2_bn
I0109 14:38:03.755430  4932 net.cpp:459] inception_4b/double_3x3_2_bn <- inception_4b/double_3x3_2
I0109 14:38:03.755435  4932 net.cpp:415] inception_4b/double_3x3_2_bn -> inception_4b/double_3x3_2_bn
I0109 14:38:03.755440  4932 net.cpp:160] Setting up inception_4b/double_3x3_2_bn
I0109 14:38:03.755451  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.755460  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_double_3x3_2
I0109 14:38:03.755463  4932 net.cpp:96] Creating Layer inception_4b/relu_double_3x3_2
I0109 14:38:03.755467  4932 net.cpp:459] inception_4b/relu_double_3x3_2 <- inception_4b/double_3x3_2_bn
I0109 14:38:03.755471  4932 net.cpp:404] inception_4b/relu_double_3x3_2 -> inception_4b/double_3x3_2_bn (in-place)
I0109 14:38:03.755476  4932 net.cpp:160] Setting up inception_4b/relu_double_3x3_2
I0109 14:38:03.755480  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.755483  4932 layer_factory.hpp:74] Creating layer inception_4b/pool
I0109 14:38:03.755487  4932 net.cpp:96] Creating Layer inception_4b/pool
I0109 14:38:03.755491  4932 net.cpp:459] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_3
I0109 14:38:03.755501  4932 net.cpp:415] inception_4b/pool -> inception_4b/pool
I0109 14:38:03.755506  4932 net.cpp:160] Setting up inception_4b/pool
I0109 14:38:03.755511  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.755515  4932 layer_factory.hpp:74] Creating layer inception_4b/pool_proj
I0109 14:38:03.755522  4932 net.cpp:96] Creating Layer inception_4b/pool_proj
I0109 14:38:03.755525  4932 net.cpp:459] inception_4b/pool_proj <- inception_4b/pool
I0109 14:38:03.755530  4932 net.cpp:415] inception_4b/pool_proj -> inception_4b/pool_proj
I0109 14:38:03.755537  4932 net.cpp:160] Setting up inception_4b/pool_proj
I0109 14:38:03.755898  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.755904  4932 layer_factory.hpp:74] Creating layer inception_4b/pool_proj_bn
I0109 14:38:03.755908  4932 layer_factory.cpp:177] Layer inception_4b/pool_proj_bn is using CAFFE engine.
I0109 14:38:03.755914  4932 net.cpp:96] Creating Layer inception_4b/pool_proj_bn
I0109 14:38:03.755918  4932 net.cpp:459] inception_4b/pool_proj_bn <- inception_4b/pool_proj
I0109 14:38:03.755923  4932 net.cpp:415] inception_4b/pool_proj_bn -> inception_4b/pool_proj_bn
I0109 14:38:03.755928  4932 net.cpp:160] Setting up inception_4b/pool_proj_bn
I0109 14:38:03.755939  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.755946  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_pool_proj
I0109 14:38:03.755951  4932 net.cpp:96] Creating Layer inception_4b/relu_pool_proj
I0109 14:38:03.755954  4932 net.cpp:459] inception_4b/relu_pool_proj <- inception_4b/pool_proj_bn
I0109 14:38:03.755959  4932 net.cpp:404] inception_4b/relu_pool_proj -> inception_4b/pool_proj_bn (in-place)
I0109 14:38:03.755964  4932 net.cpp:160] Setting up inception_4b/relu_pool_proj
I0109 14:38:03.755969  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.755971  4932 layer_factory.hpp:74] Creating layer inception_4b/output
I0109 14:38:03.755975  4932 net.cpp:96] Creating Layer inception_4b/output
I0109 14:38:03.755980  4932 net.cpp:459] inception_4b/output <- inception_4b/1x1_bn
I0109 14:38:03.755982  4932 net.cpp:459] inception_4b/output <- inception_4b/3x3_bn
I0109 14:38:03.755986  4932 net.cpp:459] inception_4b/output <- inception_4b/double_3x3_2_bn
I0109 14:38:03.755990  4932 net.cpp:459] inception_4b/output <- inception_4b/pool_proj_bn
I0109 14:38:03.755995  4932 net.cpp:415] inception_4b/output -> inception_4b/output
I0109 14:38:03.755998  4932 net.cpp:160] Setting up inception_4b/output
I0109 14:38:03.756003  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.756006  4932 layer_factory.hpp:74] Creating layer inception_4b/output_inception_4b/output_0_split
I0109 14:38:03.756011  4932 net.cpp:96] Creating Layer inception_4b/output_inception_4b/output_0_split
I0109 14:38:03.756014  4932 net.cpp:459] inception_4b/output_inception_4b/output_0_split <- inception_4b/output
I0109 14:38:03.756019  4932 net.cpp:415] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0
I0109 14:38:03.756026  4932 net.cpp:415] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1
I0109 14:38:03.756031  4932 net.cpp:415] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2
I0109 14:38:03.756036  4932 net.cpp:415] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3
I0109 14:38:03.756039  4932 net.cpp:160] Setting up inception_4b/output_inception_4b/output_0_split
I0109 14:38:03.756044  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.756048  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.756052  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.756055  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.756059  4932 layer_factory.hpp:74] Creating layer inception_4c/1x1
I0109 14:38:03.756073  4932 net.cpp:96] Creating Layer inception_4c/1x1
I0109 14:38:03.756080  4932 net.cpp:459] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0
I0109 14:38:03.756089  4932 net.cpp:415] inception_4c/1x1 -> inception_4c/1x1
I0109 14:38:03.756095  4932 net.cpp:160] Setting up inception_4c/1x1
I0109 14:38:03.756546  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.756553  4932 layer_factory.hpp:74] Creating layer inception_4c/1x1_bn
I0109 14:38:03.756558  4932 layer_factory.cpp:177] Layer inception_4c/1x1_bn is using CAFFE engine.
I0109 14:38:03.756564  4932 net.cpp:96] Creating Layer inception_4c/1x1_bn
I0109 14:38:03.756567  4932 net.cpp:459] inception_4c/1x1_bn <- inception_4c/1x1
I0109 14:38:03.756572  4932 net.cpp:415] inception_4c/1x1_bn -> inception_4c/1x1_bn
I0109 14:38:03.756577  4932 net.cpp:160] Setting up inception_4c/1x1_bn
I0109 14:38:03.756590  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.756597  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_1x1
I0109 14:38:03.756602  4932 net.cpp:96] Creating Layer inception_4c/relu_1x1
I0109 14:38:03.756604  4932 net.cpp:459] inception_4c/relu_1x1 <- inception_4c/1x1_bn
I0109 14:38:03.756608  4932 net.cpp:404] inception_4c/relu_1x1 -> inception_4c/1x1_bn (in-place)
I0109 14:38:03.756613  4932 net.cpp:160] Setting up inception_4c/relu_1x1
I0109 14:38:03.756616  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.756619  4932 layer_factory.hpp:74] Creating layer inception_4c/3x3_reduce
I0109 14:38:03.756625  4932 net.cpp:96] Creating Layer inception_4c/3x3_reduce
I0109 14:38:03.756629  4932 net.cpp:459] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1
I0109 14:38:03.756633  4932 net.cpp:415] inception_4c/3x3_reduce -> inception_4c/3x3_reduce
I0109 14:38:03.756639  4932 net.cpp:160] Setting up inception_4c/3x3_reduce
I0109 14:38:03.757001  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.757009  4932 layer_factory.hpp:74] Creating layer inception_4c/3x3_reduce_bn
I0109 14:38:03.757011  4932 layer_factory.cpp:177] Layer inception_4c/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.757017  4932 net.cpp:96] Creating Layer inception_4c/3x3_reduce_bn
I0109 14:38:03.757021  4932 net.cpp:459] inception_4c/3x3_reduce_bn <- inception_4c/3x3_reduce
I0109 14:38:03.757026  4932 net.cpp:415] inception_4c/3x3_reduce_bn -> inception_4c/3x3_reduce_bn
I0109 14:38:03.757031  4932 net.cpp:160] Setting up inception_4c/3x3_reduce_bn
I0109 14:38:03.757042  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.757050  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_3x3_reduce
I0109 14:38:03.757055  4932 net.cpp:96] Creating Layer inception_4c/relu_3x3_reduce
I0109 14:38:03.757060  4932 net.cpp:459] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce_bn
I0109 14:38:03.757063  4932 net.cpp:404] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce_bn (in-place)
I0109 14:38:03.757068  4932 net.cpp:160] Setting up inception_4c/relu_3x3_reduce
I0109 14:38:03.757072  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.757076  4932 layer_factory.hpp:74] Creating layer inception_4c/3x3
I0109 14:38:03.757081  4932 net.cpp:96] Creating Layer inception_4c/3x3
I0109 14:38:03.757083  4932 net.cpp:459] inception_4c/3x3 <- inception_4c/3x3_reduce_bn
I0109 14:38:03.757088  4932 net.cpp:415] inception_4c/3x3 -> inception_4c/3x3
I0109 14:38:03.757093  4932 net.cpp:160] Setting up inception_4c/3x3
I0109 14:38:03.757978  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.757985  4932 layer_factory.hpp:74] Creating layer inception_4c/3x3_bn
I0109 14:38:03.757988  4932 layer_factory.cpp:177] Layer inception_4c/3x3_bn is using CAFFE engine.
I0109 14:38:03.757993  4932 net.cpp:96] Creating Layer inception_4c/3x3_bn
I0109 14:38:03.757997  4932 net.cpp:459] inception_4c/3x3_bn <- inception_4c/3x3
I0109 14:38:03.758002  4932 net.cpp:415] inception_4c/3x3_bn -> inception_4c/3x3_bn
I0109 14:38:03.758008  4932 net.cpp:160] Setting up inception_4c/3x3_bn
I0109 14:38:03.758023  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.758035  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_3x3
I0109 14:38:03.758039  4932 net.cpp:96] Creating Layer inception_4c/relu_3x3
I0109 14:38:03.758044  4932 net.cpp:459] inception_4c/relu_3x3 <- inception_4c/3x3_bn
I0109 14:38:03.758049  4932 net.cpp:404] inception_4c/relu_3x3 -> inception_4c/3x3_bn (in-place)
I0109 14:38:03.758052  4932 net.cpp:160] Setting up inception_4c/relu_3x3
I0109 14:38:03.758056  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.758059  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_reduce
I0109 14:38:03.758064  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_reduce
I0109 14:38:03.758069  4932 net.cpp:459] inception_4c/double_3x3_reduce <- inception_4b/output_inception_4b/output_0_split_2
I0109 14:38:03.758074  4932 net.cpp:415] inception_4c/double_3x3_reduce -> inception_4c/double_3x3_reduce
I0109 14:38:03.758079  4932 net.cpp:160] Setting up inception_4c/double_3x3_reduce
I0109 14:38:03.758446  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.758455  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_reduce_bn
I0109 14:38:03.758460  4932 layer_factory.cpp:177] Layer inception_4c/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.758465  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_reduce_bn
I0109 14:38:03.758468  4932 net.cpp:459] inception_4c/double_3x3_reduce_bn <- inception_4c/double_3x3_reduce
I0109 14:38:03.758473  4932 net.cpp:415] inception_4c/double_3x3_reduce_bn -> inception_4c/double_3x3_reduce_bn
I0109 14:38:03.758478  4932 net.cpp:160] Setting up inception_4c/double_3x3_reduce_bn
I0109 14:38:03.758489  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.758496  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_double_3x3_reduce
I0109 14:38:03.758502  4932 net.cpp:96] Creating Layer inception_4c/relu_double_3x3_reduce
I0109 14:38:03.758504  4932 net.cpp:459] inception_4c/relu_double_3x3_reduce <- inception_4c/double_3x3_reduce_bn
I0109 14:38:03.758508  4932 net.cpp:404] inception_4c/relu_double_3x3_reduce -> inception_4c/double_3x3_reduce_bn (in-place)
I0109 14:38:03.758512  4932 net.cpp:160] Setting up inception_4c/relu_double_3x3_reduce
I0109 14:38:03.758517  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.758520  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_1
I0109 14:38:03.758525  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_1
I0109 14:38:03.758528  4932 net.cpp:459] inception_4c/double_3x3_1 <- inception_4c/double_3x3_reduce_bn
I0109 14:38:03.758533  4932 net.cpp:415] inception_4c/double_3x3_1 -> inception_4c/double_3x3_1
I0109 14:38:03.758538  4932 net.cpp:160] Setting up inception_4c/double_3x3_1
I0109 14:38:03.759425  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.759433  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_1_bn
I0109 14:38:03.759435  4932 layer_factory.cpp:177] Layer inception_4c/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.759441  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_1_bn
I0109 14:38:03.759445  4932 net.cpp:459] inception_4c/double_3x3_1_bn <- inception_4c/double_3x3_1
I0109 14:38:03.759449  4932 net.cpp:415] inception_4c/double_3x3_1_bn -> inception_4c/double_3x3_1_bn
I0109 14:38:03.759454  4932 net.cpp:160] Setting up inception_4c/double_3x3_1_bn
I0109 14:38:03.759466  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.759472  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_double_3x3_1
I0109 14:38:03.759482  4932 net.cpp:96] Creating Layer inception_4c/relu_double_3x3_1
I0109 14:38:03.759485  4932 net.cpp:459] inception_4c/relu_double_3x3_1 <- inception_4c/double_3x3_1_bn
I0109 14:38:03.759490  4932 net.cpp:404] inception_4c/relu_double_3x3_1 -> inception_4c/double_3x3_1_bn (in-place)
I0109 14:38:03.759495  4932 net.cpp:160] Setting up inception_4c/relu_double_3x3_1
I0109 14:38:03.759498  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.759506  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_2
I0109 14:38:03.759513  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_2
I0109 14:38:03.759517  4932 net.cpp:459] inception_4c/double_3x3_2 <- inception_4c/double_3x3_1_bn
I0109 14:38:03.759521  4932 net.cpp:415] inception_4c/double_3x3_2 -> inception_4c/double_3x3_2
I0109 14:38:03.759526  4932 net.cpp:160] Setting up inception_4c/double_3x3_2
I0109 14:38:03.760634  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.760643  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_2_bn
I0109 14:38:03.760645  4932 layer_factory.cpp:177] Layer inception_4c/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.760650  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_2_bn
I0109 14:38:03.760654  4932 net.cpp:459] inception_4c/double_3x3_2_bn <- inception_4c/double_3x3_2
I0109 14:38:03.760659  4932 net.cpp:415] inception_4c/double_3x3_2_bn -> inception_4c/double_3x3_2_bn
I0109 14:38:03.760664  4932 net.cpp:160] Setting up inception_4c/double_3x3_2_bn
I0109 14:38:03.760676  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.760682  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_double_3x3_2
I0109 14:38:03.760686  4932 net.cpp:96] Creating Layer inception_4c/relu_double_3x3_2
I0109 14:38:03.760690  4932 net.cpp:459] inception_4c/relu_double_3x3_2 <- inception_4c/double_3x3_2_bn
I0109 14:38:03.760694  4932 net.cpp:404] inception_4c/relu_double_3x3_2 -> inception_4c/double_3x3_2_bn (in-place)
I0109 14:38:03.760699  4932 net.cpp:160] Setting up inception_4c/relu_double_3x3_2
I0109 14:38:03.760701  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.760705  4932 layer_factory.hpp:74] Creating layer inception_4c/pool
I0109 14:38:03.760710  4932 net.cpp:96] Creating Layer inception_4c/pool
I0109 14:38:03.760715  4932 net.cpp:459] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3
I0109 14:38:03.760718  4932 net.cpp:415] inception_4c/pool -> inception_4c/pool
I0109 14:38:03.760722  4932 net.cpp:160] Setting up inception_4c/pool
I0109 14:38:03.760727  4932 net.cpp:167] Top shape: 72 576 14 14 (8128512)
I0109 14:38:03.760731  4932 layer_factory.hpp:74] Creating layer inception_4c/pool_proj
I0109 14:38:03.760738  4932 net.cpp:96] Creating Layer inception_4c/pool_proj
I0109 14:38:03.760742  4932 net.cpp:459] inception_4c/pool_proj <- inception_4c/pool
I0109 14:38:03.760746  4932 net.cpp:415] inception_4c/pool_proj -> inception_4c/pool_proj
I0109 14:38:03.760751  4932 net.cpp:160] Setting up inception_4c/pool_proj
I0109 14:38:03.761112  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.761118  4932 layer_factory.hpp:74] Creating layer inception_4c/pool_proj_bn
I0109 14:38:03.761122  4932 layer_factory.cpp:177] Layer inception_4c/pool_proj_bn is using CAFFE engine.
I0109 14:38:03.761127  4932 net.cpp:96] Creating Layer inception_4c/pool_proj_bn
I0109 14:38:03.761131  4932 net.cpp:459] inception_4c/pool_proj_bn <- inception_4c/pool_proj
I0109 14:38:03.761135  4932 net.cpp:415] inception_4c/pool_proj_bn -> inception_4c/pool_proj_bn
I0109 14:38:03.761142  4932 net.cpp:160] Setting up inception_4c/pool_proj_bn
I0109 14:38:03.761153  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.761180  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_pool_proj
I0109 14:38:03.761186  4932 net.cpp:96] Creating Layer inception_4c/relu_pool_proj
I0109 14:38:03.761189  4932 net.cpp:459] inception_4c/relu_pool_proj <- inception_4c/pool_proj_bn
I0109 14:38:03.761193  4932 net.cpp:404] inception_4c/relu_pool_proj -> inception_4c/pool_proj_bn (in-place)
I0109 14:38:03.761198  4932 net.cpp:160] Setting up inception_4c/relu_pool_proj
I0109 14:38:03.761203  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.761205  4932 layer_factory.hpp:74] Creating layer inception_4c/output
I0109 14:38:03.761210  4932 net.cpp:96] Creating Layer inception_4c/output
I0109 14:38:03.761214  4932 net.cpp:459] inception_4c/output <- inception_4c/1x1_bn
I0109 14:38:03.761224  4932 net.cpp:459] inception_4c/output <- inception_4c/3x3_bn
I0109 14:38:03.761229  4932 net.cpp:459] inception_4c/output <- inception_4c/double_3x3_2_bn
I0109 14:38:03.761232  4932 net.cpp:459] inception_4c/output <- inception_4c/pool_proj_bn
I0109 14:38:03.761236  4932 net.cpp:415] inception_4c/output -> inception_4c/output
I0109 14:38:03.761241  4932 net.cpp:160] Setting up inception_4c/output
I0109 14:38:03.761246  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.761250  4932 layer_factory.hpp:74] Creating layer inception_4c/output_inception_4c/output_0_split
I0109 14:38:03.761255  4932 net.cpp:96] Creating Layer inception_4c/output_inception_4c/output_0_split
I0109 14:38:03.761257  4932 net.cpp:459] inception_4c/output_inception_4c/output_0_split <- inception_4c/output
I0109 14:38:03.761262  4932 net.cpp:415] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0
I0109 14:38:03.761267  4932 net.cpp:415] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1
I0109 14:38:03.761272  4932 net.cpp:415] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2
I0109 14:38:03.761287  4932 net.cpp:415] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3
I0109 14:38:03.761292  4932 net.cpp:160] Setting up inception_4c/output_inception_4c/output_0_split
I0109 14:38:03.761297  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.761301  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.761307  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.761310  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.761313  4932 layer_factory.hpp:74] Creating layer inception_4d/1x1
I0109 14:38:03.761318  4932 net.cpp:96] Creating Layer inception_4d/1x1
I0109 14:38:03.761322  4932 net.cpp:459] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0
I0109 14:38:03.761327  4932 net.cpp:415] inception_4d/1x1 -> inception_4d/1x1
I0109 14:38:03.761332  4932 net.cpp:160] Setting up inception_4d/1x1
I0109 14:38:03.761618  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.761626  4932 layer_factory.hpp:74] Creating layer inception_4d/1x1_bn
I0109 14:38:03.761629  4932 layer_factory.cpp:177] Layer inception_4d/1x1_bn is using CAFFE engine.
I0109 14:38:03.761634  4932 net.cpp:96] Creating Layer inception_4d/1x1_bn
I0109 14:38:03.761638  4932 net.cpp:459] inception_4d/1x1_bn <- inception_4d/1x1
I0109 14:38:03.761644  4932 net.cpp:415] inception_4d/1x1_bn -> inception_4d/1x1_bn
I0109 14:38:03.761649  4932 net.cpp:160] Setting up inception_4d/1x1_bn
I0109 14:38:03.761660  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.761667  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_1x1
I0109 14:38:03.761672  4932 net.cpp:96] Creating Layer inception_4d/relu_1x1
I0109 14:38:03.761675  4932 net.cpp:459] inception_4d/relu_1x1 <- inception_4d/1x1_bn
I0109 14:38:03.761679  4932 net.cpp:404] inception_4d/relu_1x1 -> inception_4d/1x1_bn (in-place)
I0109 14:38:03.761683  4932 net.cpp:160] Setting up inception_4d/relu_1x1
I0109 14:38:03.761687  4932 net.cpp:167] Top shape: 72 96 14 14 (1354752)
I0109 14:38:03.761690  4932 layer_factory.hpp:74] Creating layer inception_4d/3x3_reduce
I0109 14:38:03.761695  4932 net.cpp:96] Creating Layer inception_4d/3x3_reduce
I0109 14:38:03.761699  4932 net.cpp:459] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1
I0109 14:38:03.761704  4932 net.cpp:415] inception_4d/3x3_reduce -> inception_4d/3x3_reduce
I0109 14:38:03.761709  4932 net.cpp:160] Setting up inception_4d/3x3_reduce
I0109 14:38:03.762089  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.762096  4932 layer_factory.hpp:74] Creating layer inception_4d/3x3_reduce_bn
I0109 14:38:03.762099  4932 layer_factory.cpp:177] Layer inception_4d/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.762107  4932 net.cpp:96] Creating Layer inception_4d/3x3_reduce_bn
I0109 14:38:03.762115  4932 net.cpp:459] inception_4d/3x3_reduce_bn <- inception_4d/3x3_reduce
I0109 14:38:03.762121  4932 net.cpp:415] inception_4d/3x3_reduce_bn -> inception_4d/3x3_reduce_bn
I0109 14:38:03.762126  4932 net.cpp:160] Setting up inception_4d/3x3_reduce_bn
I0109 14:38:03.762137  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.762145  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_3x3_reduce
I0109 14:38:03.762150  4932 net.cpp:96] Creating Layer inception_4d/relu_3x3_reduce
I0109 14:38:03.762153  4932 net.cpp:459] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce_bn
I0109 14:38:03.762157  4932 net.cpp:404] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce_bn (in-place)
I0109 14:38:03.762161  4932 net.cpp:160] Setting up inception_4d/relu_3x3_reduce
I0109 14:38:03.762166  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.762168  4932 layer_factory.hpp:74] Creating layer inception_4d/3x3
I0109 14:38:03.762174  4932 net.cpp:96] Creating Layer inception_4d/3x3
I0109 14:38:03.762177  4932 net.cpp:459] inception_4d/3x3 <- inception_4d/3x3_reduce_bn
I0109 14:38:03.762182  4932 net.cpp:415] inception_4d/3x3 -> inception_4d/3x3
I0109 14:38:03.762187  4932 net.cpp:160] Setting up inception_4d/3x3
I0109 14:38:03.763267  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.763276  4932 layer_factory.hpp:74] Creating layer inception_4d/3x3_bn
I0109 14:38:03.763280  4932 layer_factory.cpp:177] Layer inception_4d/3x3_bn is using CAFFE engine.
I0109 14:38:03.763285  4932 net.cpp:96] Creating Layer inception_4d/3x3_bn
I0109 14:38:03.763288  4932 net.cpp:459] inception_4d/3x3_bn <- inception_4d/3x3
I0109 14:38:03.763294  4932 net.cpp:415] inception_4d/3x3_bn -> inception_4d/3x3_bn
I0109 14:38:03.763300  4932 net.cpp:160] Setting up inception_4d/3x3_bn
I0109 14:38:03.763312  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.763319  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_3x3
I0109 14:38:03.763324  4932 net.cpp:96] Creating Layer inception_4d/relu_3x3
I0109 14:38:03.763326  4932 net.cpp:459] inception_4d/relu_3x3 <- inception_4d/3x3_bn
I0109 14:38:03.763331  4932 net.cpp:404] inception_4d/relu_3x3 -> inception_4d/3x3_bn (in-place)
I0109 14:38:03.763335  4932 net.cpp:160] Setting up inception_4d/relu_3x3
I0109 14:38:03.763339  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.763344  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_reduce
I0109 14:38:03.763348  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_reduce
I0109 14:38:03.763351  4932 net.cpp:459] inception_4d/double_3x3_reduce <- inception_4c/output_inception_4c/output_0_split_2
I0109 14:38:03.763356  4932 net.cpp:415] inception_4d/double_3x3_reduce -> inception_4d/double_3x3_reduce
I0109 14:38:03.763362  4932 net.cpp:160] Setting up inception_4d/double_3x3_reduce
I0109 14:38:03.763886  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.763896  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_reduce_bn
I0109 14:38:03.763900  4932 layer_factory.cpp:177] Layer inception_4d/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.763906  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_reduce_bn
I0109 14:38:03.763909  4932 net.cpp:459] inception_4d/double_3x3_reduce_bn <- inception_4d/double_3x3_reduce
I0109 14:38:03.763914  4932 net.cpp:415] inception_4d/double_3x3_reduce_bn -> inception_4d/double_3x3_reduce_bn
I0109 14:38:03.763921  4932 net.cpp:160] Setting up inception_4d/double_3x3_reduce_bn
I0109 14:38:03.763931  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.763938  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_double_3x3_reduce
I0109 14:38:03.763943  4932 net.cpp:96] Creating Layer inception_4d/relu_double_3x3_reduce
I0109 14:38:03.763947  4932 net.cpp:459] inception_4d/relu_double_3x3_reduce <- inception_4d/double_3x3_reduce_bn
I0109 14:38:03.763954  4932 net.cpp:404] inception_4d/relu_double_3x3_reduce -> inception_4d/double_3x3_reduce_bn (in-place)
I0109 14:38:03.763962  4932 net.cpp:160] Setting up inception_4d/relu_double_3x3_reduce
I0109 14:38:03.763967  4932 net.cpp:167] Top shape: 72 160 14 14 (2257920)
I0109 14:38:03.763969  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_1
I0109 14:38:03.763975  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_1
I0109 14:38:03.763978  4932 net.cpp:459] inception_4d/double_3x3_1 <- inception_4d/double_3x3_reduce_bn
I0109 14:38:03.763985  4932 net.cpp:415] inception_4d/double_3x3_1 -> inception_4d/double_3x3_1
I0109 14:38:03.763990  4932 net.cpp:160] Setting up inception_4d/double_3x3_1
I0109 14:38:03.765323  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.765331  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_1_bn
I0109 14:38:03.765334  4932 layer_factory.cpp:177] Layer inception_4d/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.765341  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_1_bn
I0109 14:38:03.765344  4932 net.cpp:459] inception_4d/double_3x3_1_bn <- inception_4d/double_3x3_1
I0109 14:38:03.765350  4932 net.cpp:415] inception_4d/double_3x3_1_bn -> inception_4d/double_3x3_1_bn
I0109 14:38:03.765355  4932 net.cpp:160] Setting up inception_4d/double_3x3_1_bn
I0109 14:38:03.765367  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.765373  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_double_3x3_1
I0109 14:38:03.765378  4932 net.cpp:96] Creating Layer inception_4d/relu_double_3x3_1
I0109 14:38:03.765383  4932 net.cpp:459] inception_4d/relu_double_3x3_1 <- inception_4d/double_3x3_1_bn
I0109 14:38:03.765386  4932 net.cpp:404] inception_4d/relu_double_3x3_1 -> inception_4d/double_3x3_1_bn (in-place)
I0109 14:38:03.765391  4932 net.cpp:160] Setting up inception_4d/relu_double_3x3_1
I0109 14:38:03.765395  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.765398  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_2
I0109 14:38:03.765403  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_2
I0109 14:38:03.765406  4932 net.cpp:459] inception_4d/double_3x3_2 <- inception_4d/double_3x3_1_bn
I0109 14:38:03.765411  4932 net.cpp:415] inception_4d/double_3x3_2 -> inception_4d/double_3x3_2
I0109 14:38:03.765417  4932 net.cpp:160] Setting up inception_4d/double_3x3_2
I0109 14:38:03.767016  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.767024  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_2_bn
I0109 14:38:03.767027  4932 layer_factory.cpp:177] Layer inception_4d/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.767033  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_2_bn
I0109 14:38:03.767037  4932 net.cpp:459] inception_4d/double_3x3_2_bn <- inception_4d/double_3x3_2
I0109 14:38:03.767042  4932 net.cpp:415] inception_4d/double_3x3_2_bn -> inception_4d/double_3x3_2_bn
I0109 14:38:03.767047  4932 net.cpp:160] Setting up inception_4d/double_3x3_2_bn
I0109 14:38:03.767060  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.767066  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_double_3x3_2
I0109 14:38:03.767072  4932 net.cpp:96] Creating Layer inception_4d/relu_double_3x3_2
I0109 14:38:03.767076  4932 net.cpp:459] inception_4d/relu_double_3x3_2 <- inception_4d/double_3x3_2_bn
I0109 14:38:03.767081  4932 net.cpp:404] inception_4d/relu_double_3x3_2 -> inception_4d/double_3x3_2_bn (in-place)
I0109 14:38:03.767086  4932 net.cpp:160] Setting up inception_4d/relu_double_3x3_2
I0109 14:38:03.767088  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.767092  4932 layer_factory.hpp:74] Creating layer inception_4d/pool
I0109 14:38:03.767096  4932 net.cpp:96] Creating Layer inception_4d/pool
I0109 14:38:03.767101  4932 net.cpp:459] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3
I0109 14:38:03.767104  4932 net.cpp:415] inception_4d/pool -> inception_4d/pool
I0109 14:38:03.767112  4932 net.cpp:160] Setting up inception_4d/pool
I0109 14:38:03.767122  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.767125  4932 layer_factory.hpp:74] Creating layer inception_4d/pool_proj
I0109 14:38:03.767132  4932 net.cpp:96] Creating Layer inception_4d/pool_proj
I0109 14:38:03.767135  4932 net.cpp:459] inception_4d/pool_proj <- inception_4d/pool
I0109 14:38:03.767139  4932 net.cpp:415] inception_4d/pool_proj -> inception_4d/pool_proj
I0109 14:38:03.767144  4932 net.cpp:160] Setting up inception_4d/pool_proj
I0109 14:38:03.767524  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.767530  4932 layer_factory.hpp:74] Creating layer inception_4d/pool_proj_bn
I0109 14:38:03.767534  4932 layer_factory.cpp:177] Layer inception_4d/pool_proj_bn is using CAFFE engine.
I0109 14:38:03.767539  4932 net.cpp:96] Creating Layer inception_4d/pool_proj_bn
I0109 14:38:03.767544  4932 net.cpp:459] inception_4d/pool_proj_bn <- inception_4d/pool_proj
I0109 14:38:03.767549  4932 net.cpp:415] inception_4d/pool_proj_bn -> inception_4d/pool_proj_bn
I0109 14:38:03.767554  4932 net.cpp:160] Setting up inception_4d/pool_proj_bn
I0109 14:38:03.767565  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.767572  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_pool_proj
I0109 14:38:03.767577  4932 net.cpp:96] Creating Layer inception_4d/relu_pool_proj
I0109 14:38:03.767581  4932 net.cpp:459] inception_4d/relu_pool_proj <- inception_4d/pool_proj_bn
I0109 14:38:03.767585  4932 net.cpp:404] inception_4d/relu_pool_proj -> inception_4d/pool_proj_bn (in-place)
I0109 14:38:03.767590  4932 net.cpp:160] Setting up inception_4d/relu_pool_proj
I0109 14:38:03.767593  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.767596  4932 layer_factory.hpp:74] Creating layer inception_4d/output
I0109 14:38:03.767602  4932 net.cpp:96] Creating Layer inception_4d/output
I0109 14:38:03.767606  4932 net.cpp:459] inception_4d/output <- inception_4d/1x1_bn
I0109 14:38:03.767609  4932 net.cpp:459] inception_4d/output <- inception_4d/3x3_bn
I0109 14:38:03.767613  4932 net.cpp:459] inception_4d/output <- inception_4d/double_3x3_2_bn
I0109 14:38:03.767617  4932 net.cpp:459] inception_4d/output <- inception_4d/pool_proj_bn
I0109 14:38:03.767621  4932 net.cpp:415] inception_4d/output -> inception_4d/output
I0109 14:38:03.767626  4932 net.cpp:160] Setting up inception_4d/output
I0109 14:38:03.767630  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.767634  4932 layer_factory.hpp:74] Creating layer inception_4d/output_inception_4d/output_0_split
I0109 14:38:03.767639  4932 net.cpp:96] Creating Layer inception_4d/output_inception_4d/output_0_split
I0109 14:38:03.767642  4932 net.cpp:459] inception_4d/output_inception_4d/output_0_split <- inception_4d/output
I0109 14:38:03.767647  4932 net.cpp:415] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0
I0109 14:38:03.767652  4932 net.cpp:415] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1
I0109 14:38:03.767657  4932 net.cpp:415] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2
I0109 14:38:03.767663  4932 net.cpp:160] Setting up inception_4d/output_inception_4d/output_0_split
I0109 14:38:03.767668  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.767671  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.767675  4932 net.cpp:167] Top shape: 72 608 14 14 (8580096)
I0109 14:38:03.767678  4932 layer_factory.hpp:74] Creating layer inception_4e/3x3_reduce
I0109 14:38:03.767685  4932 net.cpp:96] Creating Layer inception_4e/3x3_reduce
I0109 14:38:03.767689  4932 net.cpp:459] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_0
I0109 14:38:03.767693  4932 net.cpp:415] inception_4e/3x3_reduce -> inception_4e/3x3_reduce
I0109 14:38:03.767699  4932 net.cpp:160] Setting up inception_4e/3x3_reduce
I0109 14:38:03.768076  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.768090  4932 layer_factory.hpp:74] Creating layer inception_4e/3x3_reduce_bn
I0109 14:38:03.768093  4932 layer_factory.cpp:177] Layer inception_4e/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.768098  4932 net.cpp:96] Creating Layer inception_4e/3x3_reduce_bn
I0109 14:38:03.768101  4932 net.cpp:459] inception_4e/3x3_reduce_bn <- inception_4e/3x3_reduce
I0109 14:38:03.768110  4932 net.cpp:415] inception_4e/3x3_reduce_bn -> inception_4e/3x3_reduce_bn
I0109 14:38:03.768117  4932 net.cpp:160] Setting up inception_4e/3x3_reduce_bn
I0109 14:38:03.768129  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.768136  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_3x3_reduce
I0109 14:38:03.768141  4932 net.cpp:96] Creating Layer inception_4e/relu_3x3_reduce
I0109 14:38:03.768144  4932 net.cpp:459] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce_bn
I0109 14:38:03.768148  4932 net.cpp:404] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce_bn (in-place)
I0109 14:38:03.768152  4932 net.cpp:160] Setting up inception_4e/relu_3x3_reduce
I0109 14:38:03.768157  4932 net.cpp:167] Top shape: 72 128 14 14 (1806336)
I0109 14:38:03.768160  4932 layer_factory.hpp:74] Creating layer inception_4e/3x3
I0109 14:38:03.768165  4932 net.cpp:96] Creating Layer inception_4e/3x3
I0109 14:38:03.768169  4932 net.cpp:459] inception_4e/3x3 <- inception_4e/3x3_reduce_bn
I0109 14:38:03.768173  4932 net.cpp:415] inception_4e/3x3 -> inception_4e/3x3
I0109 14:38:03.768178  4932 net.cpp:160] Setting up inception_4e/3x3
I0109 14:38:03.769242  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.769248  4932 layer_factory.hpp:74] Creating layer inception_4e/3x3_bn
I0109 14:38:03.769251  4932 layer_factory.cpp:177] Layer inception_4e/3x3_bn is using CAFFE engine.
I0109 14:38:03.769258  4932 net.cpp:96] Creating Layer inception_4e/3x3_bn
I0109 14:38:03.769261  4932 net.cpp:459] inception_4e/3x3_bn <- inception_4e/3x3
I0109 14:38:03.769266  4932 net.cpp:415] inception_4e/3x3_bn -> inception_4e/3x3_bn
I0109 14:38:03.769273  4932 net.cpp:160] Setting up inception_4e/3x3_bn
I0109 14:38:03.769284  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.769290  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_3x3
I0109 14:38:03.769295  4932 net.cpp:96] Creating Layer inception_4e/relu_3x3
I0109 14:38:03.769299  4932 net.cpp:459] inception_4e/relu_3x3 <- inception_4e/3x3_bn
I0109 14:38:03.769304  4932 net.cpp:404] inception_4e/relu_3x3 -> inception_4e/3x3_bn (in-place)
I0109 14:38:03.769309  4932 net.cpp:160] Setting up inception_4e/relu_3x3
I0109 14:38:03.769312  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.769316  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_reduce
I0109 14:38:03.769321  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_reduce
I0109 14:38:03.769325  4932 net.cpp:459] inception_4e/double_3x3_reduce <- inception_4d/output_inception_4d/output_0_split_1
I0109 14:38:03.769330  4932 net.cpp:415] inception_4e/double_3x3_reduce -> inception_4e/double_3x3_reduce
I0109 14:38:03.769335  4932 net.cpp:160] Setting up inception_4e/double_3x3_reduce
I0109 14:38:03.769898  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.769904  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_reduce_bn
I0109 14:38:03.769908  4932 layer_factory.cpp:177] Layer inception_4e/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.769913  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_reduce_bn
I0109 14:38:03.769917  4932 net.cpp:459] inception_4e/double_3x3_reduce_bn <- inception_4e/double_3x3_reduce
I0109 14:38:03.769922  4932 net.cpp:415] inception_4e/double_3x3_reduce_bn -> inception_4e/double_3x3_reduce_bn
I0109 14:38:03.769927  4932 net.cpp:160] Setting up inception_4e/double_3x3_reduce_bn
I0109 14:38:03.769939  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.769947  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_double_3x3_reduce
I0109 14:38:03.769953  4932 net.cpp:96] Creating Layer inception_4e/relu_double_3x3_reduce
I0109 14:38:03.769961  4932 net.cpp:459] inception_4e/relu_double_3x3_reduce <- inception_4e/double_3x3_reduce_bn
I0109 14:38:03.769965  4932 net.cpp:404] inception_4e/relu_double_3x3_reduce -> inception_4e/double_3x3_reduce_bn (in-place)
I0109 14:38:03.769969  4932 net.cpp:160] Setting up inception_4e/relu_double_3x3_reduce
I0109 14:38:03.769973  4932 net.cpp:167] Top shape: 72 192 14 14 (2709504)
I0109 14:38:03.769978  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_1
I0109 14:38:03.769982  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_1
I0109 14:38:03.769986  4932 net.cpp:459] inception_4e/double_3x3_1 <- inception_4e/double_3x3_reduce_bn
I0109 14:38:03.769990  4932 net.cpp:415] inception_4e/double_3x3_1 -> inception_4e/double_3x3_1
I0109 14:38:03.769995  4932 net.cpp:160] Setting up inception_4e/double_3x3_1
I0109 14:38:03.772133  4932 net.cpp:167] Top shape: 72 256 14 14 (3612672)
I0109 14:38:03.772142  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_1_bn
I0109 14:38:03.772146  4932 layer_factory.cpp:177] Layer inception_4e/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.772151  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_1_bn
I0109 14:38:03.772156  4932 net.cpp:459] inception_4e/double_3x3_1_bn <- inception_4e/double_3x3_1
I0109 14:38:03.772161  4932 net.cpp:415] inception_4e/double_3x3_1_bn -> inception_4e/double_3x3_1_bn
I0109 14:38:03.772166  4932 net.cpp:160] Setting up inception_4e/double_3x3_1_bn
I0109 14:38:03.772179  4932 net.cpp:167] Top shape: 72 256 14 14 (3612672)
I0109 14:38:03.772186  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_double_3x3_1
I0109 14:38:03.772191  4932 net.cpp:96] Creating Layer inception_4e/relu_double_3x3_1
I0109 14:38:03.772194  4932 net.cpp:459] inception_4e/relu_double_3x3_1 <- inception_4e/double_3x3_1_bn
I0109 14:38:03.772198  4932 net.cpp:404] inception_4e/relu_double_3x3_1 -> inception_4e/double_3x3_1_bn (in-place)
I0109 14:38:03.772202  4932 net.cpp:160] Setting up inception_4e/relu_double_3x3_1
I0109 14:38:03.772207  4932 net.cpp:167] Top shape: 72 256 14 14 (3612672)
I0109 14:38:03.772209  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_2
I0109 14:38:03.772215  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_2
I0109 14:38:03.772219  4932 net.cpp:459] inception_4e/double_3x3_2 <- inception_4e/double_3x3_1_bn
I0109 14:38:03.772223  4932 net.cpp:415] inception_4e/double_3x3_2 -> inception_4e/double_3x3_2
I0109 14:38:03.772228  4932 net.cpp:160] Setting up inception_4e/double_3x3_2
I0109 14:38:03.775048  4932 net.cpp:167] Top shape: 72 256 7 7 (903168)
I0109 14:38:03.775055  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_2_bn
I0109 14:38:03.775058  4932 layer_factory.cpp:177] Layer inception_4e/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.775063  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_2_bn
I0109 14:38:03.775068  4932 net.cpp:459] inception_4e/double_3x3_2_bn <- inception_4e/double_3x3_2
I0109 14:38:03.775074  4932 net.cpp:415] inception_4e/double_3x3_2_bn -> inception_4e/double_3x3_2_bn
I0109 14:38:03.775079  4932 net.cpp:160] Setting up inception_4e/double_3x3_2_bn
I0109 14:38:03.775090  4932 net.cpp:167] Top shape: 72 256 7 7 (903168)
I0109 14:38:03.775096  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_double_3x3_2
I0109 14:38:03.775101  4932 net.cpp:96] Creating Layer inception_4e/relu_double_3x3_2
I0109 14:38:03.775105  4932 net.cpp:459] inception_4e/relu_double_3x3_2 <- inception_4e/double_3x3_2_bn
I0109 14:38:03.775110  4932 net.cpp:404] inception_4e/relu_double_3x3_2 -> inception_4e/double_3x3_2_bn (in-place)
I0109 14:38:03.775113  4932 net.cpp:160] Setting up inception_4e/relu_double_3x3_2
I0109 14:38:03.775117  4932 net.cpp:167] Top shape: 72 256 7 7 (903168)
I0109 14:38:03.775120  4932 layer_factory.hpp:74] Creating layer inception_4e/pool
I0109 14:38:03.775125  4932 net.cpp:96] Creating Layer inception_4e/pool
I0109 14:38:03.775131  4932 net.cpp:459] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_2
I0109 14:38:03.775141  4932 net.cpp:415] inception_4e/pool -> inception_4e/pool
I0109 14:38:03.775146  4932 net.cpp:160] Setting up inception_4e/pool
I0109 14:38:03.775153  4932 net.cpp:167] Top shape: 72 608 7 7 (2145024)
I0109 14:38:03.775156  4932 layer_factory.hpp:74] Creating layer inception_4e/output
I0109 14:38:03.775161  4932 net.cpp:96] Creating Layer inception_4e/output
I0109 14:38:03.775166  4932 net.cpp:459] inception_4e/output <- inception_4e/3x3_bn
I0109 14:38:03.775168  4932 net.cpp:459] inception_4e/output <- inception_4e/double_3x3_2_bn
I0109 14:38:03.775172  4932 net.cpp:459] inception_4e/output <- inception_4e/pool
I0109 14:38:03.775177  4932 net.cpp:415] inception_4e/output -> inception_4e/output
I0109 14:38:03.775182  4932 net.cpp:160] Setting up inception_4e/output
I0109 14:38:03.775187  4932 net.cpp:167] Top shape: 72 1056 7 7 (3725568)
I0109 14:38:03.775190  4932 layer_factory.hpp:74] Creating layer inception_4e/output_inception_4e/output_0_split
I0109 14:38:03.775197  4932 net.cpp:96] Creating Layer inception_4e/output_inception_4e/output_0_split
I0109 14:38:03.775199  4932 net.cpp:459] inception_4e/output_inception_4e/output_0_split <- inception_4e/output
I0109 14:38:03.775204  4932 net.cpp:415] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_0
I0109 14:38:03.775209  4932 net.cpp:415] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_1
I0109 14:38:03.775215  4932 net.cpp:415] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_2
I0109 14:38:03.775220  4932 net.cpp:415] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_3
I0109 14:38:03.775225  4932 net.cpp:160] Setting up inception_4e/output_inception_4e/output_0_split
I0109 14:38:03.775230  4932 net.cpp:167] Top shape: 72 1056 7 7 (3725568)
I0109 14:38:03.775234  4932 net.cpp:167] Top shape: 72 1056 7 7 (3725568)
I0109 14:38:03.775238  4932 net.cpp:167] Top shape: 72 1056 7 7 (3725568)
I0109 14:38:03.775241  4932 net.cpp:167] Top shape: 72 1056 7 7 (3725568)
I0109 14:38:03.775244  4932 layer_factory.hpp:74] Creating layer inception_5a/1x1
I0109 14:38:03.775249  4932 net.cpp:96] Creating Layer inception_5a/1x1
I0109 14:38:03.775252  4932 net.cpp:459] inception_5a/1x1 <- inception_4e/output_inception_4e/output_0_split_0
I0109 14:38:03.775259  4932 net.cpp:415] inception_5a/1x1 -> inception_5a/1x1
I0109 14:38:03.775264  4932 net.cpp:160] Setting up inception_5a/1x1
I0109 14:38:03.777066  4932 net.cpp:167] Top shape: 72 352 7 7 (1241856)
I0109 14:38:03.777076  4932 layer_factory.hpp:74] Creating layer inception_5a/1x1_bn
I0109 14:38:03.777079  4932 layer_factory.cpp:177] Layer inception_5a/1x1_bn is using CAFFE engine.
I0109 14:38:03.777086  4932 net.cpp:96] Creating Layer inception_5a/1x1_bn
I0109 14:38:03.777089  4932 net.cpp:459] inception_5a/1x1_bn <- inception_5a/1x1
I0109 14:38:03.777096  4932 net.cpp:415] inception_5a/1x1_bn -> inception_5a/1x1_bn
I0109 14:38:03.777101  4932 net.cpp:160] Setting up inception_5a/1x1_bn
I0109 14:38:03.777114  4932 net.cpp:167] Top shape: 72 352 7 7 (1241856)
I0109 14:38:03.777122  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_1x1
I0109 14:38:03.777125  4932 net.cpp:96] Creating Layer inception_5a/relu_1x1
I0109 14:38:03.777129  4932 net.cpp:459] inception_5a/relu_1x1 <- inception_5a/1x1_bn
I0109 14:38:03.777134  4932 net.cpp:404] inception_5a/relu_1x1 -> inception_5a/1x1_bn (in-place)
I0109 14:38:03.777138  4932 net.cpp:160] Setting up inception_5a/relu_1x1
I0109 14:38:03.777143  4932 net.cpp:167] Top shape: 72 352 7 7 (1241856)
I0109 14:38:03.777146  4932 layer_factory.hpp:74] Creating layer inception_5a/3x3_reduce
I0109 14:38:03.777151  4932 net.cpp:96] Creating Layer inception_5a/3x3_reduce
I0109 14:38:03.777154  4932 net.cpp:459] inception_5a/3x3_reduce <- inception_4e/output_inception_4e/output_0_split_1
I0109 14:38:03.777163  4932 net.cpp:415] inception_5a/3x3_reduce -> inception_5a/3x3_reduce
I0109 14:38:03.777173  4932 net.cpp:160] Setting up inception_5a/3x3_reduce
I0109 14:38:03.778144  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.778152  4932 layer_factory.hpp:74] Creating layer inception_5a/3x3_reduce_bn
I0109 14:38:03.778156  4932 layer_factory.cpp:177] Layer inception_5a/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.778162  4932 net.cpp:96] Creating Layer inception_5a/3x3_reduce_bn
I0109 14:38:03.778165  4932 net.cpp:459] inception_5a/3x3_reduce_bn <- inception_5a/3x3_reduce
I0109 14:38:03.778170  4932 net.cpp:415] inception_5a/3x3_reduce_bn -> inception_5a/3x3_reduce_bn
I0109 14:38:03.778175  4932 net.cpp:160] Setting up inception_5a/3x3_reduce_bn
I0109 14:38:03.778187  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.778193  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_3x3_reduce
I0109 14:38:03.778198  4932 net.cpp:96] Creating Layer inception_5a/relu_3x3_reduce
I0109 14:38:03.778201  4932 net.cpp:459] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce_bn
I0109 14:38:03.778205  4932 net.cpp:404] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce_bn (in-place)
I0109 14:38:03.778210  4932 net.cpp:160] Setting up inception_5a/relu_3x3_reduce
I0109 14:38:03.778214  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.778218  4932 layer_factory.hpp:74] Creating layer inception_5a/3x3
I0109 14:38:03.778223  4932 net.cpp:96] Creating Layer inception_5a/3x3
I0109 14:38:03.778225  4932 net.cpp:459] inception_5a/3x3 <- inception_5a/3x3_reduce_bn
I0109 14:38:03.778231  4932 net.cpp:415] inception_5a/3x3 -> inception_5a/3x3
I0109 14:38:03.778236  4932 net.cpp:160] Setting up inception_5a/3x3
I0109 14:38:03.781083  4932 net.cpp:167] Top shape: 72 320 7 7 (1128960)
I0109 14:38:03.781095  4932 layer_factory.hpp:74] Creating layer inception_5a/3x3_bn
I0109 14:38:03.781100  4932 layer_factory.cpp:177] Layer inception_5a/3x3_bn is using CAFFE engine.
I0109 14:38:03.781106  4932 net.cpp:96] Creating Layer inception_5a/3x3_bn
I0109 14:38:03.781111  4932 net.cpp:459] inception_5a/3x3_bn <- inception_5a/3x3
I0109 14:38:03.781116  4932 net.cpp:415] inception_5a/3x3_bn -> inception_5a/3x3_bn
I0109 14:38:03.781123  4932 net.cpp:160] Setting up inception_5a/3x3_bn
I0109 14:38:03.781137  4932 net.cpp:167] Top shape: 72 320 7 7 (1128960)
I0109 14:38:03.781144  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_3x3
I0109 14:38:03.781148  4932 net.cpp:96] Creating Layer inception_5a/relu_3x3
I0109 14:38:03.781152  4932 net.cpp:459] inception_5a/relu_3x3 <- inception_5a/3x3_bn
I0109 14:38:03.781157  4932 net.cpp:404] inception_5a/relu_3x3 -> inception_5a/3x3_bn (in-place)
I0109 14:38:03.781162  4932 net.cpp:160] Setting up inception_5a/relu_3x3
I0109 14:38:03.781165  4932 net.cpp:167] Top shape: 72 320 7 7 (1128960)
I0109 14:38:03.781168  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_reduce
I0109 14:38:03.781175  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_reduce
I0109 14:38:03.781179  4932 net.cpp:459] inception_5a/double_3x3_reduce <- inception_4e/output_inception_4e/output_0_split_2
I0109 14:38:03.781183  4932 net.cpp:415] inception_5a/double_3x3_reduce -> inception_5a/double_3x3_reduce
I0109 14:38:03.781189  4932 net.cpp:160] Setting up inception_5a/double_3x3_reduce
I0109 14:38:03.782006  4932 net.cpp:167] Top shape: 72 160 7 7 (564480)
I0109 14:38:03.782013  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_reduce_bn
I0109 14:38:03.782017  4932 layer_factory.cpp:177] Layer inception_5a/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.782023  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_reduce_bn
I0109 14:38:03.782027  4932 net.cpp:459] inception_5a/double_3x3_reduce_bn <- inception_5a/double_3x3_reduce
I0109 14:38:03.782032  4932 net.cpp:415] inception_5a/double_3x3_reduce_bn -> inception_5a/double_3x3_reduce_bn
I0109 14:38:03.782038  4932 net.cpp:160] Setting up inception_5a/double_3x3_reduce_bn
I0109 14:38:03.782053  4932 net.cpp:167] Top shape: 72 160 7 7 (564480)
I0109 14:38:03.782064  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_double_3x3_reduce
I0109 14:38:03.782070  4932 net.cpp:96] Creating Layer inception_5a/relu_double_3x3_reduce
I0109 14:38:03.782074  4932 net.cpp:459] inception_5a/relu_double_3x3_reduce <- inception_5a/double_3x3_reduce_bn
I0109 14:38:03.782078  4932 net.cpp:404] inception_5a/relu_double_3x3_reduce -> inception_5a/double_3x3_reduce_bn (in-place)
I0109 14:38:03.782083  4932 net.cpp:160] Setting up inception_5a/relu_double_3x3_reduce
I0109 14:38:03.782086  4932 net.cpp:167] Top shape: 72 160 7 7 (564480)
I0109 14:38:03.782090  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_1
I0109 14:38:03.782095  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_1
I0109 14:38:03.782099  4932 net.cpp:459] inception_5a/double_3x3_1 <- inception_5a/double_3x3_reduce_bn
I0109 14:38:03.782104  4932 net.cpp:415] inception_5a/double_3x3_1 -> inception_5a/double_3x3_1
I0109 14:38:03.782109  4932 net.cpp:160] Setting up inception_5a/double_3x3_1
I0109 14:38:03.783656  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.783664  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_1_bn
I0109 14:38:03.783668  4932 layer_factory.cpp:177] Layer inception_5a/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.783674  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_1_bn
I0109 14:38:03.783677  4932 net.cpp:459] inception_5a/double_3x3_1_bn <- inception_5a/double_3x3_1
I0109 14:38:03.783682  4932 net.cpp:415] inception_5a/double_3x3_1_bn -> inception_5a/double_3x3_1_bn
I0109 14:38:03.783687  4932 net.cpp:160] Setting up inception_5a/double_3x3_1_bn
I0109 14:38:03.783701  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.783707  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_double_3x3_1
I0109 14:38:03.783712  4932 net.cpp:96] Creating Layer inception_5a/relu_double_3x3_1
I0109 14:38:03.783715  4932 net.cpp:459] inception_5a/relu_double_3x3_1 <- inception_5a/double_3x3_1_bn
I0109 14:38:03.783720  4932 net.cpp:404] inception_5a/relu_double_3x3_1 -> inception_5a/double_3x3_1_bn (in-place)
I0109 14:38:03.783725  4932 net.cpp:160] Setting up inception_5a/relu_double_3x3_1
I0109 14:38:03.783728  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.783731  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_2
I0109 14:38:03.783737  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_2
I0109 14:38:03.783740  4932 net.cpp:459] inception_5a/double_3x3_2 <- inception_5a/double_3x3_1_bn
I0109 14:38:03.783746  4932 net.cpp:415] inception_5a/double_3x3_2 -> inception_5a/double_3x3_2
I0109 14:38:03.783751  4932 net.cpp:160] Setting up inception_5a/double_3x3_2
I0109 14:38:03.785929  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.785939  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_2_bn
I0109 14:38:03.785943  4932 layer_factory.cpp:177] Layer inception_5a/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.785949  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_2_bn
I0109 14:38:03.785953  4932 net.cpp:459] inception_5a/double_3x3_2_bn <- inception_5a/double_3x3_2
I0109 14:38:03.785959  4932 net.cpp:415] inception_5a/double_3x3_2_bn -> inception_5a/double_3x3_2_bn
I0109 14:38:03.785965  4932 net.cpp:160] Setting up inception_5a/double_3x3_2_bn
I0109 14:38:03.785977  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.785984  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_double_3x3_2
I0109 14:38:03.785989  4932 net.cpp:96] Creating Layer inception_5a/relu_double_3x3_2
I0109 14:38:03.785992  4932 net.cpp:459] inception_5a/relu_double_3x3_2 <- inception_5a/double_3x3_2_bn
I0109 14:38:03.785996  4932 net.cpp:404] inception_5a/relu_double_3x3_2 -> inception_5a/double_3x3_2_bn (in-place)
I0109 14:38:03.786000  4932 net.cpp:160] Setting up inception_5a/relu_double_3x3_2
I0109 14:38:03.786005  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.786011  4932 layer_factory.hpp:74] Creating layer inception_5a/pool
I0109 14:38:03.786020  4932 net.cpp:96] Creating Layer inception_5a/pool
I0109 14:38:03.786025  4932 net.cpp:459] inception_5a/pool <- inception_4e/output_inception_4e/output_0_split_3
I0109 14:38:03.786028  4932 net.cpp:415] inception_5a/pool -> inception_5a/pool
I0109 14:38:03.786033  4932 net.cpp:160] Setting up inception_5a/pool
I0109 14:38:03.786039  4932 net.cpp:167] Top shape: 72 1056 7 7 (3725568)
I0109 14:38:03.786042  4932 layer_factory.hpp:74] Creating layer inception_5a/pool_proj
I0109 14:38:03.786049  4932 net.cpp:96] Creating Layer inception_5a/pool_proj
I0109 14:38:03.786053  4932 net.cpp:459] inception_5a/pool_proj <- inception_5a/pool
I0109 14:38:03.786058  4932 net.cpp:415] inception_5a/pool_proj -> inception_5a/pool_proj
I0109 14:38:03.786064  4932 net.cpp:160] Setting up inception_5a/pool_proj
I0109 14:38:03.786716  4932 net.cpp:167] Top shape: 72 128 7 7 (451584)
I0109 14:38:03.786723  4932 layer_factory.hpp:74] Creating layer inception_5a/pool_proj_bn
I0109 14:38:03.786727  4932 layer_factory.cpp:177] Layer inception_5a/pool_proj_bn is using CAFFE engine.
I0109 14:38:03.786733  4932 net.cpp:96] Creating Layer inception_5a/pool_proj_bn
I0109 14:38:03.786737  4932 net.cpp:459] inception_5a/pool_proj_bn <- inception_5a/pool_proj
I0109 14:38:03.786742  4932 net.cpp:415] inception_5a/pool_proj_bn -> inception_5a/pool_proj_bn
I0109 14:38:03.786748  4932 net.cpp:160] Setting up inception_5a/pool_proj_bn
I0109 14:38:03.786761  4932 net.cpp:167] Top shape: 72 128 7 7 (451584)
I0109 14:38:03.786767  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_pool_proj
I0109 14:38:03.786772  4932 net.cpp:96] Creating Layer inception_5a/relu_pool_proj
I0109 14:38:03.786775  4932 net.cpp:459] inception_5a/relu_pool_proj <- inception_5a/pool_proj_bn
I0109 14:38:03.786779  4932 net.cpp:404] inception_5a/relu_pool_proj -> inception_5a/pool_proj_bn (in-place)
I0109 14:38:03.786784  4932 net.cpp:160] Setting up inception_5a/relu_pool_proj
I0109 14:38:03.786788  4932 net.cpp:167] Top shape: 72 128 7 7 (451584)
I0109 14:38:03.786792  4932 layer_factory.hpp:74] Creating layer inception_5a/output
I0109 14:38:03.786797  4932 net.cpp:96] Creating Layer inception_5a/output
I0109 14:38:03.786799  4932 net.cpp:459] inception_5a/output <- inception_5a/1x1_bn
I0109 14:38:03.786803  4932 net.cpp:459] inception_5a/output <- inception_5a/3x3_bn
I0109 14:38:03.786808  4932 net.cpp:459] inception_5a/output <- inception_5a/double_3x3_2_bn
I0109 14:38:03.786811  4932 net.cpp:459] inception_5a/output <- inception_5a/pool_proj_bn
I0109 14:38:03.786816  4932 net.cpp:415] inception_5a/output -> inception_5a/output
I0109 14:38:03.786821  4932 net.cpp:160] Setting up inception_5a/output
I0109 14:38:03.786826  4932 net.cpp:167] Top shape: 72 1024 7 7 (3612672)
I0109 14:38:03.786830  4932 layer_factory.hpp:74] Creating layer inception_5a/output_inception_5a/output_0_split
I0109 14:38:03.786835  4932 net.cpp:96] Creating Layer inception_5a/output_inception_5a/output_0_split
I0109 14:38:03.786839  4932 net.cpp:459] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0109 14:38:03.786842  4932 net.cpp:415] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0109 14:38:03.786849  4932 net.cpp:415] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0109 14:38:03.786854  4932 net.cpp:415] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2
I0109 14:38:03.786859  4932 net.cpp:415] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3
I0109 14:38:03.786864  4932 net.cpp:160] Setting up inception_5a/output_inception_5a/output_0_split
I0109 14:38:03.786870  4932 net.cpp:167] Top shape: 72 1024 7 7 (3612672)
I0109 14:38:03.786873  4932 net.cpp:167] Top shape: 72 1024 7 7 (3612672)
I0109 14:38:03.786877  4932 net.cpp:167] Top shape: 72 1024 7 7 (3612672)
I0109 14:38:03.786883  4932 net.cpp:167] Top shape: 72 1024 7 7 (3612672)
I0109 14:38:03.786890  4932 layer_factory.hpp:74] Creating layer inception_5b/1x1
I0109 14:38:03.786896  4932 net.cpp:96] Creating Layer inception_5b/1x1
I0109 14:38:03.786900  4932 net.cpp:459] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0109 14:38:03.786906  4932 net.cpp:415] inception_5b/1x1 -> inception_5b/1x1
I0109 14:38:03.786911  4932 net.cpp:160] Setting up inception_5b/1x1
I0109 14:38:03.788648  4932 net.cpp:167] Top shape: 72 352 7 7 (1241856)
I0109 14:38:03.788657  4932 layer_factory.hpp:74] Creating layer inception_5b/1x1_bn
I0109 14:38:03.788661  4932 layer_factory.cpp:177] Layer inception_5b/1x1_bn is using CAFFE engine.
I0109 14:38:03.788666  4932 net.cpp:96] Creating Layer inception_5b/1x1_bn
I0109 14:38:03.788671  4932 net.cpp:459] inception_5b/1x1_bn <- inception_5b/1x1
I0109 14:38:03.788676  4932 net.cpp:415] inception_5b/1x1_bn -> inception_5b/1x1_bn
I0109 14:38:03.788682  4932 net.cpp:160] Setting up inception_5b/1x1_bn
I0109 14:38:03.788694  4932 net.cpp:167] Top shape: 72 352 7 7 (1241856)
I0109 14:38:03.788702  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_1x1
I0109 14:38:03.788707  4932 net.cpp:96] Creating Layer inception_5b/relu_1x1
I0109 14:38:03.788712  4932 net.cpp:459] inception_5b/relu_1x1 <- inception_5b/1x1_bn
I0109 14:38:03.788715  4932 net.cpp:404] inception_5b/relu_1x1 -> inception_5b/1x1_bn (in-place)
I0109 14:38:03.788719  4932 net.cpp:160] Setting up inception_5b/relu_1x1
I0109 14:38:03.788723  4932 net.cpp:167] Top shape: 72 352 7 7 (1241856)
I0109 14:38:03.788727  4932 layer_factory.hpp:74] Creating layer inception_5b/3x3_reduce
I0109 14:38:03.788732  4932 net.cpp:96] Creating Layer inception_5b/3x3_reduce
I0109 14:38:03.788735  4932 net.cpp:459] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1
I0109 14:38:03.788740  4932 net.cpp:415] inception_5b/3x3_reduce -> inception_5b/3x3_reduce
I0109 14:38:03.788746  4932 net.cpp:160] Setting up inception_5b/3x3_reduce
I0109 14:38:03.789696  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.789706  4932 layer_factory.hpp:74] Creating layer inception_5b/3x3_reduce_bn
I0109 14:38:03.789711  4932 layer_factory.cpp:177] Layer inception_5b/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.789719  4932 net.cpp:96] Creating Layer inception_5b/3x3_reduce_bn
I0109 14:38:03.789726  4932 net.cpp:459] inception_5b/3x3_reduce_bn <- inception_5b/3x3_reduce
I0109 14:38:03.789732  4932 net.cpp:415] inception_5b/3x3_reduce_bn -> inception_5b/3x3_reduce_bn
I0109 14:38:03.789738  4932 net.cpp:160] Setting up inception_5b/3x3_reduce_bn
I0109 14:38:03.789752  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.789759  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_3x3_reduce
I0109 14:38:03.789764  4932 net.cpp:96] Creating Layer inception_5b/relu_3x3_reduce
I0109 14:38:03.789768  4932 net.cpp:459] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce_bn
I0109 14:38:03.789772  4932 net.cpp:404] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce_bn (in-place)
I0109 14:38:03.789777  4932 net.cpp:160] Setting up inception_5b/relu_3x3_reduce
I0109 14:38:03.789782  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.789784  4932 layer_factory.hpp:74] Creating layer inception_5b/3x3
I0109 14:38:03.789789  4932 net.cpp:96] Creating Layer inception_5b/3x3
I0109 14:38:03.789794  4932 net.cpp:459] inception_5b/3x3 <- inception_5b/3x3_reduce_bn
I0109 14:38:03.789798  4932 net.cpp:415] inception_5b/3x3 -> inception_5b/3x3
I0109 14:38:03.789803  4932 net.cpp:160] Setting up inception_5b/3x3
I0109 14:38:03.792234  4932 net.cpp:167] Top shape: 72 320 7 7 (1128960)
I0109 14:38:03.792243  4932 layer_factory.hpp:74] Creating layer inception_5b/3x3_bn
I0109 14:38:03.792246  4932 layer_factory.cpp:177] Layer inception_5b/3x3_bn is using CAFFE engine.
I0109 14:38:03.792253  4932 net.cpp:96] Creating Layer inception_5b/3x3_bn
I0109 14:38:03.792258  4932 net.cpp:459] inception_5b/3x3_bn <- inception_5b/3x3
I0109 14:38:03.792268  4932 net.cpp:415] inception_5b/3x3_bn -> inception_5b/3x3_bn
I0109 14:38:03.792274  4932 net.cpp:160] Setting up inception_5b/3x3_bn
I0109 14:38:03.792287  4932 net.cpp:167] Top shape: 72 320 7 7 (1128960)
I0109 14:38:03.792294  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_3x3
I0109 14:38:03.792299  4932 net.cpp:96] Creating Layer inception_5b/relu_3x3
I0109 14:38:03.792304  4932 net.cpp:459] inception_5b/relu_3x3 <- inception_5b/3x3_bn
I0109 14:38:03.792307  4932 net.cpp:404] inception_5b/relu_3x3 -> inception_5b/3x3_bn (in-place)
I0109 14:38:03.792311  4932 net.cpp:160] Setting up inception_5b/relu_3x3
I0109 14:38:03.792315  4932 net.cpp:167] Top shape: 72 320 7 7 (1128960)
I0109 14:38:03.792318  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_reduce
I0109 14:38:03.792325  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_reduce
I0109 14:38:03.792327  4932 net.cpp:459] inception_5b/double_3x3_reduce <- inception_5a/output_inception_5a/output_0_split_2
I0109 14:38:03.792332  4932 net.cpp:415] inception_5b/double_3x3_reduce -> inception_5b/double_3x3_reduce
I0109 14:38:03.792337  4932 net.cpp:160] Setting up inception_5b/double_3x3_reduce
I0109 14:38:03.793279  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.793287  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_reduce_bn
I0109 14:38:03.793292  4932 layer_factory.cpp:177] Layer inception_5b/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:03.793296  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_reduce_bn
I0109 14:38:03.793299  4932 net.cpp:459] inception_5b/double_3x3_reduce_bn <- inception_5b/double_3x3_reduce
I0109 14:38:03.793305  4932 net.cpp:415] inception_5b/double_3x3_reduce_bn -> inception_5b/double_3x3_reduce_bn
I0109 14:38:03.793311  4932 net.cpp:160] Setting up inception_5b/double_3x3_reduce_bn
I0109 14:38:03.793323  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.793329  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_double_3x3_reduce
I0109 14:38:03.793334  4932 net.cpp:96] Creating Layer inception_5b/relu_double_3x3_reduce
I0109 14:38:03.793337  4932 net.cpp:459] inception_5b/relu_double_3x3_reduce <- inception_5b/double_3x3_reduce_bn
I0109 14:38:03.793341  4932 net.cpp:404] inception_5b/relu_double_3x3_reduce -> inception_5b/double_3x3_reduce_bn (in-place)
I0109 14:38:03.793345  4932 net.cpp:160] Setting up inception_5b/relu_double_3x3_reduce
I0109 14:38:03.793349  4932 net.cpp:167] Top shape: 72 192 7 7 (677376)
I0109 14:38:03.793354  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_1
I0109 14:38:03.793359  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_1
I0109 14:38:03.793362  4932 net.cpp:459] inception_5b/double_3x3_1 <- inception_5b/double_3x3_reduce_bn
I0109 14:38:03.793368  4932 net.cpp:415] inception_5b/double_3x3_1 -> inception_5b/double_3x3_1
I0109 14:38:03.793373  4932 net.cpp:160] Setting up inception_5b/double_3x3_1
I0109 14:38:03.795230  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.795238  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_1_bn
I0109 14:38:03.795241  4932 layer_factory.cpp:177] Layer inception_5b/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:03.795248  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_1_bn
I0109 14:38:03.795251  4932 net.cpp:459] inception_5b/double_3x3_1_bn <- inception_5b/double_3x3_1
I0109 14:38:03.795256  4932 net.cpp:415] inception_5b/double_3x3_1_bn -> inception_5b/double_3x3_1_bn
I0109 14:38:03.795263  4932 net.cpp:160] Setting up inception_5b/double_3x3_1_bn
I0109 14:38:03.795274  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.795280  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_double_3x3_1
I0109 14:38:03.795286  4932 net.cpp:96] Creating Layer inception_5b/relu_double_3x3_1
I0109 14:38:03.795291  4932 net.cpp:459] inception_5b/relu_double_3x3_1 <- inception_5b/double_3x3_1_bn
I0109 14:38:03.795298  4932 net.cpp:404] inception_5b/relu_double_3x3_1 -> inception_5b/double_3x3_1_bn (in-place)
I0109 14:38:03.795311  4932 net.cpp:160] Setting up inception_5b/relu_double_3x3_1
I0109 14:38:03.795315  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.795318  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_2
I0109 14:38:03.795325  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_2
I0109 14:38:03.795327  4932 net.cpp:459] inception_5b/double_3x3_2 <- inception_5b/double_3x3_1_bn
I0109 14:38:03.795333  4932 net.cpp:415] inception_5b/double_3x3_2 -> inception_5b/double_3x3_2
I0109 14:38:03.795338  4932 net.cpp:160] Setting up inception_5b/double_3x3_2
I0109 14:38:03.797602  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.797612  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_2_bn
I0109 14:38:03.797616  4932 layer_factory.cpp:177] Layer inception_5b/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:03.797622  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_2_bn
I0109 14:38:03.797626  4932 net.cpp:459] inception_5b/double_3x3_2_bn <- inception_5b/double_3x3_2
I0109 14:38:03.797632  4932 net.cpp:415] inception_5b/double_3x3_2_bn -> inception_5b/double_3x3_2_bn
I0109 14:38:03.797638  4932 net.cpp:160] Setting up inception_5b/double_3x3_2_bn
I0109 14:38:03.797650  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.797657  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_double_3x3_2
I0109 14:38:03.797663  4932 net.cpp:96] Creating Layer inception_5b/relu_double_3x3_2
I0109 14:38:03.797667  4932 net.cpp:459] inception_5b/relu_double_3x3_2 <- inception_5b/double_3x3_2_bn
I0109 14:38:03.797670  4932 net.cpp:404] inception_5b/relu_double_3x3_2 -> inception_5b/double_3x3_2_bn (in-place)
I0109 14:38:03.797674  4932 net.cpp:160] Setting up inception_5b/relu_double_3x3_2
I0109 14:38:03.797678  4932 net.cpp:167] Top shape: 72 224 7 7 (790272)
I0109 14:38:03.797683  4932 layer_factory.hpp:74] Creating layer inception_5b/pool
I0109 14:38:03.797688  4932 net.cpp:96] Creating Layer inception_5b/pool
I0109 14:38:03.797691  4932 net.cpp:459] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3
I0109 14:38:03.797696  4932 net.cpp:415] inception_5b/pool -> inception_5b/pool
I0109 14:38:03.797701  4932 net.cpp:160] Setting up inception_5b/pool
I0109 14:38:03.797708  4932 net.cpp:167] Top shape: 72 1024 7 7 (3612672)
I0109 14:38:03.797711  4932 layer_factory.hpp:74] Creating layer inception_5b/pool_proj
I0109 14:38:03.797719  4932 net.cpp:96] Creating Layer inception_5b/pool_proj
I0109 14:38:03.797722  4932 net.cpp:459] inception_5b/pool_proj <- inception_5b/pool
I0109 14:38:03.797726  4932 net.cpp:415] inception_5b/pool_proj -> inception_5b/pool_proj
I0109 14:38:03.797731  4932 net.cpp:160] Setting up inception_5b/pool_proj
I0109 14:38:03.798369  4932 net.cpp:167] Top shape: 72 128 7 7 (451584)
I0109 14:38:03.798378  4932 layer_factory.hpp:74] Creating layer inception_5b/pool_proj_bn
I0109 14:38:03.798382  4932 layer_factory.cpp:177] Layer inception_5b/pool_proj_bn is using CAFFE engine.
I0109 14:38:03.798388  4932 net.cpp:96] Creating Layer inception_5b/pool_proj_bn
I0109 14:38:03.798393  4932 net.cpp:459] inception_5b/pool_proj_bn <- inception_5b/pool_proj
I0109 14:38:03.798398  4932 net.cpp:415] inception_5b/pool_proj_bn -> inception_5b/pool_proj_bn
I0109 14:38:03.798403  4932 net.cpp:160] Setting up inception_5b/pool_proj_bn
I0109 14:38:03.798416  4932 net.cpp:167] Top shape: 72 128 7 7 (451584)
I0109 14:38:03.798423  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_pool_proj
I0109 14:38:03.798427  4932 net.cpp:96] Creating Layer inception_5b/relu_pool_proj
I0109 14:38:03.798431  4932 net.cpp:459] inception_5b/relu_pool_proj <- inception_5b/pool_proj_bn
I0109 14:38:03.798436  4932 net.cpp:404] inception_5b/relu_pool_proj -> inception_5b/pool_proj_bn (in-place)
I0109 14:38:03.798440  4932 net.cpp:160] Setting up inception_5b/relu_pool_proj
I0109 14:38:03.798444  4932 net.cpp:167] Top shape: 72 128 7 7 (451584)
I0109 14:38:03.798447  4932 layer_factory.hpp:74] Creating layer inception_5b/output
I0109 14:38:03.798460  4932 net.cpp:96] Creating Layer inception_5b/output
I0109 14:38:03.798463  4932 net.cpp:459] inception_5b/output <- inception_5b/1x1_bn
I0109 14:38:03.798467  4932 net.cpp:459] inception_5b/output <- inception_5b/3x3_bn
I0109 14:38:03.798475  4932 net.cpp:459] inception_5b/output <- inception_5b/double_3x3_2_bn
I0109 14:38:03.798480  4932 net.cpp:459] inception_5b/output <- inception_5b/pool_proj_bn
I0109 14:38:03.798485  4932 net.cpp:415] inception_5b/output -> inception_5b/output
I0109 14:38:03.798490  4932 net.cpp:160] Setting up inception_5b/output
I0109 14:38:03.798496  4932 net.cpp:167] Top shape: 72 1024 7 7 (3612672)
I0109 14:38:03.798499  4932 layer_factory.hpp:74] Creating layer global_pool
I0109 14:38:03.798506  4932 net.cpp:96] Creating Layer global_pool
I0109 14:38:03.798508  4932 net.cpp:459] global_pool <- inception_5b/output
I0109 14:38:03.798513  4932 net.cpp:415] global_pool -> global_pool
I0109 14:38:03.798518  4932 net.cpp:160] Setting up global_pool
I0109 14:38:03.798523  4932 net.cpp:167] Top shape: 72 1024 1 1 (73728)
I0109 14:38:03.798527  4932 layer_factory.hpp:74] Creating layer dropout
I0109 14:38:03.798532  4932 net.cpp:96] Creating Layer dropout
I0109 14:38:03.798535  4932 net.cpp:459] dropout <- global_pool
I0109 14:38:03.798540  4932 net.cpp:404] dropout -> global_pool (in-place)
I0109 14:38:03.798547  4932 net.cpp:160] Setting up dropout
I0109 14:38:03.798553  4932 net.cpp:167] Top shape: 72 1024 1 1 (73728)
I0109 14:38:03.798557  4932 layer_factory.hpp:74] Creating layer fc-action
I0109 14:38:03.798563  4932 net.cpp:96] Creating Layer fc-action
I0109 14:38:03.798565  4932 net.cpp:459] fc-action <- global_pool
I0109 14:38:03.798571  4932 net.cpp:415] fc-action -> fc
I0109 14:38:03.798578  4932 net.cpp:160] Setting up fc-action
I0109 14:38:03.800616  4932 net.cpp:167] Top shape: 72 101 (7272)
I0109 14:38:03.800624  4932 layer_factory.hpp:74] Creating layer reshape_fc
I0109 14:38:03.800631  4932 net.cpp:96] Creating Layer reshape_fc
I0109 14:38:03.800635  4932 net.cpp:459] reshape_fc <- fc
I0109 14:38:03.800640  4932 net.cpp:415] reshape_fc -> reshape_fc
I0109 14:38:03.800647  4932 net.cpp:160] Setting up reshape_fc
I0109 14:38:03.800652  4932 net.cpp:167] Top shape: 24 1 3 101 (7272)
I0109 14:38:03.800657  4932 layer_factory.hpp:74] Creating layer pool_fusion
I0109 14:38:03.800662  4932 net.cpp:96] Creating Layer pool_fusion
I0109 14:38:03.800664  4932 net.cpp:459] pool_fusion <- reshape_fc
I0109 14:38:03.800668  4932 net.cpp:415] pool_fusion -> pool_fc
I0109 14:38:03.800673  4932 net.cpp:160] Setting up pool_fusion
I0109 14:38:03.800678  4932 net.cpp:167] Top shape: 24 1 1 101 (2424)
I0109 14:38:03.800681  4932 layer_factory.hpp:74] Creating layer loss
I0109 14:38:03.800688  4932 net.cpp:96] Creating Layer loss
I0109 14:38:03.800690  4932 net.cpp:459] loss <- pool_fc
I0109 14:38:03.800694  4932 net.cpp:459] loss <- label
I0109 14:38:03.800700  4932 net.cpp:415] loss -> loss
I0109 14:38:03.800707  4932 net.cpp:160] Setting up loss
I0109 14:38:03.800712  4932 layer_factory.hpp:74] Creating layer loss
I0109 14:38:03.800729  4932 net.cpp:167] Top shape: (1)
I0109 14:38:03.800732  4932 net.cpp:169]     with loss weight 1
I0109 14:38:03.800745  4932 net.cpp:239] loss needs backward computation.
I0109 14:38:03.800750  4932 net.cpp:239] pool_fusion needs backward computation.
I0109 14:38:03.800752  4932 net.cpp:239] reshape_fc needs backward computation.
I0109 14:38:03.800756  4932 net.cpp:239] fc-action needs backward computation.
I0109 14:38:03.800760  4932 net.cpp:239] dropout needs backward computation.
I0109 14:38:03.800762  4932 net.cpp:239] global_pool needs backward computation.
I0109 14:38:03.800765  4932 net.cpp:239] inception_5b/output needs backward computation.
I0109 14:38:03.800770  4932 net.cpp:239] inception_5b/relu_pool_proj needs backward computation.
I0109 14:38:03.800772  4932 net.cpp:239] inception_5b/pool_proj_bn needs backward computation.
I0109 14:38:03.800776  4932 net.cpp:239] inception_5b/pool_proj needs backward computation.
I0109 14:38:03.800786  4932 net.cpp:239] inception_5b/pool needs backward computation.
I0109 14:38:03.800789  4932 net.cpp:239] inception_5b/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.800792  4932 net.cpp:239] inception_5b/double_3x3_2_bn needs backward computation.
I0109 14:38:03.800796  4932 net.cpp:239] inception_5b/double_3x3_2 needs backward computation.
I0109 14:38:03.800798  4932 net.cpp:239] inception_5b/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.800801  4932 net.cpp:239] inception_5b/double_3x3_1_bn needs backward computation.
I0109 14:38:03.800804  4932 net.cpp:239] inception_5b/double_3x3_1 needs backward computation.
I0109 14:38:03.800807  4932 net.cpp:239] inception_5b/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.800810  4932 net.cpp:239] inception_5b/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.800813  4932 net.cpp:239] inception_5b/double_3x3_reduce needs backward computation.
I0109 14:38:03.800817  4932 net.cpp:239] inception_5b/relu_3x3 needs backward computation.
I0109 14:38:03.800820  4932 net.cpp:239] inception_5b/3x3_bn needs backward computation.
I0109 14:38:03.800823  4932 net.cpp:239] inception_5b/3x3 needs backward computation.
I0109 14:38:03.800827  4932 net.cpp:239] inception_5b/relu_3x3_reduce needs backward computation.
I0109 14:38:03.800830  4932 net.cpp:239] inception_5b/3x3_reduce_bn needs backward computation.
I0109 14:38:03.800833  4932 net.cpp:239] inception_5b/3x3_reduce needs backward computation.
I0109 14:38:03.800837  4932 net.cpp:239] inception_5b/relu_1x1 needs backward computation.
I0109 14:38:03.800840  4932 net.cpp:239] inception_5b/1x1_bn needs backward computation.
I0109 14:38:03.800843  4932 net.cpp:239] inception_5b/1x1 needs backward computation.
I0109 14:38:03.800848  4932 net.cpp:239] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0109 14:38:03.800850  4932 net.cpp:239] inception_5a/output needs backward computation.
I0109 14:38:03.800855  4932 net.cpp:239] inception_5a/relu_pool_proj needs backward computation.
I0109 14:38:03.800860  4932 net.cpp:239] inception_5a/pool_proj_bn needs backward computation.
I0109 14:38:03.800863  4932 net.cpp:239] inception_5a/pool_proj needs backward computation.
I0109 14:38:03.800866  4932 net.cpp:239] inception_5a/pool needs backward computation.
I0109 14:38:03.800870  4932 net.cpp:239] inception_5a/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.800873  4932 net.cpp:239] inception_5a/double_3x3_2_bn needs backward computation.
I0109 14:38:03.800878  4932 net.cpp:239] inception_5a/double_3x3_2 needs backward computation.
I0109 14:38:03.800881  4932 net.cpp:239] inception_5a/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.800884  4932 net.cpp:239] inception_5a/double_3x3_1_bn needs backward computation.
I0109 14:38:03.800887  4932 net.cpp:239] inception_5a/double_3x3_1 needs backward computation.
I0109 14:38:03.800890  4932 net.cpp:239] inception_5a/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.800894  4932 net.cpp:239] inception_5a/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.800897  4932 net.cpp:239] inception_5a/double_3x3_reduce needs backward computation.
I0109 14:38:03.800901  4932 net.cpp:239] inception_5a/relu_3x3 needs backward computation.
I0109 14:38:03.800904  4932 net.cpp:239] inception_5a/3x3_bn needs backward computation.
I0109 14:38:03.800909  4932 net.cpp:239] inception_5a/3x3 needs backward computation.
I0109 14:38:03.800911  4932 net.cpp:239] inception_5a/relu_3x3_reduce needs backward computation.
I0109 14:38:03.800915  4932 net.cpp:239] inception_5a/3x3_reduce_bn needs backward computation.
I0109 14:38:03.800918  4932 net.cpp:239] inception_5a/3x3_reduce needs backward computation.
I0109 14:38:03.800921  4932 net.cpp:239] inception_5a/relu_1x1 needs backward computation.
I0109 14:38:03.800925  4932 net.cpp:239] inception_5a/1x1_bn needs backward computation.
I0109 14:38:03.800928  4932 net.cpp:239] inception_5a/1x1 needs backward computation.
I0109 14:38:03.800933  4932 net.cpp:239] inception_4e/output_inception_4e/output_0_split needs backward computation.
I0109 14:38:03.800940  4932 net.cpp:239] inception_4e/output needs backward computation.
I0109 14:38:03.800945  4932 net.cpp:239] inception_4e/pool needs backward computation.
I0109 14:38:03.800948  4932 net.cpp:239] inception_4e/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.800951  4932 net.cpp:239] inception_4e/double_3x3_2_bn needs backward computation.
I0109 14:38:03.800956  4932 net.cpp:239] inception_4e/double_3x3_2 needs backward computation.
I0109 14:38:03.800959  4932 net.cpp:239] inception_4e/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.800962  4932 net.cpp:239] inception_4e/double_3x3_1_bn needs backward computation.
I0109 14:38:03.800966  4932 net.cpp:239] inception_4e/double_3x3_1 needs backward computation.
I0109 14:38:03.800969  4932 net.cpp:239] inception_4e/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.800972  4932 net.cpp:239] inception_4e/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.800976  4932 net.cpp:239] inception_4e/double_3x3_reduce needs backward computation.
I0109 14:38:03.800979  4932 net.cpp:239] inception_4e/relu_3x3 needs backward computation.
I0109 14:38:03.800982  4932 net.cpp:239] inception_4e/3x3_bn needs backward computation.
I0109 14:38:03.800987  4932 net.cpp:239] inception_4e/3x3 needs backward computation.
I0109 14:38:03.800989  4932 net.cpp:239] inception_4e/relu_3x3_reduce needs backward computation.
I0109 14:38:03.800992  4932 net.cpp:239] inception_4e/3x3_reduce_bn needs backward computation.
I0109 14:38:03.800997  4932 net.cpp:239] inception_4e/3x3_reduce needs backward computation.
I0109 14:38:03.800999  4932 net.cpp:239] inception_4d/output_inception_4d/output_0_split needs backward computation.
I0109 14:38:03.801003  4932 net.cpp:239] inception_4d/output needs backward computation.
I0109 14:38:03.801007  4932 net.cpp:239] inception_4d/relu_pool_proj needs backward computation.
I0109 14:38:03.801010  4932 net.cpp:239] inception_4d/pool_proj_bn needs backward computation.
I0109 14:38:03.801014  4932 net.cpp:239] inception_4d/pool_proj needs backward computation.
I0109 14:38:03.801017  4932 net.cpp:239] inception_4d/pool needs backward computation.
I0109 14:38:03.801021  4932 net.cpp:239] inception_4d/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.801024  4932 net.cpp:239] inception_4d/double_3x3_2_bn needs backward computation.
I0109 14:38:03.801028  4932 net.cpp:239] inception_4d/double_3x3_2 needs backward computation.
I0109 14:38:03.801031  4932 net.cpp:239] inception_4d/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.801034  4932 net.cpp:239] inception_4d/double_3x3_1_bn needs backward computation.
I0109 14:38:03.801038  4932 net.cpp:239] inception_4d/double_3x3_1 needs backward computation.
I0109 14:38:03.801041  4932 net.cpp:239] inception_4d/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.801044  4932 net.cpp:239] inception_4d/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.801048  4932 net.cpp:239] inception_4d/double_3x3_reduce needs backward computation.
I0109 14:38:03.801051  4932 net.cpp:239] inception_4d/relu_3x3 needs backward computation.
I0109 14:38:03.801054  4932 net.cpp:239] inception_4d/3x3_bn needs backward computation.
I0109 14:38:03.801059  4932 net.cpp:239] inception_4d/3x3 needs backward computation.
I0109 14:38:03.801061  4932 net.cpp:239] inception_4d/relu_3x3_reduce needs backward computation.
I0109 14:38:03.801064  4932 net.cpp:239] inception_4d/3x3_reduce_bn needs backward computation.
I0109 14:38:03.801069  4932 net.cpp:239] inception_4d/3x3_reduce needs backward computation.
I0109 14:38:03.801071  4932 net.cpp:239] inception_4d/relu_1x1 needs backward computation.
I0109 14:38:03.801075  4932 net.cpp:239] inception_4d/1x1_bn needs backward computation.
I0109 14:38:03.801079  4932 net.cpp:239] inception_4d/1x1 needs backward computation.
I0109 14:38:03.801081  4932 net.cpp:239] inception_4c/output_inception_4c/output_0_split needs backward computation.
I0109 14:38:03.801090  4932 net.cpp:239] inception_4c/output needs backward computation.
I0109 14:38:03.801096  4932 net.cpp:239] inception_4c/relu_pool_proj needs backward computation.
I0109 14:38:03.801100  4932 net.cpp:239] inception_4c/pool_proj_bn needs backward computation.
I0109 14:38:03.801105  4932 net.cpp:239] inception_4c/pool_proj needs backward computation.
I0109 14:38:03.801107  4932 net.cpp:239] inception_4c/pool needs backward computation.
I0109 14:38:03.801111  4932 net.cpp:239] inception_4c/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.801115  4932 net.cpp:239] inception_4c/double_3x3_2_bn needs backward computation.
I0109 14:38:03.801118  4932 net.cpp:239] inception_4c/double_3x3_2 needs backward computation.
I0109 14:38:03.801121  4932 net.cpp:239] inception_4c/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.801125  4932 net.cpp:239] inception_4c/double_3x3_1_bn needs backward computation.
I0109 14:38:03.801128  4932 net.cpp:239] inception_4c/double_3x3_1 needs backward computation.
I0109 14:38:03.801131  4932 net.cpp:239] inception_4c/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.801134  4932 net.cpp:239] inception_4c/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.801138  4932 net.cpp:239] inception_4c/double_3x3_reduce needs backward computation.
I0109 14:38:03.801141  4932 net.cpp:239] inception_4c/relu_3x3 needs backward computation.
I0109 14:38:03.801146  4932 net.cpp:239] inception_4c/3x3_bn needs backward computation.
I0109 14:38:03.801148  4932 net.cpp:239] inception_4c/3x3 needs backward computation.
I0109 14:38:03.801152  4932 net.cpp:239] inception_4c/relu_3x3_reduce needs backward computation.
I0109 14:38:03.801156  4932 net.cpp:239] inception_4c/3x3_reduce_bn needs backward computation.
I0109 14:38:03.801158  4932 net.cpp:239] inception_4c/3x3_reduce needs backward computation.
I0109 14:38:03.801162  4932 net.cpp:239] inception_4c/relu_1x1 needs backward computation.
I0109 14:38:03.801165  4932 net.cpp:239] inception_4c/1x1_bn needs backward computation.
I0109 14:38:03.801169  4932 net.cpp:239] inception_4c/1x1 needs backward computation.
I0109 14:38:03.801172  4932 net.cpp:239] inception_4b/output_inception_4b/output_0_split needs backward computation.
I0109 14:38:03.801177  4932 net.cpp:239] inception_4b/output needs backward computation.
I0109 14:38:03.801180  4932 net.cpp:239] inception_4b/relu_pool_proj needs backward computation.
I0109 14:38:03.801183  4932 net.cpp:239] inception_4b/pool_proj_bn needs backward computation.
I0109 14:38:03.801187  4932 net.cpp:239] inception_4b/pool_proj needs backward computation.
I0109 14:38:03.801190  4932 net.cpp:239] inception_4b/pool needs backward computation.
I0109 14:38:03.801194  4932 net.cpp:239] inception_4b/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.801198  4932 net.cpp:239] inception_4b/double_3x3_2_bn needs backward computation.
I0109 14:38:03.801200  4932 net.cpp:239] inception_4b/double_3x3_2 needs backward computation.
I0109 14:38:03.801204  4932 net.cpp:239] inception_4b/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.801208  4932 net.cpp:239] inception_4b/double_3x3_1_bn needs backward computation.
I0109 14:38:03.801210  4932 net.cpp:239] inception_4b/double_3x3_1 needs backward computation.
I0109 14:38:03.801214  4932 net.cpp:239] inception_4b/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.801218  4932 net.cpp:239] inception_4b/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.801220  4932 net.cpp:239] inception_4b/double_3x3_reduce needs backward computation.
I0109 14:38:03.801224  4932 net.cpp:239] inception_4b/relu_3x3 needs backward computation.
I0109 14:38:03.801228  4932 net.cpp:239] inception_4b/3x3_bn needs backward computation.
I0109 14:38:03.801230  4932 net.cpp:239] inception_4b/3x3 needs backward computation.
I0109 14:38:03.801235  4932 net.cpp:239] inception_4b/relu_3x3_reduce needs backward computation.
I0109 14:38:03.801240  4932 net.cpp:239] inception_4b/3x3_reduce_bn needs backward computation.
I0109 14:38:03.801249  4932 net.cpp:239] inception_4b/3x3_reduce needs backward computation.
I0109 14:38:03.801251  4932 net.cpp:239] inception_4b/relu_1x1 needs backward computation.
I0109 14:38:03.801255  4932 net.cpp:239] inception_4b/1x1_bn needs backward computation.
I0109 14:38:03.801259  4932 net.cpp:239] inception_4b/1x1 needs backward computation.
I0109 14:38:03.801262  4932 net.cpp:239] inception_4a/output_inception_4a/output_0_split needs backward computation.
I0109 14:38:03.801266  4932 net.cpp:239] inception_4a/output needs backward computation.
I0109 14:38:03.801270  4932 net.cpp:239] inception_4a/relu_pool_proj needs backward computation.
I0109 14:38:03.801273  4932 net.cpp:239] inception_4a/pool_proj_bn needs backward computation.
I0109 14:38:03.801276  4932 net.cpp:239] inception_4a/pool_proj needs backward computation.
I0109 14:38:03.801280  4932 net.cpp:239] inception_4a/pool needs backward computation.
I0109 14:38:03.801283  4932 net.cpp:239] inception_4a/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.801287  4932 net.cpp:239] inception_4a/double_3x3_2_bn needs backward computation.
I0109 14:38:03.801290  4932 net.cpp:239] inception_4a/double_3x3_2 needs backward computation.
I0109 14:38:03.801293  4932 net.cpp:239] inception_4a/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.801296  4932 net.cpp:239] inception_4a/double_3x3_1_bn needs backward computation.
I0109 14:38:03.801301  4932 net.cpp:239] inception_4a/double_3x3_1 needs backward computation.
I0109 14:38:03.801303  4932 net.cpp:239] inception_4a/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.801306  4932 net.cpp:239] inception_4a/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.801311  4932 net.cpp:239] inception_4a/double_3x3_reduce needs backward computation.
I0109 14:38:03.801313  4932 net.cpp:239] inception_4a/relu_3x3 needs backward computation.
I0109 14:38:03.801317  4932 net.cpp:239] inception_4a/3x3_bn needs backward computation.
I0109 14:38:03.801321  4932 net.cpp:239] inception_4a/3x3 needs backward computation.
I0109 14:38:03.801324  4932 net.cpp:239] inception_4a/relu_3x3_reduce needs backward computation.
I0109 14:38:03.801327  4932 net.cpp:239] inception_4a/3x3_reduce_bn needs backward computation.
I0109 14:38:03.801331  4932 net.cpp:239] inception_4a/3x3_reduce needs backward computation.
I0109 14:38:03.801334  4932 net.cpp:239] inception_4a/relu_1x1 needs backward computation.
I0109 14:38:03.801337  4932 net.cpp:239] inception_4a/1x1_bn needs backward computation.
I0109 14:38:03.801342  4932 net.cpp:239] inception_4a/1x1 needs backward computation.
I0109 14:38:03.801344  4932 net.cpp:239] inception_3c/output_inception_3c/output_0_split needs backward computation.
I0109 14:38:03.801348  4932 net.cpp:239] inception_3c/output needs backward computation.
I0109 14:38:03.801352  4932 net.cpp:239] inception_3c/pool needs backward computation.
I0109 14:38:03.801357  4932 net.cpp:239] inception_3c/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.801359  4932 net.cpp:239] inception_3c/double_3x3_2_bn needs backward computation.
I0109 14:38:03.801362  4932 net.cpp:239] inception_3c/double_3x3_2 needs backward computation.
I0109 14:38:03.801367  4932 net.cpp:239] inception_3c/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.801369  4932 net.cpp:239] inception_3c/double_3x3_1_bn needs backward computation.
I0109 14:38:03.801373  4932 net.cpp:239] inception_3c/double_3x3_1 needs backward computation.
I0109 14:38:03.801376  4932 net.cpp:239] inception_3c/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.801379  4932 net.cpp:239] inception_3c/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.801383  4932 net.cpp:239] inception_3c/double_3x3_reduce needs backward computation.
I0109 14:38:03.801386  4932 net.cpp:239] inception_3c/relu_3x3 needs backward computation.
I0109 14:38:03.801389  4932 net.cpp:239] inception_3c/3x3_bn needs backward computation.
I0109 14:38:03.801394  4932 net.cpp:239] inception_3c/3x3 needs backward computation.
I0109 14:38:03.801401  4932 net.cpp:239] inception_3c/relu_3x3_reduce needs backward computation.
I0109 14:38:03.801405  4932 net.cpp:239] inception_3c/3x3_reduce_bn needs backward computation.
I0109 14:38:03.801409  4932 net.cpp:239] inception_3c/3x3_reduce needs backward computation.
I0109 14:38:03.801412  4932 net.cpp:239] inception_3b/output_inception_3b/output_0_split needs backward computation.
I0109 14:38:03.801415  4932 net.cpp:239] inception_3b/output needs backward computation.
I0109 14:38:03.801420  4932 net.cpp:239] inception_3b/relu_pool_proj needs backward computation.
I0109 14:38:03.801424  4932 net.cpp:239] inception_3b/pool_proj_bn needs backward computation.
I0109 14:38:03.801427  4932 net.cpp:239] inception_3b/pool_proj needs backward computation.
I0109 14:38:03.801430  4932 net.cpp:239] inception_3b/pool needs backward computation.
I0109 14:38:03.801434  4932 net.cpp:239] inception_3b/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.801437  4932 net.cpp:239] inception_3b/double_3x3_2_bn needs backward computation.
I0109 14:38:03.801440  4932 net.cpp:239] inception_3b/double_3x3_2 needs backward computation.
I0109 14:38:03.801445  4932 net.cpp:239] inception_3b/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.801447  4932 net.cpp:239] inception_3b/double_3x3_1_bn needs backward computation.
I0109 14:38:03.801451  4932 net.cpp:239] inception_3b/double_3x3_1 needs backward computation.
I0109 14:38:03.801455  4932 net.cpp:239] inception_3b/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.801460  4932 net.cpp:239] inception_3b/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.801462  4932 net.cpp:239] inception_3b/double_3x3_reduce needs backward computation.
I0109 14:38:03.801466  4932 net.cpp:239] inception_3b/relu_3x3 needs backward computation.
I0109 14:38:03.801470  4932 net.cpp:239] inception_3b/3x3_bn needs backward computation.
I0109 14:38:03.801473  4932 net.cpp:239] inception_3b/3x3 needs backward computation.
I0109 14:38:03.801476  4932 net.cpp:239] inception_3b/relu_3x3_reduce needs backward computation.
I0109 14:38:03.801481  4932 net.cpp:239] inception_3b/3x3_reduce_bn needs backward computation.
I0109 14:38:03.801484  4932 net.cpp:239] inception_3b/3x3_reduce needs backward computation.
I0109 14:38:03.801487  4932 net.cpp:239] inception_3b/relu_1x1 needs backward computation.
I0109 14:38:03.801491  4932 net.cpp:239] inception_3b/1x1_bn needs backward computation.
I0109 14:38:03.801494  4932 net.cpp:239] inception_3b/1x1 needs backward computation.
I0109 14:38:03.801497  4932 net.cpp:239] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0109 14:38:03.801501  4932 net.cpp:239] inception_3a/output needs backward computation.
I0109 14:38:03.801506  4932 net.cpp:239] inception_3a/relu_pool_proj needs backward computation.
I0109 14:38:03.801508  4932 net.cpp:239] inception_3a/pool_proj_bn needs backward computation.
I0109 14:38:03.801512  4932 net.cpp:239] inception_3a/pool_proj needs backward computation.
I0109 14:38:03.801515  4932 net.cpp:239] inception_3a/pool needs backward computation.
I0109 14:38:03.801519  4932 net.cpp:239] inception_3a/relu_double_3x3_2 needs backward computation.
I0109 14:38:03.801522  4932 net.cpp:239] inception_3a/double_3x3_2_bn needs backward computation.
I0109 14:38:03.801527  4932 net.cpp:239] inception_3a/double_3x3_2 needs backward computation.
I0109 14:38:03.801529  4932 net.cpp:239] inception_3a/relu_double_3x3_1 needs backward computation.
I0109 14:38:03.801532  4932 net.cpp:239] inception_3a/double_3x3_1_bn needs backward computation.
I0109 14:38:03.801537  4932 net.cpp:239] inception_3a/double_3x3_1 needs backward computation.
I0109 14:38:03.801539  4932 net.cpp:239] inception_3a/relu_double_3x3_reduce needs backward computation.
I0109 14:38:03.801543  4932 net.cpp:239] inception_3a/double_3x3_reduce_bn needs backward computation.
I0109 14:38:03.801547  4932 net.cpp:239] inception_3a/double_3x3_reduce needs backward computation.
I0109 14:38:03.801554  4932 net.cpp:239] inception_3a/relu_3x3 needs backward computation.
I0109 14:38:03.801558  4932 net.cpp:239] inception_3a/3x3_bn needs backward computation.
I0109 14:38:03.801563  4932 net.cpp:239] inception_3a/3x3 needs backward computation.
I0109 14:38:03.801565  4932 net.cpp:239] inception_3a/relu_3x3_reduce needs backward computation.
I0109 14:38:03.801568  4932 net.cpp:239] inception_3a/3x3_reduce_bn needs backward computation.
I0109 14:38:03.801573  4932 net.cpp:239] inception_3a/3x3_reduce needs backward computation.
I0109 14:38:03.801575  4932 net.cpp:239] inception_3a/relu_1x1 needs backward computation.
I0109 14:38:03.801579  4932 net.cpp:239] inception_3a/1x1_bn needs backward computation.
I0109 14:38:03.801583  4932 net.cpp:239] inception_3a/1x1 needs backward computation.
I0109 14:38:03.801586  4932 net.cpp:239] pool2/3x3_s2_pool2/3x3_s2_0_split needs backward computation.
I0109 14:38:03.801589  4932 net.cpp:239] pool2/3x3_s2 needs backward computation.
I0109 14:38:03.801594  4932 net.cpp:239] conv2/relu_3x3 needs backward computation.
I0109 14:38:03.801596  4932 net.cpp:239] conv2/3x3_bn needs backward computation.
I0109 14:38:03.801599  4932 net.cpp:239] conv2/3x3 needs backward computation.
I0109 14:38:03.801604  4932 net.cpp:239] conv2/relu_3x3_reduce needs backward computation.
I0109 14:38:03.801606  4932 net.cpp:239] conv2/3x3_reduce_bn needs backward computation.
I0109 14:38:03.801610  4932 net.cpp:239] conv2/3x3_reduce needs backward computation.
I0109 14:38:03.801614  4932 net.cpp:239] pool1/3x3_s2 needs backward computation.
I0109 14:38:03.801617  4932 net.cpp:239] conv1/relu_7x7 needs backward computation.
I0109 14:38:03.801620  4932 net.cpp:239] conv1/7x7_s2_bn needs backward computation.
I0109 14:38:03.801625  4932 net.cpp:239] conv1/7x7_s2 needs backward computation.
I0109 14:38:03.801627  4932 net.cpp:241] data_reshape does not need backward computation.
I0109 14:38:03.801631  4932 net.cpp:241] data does not need backward computation.
I0109 14:38:03.801635  4932 net.cpp:282] This network produces output loss
I0109 14:38:03.801750  4932 net.cpp:531] Collecting Learning Rate and Weight Decay.
I0109 14:38:03.801776  4932 net.cpp:294] Network initialization done.
I0109 14:38:03.801780  4932 net.cpp:295] Memory required for data: 5617459588
I0109 14:38:03.806859  4932 solver.cpp:159] Creating test net (#0) specified by net file: /home/hadoop/whx/tsncaffe/mywork/ucf101/tsn_bn_inception_flow_train_val.prototxt
I0109 14:38:03.807075  4932 net.cpp:334] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0109 14:38:03.808989  4932 net.cpp:46] Initializing net from parameters: 
name: "BN-Inception"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "VideoData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 128
    is_flow: true
  }
  video_data_param {
    source: "/home/hadoop/whx/dataset/ucf101/val_flow_split1.txt"
    batch_size: 1
    new_length: 5
    num_segments: 3
    modality: FLOW
    name_pattern: "flow_%c_%04d.jpg"
  }
}
layer {
  name: "data_reshape"
  type: "Reshape"
  bottom: "data"
  top: "data_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 10
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "conv1/7x7_s2"
  type: "Convolution"
  bottom: "data_reshape"
  top: "conv1/7x7_s2"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/7x7_s2_bn"
  type: "BN"
  bottom: "conv1/7x7_s2"
  top: "conv1/7x7_s2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: false
    engine: CAFFE
  }
}
layer {
  name: "conv1/relu_7x7"
  type: "ReLU"
  bottom: "conv1/7x7_s2_bn"
  top: "conv1/7x7_s2_bn"
}
layer {
  name: "pool1/3x3_s2"
  type: "Pooling"
  bottom: "conv1/7x7_s2_bn"
  top: "pool1/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2/3x3_reduce"
  type: "Convolution"
  bottom: "pool1/3x3_s2"
  top: "conv2/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/3x3_reduce_bn"
  type: "BN"
  bottom: "conv2/3x3_reduce"
  top: "conv2/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "conv2/relu_3x3_reduce"
  type: "ReLU"
  bottom: "conv2/3x3_reduce_bn"
  top: "conv2/3x3_reduce_bn"
}
layer {
  name: "conv2/3x3"
  type: "Convolution"
  bottom: "conv2/3x3_reduce_bn"
  top: "conv2/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/3x3_bn"
  type: "BN"
  bottom: "conv2/3x3"
  top: "conv2/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "conv2/relu_3x3"
  type: "ReLU"
  bottom: "conv2/3x3_bn"
  top: "conv2/3x3_bn"
}
layer {
  name: "pool2/3x3_s2"
  type: "Pooling"
  bottom: "conv2/3x3_bn"
  top: "pool2/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "pool2/3x3_s2"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/1x1_bn"
  type: "BN"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_1x1"
  type: "ReLU"
  bottom: "inception_3a/1x1_bn"
  top: "inception_3a/1x1_bn"
}
layer {
  name: "inception_3a/3x3_reduce"
  type: "Convolution"
  bottom: "pool2/3x3_s2"
  top: "inception_3a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/3x3_reduce_bn"
  top: "inception_3a/3x3_reduce_bn"
}
layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_3a/3x3_reduce_bn"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/3x3_bn"
  type: "BN"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_3x3"
  type: "ReLU"
  bottom: "inception_3a/3x3_bn"
  top: "inception_3a/3x3_bn"
}
layer {
  name: "inception_3a/double_3x3_reduce"
  type: "Convolution"
  bottom: "pool2/3x3_s2"
  top: "inception_3a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3a/double_3x3_reduce"
  top: "inception_3a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/double_3x3_reduce_bn"
  top: "inception_3a/double_3x3_reduce_bn"
}
layer {
  name: "inception_3a/double_3x3_1"
  type: "Convolution"
  bottom: "inception_3a/double_3x3_reduce_bn"
  top: "inception_3a/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_3a/double_3x3_1"
  top: "inception_3a/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_3a/double_3x3_1_bn"
  top: "inception_3a/double_3x3_1_bn"
}
layer {
  name: "inception_3a/double_3x3_2"
  type: "Convolution"
  bottom: "inception_3a/double_3x3_1_bn"
  top: "inception_3a/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_3a/double_3x3_2"
  top: "inception_3a/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_3a/double_3x3_2_bn"
  top: "inception_3a/double_3x3_2_bn"
}
layer {
  name: "inception_3a/pool"
  type: "Pooling"
  bottom: "pool2/3x3_s2"
  top: "inception_3a/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_3a/pool_proj"
  type: "Convolution"
  bottom: "inception_3a/pool"
  top: "inception_3a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3a/pool_proj_bn"
  type: "BN"
  bottom: "inception_3a/pool_proj"
  top: "inception_3a/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3a/pool_proj_bn"
  top: "inception_3a/pool_proj_bn"
}
layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1_bn"
  bottom: "inception_3a/3x3_bn"
  bottom: "inception_3a/double_3x3_2_bn"
  bottom: "inception_3a/pool_proj_bn"
  top: "inception_3a/output"
}
layer {
  name: "inception_3b/1x1"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "inception_3b/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/1x1_bn"
  type: "BN"
  bottom: "inception_3b/1x1"
  top: "inception_3b/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_1x1"
  type: "ReLU"
  bottom: "inception_3b/1x1_bn"
  top: "inception_3b/1x1_bn"
}
layer {
  name: "inception_3b/3x3_reduce"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "inception_3b/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3b/3x3_reduce"
  top: "inception_3b/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3b/3x3_reduce_bn"
  top: "inception_3b/3x3_reduce_bn"
}
layer {
  name: "inception_3b/3x3"
  type: "Convolution"
  bottom: "inception_3b/3x3_reduce_bn"
  top: "inception_3b/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/3x3_bn"
  type: "BN"
  bottom: "inception_3b/3x3"
  top: "inception_3b/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_3x3"
  type: "ReLU"
  bottom: "inception_3b/3x3_bn"
  top: "inception_3b/3x3_bn"
}
layer {
  name: "inception_3b/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_3a/output"
  top: "inception_3b/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3b/double_3x3_reduce"
  top: "inception_3b/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3b/double_3x3_reduce_bn"
  top: "inception_3b/double_3x3_reduce_bn"
}
layer {
  name: "inception_3b/double_3x3_1"
  type: "Convolution"
  bottom: "inception_3b/double_3x3_reduce_bn"
  top: "inception_3b/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_3b/double_3x3_1"
  top: "inception_3b/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_3b/double_3x3_1_bn"
  top: "inception_3b/double_3x3_1_bn"
}
layer {
  name: "inception_3b/double_3x3_2"
  type: "Convolution"
  bottom: "inception_3b/double_3x3_1_bn"
  top: "inception_3b/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_3b/double_3x3_2"
  top: "inception_3b/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_3b/double_3x3_2_bn"
  top: "inception_3b/double_3x3_2_bn"
}
layer {
  name: "inception_3b/pool"
  type: "Pooling"
  bottom: "inception_3a/output"
  top: "inception_3b/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_3b/pool_proj"
  type: "Convolution"
  bottom: "inception_3b/pool"
  top: "inception_3b/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3b/pool_proj_bn"
  type: "BN"
  bottom: "inception_3b/pool_proj"
  top: "inception_3b/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3b/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3b/pool_proj_bn"
  top: "inception_3b/pool_proj_bn"
}
layer {
  name: "inception_3b/output"
  type: "Concat"
  bottom: "inception_3b/1x1_bn"
  bottom: "inception_3b/3x3_bn"
  bottom: "inception_3b/double_3x3_2_bn"
  bottom: "inception_3b/pool_proj_bn"
  top: "inception_3b/output"
}
layer {
  name: "inception_3c/3x3_reduce"
  type: "Convolution"
  bottom: "inception_3b/output"
  top: "inception_3c/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3c/3x3_reduce"
  top: "inception_3c/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3c/3x3_reduce_bn"
  top: "inception_3c/3x3_reduce_bn"
}
layer {
  name: "inception_3c/3x3"
  type: "Convolution"
  bottom: "inception_3c/3x3_reduce_bn"
  top: "inception_3c/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/3x3_bn"
  type: "BN"
  bottom: "inception_3c/3x3"
  top: "inception_3c/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_3x3"
  type: "ReLU"
  bottom: "inception_3c/3x3_bn"
  top: "inception_3c/3x3_bn"
}
layer {
  name: "inception_3c/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_3b/output"
  top: "inception_3c/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_3c/double_3x3_reduce"
  top: "inception_3c/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3c/double_3x3_reduce_bn"
  top: "inception_3c/double_3x3_reduce_bn"
}
layer {
  name: "inception_3c/double_3x3_1"
  type: "Convolution"
  bottom: "inception_3c/double_3x3_reduce_bn"
  top: "inception_3c/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_3c/double_3x3_1"
  top: "inception_3c/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_3c/double_3x3_1_bn"
  top: "inception_3c/double_3x3_1_bn"
}
layer {
  name: "inception_3c/double_3x3_2"
  type: "Convolution"
  bottom: "inception_3c/double_3x3_1_bn"
  top: "inception_3c/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_3c/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_3c/double_3x3_2"
  top: "inception_3c/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_3c/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_3c/double_3x3_2_bn"
  top: "inception_3c/double_3x3_2_bn"
}
layer {
  name: "inception_3c/pool"
  type: "Pooling"
  bottom: "inception_3b/output"
  top: "inception_3c/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "inception_3c/output"
  type: "Concat"
  bottom: "inception_3c/3x3_bn"
  bottom: "inception_3c/double_3x3_2_bn"
  bottom: "inception_3c/pool"
  top: "inception_3c/output"
}
layer {
  name: "inception_4a/1x1"
  type: "Convolution"
  bottom: "inception_3c/output"
  top: "inception_4a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 224
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/1x1_bn"
  type: "BN"
  bottom: "inception_4a/1x1"
  top: "inception_4a/1x1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_1x1"
  type: "ReLU"
  bottom: "inception_4a/1x1_bn"
  top: "inception_4a/1x1_bn"
}
layer {
  name: "inception_4a/3x3_reduce"
  type: "Convolution"
  bottom: "inception_3c/output"
  top: "inception_4a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/3x3_reduce_bn"
  type: "BN"
  bottom: "inception_4a/3x3_reduce"
  top: "inception_4a/3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4a/3x3_reduce_bn"
  top: "inception_4a/3x3_reduce_bn"
}
layer {
  name: "inception_4a/3x3"
  type: "Convolution"
  bottom: "inception_4a/3x3_reduce_bn"
  top: "inception_4a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/3x3_bn"
  type: "BN"
  bottom: "inception_4a/3x3"
  top: "inception_4a/3x3_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_3x3"
  type: "ReLU"
  bottom: "inception_4a/3x3_bn"
  top: "inception_4a/3x3_bn"
}
layer {
  name: "inception_4a/double_3x3_reduce"
  type: "Convolution"
  bottom: "inception_3c/output"
  top: "inception_4a/double_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/double_3x3_reduce_bn"
  type: "BN"
  bottom: "inception_4a/double_3x3_reduce"
  top: "inception_4a/double_3x3_reduce_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_double_3x3_reduce"
  type: "ReLU"
  bottom: "inception_4a/double_3x3_reduce_bn"
  top: "inception_4a/double_3x3_reduce_bn"
}
layer {
  name: "inception_4a/double_3x3_1"
  type: "Convolution"
  bottom: "inception_4a/double_3x3_reduce_bn"
  top: "inception_4a/double_3x3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/double_3x3_1_bn"
  type: "BN"
  bottom: "inception_4a/double_3x3_1"
  top: "inception_4a/double_3x3_1_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_double_3x3_1"
  type: "ReLU"
  bottom: "inception_4a/double_3x3_1_bn"
  top: "inception_4a/double_3x3_1_bn"
}
layer {
  name: "inception_4a/double_3x3_2"
  type: "Convolution"
  bottom: "inception_4a/double_3x3_1_bn"
  top: "inception_4a/double_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/double_3x3_2_bn"
  type: "BN"
  bottom: "inception_4a/double_3x3_2"
  top: "inception_4a/double_3x3_2_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_double_3x3_2"
  type: "ReLU"
  bottom: "inception_4a/double_3x3_2_bn"
  top: "inception_4a/double_3x3_2_bn"
}
layer {
  name: "inception_4a/pool"
  type: "Pooling"
  bottom: "inception_3c/output"
  top: "inception_4a/pool"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "inception_4a/pool_proj"
  type: "Convolution"
  bottom: "inception_4a/pool"
  top: "inception_4a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "inception_4a/pool_proj_bn"
  type: "BN"
  bottom: "inception_4a/pool_proj"
  top: "inception_4a/pool_proj_bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    engine: CAFFE
  }
}
layer {
  name: "inception_4a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_4a/pool_proj_bn"
  top: "inception_4a/pool_proj_bn"
}
layer {
  name: "inception_4a/output"
  type: "Concat"
  bottom: "inception_4a/1x1_bn"
  bottom: "inception_4a/3x3_bn"
  bottom: "inception_4a/double_3x3_2_bn"
  bottom: "inception_4a/pool_proj_bn"
  top: "inception_4a/output"
}
layer {
  name: "inception_4
I0109 14:38:03.809772  4932 layer_factory.hpp:74] Creating layer data
I0109 14:38:03.809782  4932 net.cpp:96] Creating Layer data
I0109 14:38:03.809793  4932 net.cpp:415] data -> data
I0109 14:38:03.809808  4932 net.cpp:415] data -> label
I0109 14:38:03.809813  4932 net.cpp:160] Setting up data
I0109 14:38:03.809818  4932 video_data_layer.cpp:34] Opening file: /home/hadoop/whx/dataset/ucf101/val_flow_split1.txt
I0109 14:38:03.811386  4932 video_data_layer.cpp:50] A total of 3783 videos.
I0109 14:38:04.491367  4932 video_data_layer.cpp:89] output data size: 1,30,224,224
I0109 14:38:04.492415  4932 net.cpp:167] Top shape: 1 30 224 224 (1505280)
I0109 14:38:04.492425  4932 net.cpp:167] Top shape: 1 1 1 1 (1)
I0109 14:38:04.492431  4932 layer_factory.hpp:74] Creating layer label_data_1_split
I0109 14:38:04.492441  4932 net.cpp:96] Creating Layer label_data_1_split
I0109 14:38:04.492445  4932 net.cpp:459] label_data_1_split <- label
I0109 14:38:04.492450  4932 net.cpp:415] label_data_1_split -> label_data_1_split_0
I0109 14:38:04.492458  4932 net.cpp:415] label_data_1_split -> label_data_1_split_1
I0109 14:38:04.492467  4932 net.cpp:160] Setting up label_data_1_split
I0109 14:38:04.492475  4932 net.cpp:167] Top shape: 1 1 1 1 (1)
I0109 14:38:04.492478  4932 net.cpp:167] Top shape: 1 1 1 1 (1)
I0109 14:38:04.492482  4932 layer_factory.hpp:74] Creating layer data_reshape
I0109 14:38:04.492489  4932 net.cpp:96] Creating Layer data_reshape
I0109 14:38:04.492492  4932 net.cpp:459] data_reshape <- data
I0109 14:38:04.492497  4932 net.cpp:415] data_reshape -> data_reshape
I0109 14:38:04.492502  4932 net.cpp:160] Setting up data_reshape
I0109 14:38:04.492508  4932 net.cpp:167] Top shape: 3 10 224 224 (1505280)
I0109 14:38:04.492512  4932 layer_factory.hpp:74] Creating layer conv1/7x7_s2
I0109 14:38:04.492519  4932 net.cpp:96] Creating Layer conv1/7x7_s2
I0109 14:38:04.492522  4932 net.cpp:459] conv1/7x7_s2 <- data_reshape
I0109 14:38:04.492527  4932 net.cpp:415] conv1/7x7_s2 -> conv1/7x7_s2
I0109 14:38:04.492532  4932 net.cpp:160] Setting up conv1/7x7_s2
I0109 14:38:04.492676  4932 net.cpp:167] Top shape: 3 64 112 112 (2408448)
I0109 14:38:04.492683  4932 layer_factory.hpp:74] Creating layer conv1/7x7_s2_bn
I0109 14:38:04.492687  4932 layer_factory.cpp:177] Layer conv1/7x7_s2_bn is using CAFFE engine.
I0109 14:38:04.492693  4932 net.cpp:96] Creating Layer conv1/7x7_s2_bn
I0109 14:38:04.492697  4932 net.cpp:459] conv1/7x7_s2_bn <- conv1/7x7_s2
I0109 14:38:04.492702  4932 net.cpp:415] conv1/7x7_s2_bn -> conv1/7x7_s2_bn
I0109 14:38:04.492707  4932 net.cpp:160] Setting up conv1/7x7_s2_bn
I0109 14:38:04.492729  4932 net.cpp:167] Top shape: 3 64 112 112 (2408448)
I0109 14:38:04.492738  4932 layer_factory.hpp:74] Creating layer conv1/relu_7x7
I0109 14:38:04.492743  4932 net.cpp:96] Creating Layer conv1/relu_7x7
I0109 14:38:04.492745  4932 net.cpp:459] conv1/relu_7x7 <- conv1/7x7_s2_bn
I0109 14:38:04.492749  4932 net.cpp:404] conv1/relu_7x7 -> conv1/7x7_s2_bn (in-place)
I0109 14:38:04.492753  4932 net.cpp:160] Setting up conv1/relu_7x7
I0109 14:38:04.492758  4932 net.cpp:167] Top shape: 3 64 112 112 (2408448)
I0109 14:38:04.492760  4932 layer_factory.hpp:74] Creating layer pool1/3x3_s2
I0109 14:38:04.492766  4932 net.cpp:96] Creating Layer pool1/3x3_s2
I0109 14:38:04.492769  4932 net.cpp:459] pool1/3x3_s2 <- conv1/7x7_s2_bn
I0109 14:38:04.492774  4932 net.cpp:415] pool1/3x3_s2 -> pool1/3x3_s2
I0109 14:38:04.492779  4932 net.cpp:160] Setting up pool1/3x3_s2
I0109 14:38:04.492784  4932 net.cpp:167] Top shape: 3 64 56 56 (602112)
I0109 14:38:04.492787  4932 layer_factory.hpp:74] Creating layer conv2/3x3_reduce
I0109 14:38:04.492794  4932 net.cpp:96] Creating Layer conv2/3x3_reduce
I0109 14:38:04.492797  4932 net.cpp:459] conv2/3x3_reduce <- pool1/3x3_s2
I0109 14:38:04.492801  4932 net.cpp:415] conv2/3x3_reduce -> conv2/3x3_reduce
I0109 14:38:04.492806  4932 net.cpp:160] Setting up conv2/3x3_reduce
I0109 14:38:04.492836  4932 net.cpp:167] Top shape: 3 64 56 56 (602112)
I0109 14:38:04.492841  4932 layer_factory.hpp:74] Creating layer conv2/3x3_reduce_bn
I0109 14:38:04.492846  4932 layer_factory.cpp:177] Layer conv2/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.492856  4932 net.cpp:96] Creating Layer conv2/3x3_reduce_bn
I0109 14:38:04.492864  4932 net.cpp:459] conv2/3x3_reduce_bn <- conv2/3x3_reduce
I0109 14:38:04.492871  4932 net.cpp:415] conv2/3x3_reduce_bn -> conv2/3x3_reduce_bn
I0109 14:38:04.492875  4932 net.cpp:160] Setting up conv2/3x3_reduce_bn
I0109 14:38:04.492888  4932 net.cpp:167] Top shape: 3 64 56 56 (602112)
I0109 14:38:04.492895  4932 layer_factory.hpp:74] Creating layer conv2/relu_3x3_reduce
I0109 14:38:04.492900  4932 net.cpp:96] Creating Layer conv2/relu_3x3_reduce
I0109 14:38:04.492903  4932 net.cpp:459] conv2/relu_3x3_reduce <- conv2/3x3_reduce_bn
I0109 14:38:04.492908  4932 net.cpp:404] conv2/relu_3x3_reduce -> conv2/3x3_reduce_bn (in-place)
I0109 14:38:04.492913  4932 net.cpp:160] Setting up conv2/relu_3x3_reduce
I0109 14:38:04.492915  4932 net.cpp:167] Top shape: 3 64 56 56 (602112)
I0109 14:38:04.492918  4932 layer_factory.hpp:74] Creating layer conv2/3x3
I0109 14:38:04.492923  4932 net.cpp:96] Creating Layer conv2/3x3
I0109 14:38:04.492926  4932 net.cpp:459] conv2/3x3 <- conv2/3x3_reduce_bn
I0109 14:38:04.492930  4932 net.cpp:415] conv2/3x3 -> conv2/3x3
I0109 14:38:04.492934  4932 net.cpp:160] Setting up conv2/3x3
I0109 14:38:04.493410  4932 net.cpp:167] Top shape: 3 192 56 56 (1806336)
I0109 14:38:04.493417  4932 layer_factory.hpp:74] Creating layer conv2/3x3_bn
I0109 14:38:04.493419  4932 layer_factory.cpp:177] Layer conv2/3x3_bn is using CAFFE engine.
I0109 14:38:04.493424  4932 net.cpp:96] Creating Layer conv2/3x3_bn
I0109 14:38:04.493427  4932 net.cpp:459] conv2/3x3_bn <- conv2/3x3
I0109 14:38:04.493432  4932 net.cpp:415] conv2/3x3_bn -> conv2/3x3_bn
I0109 14:38:04.493437  4932 net.cpp:160] Setting up conv2/3x3_bn
I0109 14:38:04.493451  4932 net.cpp:167] Top shape: 3 192 56 56 (1806336)
I0109 14:38:04.493458  4932 layer_factory.hpp:74] Creating layer conv2/relu_3x3
I0109 14:38:04.493463  4932 net.cpp:96] Creating Layer conv2/relu_3x3
I0109 14:38:04.493465  4932 net.cpp:459] conv2/relu_3x3 <- conv2/3x3_bn
I0109 14:38:04.493469  4932 net.cpp:404] conv2/relu_3x3 -> conv2/3x3_bn (in-place)
I0109 14:38:04.493474  4932 net.cpp:160] Setting up conv2/relu_3x3
I0109 14:38:04.493477  4932 net.cpp:167] Top shape: 3 192 56 56 (1806336)
I0109 14:38:04.493480  4932 layer_factory.hpp:74] Creating layer pool2/3x3_s2
I0109 14:38:04.493484  4932 net.cpp:96] Creating Layer pool2/3x3_s2
I0109 14:38:04.493487  4932 net.cpp:459] pool2/3x3_s2 <- conv2/3x3_bn
I0109 14:38:04.493491  4932 net.cpp:415] pool2/3x3_s2 -> pool2/3x3_s2
I0109 14:38:04.493496  4932 net.cpp:160] Setting up pool2/3x3_s2
I0109 14:38:04.493501  4932 net.cpp:167] Top shape: 3 192 28 28 (451584)
I0109 14:38:04.493505  4932 layer_factory.hpp:74] Creating layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0109 14:38:04.493508  4932 net.cpp:96] Creating Layer pool2/3x3_s2_pool2/3x3_s2_0_split
I0109 14:38:04.493510  4932 net.cpp:459] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2
I0109 14:38:04.493515  4932 net.cpp:415] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0109 14:38:04.493518  4932 net.cpp:415] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0109 14:38:04.493523  4932 net.cpp:415] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0109 14:38:04.493528  4932 net.cpp:415] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0109 14:38:04.493533  4932 net.cpp:160] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split
I0109 14:38:04.493537  4932 net.cpp:167] Top shape: 3 192 28 28 (451584)
I0109 14:38:04.493541  4932 net.cpp:167] Top shape: 3 192 28 28 (451584)
I0109 14:38:04.493544  4932 net.cpp:167] Top shape: 3 192 28 28 (451584)
I0109 14:38:04.493548  4932 net.cpp:167] Top shape: 3 192 28 28 (451584)
I0109 14:38:04.493551  4932 layer_factory.hpp:74] Creating layer inception_3a/1x1
I0109 14:38:04.493556  4932 net.cpp:96] Creating Layer inception_3a/1x1
I0109 14:38:04.493559  4932 net.cpp:459] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0
I0109 14:38:04.493563  4932 net.cpp:415] inception_3a/1x1 -> inception_3a/1x1
I0109 14:38:04.493571  4932 net.cpp:160] Setting up inception_3a/1x1
I0109 14:38:04.493633  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.493638  4932 layer_factory.hpp:74] Creating layer inception_3a/1x1_bn
I0109 14:38:04.493641  4932 layer_factory.cpp:177] Layer inception_3a/1x1_bn is using CAFFE engine.
I0109 14:38:04.493647  4932 net.cpp:96] Creating Layer inception_3a/1x1_bn
I0109 14:38:04.493650  4932 net.cpp:459] inception_3a/1x1_bn <- inception_3a/1x1
I0109 14:38:04.493654  4932 net.cpp:415] inception_3a/1x1_bn -> inception_3a/1x1_bn
I0109 14:38:04.493659  4932 net.cpp:160] Setting up inception_3a/1x1_bn
I0109 14:38:04.493670  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.493677  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_1x1
I0109 14:38:04.493682  4932 net.cpp:96] Creating Layer inception_3a/relu_1x1
I0109 14:38:04.493685  4932 net.cpp:459] inception_3a/relu_1x1 <- inception_3a/1x1_bn
I0109 14:38:04.493688  4932 net.cpp:404] inception_3a/relu_1x1 -> inception_3a/1x1_bn (in-place)
I0109 14:38:04.493692  4932 net.cpp:160] Setting up inception_3a/relu_1x1
I0109 14:38:04.493696  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.493698  4932 layer_factory.hpp:74] Creating layer inception_3a/3x3_reduce
I0109 14:38:04.493705  4932 net.cpp:96] Creating Layer inception_3a/3x3_reduce
I0109 14:38:04.493707  4932 net.cpp:459] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1
I0109 14:38:04.493711  4932 net.cpp:415] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I0109 14:38:04.493716  4932 net.cpp:160] Setting up inception_3a/3x3_reduce
I0109 14:38:04.493775  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.493782  4932 layer_factory.hpp:74] Creating layer inception_3a/3x3_reduce_bn
I0109 14:38:04.493784  4932 layer_factory.cpp:177] Layer inception_3a/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.493789  4932 net.cpp:96] Creating Layer inception_3a/3x3_reduce_bn
I0109 14:38:04.493793  4932 net.cpp:459] inception_3a/3x3_reduce_bn <- inception_3a/3x3_reduce
I0109 14:38:04.493798  4932 net.cpp:415] inception_3a/3x3_reduce_bn -> inception_3a/3x3_reduce_bn
I0109 14:38:04.493803  4932 net.cpp:160] Setting up inception_3a/3x3_reduce_bn
I0109 14:38:04.493813  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.493818  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_3x3_reduce
I0109 14:38:04.493823  4932 net.cpp:96] Creating Layer inception_3a/relu_3x3_reduce
I0109 14:38:04.493825  4932 net.cpp:459] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce_bn
I0109 14:38:04.493829  4932 net.cpp:404] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce_bn (in-place)
I0109 14:38:04.493834  4932 net.cpp:160] Setting up inception_3a/relu_3x3_reduce
I0109 14:38:04.493837  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.493840  4932 layer_factory.hpp:74] Creating layer inception_3a/3x3
I0109 14:38:04.493844  4932 net.cpp:96] Creating Layer inception_3a/3x3
I0109 14:38:04.493847  4932 net.cpp:459] inception_3a/3x3 <- inception_3a/3x3_reduce_bn
I0109 14:38:04.493852  4932 net.cpp:415] inception_3a/3x3 -> inception_3a/3x3
I0109 14:38:04.493857  4932 net.cpp:160] Setting up inception_3a/3x3
I0109 14:38:04.494020  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.494026  4932 layer_factory.hpp:74] Creating layer inception_3a/3x3_bn
I0109 14:38:04.494029  4932 layer_factory.cpp:177] Layer inception_3a/3x3_bn is using CAFFE engine.
I0109 14:38:04.494035  4932 net.cpp:96] Creating Layer inception_3a/3x3_bn
I0109 14:38:04.494037  4932 net.cpp:459] inception_3a/3x3_bn <- inception_3a/3x3
I0109 14:38:04.494041  4932 net.cpp:415] inception_3a/3x3_bn -> inception_3a/3x3_bn
I0109 14:38:04.494045  4932 net.cpp:160] Setting up inception_3a/3x3_bn
I0109 14:38:04.494057  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.494065  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_3x3
I0109 14:38:04.494071  4932 net.cpp:96] Creating Layer inception_3a/relu_3x3
I0109 14:38:04.494076  4932 net.cpp:459] inception_3a/relu_3x3 <- inception_3a/3x3_bn
I0109 14:38:04.494082  4932 net.cpp:404] inception_3a/relu_3x3 -> inception_3a/3x3_bn (in-place)
I0109 14:38:04.494086  4932 net.cpp:160] Setting up inception_3a/relu_3x3
I0109 14:38:04.494091  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.494093  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_reduce
I0109 14:38:04.494097  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_reduce
I0109 14:38:04.494101  4932 net.cpp:459] inception_3a/double_3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2
I0109 14:38:04.494105  4932 net.cpp:415] inception_3a/double_3x3_reduce -> inception_3a/double_3x3_reduce
I0109 14:38:04.494110  4932 net.cpp:160] Setting up inception_3a/double_3x3_reduce
I0109 14:38:04.494168  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.494174  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_reduce_bn
I0109 14:38:04.494176  4932 layer_factory.cpp:177] Layer inception_3a/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.494181  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_reduce_bn
I0109 14:38:04.494185  4932 net.cpp:459] inception_3a/double_3x3_reduce_bn <- inception_3a/double_3x3_reduce
I0109 14:38:04.494189  4932 net.cpp:415] inception_3a/double_3x3_reduce_bn -> inception_3a/double_3x3_reduce_bn
I0109 14:38:04.494194  4932 net.cpp:160] Setting up inception_3a/double_3x3_reduce_bn
I0109 14:38:04.494204  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.494210  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_reduce
I0109 14:38:04.494215  4932 net.cpp:96] Creating Layer inception_3a/relu_double_3x3_reduce
I0109 14:38:04.494216  4932 net.cpp:459] inception_3a/relu_double_3x3_reduce <- inception_3a/double_3x3_reduce_bn
I0109 14:38:04.494220  4932 net.cpp:404] inception_3a/relu_double_3x3_reduce -> inception_3a/double_3x3_reduce_bn (in-place)
I0109 14:38:04.494225  4932 net.cpp:160] Setting up inception_3a/relu_double_3x3_reduce
I0109 14:38:04.494227  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.494230  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_1
I0109 14:38:04.494235  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_1
I0109 14:38:04.494238  4932 net.cpp:459] inception_3a/double_3x3_1 <- inception_3a/double_3x3_reduce_bn
I0109 14:38:04.494243  4932 net.cpp:415] inception_3a/double_3x3_1 -> inception_3a/double_3x3_1
I0109 14:38:04.494248  4932 net.cpp:160] Setting up inception_3a/double_3x3_1
I0109 14:38:04.494488  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.494493  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_1_bn
I0109 14:38:04.494496  4932 layer_factory.cpp:177] Layer inception_3a/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.494500  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_1_bn
I0109 14:38:04.494503  4932 net.cpp:459] inception_3a/double_3x3_1_bn <- inception_3a/double_3x3_1
I0109 14:38:04.494509  4932 net.cpp:415] inception_3a/double_3x3_1_bn -> inception_3a/double_3x3_1_bn
I0109 14:38:04.494514  4932 net.cpp:160] Setting up inception_3a/double_3x3_1_bn
I0109 14:38:04.494524  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.494531  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_1
I0109 14:38:04.494535  4932 net.cpp:96] Creating Layer inception_3a/relu_double_3x3_1
I0109 14:38:04.494539  4932 net.cpp:459] inception_3a/relu_double_3x3_1 <- inception_3a/double_3x3_1_bn
I0109 14:38:04.494542  4932 net.cpp:404] inception_3a/relu_double_3x3_1 -> inception_3a/double_3x3_1_bn (in-place)
I0109 14:38:04.494546  4932 net.cpp:160] Setting up inception_3a/relu_double_3x3_1
I0109 14:38:04.494550  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.494554  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_2
I0109 14:38:04.494557  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_2
I0109 14:38:04.494560  4932 net.cpp:459] inception_3a/double_3x3_2 <- inception_3a/double_3x3_1_bn
I0109 14:38:04.494570  4932 net.cpp:415] inception_3a/double_3x3_2 -> inception_3a/double_3x3_2
I0109 14:38:04.494575  4932 net.cpp:160] Setting up inception_3a/double_3x3_2
I0109 14:38:04.494930  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.494935  4932 layer_factory.hpp:74] Creating layer inception_3a/double_3x3_2_bn
I0109 14:38:04.494938  4932 layer_factory.cpp:177] Layer inception_3a/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.494943  4932 net.cpp:96] Creating Layer inception_3a/double_3x3_2_bn
I0109 14:38:04.494947  4932 net.cpp:459] inception_3a/double_3x3_2_bn <- inception_3a/double_3x3_2
I0109 14:38:04.494952  4932 net.cpp:415] inception_3a/double_3x3_2_bn -> inception_3a/double_3x3_2_bn
I0109 14:38:04.494957  4932 net.cpp:160] Setting up inception_3a/double_3x3_2_bn
I0109 14:38:04.494967  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.494973  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_double_3x3_2
I0109 14:38:04.494978  4932 net.cpp:96] Creating Layer inception_3a/relu_double_3x3_2
I0109 14:38:04.494982  4932 net.cpp:459] inception_3a/relu_double_3x3_2 <- inception_3a/double_3x3_2_bn
I0109 14:38:04.494985  4932 net.cpp:404] inception_3a/relu_double_3x3_2 -> inception_3a/double_3x3_2_bn (in-place)
I0109 14:38:04.494989  4932 net.cpp:160] Setting up inception_3a/relu_double_3x3_2
I0109 14:38:04.494993  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.494997  4932 layer_factory.hpp:74] Creating layer inception_3a/pool
I0109 14:38:04.495000  4932 net.cpp:96] Creating Layer inception_3a/pool
I0109 14:38:04.495003  4932 net.cpp:459] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3
I0109 14:38:04.495007  4932 net.cpp:415] inception_3a/pool -> inception_3a/pool
I0109 14:38:04.495010  4932 net.cpp:160] Setting up inception_3a/pool
I0109 14:38:04.495018  4932 net.cpp:167] Top shape: 3 192 28 28 (451584)
I0109 14:38:04.495020  4932 layer_factory.hpp:74] Creating layer inception_3a/pool_proj
I0109 14:38:04.495024  4932 net.cpp:96] Creating Layer inception_3a/pool_proj
I0109 14:38:04.495028  4932 net.cpp:459] inception_3a/pool_proj <- inception_3a/pool
I0109 14:38:04.495033  4932 net.cpp:415] inception_3a/pool_proj -> inception_3a/pool_proj
I0109 14:38:04.495038  4932 net.cpp:160] Setting up inception_3a/pool_proj
I0109 14:38:04.495069  4932 net.cpp:167] Top shape: 3 32 28 28 (75264)
I0109 14:38:04.495074  4932 layer_factory.hpp:74] Creating layer inception_3a/pool_proj_bn
I0109 14:38:04.495077  4932 layer_factory.cpp:177] Layer inception_3a/pool_proj_bn is using CAFFE engine.
I0109 14:38:04.495082  4932 net.cpp:96] Creating Layer inception_3a/pool_proj_bn
I0109 14:38:04.495085  4932 net.cpp:459] inception_3a/pool_proj_bn <- inception_3a/pool_proj
I0109 14:38:04.495090  4932 net.cpp:415] inception_3a/pool_proj_bn -> inception_3a/pool_proj_bn
I0109 14:38:04.495095  4932 net.cpp:160] Setting up inception_3a/pool_proj_bn
I0109 14:38:04.495103  4932 net.cpp:167] Top shape: 3 32 28 28 (75264)
I0109 14:38:04.495110  4932 layer_factory.hpp:74] Creating layer inception_3a/relu_pool_proj
I0109 14:38:04.495113  4932 net.cpp:96] Creating Layer inception_3a/relu_pool_proj
I0109 14:38:04.495117  4932 net.cpp:459] inception_3a/relu_pool_proj <- inception_3a/pool_proj_bn
I0109 14:38:04.495121  4932 net.cpp:404] inception_3a/relu_pool_proj -> inception_3a/pool_proj_bn (in-place)
I0109 14:38:04.495126  4932 net.cpp:160] Setting up inception_3a/relu_pool_proj
I0109 14:38:04.495128  4932 net.cpp:167] Top shape: 3 32 28 28 (75264)
I0109 14:38:04.495131  4932 layer_factory.hpp:74] Creating layer inception_3a/output
I0109 14:38:04.495136  4932 net.cpp:96] Creating Layer inception_3a/output
I0109 14:38:04.495139  4932 net.cpp:459] inception_3a/output <- inception_3a/1x1_bn
I0109 14:38:04.495142  4932 net.cpp:459] inception_3a/output <- inception_3a/3x3_bn
I0109 14:38:04.495146  4932 net.cpp:459] inception_3a/output <- inception_3a/double_3x3_2_bn
I0109 14:38:04.495149  4932 net.cpp:459] inception_3a/output <- inception_3a/pool_proj_bn
I0109 14:38:04.495157  4932 net.cpp:415] inception_3a/output -> inception_3a/output
I0109 14:38:04.495164  4932 net.cpp:160] Setting up inception_3a/output
I0109 14:38:04.495170  4932 net.cpp:167] Top shape: 3 256 28 28 (602112)
I0109 14:38:04.495173  4932 layer_factory.hpp:74] Creating layer inception_3a/output_inception_3a/output_0_split
I0109 14:38:04.495178  4932 net.cpp:96] Creating Layer inception_3a/output_inception_3a/output_0_split
I0109 14:38:04.495182  4932 net.cpp:459] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I0109 14:38:04.495185  4932 net.cpp:415] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I0109 14:38:04.495189  4932 net.cpp:415] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I0109 14:38:04.495194  4932 net.cpp:415] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I0109 14:38:04.495198  4932 net.cpp:415] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3
I0109 14:38:04.495203  4932 net.cpp:160] Setting up inception_3a/output_inception_3a/output_0_split
I0109 14:38:04.495206  4932 net.cpp:167] Top shape: 3 256 28 28 (602112)
I0109 14:38:04.495210  4932 net.cpp:167] Top shape: 3 256 28 28 (602112)
I0109 14:38:04.495213  4932 net.cpp:167] Top shape: 3 256 28 28 (602112)
I0109 14:38:04.495216  4932 net.cpp:167] Top shape: 3 256 28 28 (602112)
I0109 14:38:04.495219  4932 layer_factory.hpp:74] Creating layer inception_3b/1x1
I0109 14:38:04.495225  4932 net.cpp:96] Creating Layer inception_3b/1x1
I0109 14:38:04.495229  4932 net.cpp:459] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0
I0109 14:38:04.495234  4932 net.cpp:415] inception_3b/1x1 -> inception_3b/1x1
I0109 14:38:04.495237  4932 net.cpp:160] Setting up inception_3b/1x1
I0109 14:38:04.495313  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.495319  4932 layer_factory.hpp:74] Creating layer inception_3b/1x1_bn
I0109 14:38:04.495322  4932 layer_factory.cpp:177] Layer inception_3b/1x1_bn is using CAFFE engine.
I0109 14:38:04.495326  4932 net.cpp:96] Creating Layer inception_3b/1x1_bn
I0109 14:38:04.495329  4932 net.cpp:459] inception_3b/1x1_bn <- inception_3b/1x1
I0109 14:38:04.495334  4932 net.cpp:415] inception_3b/1x1_bn -> inception_3b/1x1_bn
I0109 14:38:04.495339  4932 net.cpp:160] Setting up inception_3b/1x1_bn
I0109 14:38:04.495352  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.495362  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_1x1
I0109 14:38:04.495365  4932 net.cpp:96] Creating Layer inception_3b/relu_1x1
I0109 14:38:04.495369  4932 net.cpp:459] inception_3b/relu_1x1 <- inception_3b/1x1_bn
I0109 14:38:04.495373  4932 net.cpp:404] inception_3b/relu_1x1 -> inception_3b/1x1_bn (in-place)
I0109 14:38:04.495376  4932 net.cpp:160] Setting up inception_3b/relu_1x1
I0109 14:38:04.495379  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.495383  4932 layer_factory.hpp:74] Creating layer inception_3b/3x3_reduce
I0109 14:38:04.495388  4932 net.cpp:96] Creating Layer inception_3b/3x3_reduce
I0109 14:38:04.495391  4932 net.cpp:459] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I0109 14:38:04.495395  4932 net.cpp:415] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I0109 14:38:04.495400  4932 net.cpp:160] Setting up inception_3b/3x3_reduce
I0109 14:38:04.495481  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.495488  4932 layer_factory.hpp:74] Creating layer inception_3b/3x3_reduce_bn
I0109 14:38:04.495491  4932 layer_factory.cpp:177] Layer inception_3b/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.495496  4932 net.cpp:96] Creating Layer inception_3b/3x3_reduce_bn
I0109 14:38:04.495499  4932 net.cpp:459] inception_3b/3x3_reduce_bn <- inception_3b/3x3_reduce
I0109 14:38:04.495504  4932 net.cpp:415] inception_3b/3x3_reduce_bn -> inception_3b/3x3_reduce_bn
I0109 14:38:04.495512  4932 net.cpp:160] Setting up inception_3b/3x3_reduce_bn
I0109 14:38:04.495527  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.495532  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_3x3_reduce
I0109 14:38:04.495537  4932 net.cpp:96] Creating Layer inception_3b/relu_3x3_reduce
I0109 14:38:04.495539  4932 net.cpp:459] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce_bn
I0109 14:38:04.495544  4932 net.cpp:404] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce_bn (in-place)
I0109 14:38:04.495548  4932 net.cpp:160] Setting up inception_3b/relu_3x3_reduce
I0109 14:38:04.495551  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.495554  4932 layer_factory.hpp:74] Creating layer inception_3b/3x3
I0109 14:38:04.495559  4932 net.cpp:96] Creating Layer inception_3b/3x3
I0109 14:38:04.495563  4932 net.cpp:459] inception_3b/3x3 <- inception_3b/3x3_reduce_bn
I0109 14:38:04.495568  4932 net.cpp:415] inception_3b/3x3 -> inception_3b/3x3
I0109 14:38:04.495573  4932 net.cpp:160] Setting up inception_3b/3x3
I0109 14:38:04.495816  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.495822  4932 layer_factory.hpp:74] Creating layer inception_3b/3x3_bn
I0109 14:38:04.495826  4932 layer_factory.cpp:177] Layer inception_3b/3x3_bn is using CAFFE engine.
I0109 14:38:04.495831  4932 net.cpp:96] Creating Layer inception_3b/3x3_bn
I0109 14:38:04.495834  4932 net.cpp:459] inception_3b/3x3_bn <- inception_3b/3x3
I0109 14:38:04.495839  4932 net.cpp:415] inception_3b/3x3_bn -> inception_3b/3x3_bn
I0109 14:38:04.495843  4932 net.cpp:160] Setting up inception_3b/3x3_bn
I0109 14:38:04.495854  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.495860  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_3x3
I0109 14:38:04.495864  4932 net.cpp:96] Creating Layer inception_3b/relu_3x3
I0109 14:38:04.495867  4932 net.cpp:459] inception_3b/relu_3x3 <- inception_3b/3x3_bn
I0109 14:38:04.495872  4932 net.cpp:404] inception_3b/relu_3x3 -> inception_3b/3x3_bn (in-place)
I0109 14:38:04.495875  4932 net.cpp:160] Setting up inception_3b/relu_3x3
I0109 14:38:04.495879  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.495882  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_reduce
I0109 14:38:04.495887  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_reduce
I0109 14:38:04.495889  4932 net.cpp:459] inception_3b/double_3x3_reduce <- inception_3a/output_inception_3a/output_0_split_2
I0109 14:38:04.495894  4932 net.cpp:415] inception_3b/double_3x3_reduce -> inception_3b/double_3x3_reduce
I0109 14:38:04.495899  4932 net.cpp:160] Setting up inception_3b/double_3x3_reduce
I0109 14:38:04.495975  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.495981  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_reduce_bn
I0109 14:38:04.495985  4932 layer_factory.cpp:177] Layer inception_3b/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.495990  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_reduce_bn
I0109 14:38:04.495992  4932 net.cpp:459] inception_3b/double_3x3_reduce_bn <- inception_3b/double_3x3_reduce
I0109 14:38:04.495996  4932 net.cpp:415] inception_3b/double_3x3_reduce_bn -> inception_3b/double_3x3_reduce_bn
I0109 14:38:04.496001  4932 net.cpp:160] Setting up inception_3b/double_3x3_reduce_bn
I0109 14:38:04.496012  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.496017  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_reduce
I0109 14:38:04.496021  4932 net.cpp:96] Creating Layer inception_3b/relu_double_3x3_reduce
I0109 14:38:04.496024  4932 net.cpp:459] inception_3b/relu_double_3x3_reduce <- inception_3b/double_3x3_reduce_bn
I0109 14:38:04.496027  4932 net.cpp:404] inception_3b/relu_double_3x3_reduce -> inception_3b/double_3x3_reduce_bn (in-place)
I0109 14:38:04.496031  4932 net.cpp:160] Setting up inception_3b/relu_double_3x3_reduce
I0109 14:38:04.496035  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.496038  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_1
I0109 14:38:04.496048  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_1
I0109 14:38:04.496052  4932 net.cpp:459] inception_3b/double_3x3_1 <- inception_3b/double_3x3_reduce_bn
I0109 14:38:04.496057  4932 net.cpp:415] inception_3b/double_3x3_1 -> inception_3b/double_3x3_1
I0109 14:38:04.496062  4932 net.cpp:160] Setting up inception_3b/double_3x3_1
I0109 14:38:04.496310  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.496317  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_1_bn
I0109 14:38:04.496321  4932 layer_factory.cpp:177] Layer inception_3b/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.496325  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_1_bn
I0109 14:38:04.496328  4932 net.cpp:459] inception_3b/double_3x3_1_bn <- inception_3b/double_3x3_1
I0109 14:38:04.496335  4932 net.cpp:415] inception_3b/double_3x3_1_bn -> inception_3b/double_3x3_1_bn
I0109 14:38:04.496338  4932 net.cpp:160] Setting up inception_3b/double_3x3_1_bn
I0109 14:38:04.496350  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.496356  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_1
I0109 14:38:04.496359  4932 net.cpp:96] Creating Layer inception_3b/relu_double_3x3_1
I0109 14:38:04.496362  4932 net.cpp:459] inception_3b/relu_double_3x3_1 <- inception_3b/double_3x3_1_bn
I0109 14:38:04.496366  4932 net.cpp:404] inception_3b/relu_double_3x3_1 -> inception_3b/double_3x3_1_bn (in-place)
I0109 14:38:04.496371  4932 net.cpp:160] Setting up inception_3b/relu_double_3x3_1
I0109 14:38:04.496373  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.496376  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_2
I0109 14:38:04.496381  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_2
I0109 14:38:04.496384  4932 net.cpp:459] inception_3b/double_3x3_2 <- inception_3b/double_3x3_1_bn
I0109 14:38:04.496388  4932 net.cpp:415] inception_3b/double_3x3_2 -> inception_3b/double_3x3_2
I0109 14:38:04.496392  4932 net.cpp:160] Setting up inception_3b/double_3x3_2
I0109 14:38:04.496747  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.496753  4932 layer_factory.hpp:74] Creating layer inception_3b/double_3x3_2_bn
I0109 14:38:04.496757  4932 layer_factory.cpp:177] Layer inception_3b/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.496762  4932 net.cpp:96] Creating Layer inception_3b/double_3x3_2_bn
I0109 14:38:04.496765  4932 net.cpp:459] inception_3b/double_3x3_2_bn <- inception_3b/double_3x3_2
I0109 14:38:04.496770  4932 net.cpp:415] inception_3b/double_3x3_2_bn -> inception_3b/double_3x3_2_bn
I0109 14:38:04.496775  4932 net.cpp:160] Setting up inception_3b/double_3x3_2_bn
I0109 14:38:04.496785  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.496793  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_double_3x3_2
I0109 14:38:04.496796  4932 net.cpp:96] Creating Layer inception_3b/relu_double_3x3_2
I0109 14:38:04.496799  4932 net.cpp:459] inception_3b/relu_double_3x3_2 <- inception_3b/double_3x3_2_bn
I0109 14:38:04.496803  4932 net.cpp:404] inception_3b/relu_double_3x3_2 -> inception_3b/double_3x3_2_bn (in-place)
I0109 14:38:04.496806  4932 net.cpp:160] Setting up inception_3b/relu_double_3x3_2
I0109 14:38:04.496809  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.496812  4932 layer_factory.hpp:74] Creating layer inception_3b/pool
I0109 14:38:04.496816  4932 net.cpp:96] Creating Layer inception_3b/pool
I0109 14:38:04.496819  4932 net.cpp:459] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3
I0109 14:38:04.496824  4932 net.cpp:415] inception_3b/pool -> inception_3b/pool
I0109 14:38:04.496829  4932 net.cpp:160] Setting up inception_3b/pool
I0109 14:38:04.496834  4932 net.cpp:167] Top shape: 3 256 28 28 (602112)
I0109 14:38:04.496836  4932 layer_factory.hpp:74] Creating layer inception_3b/pool_proj
I0109 14:38:04.496841  4932 net.cpp:96] Creating Layer inception_3b/pool_proj
I0109 14:38:04.496845  4932 net.cpp:459] inception_3b/pool_proj <- inception_3b/pool
I0109 14:38:04.496855  4932 net.cpp:415] inception_3b/pool_proj -> inception_3b/pool_proj
I0109 14:38:04.496860  4932 net.cpp:160] Setting up inception_3b/pool_proj
I0109 14:38:04.496937  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.496942  4932 layer_factory.hpp:74] Creating layer inception_3b/pool_proj_bn
I0109 14:38:04.496947  4932 layer_factory.cpp:177] Layer inception_3b/pool_proj_bn is using CAFFE engine.
I0109 14:38:04.496951  4932 net.cpp:96] Creating Layer inception_3b/pool_proj_bn
I0109 14:38:04.496954  4932 net.cpp:459] inception_3b/pool_proj_bn <- inception_3b/pool_proj
I0109 14:38:04.496959  4932 net.cpp:415] inception_3b/pool_proj_bn -> inception_3b/pool_proj_bn
I0109 14:38:04.496964  4932 net.cpp:160] Setting up inception_3b/pool_proj_bn
I0109 14:38:04.496973  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.496980  4932 layer_factory.hpp:74] Creating layer inception_3b/relu_pool_proj
I0109 14:38:04.496985  4932 net.cpp:96] Creating Layer inception_3b/relu_pool_proj
I0109 14:38:04.496989  4932 net.cpp:459] inception_3b/relu_pool_proj <- inception_3b/pool_proj_bn
I0109 14:38:04.496992  4932 net.cpp:404] inception_3b/relu_pool_proj -> inception_3b/pool_proj_bn (in-place)
I0109 14:38:04.496996  4932 net.cpp:160] Setting up inception_3b/relu_pool_proj
I0109 14:38:04.497000  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.497004  4932 layer_factory.hpp:74] Creating layer inception_3b/output
I0109 14:38:04.497007  4932 net.cpp:96] Creating Layer inception_3b/output
I0109 14:38:04.497010  4932 net.cpp:459] inception_3b/output <- inception_3b/1x1_bn
I0109 14:38:04.497014  4932 net.cpp:459] inception_3b/output <- inception_3b/3x3_bn
I0109 14:38:04.497017  4932 net.cpp:459] inception_3b/output <- inception_3b/double_3x3_2_bn
I0109 14:38:04.497020  4932 net.cpp:459] inception_3b/output <- inception_3b/pool_proj_bn
I0109 14:38:04.497025  4932 net.cpp:415] inception_3b/output -> inception_3b/output
I0109 14:38:04.497028  4932 net.cpp:160] Setting up inception_3b/output
I0109 14:38:04.497032  4932 net.cpp:167] Top shape: 3 320 28 28 (752640)
I0109 14:38:04.497035  4932 layer_factory.hpp:74] Creating layer inception_3b/output_inception_3b/output_0_split
I0109 14:38:04.497040  4932 net.cpp:96] Creating Layer inception_3b/output_inception_3b/output_0_split
I0109 14:38:04.497042  4932 net.cpp:459] inception_3b/output_inception_3b/output_0_split <- inception_3b/output
I0109 14:38:04.497052  4932 net.cpp:415] inception_3b/output_inception_3b/output_0_split -> inception_3b/output_inception_3b/output_0_split_0
I0109 14:38:04.497058  4932 net.cpp:415] inception_3b/output_inception_3b/output_0_split -> inception_3b/output_inception_3b/output_0_split_1
I0109 14:38:04.497062  4932 net.cpp:415] inception_3b/output_inception_3b/output_0_split -> inception_3b/output_inception_3b/output_0_split_2
I0109 14:38:04.497066  4932 net.cpp:160] Setting up inception_3b/output_inception_3b/output_0_split
I0109 14:38:04.497071  4932 net.cpp:167] Top shape: 3 320 28 28 (752640)
I0109 14:38:04.497074  4932 net.cpp:167] Top shape: 3 320 28 28 (752640)
I0109 14:38:04.497078  4932 net.cpp:167] Top shape: 3 320 28 28 (752640)
I0109 14:38:04.497081  4932 layer_factory.hpp:74] Creating layer inception_3c/3x3_reduce
I0109 14:38:04.497087  4932 net.cpp:96] Creating Layer inception_3c/3x3_reduce
I0109 14:38:04.497090  4932 net.cpp:459] inception_3c/3x3_reduce <- inception_3b/output_inception_3b/output_0_split_0
I0109 14:38:04.497094  4932 net.cpp:415] inception_3c/3x3_reduce -> inception_3c/3x3_reduce
I0109 14:38:04.497098  4932 net.cpp:160] Setting up inception_3c/3x3_reduce
I0109 14:38:04.497283  4932 net.cpp:167] Top shape: 3 128 28 28 (301056)
I0109 14:38:04.497289  4932 layer_factory.hpp:74] Creating layer inception_3c/3x3_reduce_bn
I0109 14:38:04.497293  4932 layer_factory.cpp:177] Layer inception_3c/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.497301  4932 net.cpp:96] Creating Layer inception_3c/3x3_reduce_bn
I0109 14:38:04.497305  4932 net.cpp:459] inception_3c/3x3_reduce_bn <- inception_3c/3x3_reduce
I0109 14:38:04.497315  4932 net.cpp:415] inception_3c/3x3_reduce_bn -> inception_3c/3x3_reduce_bn
I0109 14:38:04.497321  4932 net.cpp:160] Setting up inception_3c/3x3_reduce_bn
I0109 14:38:04.497333  4932 net.cpp:167] Top shape: 3 128 28 28 (301056)
I0109 14:38:04.497339  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_3x3_reduce
I0109 14:38:04.497344  4932 net.cpp:96] Creating Layer inception_3c/relu_3x3_reduce
I0109 14:38:04.497346  4932 net.cpp:459] inception_3c/relu_3x3_reduce <- inception_3c/3x3_reduce_bn
I0109 14:38:04.497349  4932 net.cpp:404] inception_3c/relu_3x3_reduce -> inception_3c/3x3_reduce_bn (in-place)
I0109 14:38:04.497354  4932 net.cpp:160] Setting up inception_3c/relu_3x3_reduce
I0109 14:38:04.497357  4932 net.cpp:167] Top shape: 3 128 28 28 (301056)
I0109 14:38:04.497360  4932 layer_factory.hpp:74] Creating layer inception_3c/3x3
I0109 14:38:04.497365  4932 net.cpp:96] Creating Layer inception_3c/3x3
I0109 14:38:04.497369  4932 net.cpp:459] inception_3c/3x3 <- inception_3c/3x3_reduce_bn
I0109 14:38:04.497372  4932 net.cpp:415] inception_3c/3x3 -> inception_3c/3x3
I0109 14:38:04.497377  4932 net.cpp:160] Setting up inception_3c/3x3
I0109 14:38:04.498154  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.498162  4932 layer_factory.hpp:74] Creating layer inception_3c/3x3_bn
I0109 14:38:04.498164  4932 layer_factory.cpp:177] Layer inception_3c/3x3_bn is using CAFFE engine.
I0109 14:38:04.498169  4932 net.cpp:96] Creating Layer inception_3c/3x3_bn
I0109 14:38:04.498172  4932 net.cpp:459] inception_3c/3x3_bn <- inception_3c/3x3
I0109 14:38:04.498178  4932 net.cpp:415] inception_3c/3x3_bn -> inception_3c/3x3_bn
I0109 14:38:04.498183  4932 net.cpp:160] Setting up inception_3c/3x3_bn
I0109 14:38:04.498193  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.498198  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_3x3
I0109 14:38:04.498203  4932 net.cpp:96] Creating Layer inception_3c/relu_3x3
I0109 14:38:04.498205  4932 net.cpp:459] inception_3c/relu_3x3 <- inception_3c/3x3_bn
I0109 14:38:04.498209  4932 net.cpp:404] inception_3c/relu_3x3 -> inception_3c/3x3_bn (in-place)
I0109 14:38:04.498214  4932 net.cpp:160] Setting up inception_3c/relu_3x3
I0109 14:38:04.498217  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.498219  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_reduce
I0109 14:38:04.498224  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_reduce
I0109 14:38:04.498227  4932 net.cpp:459] inception_3c/double_3x3_reduce <- inception_3b/output_inception_3b/output_0_split_1
I0109 14:38:04.498232  4932 net.cpp:415] inception_3c/double_3x3_reduce -> inception_3c/double_3x3_reduce
I0109 14:38:04.498237  4932 net.cpp:160] Setting up inception_3c/double_3x3_reduce
I0109 14:38:04.498332  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.498337  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_reduce_bn
I0109 14:38:04.498340  4932 layer_factory.cpp:177] Layer inception_3c/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.498344  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_reduce_bn
I0109 14:38:04.498347  4932 net.cpp:459] inception_3c/double_3x3_reduce_bn <- inception_3c/double_3x3_reduce
I0109 14:38:04.498353  4932 net.cpp:415] inception_3c/double_3x3_reduce_bn -> inception_3c/double_3x3_reduce_bn
I0109 14:38:04.498358  4932 net.cpp:160] Setting up inception_3c/double_3x3_reduce_bn
I0109 14:38:04.498369  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.498374  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_double_3x3_reduce
I0109 14:38:04.498379  4932 net.cpp:96] Creating Layer inception_3c/relu_double_3x3_reduce
I0109 14:38:04.498383  4932 net.cpp:459] inception_3c/relu_double_3x3_reduce <- inception_3c/double_3x3_reduce_bn
I0109 14:38:04.498385  4932 net.cpp:404] inception_3c/relu_double_3x3_reduce -> inception_3c/double_3x3_reduce_bn (in-place)
I0109 14:38:04.498389  4932 net.cpp:160] Setting up inception_3c/relu_double_3x3_reduce
I0109 14:38:04.498399  4932 net.cpp:167] Top shape: 3 64 28 28 (150528)
I0109 14:38:04.498401  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_1
I0109 14:38:04.498406  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_1
I0109 14:38:04.498409  4932 net.cpp:459] inception_3c/double_3x3_1 <- inception_3c/double_3x3_reduce_bn
I0109 14:38:04.498414  4932 net.cpp:415] inception_3c/double_3x3_1 -> inception_3c/double_3x3_1
I0109 14:38:04.498419  4932 net.cpp:160] Setting up inception_3c/double_3x3_1
I0109 14:38:04.498657  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.498663  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_1_bn
I0109 14:38:04.498667  4932 layer_factory.cpp:177] Layer inception_3c/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.498672  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_1_bn
I0109 14:38:04.498675  4932 net.cpp:459] inception_3c/double_3x3_1_bn <- inception_3c/double_3x3_1
I0109 14:38:04.498679  4932 net.cpp:415] inception_3c/double_3x3_1_bn -> inception_3c/double_3x3_1_bn
I0109 14:38:04.498684  4932 net.cpp:160] Setting up inception_3c/double_3x3_1_bn
I0109 14:38:04.498694  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.498702  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_double_3x3_1
I0109 14:38:04.498705  4932 net.cpp:96] Creating Layer inception_3c/relu_double_3x3_1
I0109 14:38:04.498708  4932 net.cpp:459] inception_3c/relu_double_3x3_1 <- inception_3c/double_3x3_1_bn
I0109 14:38:04.498711  4932 net.cpp:404] inception_3c/relu_double_3x3_1 -> inception_3c/double_3x3_1_bn (in-place)
I0109 14:38:04.498715  4932 net.cpp:160] Setting up inception_3c/relu_double_3x3_1
I0109 14:38:04.498718  4932 net.cpp:167] Top shape: 3 96 28 28 (225792)
I0109 14:38:04.498721  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_2
I0109 14:38:04.498726  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_2
I0109 14:38:04.498729  4932 net.cpp:459] inception_3c/double_3x3_2 <- inception_3c/double_3x3_1_bn
I0109 14:38:04.498733  4932 net.cpp:415] inception_3c/double_3x3_2 -> inception_3c/double_3x3_2
I0109 14:38:04.498741  4932 net.cpp:160] Setting up inception_3c/double_3x3_2
I0109 14:38:04.499116  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.499125  4932 layer_factory.hpp:74] Creating layer inception_3c/double_3x3_2_bn
I0109 14:38:04.499127  4932 layer_factory.cpp:177] Layer inception_3c/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.499132  4932 net.cpp:96] Creating Layer inception_3c/double_3x3_2_bn
I0109 14:38:04.499135  4932 net.cpp:459] inception_3c/double_3x3_2_bn <- inception_3c/double_3x3_2
I0109 14:38:04.499140  4932 net.cpp:415] inception_3c/double_3x3_2_bn -> inception_3c/double_3x3_2_bn
I0109 14:38:04.499145  4932 net.cpp:160] Setting up inception_3c/double_3x3_2_bn
I0109 14:38:04.499155  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.499167  4932 layer_factory.hpp:74] Creating layer inception_3c/relu_double_3x3_2
I0109 14:38:04.499171  4932 net.cpp:96] Creating Layer inception_3c/relu_double_3x3_2
I0109 14:38:04.499174  4932 net.cpp:459] inception_3c/relu_double_3x3_2 <- inception_3c/double_3x3_2_bn
I0109 14:38:04.499178  4932 net.cpp:404] inception_3c/relu_double_3x3_2 -> inception_3c/double_3x3_2_bn (in-place)
I0109 14:38:04.499181  4932 net.cpp:160] Setting up inception_3c/relu_double_3x3_2
I0109 14:38:04.499186  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.499188  4932 layer_factory.hpp:74] Creating layer inception_3c/pool
I0109 14:38:04.499192  4932 net.cpp:96] Creating Layer inception_3c/pool
I0109 14:38:04.499195  4932 net.cpp:459] inception_3c/pool <- inception_3b/output_inception_3b/output_0_split_2
I0109 14:38:04.499200  4932 net.cpp:415] inception_3c/pool -> inception_3c/pool
I0109 14:38:04.499204  4932 net.cpp:160] Setting up inception_3c/pool
I0109 14:38:04.499209  4932 net.cpp:167] Top shape: 3 320 14 14 (188160)
I0109 14:38:04.499212  4932 layer_factory.hpp:74] Creating layer inception_3c/output
I0109 14:38:04.499219  4932 net.cpp:96] Creating Layer inception_3c/output
I0109 14:38:04.499227  4932 net.cpp:459] inception_3c/output <- inception_3c/3x3_bn
I0109 14:38:04.499229  4932 net.cpp:459] inception_3c/output <- inception_3c/double_3x3_2_bn
I0109 14:38:04.499233  4932 net.cpp:459] inception_3c/output <- inception_3c/pool
I0109 14:38:04.499238  4932 net.cpp:415] inception_3c/output -> inception_3c/output
I0109 14:38:04.499243  4932 net.cpp:160] Setting up inception_3c/output
I0109 14:38:04.499248  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.499250  4932 layer_factory.hpp:74] Creating layer inception_3c/output_inception_3c/output_0_split
I0109 14:38:04.499254  4932 net.cpp:96] Creating Layer inception_3c/output_inception_3c/output_0_split
I0109 14:38:04.499258  4932 net.cpp:459] inception_3c/output_inception_3c/output_0_split <- inception_3c/output
I0109 14:38:04.499261  4932 net.cpp:415] inception_3c/output_inception_3c/output_0_split -> inception_3c/output_inception_3c/output_0_split_0
I0109 14:38:04.499265  4932 net.cpp:415] inception_3c/output_inception_3c/output_0_split -> inception_3c/output_inception_3c/output_0_split_1
I0109 14:38:04.499271  4932 net.cpp:415] inception_3c/output_inception_3c/output_0_split -> inception_3c/output_inception_3c/output_0_split_2
I0109 14:38:04.499275  4932 net.cpp:415] inception_3c/output_inception_3c/output_0_split -> inception_3c/output_inception_3c/output_0_split_3
I0109 14:38:04.499279  4932 net.cpp:160] Setting up inception_3c/output_inception_3c/output_0_split
I0109 14:38:04.499284  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.499287  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.499291  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.499294  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.499297  4932 layer_factory.hpp:74] Creating layer inception_4a/1x1
I0109 14:38:04.499303  4932 net.cpp:96] Creating Layer inception_4a/1x1
I0109 14:38:04.499306  4932 net.cpp:459] inception_4a/1x1 <- inception_3c/output_inception_3c/output_0_split_0
I0109 14:38:04.499310  4932 net.cpp:415] inception_4a/1x1 -> inception_4a/1x1
I0109 14:38:04.499315  4932 net.cpp:160] Setting up inception_4a/1x1
I0109 14:38:04.499863  4932 net.cpp:167] Top shape: 3 224 14 14 (131712)
I0109 14:38:04.499869  4932 layer_factory.hpp:74] Creating layer inception_4a/1x1_bn
I0109 14:38:04.499873  4932 layer_factory.cpp:177] Layer inception_4a/1x1_bn is using CAFFE engine.
I0109 14:38:04.499877  4932 net.cpp:96] Creating Layer inception_4a/1x1_bn
I0109 14:38:04.499881  4932 net.cpp:459] inception_4a/1x1_bn <- inception_4a/1x1
I0109 14:38:04.499886  4932 net.cpp:415] inception_4a/1x1_bn -> inception_4a/1x1_bn
I0109 14:38:04.499891  4932 net.cpp:160] Setting up inception_4a/1x1_bn
I0109 14:38:04.499902  4932 net.cpp:167] Top shape: 3 224 14 14 (131712)
I0109 14:38:04.499907  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_1x1
I0109 14:38:04.499912  4932 net.cpp:96] Creating Layer inception_4a/relu_1x1
I0109 14:38:04.499914  4932 net.cpp:459] inception_4a/relu_1x1 <- inception_4a/1x1_bn
I0109 14:38:04.499918  4932 net.cpp:404] inception_4a/relu_1x1 -> inception_4a/1x1_bn (in-place)
I0109 14:38:04.499922  4932 net.cpp:160] Setting up inception_4a/relu_1x1
I0109 14:38:04.499925  4932 net.cpp:167] Top shape: 3 224 14 14 (131712)
I0109 14:38:04.499928  4932 layer_factory.hpp:74] Creating layer inception_4a/3x3_reduce
I0109 14:38:04.499934  4932 net.cpp:96] Creating Layer inception_4a/3x3_reduce
I0109 14:38:04.499938  4932 net.cpp:459] inception_4a/3x3_reduce <- inception_3c/output_inception_3c/output_0_split_1
I0109 14:38:04.499941  4932 net.cpp:415] inception_4a/3x3_reduce -> inception_4a/3x3_reduce
I0109 14:38:04.499946  4932 net.cpp:160] Setting up inception_4a/3x3_reduce
I0109 14:38:04.500118  4932 net.cpp:167] Top shape: 3 64 14 14 (37632)
I0109 14:38:04.500124  4932 layer_factory.hpp:74] Creating layer inception_4a/3x3_reduce_bn
I0109 14:38:04.500128  4932 layer_factory.cpp:177] Layer inception_4a/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.500139  4932 net.cpp:96] Creating Layer inception_4a/3x3_reduce_bn
I0109 14:38:04.500143  4932 net.cpp:459] inception_4a/3x3_reduce_bn <- inception_4a/3x3_reduce
I0109 14:38:04.500147  4932 net.cpp:415] inception_4a/3x3_reduce_bn -> inception_4a/3x3_reduce_bn
I0109 14:38:04.500152  4932 net.cpp:160] Setting up inception_4a/3x3_reduce_bn
I0109 14:38:04.500167  4932 net.cpp:167] Top shape: 3 64 14 14 (37632)
I0109 14:38:04.500174  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_3x3_reduce
I0109 14:38:04.500180  4932 net.cpp:96] Creating Layer inception_4a/relu_3x3_reduce
I0109 14:38:04.500182  4932 net.cpp:459] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce_bn
I0109 14:38:04.500186  4932 net.cpp:404] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce_bn (in-place)
I0109 14:38:04.500190  4932 net.cpp:160] Setting up inception_4a/relu_3x3_reduce
I0109 14:38:04.500193  4932 net.cpp:167] Top shape: 3 64 14 14 (37632)
I0109 14:38:04.500196  4932 layer_factory.hpp:74] Creating layer inception_4a/3x3
I0109 14:38:04.500201  4932 net.cpp:96] Creating Layer inception_4a/3x3
I0109 14:38:04.500205  4932 net.cpp:459] inception_4a/3x3 <- inception_4a/3x3_reduce_bn
I0109 14:38:04.500210  4932 net.cpp:415] inception_4a/3x3 -> inception_4a/3x3
I0109 14:38:04.500213  4932 net.cpp:160] Setting up inception_4a/3x3
I0109 14:38:04.500453  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.500459  4932 layer_factory.hpp:74] Creating layer inception_4a/3x3_bn
I0109 14:38:04.500463  4932 layer_factory.cpp:177] Layer inception_4a/3x3_bn is using CAFFE engine.
I0109 14:38:04.500466  4932 net.cpp:96] Creating Layer inception_4a/3x3_bn
I0109 14:38:04.500469  4932 net.cpp:459] inception_4a/3x3_bn <- inception_4a/3x3
I0109 14:38:04.500474  4932 net.cpp:415] inception_4a/3x3_bn -> inception_4a/3x3_bn
I0109 14:38:04.500479  4932 net.cpp:160] Setting up inception_4a/3x3_bn
I0109 14:38:04.500489  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.500494  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_3x3
I0109 14:38:04.500499  4932 net.cpp:96] Creating Layer inception_4a/relu_3x3
I0109 14:38:04.500502  4932 net.cpp:459] inception_4a/relu_3x3 <- inception_4a/3x3_bn
I0109 14:38:04.500505  4932 net.cpp:404] inception_4a/relu_3x3 -> inception_4a/3x3_bn (in-place)
I0109 14:38:04.500509  4932 net.cpp:160] Setting up inception_4a/relu_3x3
I0109 14:38:04.500514  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.500515  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_reduce
I0109 14:38:04.500520  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_reduce
I0109 14:38:04.500524  4932 net.cpp:459] inception_4a/double_3x3_reduce <- inception_3c/output_inception_3c/output_0_split_2
I0109 14:38:04.500529  4932 net.cpp:415] inception_4a/double_3x3_reduce -> inception_4a/double_3x3_reduce
I0109 14:38:04.500532  4932 net.cpp:160] Setting up inception_4a/double_3x3_reduce
I0109 14:38:04.500773  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.500778  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_reduce_bn
I0109 14:38:04.500782  4932 layer_factory.cpp:177] Layer inception_4a/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.500787  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_reduce_bn
I0109 14:38:04.500790  4932 net.cpp:459] inception_4a/double_3x3_reduce_bn <- inception_4a/double_3x3_reduce
I0109 14:38:04.500794  4932 net.cpp:415] inception_4a/double_3x3_reduce_bn -> inception_4a/double_3x3_reduce_bn
I0109 14:38:04.500798  4932 net.cpp:160] Setting up inception_4a/double_3x3_reduce_bn
I0109 14:38:04.500809  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.500814  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_double_3x3_reduce
I0109 14:38:04.500818  4932 net.cpp:96] Creating Layer inception_4a/relu_double_3x3_reduce
I0109 14:38:04.500821  4932 net.cpp:459] inception_4a/relu_double_3x3_reduce <- inception_4a/double_3x3_reduce_bn
I0109 14:38:04.500828  4932 net.cpp:404] inception_4a/relu_double_3x3_reduce -> inception_4a/double_3x3_reduce_bn (in-place)
I0109 14:38:04.500834  4932 net.cpp:160] Setting up inception_4a/relu_double_3x3_reduce
I0109 14:38:04.500838  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.500840  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_1
I0109 14:38:04.500846  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_1
I0109 14:38:04.500849  4932 net.cpp:459] inception_4a/double_3x3_1 <- inception_4a/double_3x3_reduce_bn
I0109 14:38:04.500854  4932 net.cpp:415] inception_4a/double_3x3_1 -> inception_4a/double_3x3_1
I0109 14:38:04.500859  4932 net.cpp:160] Setting up inception_4a/double_3x3_1
I0109 14:38:04.501354  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.501363  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_1_bn
I0109 14:38:04.501365  4932 layer_factory.cpp:177] Layer inception_4a/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.501370  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_1_bn
I0109 14:38:04.501374  4932 net.cpp:459] inception_4a/double_3x3_1_bn <- inception_4a/double_3x3_1
I0109 14:38:04.501379  4932 net.cpp:415] inception_4a/double_3x3_1_bn -> inception_4a/double_3x3_1_bn
I0109 14:38:04.501384  4932 net.cpp:160] Setting up inception_4a/double_3x3_1_bn
I0109 14:38:04.501394  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.501399  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_double_3x3_1
I0109 14:38:04.501405  4932 net.cpp:96] Creating Layer inception_4a/relu_double_3x3_1
I0109 14:38:04.501407  4932 net.cpp:459] inception_4a/relu_double_3x3_1 <- inception_4a/double_3x3_1_bn
I0109 14:38:04.501411  4932 net.cpp:404] inception_4a/relu_double_3x3_1 -> inception_4a/double_3x3_1_bn (in-place)
I0109 14:38:04.501415  4932 net.cpp:160] Setting up inception_4a/relu_double_3x3_1
I0109 14:38:04.501420  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.501421  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_2
I0109 14:38:04.501427  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_2
I0109 14:38:04.501430  4932 net.cpp:459] inception_4a/double_3x3_2 <- inception_4a/double_3x3_1_bn
I0109 14:38:04.501435  4932 net.cpp:415] inception_4a/double_3x3_2 -> inception_4a/double_3x3_2
I0109 14:38:04.501438  4932 net.cpp:160] Setting up inception_4a/double_3x3_2
I0109 14:38:04.502063  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.502068  4932 layer_factory.hpp:74] Creating layer inception_4a/double_3x3_2_bn
I0109 14:38:04.502071  4932 layer_factory.cpp:177] Layer inception_4a/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.502075  4932 net.cpp:96] Creating Layer inception_4a/double_3x3_2_bn
I0109 14:38:04.502079  4932 net.cpp:459] inception_4a/double_3x3_2_bn <- inception_4a/double_3x3_2
I0109 14:38:04.502084  4932 net.cpp:415] inception_4a/double_3x3_2_bn -> inception_4a/double_3x3_2_bn
I0109 14:38:04.502089  4932 net.cpp:160] Setting up inception_4a/double_3x3_2_bn
I0109 14:38:04.502099  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.502104  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_double_3x3_2
I0109 14:38:04.502109  4932 net.cpp:96] Creating Layer inception_4a/relu_double_3x3_2
I0109 14:38:04.502111  4932 net.cpp:459] inception_4a/relu_double_3x3_2 <- inception_4a/double_3x3_2_bn
I0109 14:38:04.502115  4932 net.cpp:404] inception_4a/relu_double_3x3_2 -> inception_4a/double_3x3_2_bn (in-place)
I0109 14:38:04.502118  4932 net.cpp:160] Setting up inception_4a/relu_double_3x3_2
I0109 14:38:04.502121  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.502125  4932 layer_factory.hpp:74] Creating layer inception_4a/pool
I0109 14:38:04.502128  4932 net.cpp:96] Creating Layer inception_4a/pool
I0109 14:38:04.502131  4932 net.cpp:459] inception_4a/pool <- inception_3c/output_inception_3c/output_0_split_3
I0109 14:38:04.502135  4932 net.cpp:415] inception_4a/pool -> inception_4a/pool
I0109 14:38:04.502140  4932 net.cpp:160] Setting up inception_4a/pool
I0109 14:38:04.502147  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.502153  4932 layer_factory.hpp:74] Creating layer inception_4a/pool_proj
I0109 14:38:04.502159  4932 net.cpp:96] Creating Layer inception_4a/pool_proj
I0109 14:38:04.502162  4932 net.cpp:459] inception_4a/pool_proj <- inception_4a/pool
I0109 14:38:04.502166  4932 net.cpp:415] inception_4a/pool_proj -> inception_4a/pool_proj
I0109 14:38:04.502171  4932 net.cpp:160] Setting up inception_4a/pool_proj
I0109 14:38:04.502486  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.502492  4932 layer_factory.hpp:74] Creating layer inception_4a/pool_proj_bn
I0109 14:38:04.502496  4932 layer_factory.cpp:177] Layer inception_4a/pool_proj_bn is using CAFFE engine.
I0109 14:38:04.502501  4932 net.cpp:96] Creating Layer inception_4a/pool_proj_bn
I0109 14:38:04.502503  4932 net.cpp:459] inception_4a/pool_proj_bn <- inception_4a/pool_proj
I0109 14:38:04.502508  4932 net.cpp:415] inception_4a/pool_proj_bn -> inception_4a/pool_proj_bn
I0109 14:38:04.502512  4932 net.cpp:160] Setting up inception_4a/pool_proj_bn
I0109 14:38:04.502522  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.502528  4932 layer_factory.hpp:74] Creating layer inception_4a/relu_pool_proj
I0109 14:38:04.502533  4932 net.cpp:96] Creating Layer inception_4a/relu_pool_proj
I0109 14:38:04.502537  4932 net.cpp:459] inception_4a/relu_pool_proj <- inception_4a/pool_proj_bn
I0109 14:38:04.502539  4932 net.cpp:404] inception_4a/relu_pool_proj -> inception_4a/pool_proj_bn (in-place)
I0109 14:38:04.502543  4932 net.cpp:160] Setting up inception_4a/relu_pool_proj
I0109 14:38:04.502547  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.502549  4932 layer_factory.hpp:74] Creating layer inception_4a/output
I0109 14:38:04.502553  4932 net.cpp:96] Creating Layer inception_4a/output
I0109 14:38:04.502557  4932 net.cpp:459] inception_4a/output <- inception_4a/1x1_bn
I0109 14:38:04.502560  4932 net.cpp:459] inception_4a/output <- inception_4a/3x3_bn
I0109 14:38:04.502563  4932 net.cpp:459] inception_4a/output <- inception_4a/double_3x3_2_bn
I0109 14:38:04.502566  4932 net.cpp:459] inception_4a/output <- inception_4a/pool_proj_bn
I0109 14:38:04.502571  4932 net.cpp:415] inception_4a/output -> inception_4a/output
I0109 14:38:04.502575  4932 net.cpp:160] Setting up inception_4a/output
I0109 14:38:04.502580  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.502583  4932 layer_factory.hpp:74] Creating layer inception_4a/output_inception_4a/output_0_split
I0109 14:38:04.502588  4932 net.cpp:96] Creating Layer inception_4a/output_inception_4a/output_0_split
I0109 14:38:04.502590  4932 net.cpp:459] inception_4a/output_inception_4a/output_0_split <- inception_4a/output
I0109 14:38:04.502593  4932 net.cpp:415] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0
I0109 14:38:04.502599  4932 net.cpp:415] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1
I0109 14:38:04.502604  4932 net.cpp:415] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2
I0109 14:38:04.502609  4932 net.cpp:415] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3
I0109 14:38:04.502612  4932 net.cpp:160] Setting up inception_4a/output_inception_4a/output_0_split
I0109 14:38:04.502616  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.502620  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.502624  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.502626  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.502629  4932 layer_factory.hpp:74] Creating layer inception_4b/1x1
I0109 14:38:04.502635  4932 net.cpp:96] Creating Layer inception_4b/1x1
I0109 14:38:04.502637  4932 net.cpp:459] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_0
I0109 14:38:04.502641  4932 net.cpp:415] inception_4b/1x1 -> inception_4b/1x1
I0109 14:38:04.502648  4932 net.cpp:160] Setting up inception_4b/1x1
I0109 14:38:04.503387  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.503401  4932 layer_factory.hpp:74] Creating layer inception_4b/1x1_bn
I0109 14:38:04.503407  4932 layer_factory.cpp:177] Layer inception_4b/1x1_bn is using CAFFE engine.
I0109 14:38:04.503415  4932 net.cpp:96] Creating Layer inception_4b/1x1_bn
I0109 14:38:04.503420  4932 net.cpp:459] inception_4b/1x1_bn <- inception_4b/1x1
I0109 14:38:04.503428  4932 net.cpp:415] inception_4b/1x1_bn -> inception_4b/1x1_bn
I0109 14:38:04.503437  4932 net.cpp:160] Setting up inception_4b/1x1_bn
I0109 14:38:04.503453  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.503460  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_1x1
I0109 14:38:04.503468  4932 net.cpp:96] Creating Layer inception_4b/relu_1x1
I0109 14:38:04.503473  4932 net.cpp:459] inception_4b/relu_1x1 <- inception_4b/1x1_bn
I0109 14:38:04.503479  4932 net.cpp:404] inception_4b/relu_1x1 -> inception_4b/1x1_bn (in-place)
I0109 14:38:04.503484  4932 net.cpp:160] Setting up inception_4b/relu_1x1
I0109 14:38:04.503489  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.503494  4932 layer_factory.hpp:74] Creating layer inception_4b/3x3_reduce
I0109 14:38:04.503500  4932 net.cpp:96] Creating Layer inception_4b/3x3_reduce
I0109 14:38:04.503505  4932 net.cpp:459] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_1
I0109 14:38:04.503514  4932 net.cpp:415] inception_4b/3x3_reduce -> inception_4b/3x3_reduce
I0109 14:38:04.503520  4932 net.cpp:160] Setting up inception_4b/3x3_reduce
I0109 14:38:04.503903  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.503916  4932 layer_factory.hpp:74] Creating layer inception_4b/3x3_reduce_bn
I0109 14:38:04.503922  4932 layer_factory.cpp:177] Layer inception_4b/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.503929  4932 net.cpp:96] Creating Layer inception_4b/3x3_reduce_bn
I0109 14:38:04.503935  4932 net.cpp:459] inception_4b/3x3_reduce_bn <- inception_4b/3x3_reduce
I0109 14:38:04.503945  4932 net.cpp:415] inception_4b/3x3_reduce_bn -> inception_4b/3x3_reduce_bn
I0109 14:38:04.503955  4932 net.cpp:160] Setting up inception_4b/3x3_reduce_bn
I0109 14:38:04.503973  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.503979  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_3x3_reduce
I0109 14:38:04.503984  4932 net.cpp:96] Creating Layer inception_4b/relu_3x3_reduce
I0109 14:38:04.503988  4932 net.cpp:459] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce_bn
I0109 14:38:04.503991  4932 net.cpp:404] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce_bn (in-place)
I0109 14:38:04.503996  4932 net.cpp:160] Setting up inception_4b/relu_3x3_reduce
I0109 14:38:04.503999  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.504003  4932 layer_factory.hpp:74] Creating layer inception_4b/3x3
I0109 14:38:04.504009  4932 net.cpp:96] Creating Layer inception_4b/3x3
I0109 14:38:04.504011  4932 net.cpp:459] inception_4b/3x3 <- inception_4b/3x3_reduce_bn
I0109 14:38:04.504016  4932 net.cpp:415] inception_4b/3x3 -> inception_4b/3x3
I0109 14:38:04.504022  4932 net.cpp:160] Setting up inception_4b/3x3
I0109 14:38:04.504926  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.504940  4932 layer_factory.hpp:74] Creating layer inception_4b/3x3_bn
I0109 14:38:04.504945  4932 layer_factory.cpp:177] Layer inception_4b/3x3_bn is using CAFFE engine.
I0109 14:38:04.504953  4932 net.cpp:96] Creating Layer inception_4b/3x3_bn
I0109 14:38:04.504959  4932 net.cpp:459] inception_4b/3x3_bn <- inception_4b/3x3
I0109 14:38:04.504967  4932 net.cpp:415] inception_4b/3x3_bn -> inception_4b/3x3_bn
I0109 14:38:04.504976  4932 net.cpp:160] Setting up inception_4b/3x3_bn
I0109 14:38:04.504992  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.505002  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_3x3
I0109 14:38:04.505008  4932 net.cpp:96] Creating Layer inception_4b/relu_3x3
I0109 14:38:04.505018  4932 net.cpp:459] inception_4b/relu_3x3 <- inception_4b/3x3_bn
I0109 14:38:04.505031  4932 net.cpp:404] inception_4b/relu_3x3 -> inception_4b/3x3_bn (in-place)
I0109 14:38:04.505038  4932 net.cpp:160] Setting up inception_4b/relu_3x3
I0109 14:38:04.505044  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.505048  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_reduce
I0109 14:38:04.505056  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_reduce
I0109 14:38:04.505061  4932 net.cpp:459] inception_4b/double_3x3_reduce <- inception_4a/output_inception_4a/output_0_split_2
I0109 14:38:04.505067  4932 net.cpp:415] inception_4b/double_3x3_reduce -> inception_4b/double_3x3_reduce
I0109 14:38:04.505075  4932 net.cpp:160] Setting up inception_4b/double_3x3_reduce
I0109 14:38:04.505509  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.505522  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_reduce_bn
I0109 14:38:04.505527  4932 layer_factory.cpp:177] Layer inception_4b/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.505535  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_reduce_bn
I0109 14:38:04.505542  4932 net.cpp:459] inception_4b/double_3x3_reduce_bn <- inception_4b/double_3x3_reduce
I0109 14:38:04.505549  4932 net.cpp:415] inception_4b/double_3x3_reduce_bn -> inception_4b/double_3x3_reduce_bn
I0109 14:38:04.505558  4932 net.cpp:160] Setting up inception_4b/double_3x3_reduce_bn
I0109 14:38:04.505576  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.505587  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_double_3x3_reduce
I0109 14:38:04.505595  4932 net.cpp:96] Creating Layer inception_4b/relu_double_3x3_reduce
I0109 14:38:04.505600  4932 net.cpp:459] inception_4b/relu_double_3x3_reduce <- inception_4b/double_3x3_reduce_bn
I0109 14:38:04.505607  4932 net.cpp:404] inception_4b/relu_double_3x3_reduce -> inception_4b/double_3x3_reduce_bn (in-place)
I0109 14:38:04.505614  4932 net.cpp:160] Setting up inception_4b/relu_double_3x3_reduce
I0109 14:38:04.505620  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.505625  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_1
I0109 14:38:04.505632  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_1
I0109 14:38:04.505637  4932 net.cpp:459] inception_4b/double_3x3_1 <- inception_4b/double_3x3_reduce_bn
I0109 14:38:04.505645  4932 net.cpp:415] inception_4b/double_3x3_1 -> inception_4b/double_3x3_1
I0109 14:38:04.505653  4932 net.cpp:160] Setting up inception_4b/double_3x3_1
I0109 14:38:04.506520  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.506533  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_1_bn
I0109 14:38:04.506541  4932 layer_factory.cpp:177] Layer inception_4b/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.506551  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_1_bn
I0109 14:38:04.506557  4932 net.cpp:459] inception_4b/double_3x3_1_bn <- inception_4b/double_3x3_1
I0109 14:38:04.506567  4932 net.cpp:415] inception_4b/double_3x3_1_bn -> inception_4b/double_3x3_1_bn
I0109 14:38:04.506577  4932 net.cpp:160] Setting up inception_4b/double_3x3_1_bn
I0109 14:38:04.506598  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.506610  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_double_3x3_1
I0109 14:38:04.506618  4932 net.cpp:96] Creating Layer inception_4b/relu_double_3x3_1
I0109 14:38:04.506624  4932 net.cpp:459] inception_4b/relu_double_3x3_1 <- inception_4b/double_3x3_1_bn
I0109 14:38:04.506633  4932 net.cpp:404] inception_4b/relu_double_3x3_1 -> inception_4b/double_3x3_1_bn (in-place)
I0109 14:38:04.506641  4932 net.cpp:160] Setting up inception_4b/relu_double_3x3_1
I0109 14:38:04.506649  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.506654  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_2
I0109 14:38:04.506660  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_2
I0109 14:38:04.506664  4932 net.cpp:459] inception_4b/double_3x3_2 <- inception_4b/double_3x3_1_bn
I0109 14:38:04.506680  4932 net.cpp:415] inception_4b/double_3x3_2 -> inception_4b/double_3x3_2
I0109 14:38:04.506690  4932 net.cpp:160] Setting up inception_4b/double_3x3_2
I0109 14:38:04.507835  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.507849  4932 layer_factory.hpp:74] Creating layer inception_4b/double_3x3_2_bn
I0109 14:38:04.507856  4932 layer_factory.cpp:177] Layer inception_4b/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.507864  4932 net.cpp:96] Creating Layer inception_4b/double_3x3_2_bn
I0109 14:38:04.507870  4932 net.cpp:459] inception_4b/double_3x3_2_bn <- inception_4b/double_3x3_2
I0109 14:38:04.507877  4932 net.cpp:415] inception_4b/double_3x3_2_bn -> inception_4b/double_3x3_2_bn
I0109 14:38:04.507885  4932 net.cpp:160] Setting up inception_4b/double_3x3_2_bn
I0109 14:38:04.507903  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.507913  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_double_3x3_2
I0109 14:38:04.507920  4932 net.cpp:96] Creating Layer inception_4b/relu_double_3x3_2
I0109 14:38:04.507926  4932 net.cpp:459] inception_4b/relu_double_3x3_2 <- inception_4b/double_3x3_2_bn
I0109 14:38:04.507932  4932 net.cpp:404] inception_4b/relu_double_3x3_2 -> inception_4b/double_3x3_2_bn (in-place)
I0109 14:38:04.507938  4932 net.cpp:160] Setting up inception_4b/relu_double_3x3_2
I0109 14:38:04.507944  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.507949  4932 layer_factory.hpp:74] Creating layer inception_4b/pool
I0109 14:38:04.507956  4932 net.cpp:96] Creating Layer inception_4b/pool
I0109 14:38:04.507961  4932 net.cpp:459] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_3
I0109 14:38:04.507968  4932 net.cpp:415] inception_4b/pool -> inception_4b/pool
I0109 14:38:04.507974  4932 net.cpp:160] Setting up inception_4b/pool
I0109 14:38:04.507982  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.507987  4932 layer_factory.hpp:74] Creating layer inception_4b/pool_proj
I0109 14:38:04.507997  4932 net.cpp:96] Creating Layer inception_4b/pool_proj
I0109 14:38:04.508002  4932 net.cpp:459] inception_4b/pool_proj <- inception_4b/pool
I0109 14:38:04.508010  4932 net.cpp:415] inception_4b/pool_proj -> inception_4b/pool_proj
I0109 14:38:04.508018  4932 net.cpp:160] Setting up inception_4b/pool_proj
I0109 14:38:04.508615  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.508627  4932 layer_factory.hpp:74] Creating layer inception_4b/pool_proj_bn
I0109 14:38:04.508632  4932 layer_factory.cpp:177] Layer inception_4b/pool_proj_bn is using CAFFE engine.
I0109 14:38:04.508641  4932 net.cpp:96] Creating Layer inception_4b/pool_proj_bn
I0109 14:38:04.508646  4932 net.cpp:459] inception_4b/pool_proj_bn <- inception_4b/pool_proj
I0109 14:38:04.508652  4932 net.cpp:415] inception_4b/pool_proj_bn -> inception_4b/pool_proj_bn
I0109 14:38:04.508661  4932 net.cpp:160] Setting up inception_4b/pool_proj_bn
I0109 14:38:04.508675  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.508683  4932 layer_factory.hpp:74] Creating layer inception_4b/relu_pool_proj
I0109 14:38:04.508689  4932 net.cpp:96] Creating Layer inception_4b/relu_pool_proj
I0109 14:38:04.508694  4932 net.cpp:459] inception_4b/relu_pool_proj <- inception_4b/pool_proj_bn
I0109 14:38:04.508700  4932 net.cpp:404] inception_4b/relu_pool_proj -> inception_4b/pool_proj_bn (in-place)
I0109 14:38:04.508707  4932 net.cpp:160] Setting up inception_4b/relu_pool_proj
I0109 14:38:04.508713  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.508716  4932 layer_factory.hpp:74] Creating layer inception_4b/output
I0109 14:38:04.508723  4932 net.cpp:96] Creating Layer inception_4b/output
I0109 14:38:04.508728  4932 net.cpp:459] inception_4b/output <- inception_4b/1x1_bn
I0109 14:38:04.508733  4932 net.cpp:459] inception_4b/output <- inception_4b/3x3_bn
I0109 14:38:04.508738  4932 net.cpp:459] inception_4b/output <- inception_4b/double_3x3_2_bn
I0109 14:38:04.508744  4932 net.cpp:459] inception_4b/output <- inception_4b/pool_proj_bn
I0109 14:38:04.508757  4932 net.cpp:415] inception_4b/output -> inception_4b/output
I0109 14:38:04.508764  4932 net.cpp:160] Setting up inception_4b/output
I0109 14:38:04.508771  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.508776  4932 layer_factory.hpp:74] Creating layer inception_4b/output_inception_4b/output_0_split
I0109 14:38:04.508797  4932 net.cpp:96] Creating Layer inception_4b/output_inception_4b/output_0_split
I0109 14:38:04.508802  4932 net.cpp:459] inception_4b/output_inception_4b/output_0_split <- inception_4b/output
I0109 14:38:04.508808  4932 net.cpp:415] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0
I0109 14:38:04.508816  4932 net.cpp:415] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1
I0109 14:38:04.508822  4932 net.cpp:415] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2
I0109 14:38:04.508831  4932 net.cpp:415] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3
I0109 14:38:04.508836  4932 net.cpp:160] Setting up inception_4b/output_inception_4b/output_0_split
I0109 14:38:04.508843  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.508849  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.508854  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.508859  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.508865  4932 layer_factory.hpp:74] Creating layer inception_4c/1x1
I0109 14:38:04.508873  4932 net.cpp:96] Creating Layer inception_4c/1x1
I0109 14:38:04.508879  4932 net.cpp:459] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0
I0109 14:38:04.508885  4932 net.cpp:415] inception_4c/1x1 -> inception_4c/1x1
I0109 14:38:04.508893  4932 net.cpp:160] Setting up inception_4c/1x1
I0109 14:38:04.509619  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.509630  4932 layer_factory.hpp:74] Creating layer inception_4c/1x1_bn
I0109 14:38:04.509635  4932 layer_factory.cpp:177] Layer inception_4c/1x1_bn is using CAFFE engine.
I0109 14:38:04.509642  4932 net.cpp:96] Creating Layer inception_4c/1x1_bn
I0109 14:38:04.509647  4932 net.cpp:459] inception_4c/1x1_bn <- inception_4c/1x1
I0109 14:38:04.509659  4932 net.cpp:415] inception_4c/1x1_bn -> inception_4c/1x1_bn
I0109 14:38:04.509666  4932 net.cpp:160] Setting up inception_4c/1x1_bn
I0109 14:38:04.509681  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.509690  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_1x1
I0109 14:38:04.509696  4932 net.cpp:96] Creating Layer inception_4c/relu_1x1
I0109 14:38:04.509701  4932 net.cpp:459] inception_4c/relu_1x1 <- inception_4c/1x1_bn
I0109 14:38:04.509706  4932 net.cpp:404] inception_4c/relu_1x1 -> inception_4c/1x1_bn (in-place)
I0109 14:38:04.509711  4932 net.cpp:160] Setting up inception_4c/relu_1x1
I0109 14:38:04.509716  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.509721  4932 layer_factory.hpp:74] Creating layer inception_4c/3x3_reduce
I0109 14:38:04.509728  4932 net.cpp:96] Creating Layer inception_4c/3x3_reduce
I0109 14:38:04.509733  4932 net.cpp:459] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1
I0109 14:38:04.509740  4932 net.cpp:415] inception_4c/3x3_reduce -> inception_4c/3x3_reduce
I0109 14:38:04.509747  4932 net.cpp:160] Setting up inception_4c/3x3_reduce
I0109 14:38:04.510329  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.510336  4932 layer_factory.hpp:74] Creating layer inception_4c/3x3_reduce_bn
I0109 14:38:04.510341  4932 layer_factory.cpp:177] Layer inception_4c/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.510349  4932 net.cpp:96] Creating Layer inception_4c/3x3_reduce_bn
I0109 14:38:04.510354  4932 net.cpp:459] inception_4c/3x3_reduce_bn <- inception_4c/3x3_reduce
I0109 14:38:04.510361  4932 net.cpp:415] inception_4c/3x3_reduce_bn -> inception_4c/3x3_reduce_bn
I0109 14:38:04.510371  4932 net.cpp:160] Setting up inception_4c/3x3_reduce_bn
I0109 14:38:04.510391  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.510401  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_3x3_reduce
I0109 14:38:04.510407  4932 net.cpp:96] Creating Layer inception_4c/relu_3x3_reduce
I0109 14:38:04.510412  4932 net.cpp:459] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce_bn
I0109 14:38:04.510417  4932 net.cpp:404] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce_bn (in-place)
I0109 14:38:04.510423  4932 net.cpp:160] Setting up inception_4c/relu_3x3_reduce
I0109 14:38:04.510428  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.510433  4932 layer_factory.hpp:74] Creating layer inception_4c/3x3
I0109 14:38:04.510442  4932 net.cpp:96] Creating Layer inception_4c/3x3
I0109 14:38:04.510447  4932 net.cpp:459] inception_4c/3x3 <- inception_4c/3x3_reduce_bn
I0109 14:38:04.510452  4932 net.cpp:415] inception_4c/3x3 -> inception_4c/3x3
I0109 14:38:04.510458  4932 net.cpp:160] Setting up inception_4c/3x3
I0109 14:38:04.511901  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.511910  4932 layer_factory.hpp:74] Creating layer inception_4c/3x3_bn
I0109 14:38:04.511915  4932 layer_factory.cpp:177] Layer inception_4c/3x3_bn is using CAFFE engine.
I0109 14:38:04.511922  4932 net.cpp:96] Creating Layer inception_4c/3x3_bn
I0109 14:38:04.511926  4932 net.cpp:459] inception_4c/3x3_bn <- inception_4c/3x3
I0109 14:38:04.511934  4932 net.cpp:415] inception_4c/3x3_bn -> inception_4c/3x3_bn
I0109 14:38:04.511941  4932 net.cpp:160] Setting up inception_4c/3x3_bn
I0109 14:38:04.511957  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.511965  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_3x3
I0109 14:38:04.511971  4932 net.cpp:96] Creating Layer inception_4c/relu_3x3
I0109 14:38:04.511976  4932 net.cpp:459] inception_4c/relu_3x3 <- inception_4c/3x3_bn
I0109 14:38:04.511981  4932 net.cpp:404] inception_4c/relu_3x3 -> inception_4c/3x3_bn (in-place)
I0109 14:38:04.511987  4932 net.cpp:160] Setting up inception_4c/relu_3x3
I0109 14:38:04.511992  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.511997  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_reduce
I0109 14:38:04.512006  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_reduce
I0109 14:38:04.512011  4932 net.cpp:459] inception_4c/double_3x3_reduce <- inception_4b/output_inception_4b/output_0_split_2
I0109 14:38:04.512017  4932 net.cpp:415] inception_4c/double_3x3_reduce -> inception_4c/double_3x3_reduce
I0109 14:38:04.512024  4932 net.cpp:160] Setting up inception_4c/double_3x3_reduce
I0109 14:38:04.512615  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.512625  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_reduce_bn
I0109 14:38:04.512630  4932 layer_factory.cpp:177] Layer inception_4c/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.512639  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_reduce_bn
I0109 14:38:04.512643  4932 net.cpp:459] inception_4c/double_3x3_reduce_bn <- inception_4c/double_3x3_reduce
I0109 14:38:04.512651  4932 net.cpp:415] inception_4c/double_3x3_reduce_bn -> inception_4c/double_3x3_reduce_bn
I0109 14:38:04.512658  4932 net.cpp:160] Setting up inception_4c/double_3x3_reduce_bn
I0109 14:38:04.512676  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.512686  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_double_3x3_reduce
I0109 14:38:04.512692  4932 net.cpp:96] Creating Layer inception_4c/relu_double_3x3_reduce
I0109 14:38:04.512697  4932 net.cpp:459] inception_4c/relu_double_3x3_reduce <- inception_4c/double_3x3_reduce_bn
I0109 14:38:04.512703  4932 net.cpp:404] inception_4c/relu_double_3x3_reduce -> inception_4c/double_3x3_reduce_bn (in-place)
I0109 14:38:04.512711  4932 net.cpp:160] Setting up inception_4c/relu_double_3x3_reduce
I0109 14:38:04.512717  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.512723  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_1
I0109 14:38:04.512737  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_1
I0109 14:38:04.512742  4932 net.cpp:459] inception_4c/double_3x3_1 <- inception_4c/double_3x3_reduce_bn
I0109 14:38:04.512748  4932 net.cpp:415] inception_4c/double_3x3_1 -> inception_4c/double_3x3_1
I0109 14:38:04.512754  4932 net.cpp:160] Setting up inception_4c/double_3x3_1
I0109 14:38:04.514196  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.514205  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_1_bn
I0109 14:38:04.514210  4932 layer_factory.cpp:177] Layer inception_4c/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.514216  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_1_bn
I0109 14:38:04.514221  4932 net.cpp:459] inception_4c/double_3x3_1_bn <- inception_4c/double_3x3_1
I0109 14:38:04.514228  4932 net.cpp:415] inception_4c/double_3x3_1_bn -> inception_4c/double_3x3_1_bn
I0109 14:38:04.514235  4932 net.cpp:160] Setting up inception_4c/double_3x3_1_bn
I0109 14:38:04.514251  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.514259  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_double_3x3_1
I0109 14:38:04.514266  4932 net.cpp:96] Creating Layer inception_4c/relu_double_3x3_1
I0109 14:38:04.514271  4932 net.cpp:459] inception_4c/relu_double_3x3_1 <- inception_4c/double_3x3_1_bn
I0109 14:38:04.514277  4932 net.cpp:404] inception_4c/relu_double_3x3_1 -> inception_4c/double_3x3_1_bn (in-place)
I0109 14:38:04.514282  4932 net.cpp:160] Setting up inception_4c/relu_double_3x3_1
I0109 14:38:04.514288  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.514292  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_2
I0109 14:38:04.514299  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_2
I0109 14:38:04.514304  4932 net.cpp:459] inception_4c/double_3x3_2 <- inception_4c/double_3x3_1_bn
I0109 14:38:04.514312  4932 net.cpp:415] inception_4c/double_3x3_2 -> inception_4c/double_3x3_2
I0109 14:38:04.514319  4932 net.cpp:160] Setting up inception_4c/double_3x3_2
I0109 14:38:04.516124  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.516136  4932 layer_factory.hpp:74] Creating layer inception_4c/double_3x3_2_bn
I0109 14:38:04.516141  4932 layer_factory.cpp:177] Layer inception_4c/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.516149  4932 net.cpp:96] Creating Layer inception_4c/double_3x3_2_bn
I0109 14:38:04.516155  4932 net.cpp:459] inception_4c/double_3x3_2_bn <- inception_4c/double_3x3_2
I0109 14:38:04.516161  4932 net.cpp:415] inception_4c/double_3x3_2_bn -> inception_4c/double_3x3_2_bn
I0109 14:38:04.516170  4932 net.cpp:160] Setting up inception_4c/double_3x3_2_bn
I0109 14:38:04.516186  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.516196  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_double_3x3_2
I0109 14:38:04.516201  4932 net.cpp:96] Creating Layer inception_4c/relu_double_3x3_2
I0109 14:38:04.516206  4932 net.cpp:459] inception_4c/relu_double_3x3_2 <- inception_4c/double_3x3_2_bn
I0109 14:38:04.516211  4932 net.cpp:404] inception_4c/relu_double_3x3_2 -> inception_4c/double_3x3_2_bn (in-place)
I0109 14:38:04.516217  4932 net.cpp:160] Setting up inception_4c/relu_double_3x3_2
I0109 14:38:04.516222  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.516227  4932 layer_factory.hpp:74] Creating layer inception_4c/pool
I0109 14:38:04.516233  4932 net.cpp:96] Creating Layer inception_4c/pool
I0109 14:38:04.516237  4932 net.cpp:459] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3
I0109 14:38:04.516242  4932 net.cpp:415] inception_4c/pool -> inception_4c/pool
I0109 14:38:04.516248  4932 net.cpp:160] Setting up inception_4c/pool
I0109 14:38:04.516255  4932 net.cpp:167] Top shape: 3 576 14 14 (338688)
I0109 14:38:04.516260  4932 layer_factory.hpp:74] Creating layer inception_4c/pool_proj
I0109 14:38:04.516268  4932 net.cpp:96] Creating Layer inception_4c/pool_proj
I0109 14:38:04.516273  4932 net.cpp:459] inception_4c/pool_proj <- inception_4c/pool
I0109 14:38:04.516286  4932 net.cpp:415] inception_4c/pool_proj -> inception_4c/pool_proj
I0109 14:38:04.516294  4932 net.cpp:160] Setting up inception_4c/pool_proj
I0109 14:38:04.516878  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.516888  4932 layer_factory.hpp:74] Creating layer inception_4c/pool_proj_bn
I0109 14:38:04.516893  4932 layer_factory.cpp:177] Layer inception_4c/pool_proj_bn is using CAFFE engine.
I0109 14:38:04.516901  4932 net.cpp:96] Creating Layer inception_4c/pool_proj_bn
I0109 14:38:04.516906  4932 net.cpp:459] inception_4c/pool_proj_bn <- inception_4c/pool_proj
I0109 14:38:04.516911  4932 net.cpp:415] inception_4c/pool_proj_bn -> inception_4c/pool_proj_bn
I0109 14:38:04.516918  4932 net.cpp:160] Setting up inception_4c/pool_proj_bn
I0109 14:38:04.516933  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.516964  4932 layer_factory.hpp:74] Creating layer inception_4c/relu_pool_proj
I0109 14:38:04.516971  4932 net.cpp:96] Creating Layer inception_4c/relu_pool_proj
I0109 14:38:04.516976  4932 net.cpp:459] inception_4c/relu_pool_proj <- inception_4c/pool_proj_bn
I0109 14:38:04.516983  4932 net.cpp:404] inception_4c/relu_pool_proj -> inception_4c/pool_proj_bn (in-place)
I0109 14:38:04.516988  4932 net.cpp:160] Setting up inception_4c/relu_pool_proj
I0109 14:38:04.516993  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.516999  4932 layer_factory.hpp:74] Creating layer inception_4c/output
I0109 14:38:04.517004  4932 net.cpp:96] Creating Layer inception_4c/output
I0109 14:38:04.517009  4932 net.cpp:459] inception_4c/output <- inception_4c/1x1_bn
I0109 14:38:04.517015  4932 net.cpp:459] inception_4c/output <- inception_4c/3x3_bn
I0109 14:38:04.517020  4932 net.cpp:459] inception_4c/output <- inception_4c/double_3x3_2_bn
I0109 14:38:04.517025  4932 net.cpp:459] inception_4c/output <- inception_4c/pool_proj_bn
I0109 14:38:04.517031  4932 net.cpp:415] inception_4c/output -> inception_4c/output
I0109 14:38:04.517038  4932 net.cpp:160] Setting up inception_4c/output
I0109 14:38:04.517046  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.517051  4932 layer_factory.hpp:74] Creating layer inception_4c/output_inception_4c/output_0_split
I0109 14:38:04.517058  4932 net.cpp:96] Creating Layer inception_4c/output_inception_4c/output_0_split
I0109 14:38:04.517062  4932 net.cpp:459] inception_4c/output_inception_4c/output_0_split <- inception_4c/output
I0109 14:38:04.517071  4932 net.cpp:415] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0
I0109 14:38:04.517091  4932 net.cpp:415] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1
I0109 14:38:04.517098  4932 net.cpp:415] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2
I0109 14:38:04.517105  4932 net.cpp:415] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3
I0109 14:38:04.517112  4932 net.cpp:160] Setting up inception_4c/output_inception_4c/output_0_split
I0109 14:38:04.517120  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.517127  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.517132  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.517138  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.517143  4932 layer_factory.hpp:74] Creating layer inception_4d/1x1
I0109 14:38:04.517151  4932 net.cpp:96] Creating Layer inception_4d/1x1
I0109 14:38:04.517156  4932 net.cpp:459] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0
I0109 14:38:04.517163  4932 net.cpp:415] inception_4d/1x1 -> inception_4d/1x1
I0109 14:38:04.517170  4932 net.cpp:160] Setting up inception_4d/1x1
I0109 14:38:04.517637  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.517647  4932 layer_factory.hpp:74] Creating layer inception_4d/1x1_bn
I0109 14:38:04.517652  4932 layer_factory.cpp:177] Layer inception_4d/1x1_bn is using CAFFE engine.
I0109 14:38:04.517666  4932 net.cpp:96] Creating Layer inception_4d/1x1_bn
I0109 14:38:04.517671  4932 net.cpp:459] inception_4d/1x1_bn <- inception_4d/1x1
I0109 14:38:04.517679  4932 net.cpp:415] inception_4d/1x1_bn -> inception_4d/1x1_bn
I0109 14:38:04.517688  4932 net.cpp:160] Setting up inception_4d/1x1_bn
I0109 14:38:04.517704  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.517714  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_1x1
I0109 14:38:04.517720  4932 net.cpp:96] Creating Layer inception_4d/relu_1x1
I0109 14:38:04.517725  4932 net.cpp:459] inception_4d/relu_1x1 <- inception_4d/1x1_bn
I0109 14:38:04.517731  4932 net.cpp:404] inception_4d/relu_1x1 -> inception_4d/1x1_bn (in-place)
I0109 14:38:04.517737  4932 net.cpp:160] Setting up inception_4d/relu_1x1
I0109 14:38:04.517743  4932 net.cpp:167] Top shape: 3 96 14 14 (56448)
I0109 14:38:04.517748  4932 layer_factory.hpp:74] Creating layer inception_4d/3x3_reduce
I0109 14:38:04.517757  4932 net.cpp:96] Creating Layer inception_4d/3x3_reduce
I0109 14:38:04.517762  4932 net.cpp:459] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1
I0109 14:38:04.517770  4932 net.cpp:415] inception_4d/3x3_reduce -> inception_4d/3x3_reduce
I0109 14:38:04.517776  4932 net.cpp:160] Setting up inception_4d/3x3_reduce
I0109 14:38:04.518393  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.518401  4932 layer_factory.hpp:74] Creating layer inception_4d/3x3_reduce_bn
I0109 14:38:04.518405  4932 layer_factory.cpp:177] Layer inception_4d/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.518414  4932 net.cpp:96] Creating Layer inception_4d/3x3_reduce_bn
I0109 14:38:04.518419  4932 net.cpp:459] inception_4d/3x3_reduce_bn <- inception_4d/3x3_reduce
I0109 14:38:04.518424  4932 net.cpp:415] inception_4d/3x3_reduce_bn -> inception_4d/3x3_reduce_bn
I0109 14:38:04.518430  4932 net.cpp:160] Setting up inception_4d/3x3_reduce_bn
I0109 14:38:04.518445  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.518453  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_3x3_reduce
I0109 14:38:04.518460  4932 net.cpp:96] Creating Layer inception_4d/relu_3x3_reduce
I0109 14:38:04.518465  4932 net.cpp:459] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce_bn
I0109 14:38:04.518471  4932 net.cpp:404] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce_bn (in-place)
I0109 14:38:04.518476  4932 net.cpp:160] Setting up inception_4d/relu_3x3_reduce
I0109 14:38:04.518481  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.518486  4932 layer_factory.hpp:74] Creating layer inception_4d/3x3
I0109 14:38:04.518492  4932 net.cpp:96] Creating Layer inception_4d/3x3
I0109 14:38:04.518496  4932 net.cpp:459] inception_4d/3x3 <- inception_4d/3x3_reduce_bn
I0109 14:38:04.518503  4932 net.cpp:415] inception_4d/3x3 -> inception_4d/3x3
I0109 14:38:04.518509  4932 net.cpp:160] Setting up inception_4d/3x3
I0109 14:38:04.520248  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.520259  4932 layer_factory.hpp:74] Creating layer inception_4d/3x3_bn
I0109 14:38:04.520264  4932 layer_factory.cpp:177] Layer inception_4d/3x3_bn is using CAFFE engine.
I0109 14:38:04.520272  4932 net.cpp:96] Creating Layer inception_4d/3x3_bn
I0109 14:38:04.520277  4932 net.cpp:459] inception_4d/3x3_bn <- inception_4d/3x3
I0109 14:38:04.520287  4932 net.cpp:415] inception_4d/3x3_bn -> inception_4d/3x3_bn
I0109 14:38:04.520294  4932 net.cpp:160] Setting up inception_4d/3x3_bn
I0109 14:38:04.520311  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.520320  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_3x3
I0109 14:38:04.520326  4932 net.cpp:96] Creating Layer inception_4d/relu_3x3
I0109 14:38:04.520331  4932 net.cpp:459] inception_4d/relu_3x3 <- inception_4d/3x3_bn
I0109 14:38:04.520339  4932 net.cpp:404] inception_4d/relu_3x3 -> inception_4d/3x3_bn (in-place)
I0109 14:38:04.520345  4932 net.cpp:160] Setting up inception_4d/relu_3x3
I0109 14:38:04.520351  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.520364  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_reduce
I0109 14:38:04.520371  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_reduce
I0109 14:38:04.520376  4932 net.cpp:459] inception_4d/double_3x3_reduce <- inception_4c/output_inception_4c/output_0_split_2
I0109 14:38:04.520385  4932 net.cpp:415] inception_4d/double_3x3_reduce -> inception_4d/double_3x3_reduce
I0109 14:38:04.520391  4932 net.cpp:160] Setting up inception_4d/double_3x3_reduce
I0109 14:38:04.521164  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.521173  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_reduce_bn
I0109 14:38:04.521178  4932 layer_factory.cpp:177] Layer inception_4d/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.521184  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_reduce_bn
I0109 14:38:04.521189  4932 net.cpp:459] inception_4d/double_3x3_reduce_bn <- inception_4d/double_3x3_reduce
I0109 14:38:04.521196  4932 net.cpp:415] inception_4d/double_3x3_reduce_bn -> inception_4d/double_3x3_reduce_bn
I0109 14:38:04.521203  4932 net.cpp:160] Setting up inception_4d/double_3x3_reduce_bn
I0109 14:38:04.521219  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.521227  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_double_3x3_reduce
I0109 14:38:04.521234  4932 net.cpp:96] Creating Layer inception_4d/relu_double_3x3_reduce
I0109 14:38:04.521239  4932 net.cpp:459] inception_4d/relu_double_3x3_reduce <- inception_4d/double_3x3_reduce_bn
I0109 14:38:04.521245  4932 net.cpp:404] inception_4d/relu_double_3x3_reduce -> inception_4d/double_3x3_reduce_bn (in-place)
I0109 14:38:04.521250  4932 net.cpp:160] Setting up inception_4d/relu_double_3x3_reduce
I0109 14:38:04.521256  4932 net.cpp:167] Top shape: 3 160 14 14 (94080)
I0109 14:38:04.521260  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_1
I0109 14:38:04.521267  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_1
I0109 14:38:04.521271  4932 net.cpp:459] inception_4d/double_3x3_1 <- inception_4d/double_3x3_reduce_bn
I0109 14:38:04.521278  4932 net.cpp:415] inception_4d/double_3x3_1 -> inception_4d/double_3x3_1
I0109 14:38:04.521286  4932 net.cpp:160] Setting up inception_4d/double_3x3_1
I0109 14:38:04.523375  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.523386  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_1_bn
I0109 14:38:04.523388  4932 layer_factory.cpp:177] Layer inception_4d/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.523394  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_1_bn
I0109 14:38:04.523398  4932 net.cpp:459] inception_4d/double_3x3_1_bn <- inception_4d/double_3x3_1
I0109 14:38:04.523403  4932 net.cpp:415] inception_4d/double_3x3_1_bn -> inception_4d/double_3x3_1_bn
I0109 14:38:04.523408  4932 net.cpp:160] Setting up inception_4d/double_3x3_1_bn
I0109 14:38:04.523419  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.523425  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_double_3x3_1
I0109 14:38:04.523429  4932 net.cpp:96] Creating Layer inception_4d/relu_double_3x3_1
I0109 14:38:04.523432  4932 net.cpp:459] inception_4d/relu_double_3x3_1 <- inception_4d/double_3x3_1_bn
I0109 14:38:04.523435  4932 net.cpp:404] inception_4d/relu_double_3x3_1 -> inception_4d/double_3x3_1_bn (in-place)
I0109 14:38:04.523439  4932 net.cpp:160] Setting up inception_4d/relu_double_3x3_1
I0109 14:38:04.523443  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.523447  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_2
I0109 14:38:04.523452  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_2
I0109 14:38:04.523454  4932 net.cpp:459] inception_4d/double_3x3_2 <- inception_4d/double_3x3_1_bn
I0109 14:38:04.523459  4932 net.cpp:415] inception_4d/double_3x3_2 -> inception_4d/double_3x3_2
I0109 14:38:04.523464  4932 net.cpp:160] Setting up inception_4d/double_3x3_2
I0109 14:38:04.524869  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.524883  4932 layer_factory.hpp:74] Creating layer inception_4d/double_3x3_2_bn
I0109 14:38:04.524886  4932 layer_factory.cpp:177] Layer inception_4d/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.524893  4932 net.cpp:96] Creating Layer inception_4d/double_3x3_2_bn
I0109 14:38:04.524896  4932 net.cpp:459] inception_4d/double_3x3_2_bn <- inception_4d/double_3x3_2
I0109 14:38:04.524901  4932 net.cpp:415] inception_4d/double_3x3_2_bn -> inception_4d/double_3x3_2_bn
I0109 14:38:04.524906  4932 net.cpp:160] Setting up inception_4d/double_3x3_2_bn
I0109 14:38:04.524916  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.524922  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_double_3x3_2
I0109 14:38:04.524927  4932 net.cpp:96] Creating Layer inception_4d/relu_double_3x3_2
I0109 14:38:04.524930  4932 net.cpp:459] inception_4d/relu_double_3x3_2 <- inception_4d/double_3x3_2_bn
I0109 14:38:04.524933  4932 net.cpp:404] inception_4d/relu_double_3x3_2 -> inception_4d/double_3x3_2_bn (in-place)
I0109 14:38:04.524937  4932 net.cpp:160] Setting up inception_4d/relu_double_3x3_2
I0109 14:38:04.524941  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.524943  4932 layer_factory.hpp:74] Creating layer inception_4d/pool
I0109 14:38:04.524948  4932 net.cpp:96] Creating Layer inception_4d/pool
I0109 14:38:04.524951  4932 net.cpp:459] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3
I0109 14:38:04.524955  4932 net.cpp:415] inception_4d/pool -> inception_4d/pool
I0109 14:38:04.524960  4932 net.cpp:160] Setting up inception_4d/pool
I0109 14:38:04.524965  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.524967  4932 layer_factory.hpp:74] Creating layer inception_4d/pool_proj
I0109 14:38:04.524973  4932 net.cpp:96] Creating Layer inception_4d/pool_proj
I0109 14:38:04.524976  4932 net.cpp:459] inception_4d/pool_proj <- inception_4d/pool
I0109 14:38:04.524981  4932 net.cpp:415] inception_4d/pool_proj -> inception_4d/pool_proj
I0109 14:38:04.524986  4932 net.cpp:160] Setting up inception_4d/pool_proj
I0109 14:38:04.525321  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.525327  4932 layer_factory.hpp:74] Creating layer inception_4d/pool_proj_bn
I0109 14:38:04.525331  4932 layer_factory.cpp:177] Layer inception_4d/pool_proj_bn is using CAFFE engine.
I0109 14:38:04.525336  4932 net.cpp:96] Creating Layer inception_4d/pool_proj_bn
I0109 14:38:04.525339  4932 net.cpp:459] inception_4d/pool_proj_bn <- inception_4d/pool_proj
I0109 14:38:04.525343  4932 net.cpp:415] inception_4d/pool_proj_bn -> inception_4d/pool_proj_bn
I0109 14:38:04.525348  4932 net.cpp:160] Setting up inception_4d/pool_proj_bn
I0109 14:38:04.525357  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.525363  4932 layer_factory.hpp:74] Creating layer inception_4d/relu_pool_proj
I0109 14:38:04.525367  4932 net.cpp:96] Creating Layer inception_4d/relu_pool_proj
I0109 14:38:04.525370  4932 net.cpp:459] inception_4d/relu_pool_proj <- inception_4d/pool_proj_bn
I0109 14:38:04.525374  4932 net.cpp:404] inception_4d/relu_pool_proj -> inception_4d/pool_proj_bn (in-place)
I0109 14:38:04.525378  4932 net.cpp:160] Setting up inception_4d/relu_pool_proj
I0109 14:38:04.525382  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.525385  4932 layer_factory.hpp:74] Creating layer inception_4d/output
I0109 14:38:04.525389  4932 net.cpp:96] Creating Layer inception_4d/output
I0109 14:38:04.525393  4932 net.cpp:459] inception_4d/output <- inception_4d/1x1_bn
I0109 14:38:04.525395  4932 net.cpp:459] inception_4d/output <- inception_4d/3x3_bn
I0109 14:38:04.525399  4932 net.cpp:459] inception_4d/output <- inception_4d/double_3x3_2_bn
I0109 14:38:04.525403  4932 net.cpp:459] inception_4d/output <- inception_4d/pool_proj_bn
I0109 14:38:04.525406  4932 net.cpp:415] inception_4d/output -> inception_4d/output
I0109 14:38:04.525410  4932 net.cpp:160] Setting up inception_4d/output
I0109 14:38:04.525414  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.525420  4932 layer_factory.hpp:74] Creating layer inception_4d/output_inception_4d/output_0_split
I0109 14:38:04.525427  4932 net.cpp:96] Creating Layer inception_4d/output_inception_4d/output_0_split
I0109 14:38:04.525430  4932 net.cpp:459] inception_4d/output_inception_4d/output_0_split <- inception_4d/output
I0109 14:38:04.525436  4932 net.cpp:415] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0
I0109 14:38:04.525440  4932 net.cpp:415] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1
I0109 14:38:04.525445  4932 net.cpp:415] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2
I0109 14:38:04.525449  4932 net.cpp:160] Setting up inception_4d/output_inception_4d/output_0_split
I0109 14:38:04.525454  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.525459  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.525461  4932 net.cpp:167] Top shape: 3 608 14 14 (357504)
I0109 14:38:04.525465  4932 layer_factory.hpp:74] Creating layer inception_4e/3x3_reduce
I0109 14:38:04.525470  4932 net.cpp:96] Creating Layer inception_4e/3x3_reduce
I0109 14:38:04.525472  4932 net.cpp:459] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_0
I0109 14:38:04.525477  4932 net.cpp:415] inception_4e/3x3_reduce -> inception_4e/3x3_reduce
I0109 14:38:04.525482  4932 net.cpp:160] Setting up inception_4e/3x3_reduce
I0109 14:38:04.525815  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.525821  4932 layer_factory.hpp:74] Creating layer inception_4e/3x3_reduce_bn
I0109 14:38:04.525825  4932 layer_factory.cpp:177] Layer inception_4e/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.525830  4932 net.cpp:96] Creating Layer inception_4e/3x3_reduce_bn
I0109 14:38:04.525832  4932 net.cpp:459] inception_4e/3x3_reduce_bn <- inception_4e/3x3_reduce
I0109 14:38:04.525837  4932 net.cpp:415] inception_4e/3x3_reduce_bn -> inception_4e/3x3_reduce_bn
I0109 14:38:04.525842  4932 net.cpp:160] Setting up inception_4e/3x3_reduce_bn
I0109 14:38:04.525853  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.525859  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_3x3_reduce
I0109 14:38:04.525863  4932 net.cpp:96] Creating Layer inception_4e/relu_3x3_reduce
I0109 14:38:04.525867  4932 net.cpp:459] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce_bn
I0109 14:38:04.525871  4932 net.cpp:404] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce_bn (in-place)
I0109 14:38:04.525874  4932 net.cpp:160] Setting up inception_4e/relu_3x3_reduce
I0109 14:38:04.525878  4932 net.cpp:167] Top shape: 3 128 14 14 (75264)
I0109 14:38:04.525882  4932 layer_factory.hpp:74] Creating layer inception_4e/3x3
I0109 14:38:04.525887  4932 net.cpp:96] Creating Layer inception_4e/3x3
I0109 14:38:04.525889  4932 net.cpp:459] inception_4e/3x3 <- inception_4e/3x3_reduce_bn
I0109 14:38:04.525894  4932 net.cpp:415] inception_4e/3x3 -> inception_4e/3x3
I0109 14:38:04.525898  4932 net.cpp:160] Setting up inception_4e/3x3
I0109 14:38:04.526832  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.526839  4932 layer_factory.hpp:74] Creating layer inception_4e/3x3_bn
I0109 14:38:04.526842  4932 layer_factory.cpp:177] Layer inception_4e/3x3_bn is using CAFFE engine.
I0109 14:38:04.526847  4932 net.cpp:96] Creating Layer inception_4e/3x3_bn
I0109 14:38:04.526850  4932 net.cpp:459] inception_4e/3x3_bn <- inception_4e/3x3
I0109 14:38:04.526855  4932 net.cpp:415] inception_4e/3x3_bn -> inception_4e/3x3_bn
I0109 14:38:04.526859  4932 net.cpp:160] Setting up inception_4e/3x3_bn
I0109 14:38:04.526870  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.526875  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_3x3
I0109 14:38:04.526880  4932 net.cpp:96] Creating Layer inception_4e/relu_3x3
I0109 14:38:04.526882  4932 net.cpp:459] inception_4e/relu_3x3 <- inception_4e/3x3_bn
I0109 14:38:04.526887  4932 net.cpp:404] inception_4e/relu_3x3 -> inception_4e/3x3_bn (in-place)
I0109 14:38:04.526896  4932 net.cpp:160] Setting up inception_4e/relu_3x3
I0109 14:38:04.526899  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.526902  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_reduce
I0109 14:38:04.526907  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_reduce
I0109 14:38:04.526911  4932 net.cpp:459] inception_4e/double_3x3_reduce <- inception_4d/output_inception_4d/output_0_split_1
I0109 14:38:04.526914  4932 net.cpp:415] inception_4e/double_3x3_reduce -> inception_4e/double_3x3_reduce
I0109 14:38:04.526918  4932 net.cpp:160] Setting up inception_4e/double_3x3_reduce
I0109 14:38:04.527415  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.527421  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_reduce_bn
I0109 14:38:04.527425  4932 layer_factory.cpp:177] Layer inception_4e/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.527428  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_reduce_bn
I0109 14:38:04.527432  4932 net.cpp:459] inception_4e/double_3x3_reduce_bn <- inception_4e/double_3x3_reduce
I0109 14:38:04.527436  4932 net.cpp:415] inception_4e/double_3x3_reduce_bn -> inception_4e/double_3x3_reduce_bn
I0109 14:38:04.527441  4932 net.cpp:160] Setting up inception_4e/double_3x3_reduce_bn
I0109 14:38:04.527452  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.527457  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_double_3x3_reduce
I0109 14:38:04.527462  4932 net.cpp:96] Creating Layer inception_4e/relu_double_3x3_reduce
I0109 14:38:04.527465  4932 net.cpp:459] inception_4e/relu_double_3x3_reduce <- inception_4e/double_3x3_reduce_bn
I0109 14:38:04.527468  4932 net.cpp:404] inception_4e/relu_double_3x3_reduce -> inception_4e/double_3x3_reduce_bn (in-place)
I0109 14:38:04.527472  4932 net.cpp:160] Setting up inception_4e/relu_double_3x3_reduce
I0109 14:38:04.527477  4932 net.cpp:167] Top shape: 3 192 14 14 (112896)
I0109 14:38:04.527478  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_1
I0109 14:38:04.527483  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_1
I0109 14:38:04.527487  4932 net.cpp:459] inception_4e/double_3x3_1 <- inception_4e/double_3x3_reduce_bn
I0109 14:38:04.527490  4932 net.cpp:415] inception_4e/double_3x3_1 -> inception_4e/double_3x3_1
I0109 14:38:04.527495  4932 net.cpp:160] Setting up inception_4e/double_3x3_1
I0109 14:38:04.529364  4932 net.cpp:167] Top shape: 3 256 14 14 (150528)
I0109 14:38:04.529372  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_1_bn
I0109 14:38:04.529376  4932 layer_factory.cpp:177] Layer inception_4e/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.529381  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_1_bn
I0109 14:38:04.529383  4932 net.cpp:459] inception_4e/double_3x3_1_bn <- inception_4e/double_3x3_1
I0109 14:38:04.529389  4932 net.cpp:415] inception_4e/double_3x3_1_bn -> inception_4e/double_3x3_1_bn
I0109 14:38:04.529394  4932 net.cpp:160] Setting up inception_4e/double_3x3_1_bn
I0109 14:38:04.529404  4932 net.cpp:167] Top shape: 3 256 14 14 (150528)
I0109 14:38:04.529410  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_double_3x3_1
I0109 14:38:04.529414  4932 net.cpp:96] Creating Layer inception_4e/relu_double_3x3_1
I0109 14:38:04.529418  4932 net.cpp:459] inception_4e/relu_double_3x3_1 <- inception_4e/double_3x3_1_bn
I0109 14:38:04.529422  4932 net.cpp:404] inception_4e/relu_double_3x3_1 -> inception_4e/double_3x3_1_bn (in-place)
I0109 14:38:04.529425  4932 net.cpp:160] Setting up inception_4e/relu_double_3x3_1
I0109 14:38:04.529428  4932 net.cpp:167] Top shape: 3 256 14 14 (150528)
I0109 14:38:04.529431  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_2
I0109 14:38:04.529436  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_2
I0109 14:38:04.529439  4932 net.cpp:459] inception_4e/double_3x3_2 <- inception_4e/double_3x3_1_bn
I0109 14:38:04.529443  4932 net.cpp:415] inception_4e/double_3x3_2 -> inception_4e/double_3x3_2
I0109 14:38:04.529453  4932 net.cpp:160] Setting up inception_4e/double_3x3_2
I0109 14:38:04.531926  4932 net.cpp:167] Top shape: 3 256 7 7 (37632)
I0109 14:38:04.531934  4932 layer_factory.hpp:74] Creating layer inception_4e/double_3x3_2_bn
I0109 14:38:04.531936  4932 layer_factory.cpp:177] Layer inception_4e/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.531941  4932 net.cpp:96] Creating Layer inception_4e/double_3x3_2_bn
I0109 14:38:04.531944  4932 net.cpp:459] inception_4e/double_3x3_2_bn <- inception_4e/double_3x3_2
I0109 14:38:04.531949  4932 net.cpp:415] inception_4e/double_3x3_2_bn -> inception_4e/double_3x3_2_bn
I0109 14:38:04.531955  4932 net.cpp:160] Setting up inception_4e/double_3x3_2_bn
I0109 14:38:04.531965  4932 net.cpp:167] Top shape: 3 256 7 7 (37632)
I0109 14:38:04.531970  4932 layer_factory.hpp:74] Creating layer inception_4e/relu_double_3x3_2
I0109 14:38:04.531975  4932 net.cpp:96] Creating Layer inception_4e/relu_double_3x3_2
I0109 14:38:04.531976  4932 net.cpp:459] inception_4e/relu_double_3x3_2 <- inception_4e/double_3x3_2_bn
I0109 14:38:04.531981  4932 net.cpp:404] inception_4e/relu_double_3x3_2 -> inception_4e/double_3x3_2_bn (in-place)
I0109 14:38:04.531985  4932 net.cpp:160] Setting up inception_4e/relu_double_3x3_2
I0109 14:38:04.531988  4932 net.cpp:167] Top shape: 3 256 7 7 (37632)
I0109 14:38:04.531991  4932 layer_factory.hpp:74] Creating layer inception_4e/pool
I0109 14:38:04.531996  4932 net.cpp:96] Creating Layer inception_4e/pool
I0109 14:38:04.531998  4932 net.cpp:459] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_2
I0109 14:38:04.532003  4932 net.cpp:415] inception_4e/pool -> inception_4e/pool
I0109 14:38:04.532007  4932 net.cpp:160] Setting up inception_4e/pool
I0109 14:38:04.532013  4932 net.cpp:167] Top shape: 3 608 7 7 (89376)
I0109 14:38:04.532016  4932 layer_factory.hpp:74] Creating layer inception_4e/output
I0109 14:38:04.532021  4932 net.cpp:96] Creating Layer inception_4e/output
I0109 14:38:04.532023  4932 net.cpp:459] inception_4e/output <- inception_4e/3x3_bn
I0109 14:38:04.532027  4932 net.cpp:459] inception_4e/output <- inception_4e/double_3x3_2_bn
I0109 14:38:04.532030  4932 net.cpp:459] inception_4e/output <- inception_4e/pool
I0109 14:38:04.532034  4932 net.cpp:415] inception_4e/output -> inception_4e/output
I0109 14:38:04.532038  4932 net.cpp:160] Setting up inception_4e/output
I0109 14:38:04.532042  4932 net.cpp:167] Top shape: 3 1056 7 7 (155232)
I0109 14:38:04.532045  4932 layer_factory.hpp:74] Creating layer inception_4e/output_inception_4e/output_0_split
I0109 14:38:04.532052  4932 net.cpp:96] Creating Layer inception_4e/output_inception_4e/output_0_split
I0109 14:38:04.532054  4932 net.cpp:459] inception_4e/output_inception_4e/output_0_split <- inception_4e/output
I0109 14:38:04.532058  4932 net.cpp:415] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_0
I0109 14:38:04.532063  4932 net.cpp:415] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_1
I0109 14:38:04.532068  4932 net.cpp:415] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_2
I0109 14:38:04.532071  4932 net.cpp:415] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_3
I0109 14:38:04.532076  4932 net.cpp:160] Setting up inception_4e/output_inception_4e/output_0_split
I0109 14:38:04.532081  4932 net.cpp:167] Top shape: 3 1056 7 7 (155232)
I0109 14:38:04.532084  4932 net.cpp:167] Top shape: 3 1056 7 7 (155232)
I0109 14:38:04.532088  4932 net.cpp:167] Top shape: 3 1056 7 7 (155232)
I0109 14:38:04.532091  4932 net.cpp:167] Top shape: 3 1056 7 7 (155232)
I0109 14:38:04.532094  4932 layer_factory.hpp:74] Creating layer inception_5a/1x1
I0109 14:38:04.532099  4932 net.cpp:96] Creating Layer inception_5a/1x1
I0109 14:38:04.532101  4932 net.cpp:459] inception_5a/1x1 <- inception_4e/output_inception_4e/output_0_split_0
I0109 14:38:04.532106  4932 net.cpp:415] inception_5a/1x1 -> inception_5a/1x1
I0109 14:38:04.532124  4932 net.cpp:160] Setting up inception_5a/1x1
I0109 14:38:04.533684  4932 net.cpp:167] Top shape: 3 352 7 7 (51744)
I0109 14:38:04.533691  4932 layer_factory.hpp:74] Creating layer inception_5a/1x1_bn
I0109 14:38:04.533694  4932 layer_factory.cpp:177] Layer inception_5a/1x1_bn is using CAFFE engine.
I0109 14:38:04.533699  4932 net.cpp:96] Creating Layer inception_5a/1x1_bn
I0109 14:38:04.533704  4932 net.cpp:459] inception_5a/1x1_bn <- inception_5a/1x1
I0109 14:38:04.533709  4932 net.cpp:415] inception_5a/1x1_bn -> inception_5a/1x1_bn
I0109 14:38:04.533713  4932 net.cpp:160] Setting up inception_5a/1x1_bn
I0109 14:38:04.533725  4932 net.cpp:167] Top shape: 3 352 7 7 (51744)
I0109 14:38:04.533730  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_1x1
I0109 14:38:04.533735  4932 net.cpp:96] Creating Layer inception_5a/relu_1x1
I0109 14:38:04.533737  4932 net.cpp:459] inception_5a/relu_1x1 <- inception_5a/1x1_bn
I0109 14:38:04.533741  4932 net.cpp:404] inception_5a/relu_1x1 -> inception_5a/1x1_bn (in-place)
I0109 14:38:04.533746  4932 net.cpp:160] Setting up inception_5a/relu_1x1
I0109 14:38:04.533748  4932 net.cpp:167] Top shape: 3 352 7 7 (51744)
I0109 14:38:04.533751  4932 layer_factory.hpp:74] Creating layer inception_5a/3x3_reduce
I0109 14:38:04.533756  4932 net.cpp:96] Creating Layer inception_5a/3x3_reduce
I0109 14:38:04.533759  4932 net.cpp:459] inception_5a/3x3_reduce <- inception_4e/output_inception_4e/output_0_split_1
I0109 14:38:04.533764  4932 net.cpp:415] inception_5a/3x3_reduce -> inception_5a/3x3_reduce
I0109 14:38:04.533769  4932 net.cpp:160] Setting up inception_5a/3x3_reduce
I0109 14:38:04.534626  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.534632  4932 layer_factory.hpp:74] Creating layer inception_5a/3x3_reduce_bn
I0109 14:38:04.534636  4932 layer_factory.cpp:177] Layer inception_5a/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.534641  4932 net.cpp:96] Creating Layer inception_5a/3x3_reduce_bn
I0109 14:38:04.534643  4932 net.cpp:459] inception_5a/3x3_reduce_bn <- inception_5a/3x3_reduce
I0109 14:38:04.534648  4932 net.cpp:415] inception_5a/3x3_reduce_bn -> inception_5a/3x3_reduce_bn
I0109 14:38:04.534653  4932 net.cpp:160] Setting up inception_5a/3x3_reduce_bn
I0109 14:38:04.534663  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.534668  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_3x3_reduce
I0109 14:38:04.534673  4932 net.cpp:96] Creating Layer inception_5a/relu_3x3_reduce
I0109 14:38:04.534677  4932 net.cpp:459] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce_bn
I0109 14:38:04.534680  4932 net.cpp:404] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce_bn (in-place)
I0109 14:38:04.534684  4932 net.cpp:160] Setting up inception_5a/relu_3x3_reduce
I0109 14:38:04.534687  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.534690  4932 layer_factory.hpp:74] Creating layer inception_5a/3x3
I0109 14:38:04.534695  4932 net.cpp:96] Creating Layer inception_5a/3x3
I0109 14:38:04.534698  4932 net.cpp:459] inception_5a/3x3 <- inception_5a/3x3_reduce_bn
I0109 14:38:04.534703  4932 net.cpp:415] inception_5a/3x3 -> inception_5a/3x3
I0109 14:38:04.534708  4932 net.cpp:160] Setting up inception_5a/3x3
I0109 14:38:04.537035  4932 net.cpp:167] Top shape: 3 320 7 7 (47040)
I0109 14:38:04.537044  4932 layer_factory.hpp:74] Creating layer inception_5a/3x3_bn
I0109 14:38:04.537046  4932 layer_factory.cpp:177] Layer inception_5a/3x3_bn is using CAFFE engine.
I0109 14:38:04.537051  4932 net.cpp:96] Creating Layer inception_5a/3x3_bn
I0109 14:38:04.537055  4932 net.cpp:459] inception_5a/3x3_bn <- inception_5a/3x3
I0109 14:38:04.537060  4932 net.cpp:415] inception_5a/3x3_bn -> inception_5a/3x3_bn
I0109 14:38:04.537065  4932 net.cpp:160] Setting up inception_5a/3x3_bn
I0109 14:38:04.537075  4932 net.cpp:167] Top shape: 3 320 7 7 (47040)
I0109 14:38:04.537081  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_3x3
I0109 14:38:04.537084  4932 net.cpp:96] Creating Layer inception_5a/relu_3x3
I0109 14:38:04.537089  4932 net.cpp:459] inception_5a/relu_3x3 <- inception_5a/3x3_bn
I0109 14:38:04.537098  4932 net.cpp:404] inception_5a/relu_3x3 -> inception_5a/3x3_bn (in-place)
I0109 14:38:04.537102  4932 net.cpp:160] Setting up inception_5a/relu_3x3
I0109 14:38:04.537106  4932 net.cpp:167] Top shape: 3 320 7 7 (47040)
I0109 14:38:04.537108  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_reduce
I0109 14:38:04.537113  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_reduce
I0109 14:38:04.537117  4932 net.cpp:459] inception_5a/double_3x3_reduce <- inception_4e/output_inception_4e/output_0_split_2
I0109 14:38:04.537122  4932 net.cpp:415] inception_5a/double_3x3_reduce -> inception_5a/double_3x3_reduce
I0109 14:38:04.537127  4932 net.cpp:160] Setting up inception_5a/double_3x3_reduce
I0109 14:38:04.537840  4932 net.cpp:167] Top shape: 3 160 7 7 (23520)
I0109 14:38:04.537847  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_reduce_bn
I0109 14:38:04.537850  4932 layer_factory.cpp:177] Layer inception_5a/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.537854  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_reduce_bn
I0109 14:38:04.537858  4932 net.cpp:459] inception_5a/double_3x3_reduce_bn <- inception_5a/double_3x3_reduce
I0109 14:38:04.537863  4932 net.cpp:415] inception_5a/double_3x3_reduce_bn -> inception_5a/double_3x3_reduce_bn
I0109 14:38:04.537866  4932 net.cpp:160] Setting up inception_5a/double_3x3_reduce_bn
I0109 14:38:04.537878  4932 net.cpp:167] Top shape: 3 160 7 7 (23520)
I0109 14:38:04.537883  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_double_3x3_reduce
I0109 14:38:04.537886  4932 net.cpp:96] Creating Layer inception_5a/relu_double_3x3_reduce
I0109 14:38:04.537889  4932 net.cpp:459] inception_5a/relu_double_3x3_reduce <- inception_5a/double_3x3_reduce_bn
I0109 14:38:04.537894  4932 net.cpp:404] inception_5a/relu_double_3x3_reduce -> inception_5a/double_3x3_reduce_bn (in-place)
I0109 14:38:04.537897  4932 net.cpp:160] Setting up inception_5a/relu_double_3x3_reduce
I0109 14:38:04.537900  4932 net.cpp:167] Top shape: 3 160 7 7 (23520)
I0109 14:38:04.537904  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_1
I0109 14:38:04.537909  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_1
I0109 14:38:04.537911  4932 net.cpp:459] inception_5a/double_3x3_1 <- inception_5a/double_3x3_reduce_bn
I0109 14:38:04.537915  4932 net.cpp:415] inception_5a/double_3x3_1 -> inception_5a/double_3x3_1
I0109 14:38:04.537919  4932 net.cpp:160] Setting up inception_5a/double_3x3_1
I0109 14:38:04.539273  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.539280  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_1_bn
I0109 14:38:04.539283  4932 layer_factory.cpp:177] Layer inception_5a/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.539288  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_1_bn
I0109 14:38:04.539293  4932 net.cpp:459] inception_5a/double_3x3_1_bn <- inception_5a/double_3x3_1
I0109 14:38:04.539297  4932 net.cpp:415] inception_5a/double_3x3_1_bn -> inception_5a/double_3x3_1_bn
I0109 14:38:04.539301  4932 net.cpp:160] Setting up inception_5a/double_3x3_1_bn
I0109 14:38:04.539311  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.539319  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_double_3x3_1
I0109 14:38:04.539322  4932 net.cpp:96] Creating Layer inception_5a/relu_double_3x3_1
I0109 14:38:04.539325  4932 net.cpp:459] inception_5a/relu_double_3x3_1 <- inception_5a/double_3x3_1_bn
I0109 14:38:04.539330  4932 net.cpp:404] inception_5a/relu_double_3x3_1 -> inception_5a/double_3x3_1_bn (in-place)
I0109 14:38:04.539333  4932 net.cpp:160] Setting up inception_5a/relu_double_3x3_1
I0109 14:38:04.539336  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.539340  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_2
I0109 14:38:04.539345  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_2
I0109 14:38:04.539346  4932 net.cpp:459] inception_5a/double_3x3_2 <- inception_5a/double_3x3_1_bn
I0109 14:38:04.539358  4932 net.cpp:415] inception_5a/double_3x3_2 -> inception_5a/double_3x3_2
I0109 14:38:04.539363  4932 net.cpp:160] Setting up inception_5a/double_3x3_2
I0109 14:38:04.541265  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.541271  4932 layer_factory.hpp:74] Creating layer inception_5a/double_3x3_2_bn
I0109 14:38:04.541275  4932 layer_factory.cpp:177] Layer inception_5a/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.541278  4932 net.cpp:96] Creating Layer inception_5a/double_3x3_2_bn
I0109 14:38:04.541282  4932 net.cpp:459] inception_5a/double_3x3_2_bn <- inception_5a/double_3x3_2
I0109 14:38:04.541287  4932 net.cpp:415] inception_5a/double_3x3_2_bn -> inception_5a/double_3x3_2_bn
I0109 14:38:04.541291  4932 net.cpp:160] Setting up inception_5a/double_3x3_2_bn
I0109 14:38:04.541302  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.541308  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_double_3x3_2
I0109 14:38:04.541312  4932 net.cpp:96] Creating Layer inception_5a/relu_double_3x3_2
I0109 14:38:04.541316  4932 net.cpp:459] inception_5a/relu_double_3x3_2 <- inception_5a/double_3x3_2_bn
I0109 14:38:04.541319  4932 net.cpp:404] inception_5a/relu_double_3x3_2 -> inception_5a/double_3x3_2_bn (in-place)
I0109 14:38:04.541323  4932 net.cpp:160] Setting up inception_5a/relu_double_3x3_2
I0109 14:38:04.541326  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.541329  4932 layer_factory.hpp:74] Creating layer inception_5a/pool
I0109 14:38:04.541334  4932 net.cpp:96] Creating Layer inception_5a/pool
I0109 14:38:04.541337  4932 net.cpp:459] inception_5a/pool <- inception_4e/output_inception_4e/output_0_split_3
I0109 14:38:04.541342  4932 net.cpp:415] inception_5a/pool -> inception_5a/pool
I0109 14:38:04.541347  4932 net.cpp:160] Setting up inception_5a/pool
I0109 14:38:04.541352  4932 net.cpp:167] Top shape: 3 1056 7 7 (155232)
I0109 14:38:04.541354  4932 layer_factory.hpp:74] Creating layer inception_5a/pool_proj
I0109 14:38:04.541359  4932 net.cpp:96] Creating Layer inception_5a/pool_proj
I0109 14:38:04.541363  4932 net.cpp:459] inception_5a/pool_proj <- inception_5a/pool
I0109 14:38:04.541368  4932 net.cpp:415] inception_5a/pool_proj -> inception_5a/pool_proj
I0109 14:38:04.541371  4932 net.cpp:160] Setting up inception_5a/pool_proj
I0109 14:38:04.541946  4932 net.cpp:167] Top shape: 3 128 7 7 (18816)
I0109 14:38:04.541952  4932 layer_factory.hpp:74] Creating layer inception_5a/pool_proj_bn
I0109 14:38:04.541955  4932 layer_factory.cpp:177] Layer inception_5a/pool_proj_bn is using CAFFE engine.
I0109 14:38:04.541960  4932 net.cpp:96] Creating Layer inception_5a/pool_proj_bn
I0109 14:38:04.541962  4932 net.cpp:459] inception_5a/pool_proj_bn <- inception_5a/pool_proj
I0109 14:38:04.541967  4932 net.cpp:415] inception_5a/pool_proj_bn -> inception_5a/pool_proj_bn
I0109 14:38:04.541972  4932 net.cpp:160] Setting up inception_5a/pool_proj_bn
I0109 14:38:04.541981  4932 net.cpp:167] Top shape: 3 128 7 7 (18816)
I0109 14:38:04.541986  4932 layer_factory.hpp:74] Creating layer inception_5a/relu_pool_proj
I0109 14:38:04.541991  4932 net.cpp:96] Creating Layer inception_5a/relu_pool_proj
I0109 14:38:04.541995  4932 net.cpp:459] inception_5a/relu_pool_proj <- inception_5a/pool_proj_bn
I0109 14:38:04.541998  4932 net.cpp:404] inception_5a/relu_pool_proj -> inception_5a/pool_proj_bn (in-place)
I0109 14:38:04.542002  4932 net.cpp:160] Setting up inception_5a/relu_pool_proj
I0109 14:38:04.542006  4932 net.cpp:167] Top shape: 3 128 7 7 (18816)
I0109 14:38:04.542008  4932 layer_factory.hpp:74] Creating layer inception_5a/output
I0109 14:38:04.542013  4932 net.cpp:96] Creating Layer inception_5a/output
I0109 14:38:04.542016  4932 net.cpp:459] inception_5a/output <- inception_5a/1x1_bn
I0109 14:38:04.542019  4932 net.cpp:459] inception_5a/output <- inception_5a/3x3_bn
I0109 14:38:04.542022  4932 net.cpp:459] inception_5a/output <- inception_5a/double_3x3_2_bn
I0109 14:38:04.542026  4932 net.cpp:459] inception_5a/output <- inception_5a/pool_proj_bn
I0109 14:38:04.542037  4932 net.cpp:415] inception_5a/output -> inception_5a/output
I0109 14:38:04.542040  4932 net.cpp:160] Setting up inception_5a/output
I0109 14:38:04.542045  4932 net.cpp:167] Top shape: 3 1024 7 7 (150528)
I0109 14:38:04.542048  4932 layer_factory.hpp:74] Creating layer inception_5a/output_inception_5a/output_0_split
I0109 14:38:04.542054  4932 net.cpp:96] Creating Layer inception_5a/output_inception_5a/output_0_split
I0109 14:38:04.542057  4932 net.cpp:459] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I0109 14:38:04.542062  4932 net.cpp:415] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I0109 14:38:04.542065  4932 net.cpp:415] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I0109 14:38:04.542071  4932 net.cpp:415] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2
I0109 14:38:04.542075  4932 net.cpp:415] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3
I0109 14:38:04.542079  4932 net.cpp:160] Setting up inception_5a/output_inception_5a/output_0_split
I0109 14:38:04.542083  4932 net.cpp:167] Top shape: 3 1024 7 7 (150528)
I0109 14:38:04.542088  4932 net.cpp:167] Top shape: 3 1024 7 7 (150528)
I0109 14:38:04.542090  4932 net.cpp:167] Top shape: 3 1024 7 7 (150528)
I0109 14:38:04.542093  4932 net.cpp:167] Top shape: 3 1024 7 7 (150528)
I0109 14:38:04.542096  4932 layer_factory.hpp:74] Creating layer inception_5b/1x1
I0109 14:38:04.542101  4932 net.cpp:96] Creating Layer inception_5b/1x1
I0109 14:38:04.542104  4932 net.cpp:459] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I0109 14:38:04.542109  4932 net.cpp:415] inception_5b/1x1 -> inception_5b/1x1
I0109 14:38:04.542114  4932 net.cpp:160] Setting up inception_5b/1x1
I0109 14:38:04.543793  4932 net.cpp:167] Top shape: 3 352 7 7 (51744)
I0109 14:38:04.543803  4932 layer_factory.hpp:74] Creating layer inception_5b/1x1_bn
I0109 14:38:04.543807  4932 layer_factory.cpp:177] Layer inception_5b/1x1_bn is using CAFFE engine.
I0109 14:38:04.543813  4932 net.cpp:96] Creating Layer inception_5b/1x1_bn
I0109 14:38:04.543817  4932 net.cpp:459] inception_5b/1x1_bn <- inception_5b/1x1
I0109 14:38:04.543823  4932 net.cpp:415] inception_5b/1x1_bn -> inception_5b/1x1_bn
I0109 14:38:04.543828  4932 net.cpp:160] Setting up inception_5b/1x1_bn
I0109 14:38:04.543840  4932 net.cpp:167] Top shape: 3 352 7 7 (51744)
I0109 14:38:04.543846  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_1x1
I0109 14:38:04.543850  4932 net.cpp:96] Creating Layer inception_5b/relu_1x1
I0109 14:38:04.543853  4932 net.cpp:459] inception_5b/relu_1x1 <- inception_5b/1x1_bn
I0109 14:38:04.543858  4932 net.cpp:404] inception_5b/relu_1x1 -> inception_5b/1x1_bn (in-place)
I0109 14:38:04.543862  4932 net.cpp:160] Setting up inception_5b/relu_1x1
I0109 14:38:04.543865  4932 net.cpp:167] Top shape: 3 352 7 7 (51744)
I0109 14:38:04.543869  4932 layer_factory.hpp:74] Creating layer inception_5b/3x3_reduce
I0109 14:38:04.543874  4932 net.cpp:96] Creating Layer inception_5b/3x3_reduce
I0109 14:38:04.543876  4932 net.cpp:459] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1
I0109 14:38:04.543881  4932 net.cpp:415] inception_5b/3x3_reduce -> inception_5b/3x3_reduce
I0109 14:38:04.543887  4932 net.cpp:160] Setting up inception_5b/3x3_reduce
I0109 14:38:04.544731  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.544739  4932 layer_factory.hpp:74] Creating layer inception_5b/3x3_reduce_bn
I0109 14:38:04.544742  4932 layer_factory.cpp:177] Layer inception_5b/3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.544747  4932 net.cpp:96] Creating Layer inception_5b/3x3_reduce_bn
I0109 14:38:04.544751  4932 net.cpp:459] inception_5b/3x3_reduce_bn <- inception_5b/3x3_reduce
I0109 14:38:04.544756  4932 net.cpp:415] inception_5b/3x3_reduce_bn -> inception_5b/3x3_reduce_bn
I0109 14:38:04.544764  4932 net.cpp:160] Setting up inception_5b/3x3_reduce_bn
I0109 14:38:04.544780  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.544785  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_3x3_reduce
I0109 14:38:04.544790  4932 net.cpp:96] Creating Layer inception_5b/relu_3x3_reduce
I0109 14:38:04.544792  4932 net.cpp:459] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce_bn
I0109 14:38:04.544797  4932 net.cpp:404] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce_bn (in-place)
I0109 14:38:04.544801  4932 net.cpp:160] Setting up inception_5b/relu_3x3_reduce
I0109 14:38:04.544805  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.544807  4932 layer_factory.hpp:74] Creating layer inception_5b/3x3
I0109 14:38:04.544812  4932 net.cpp:96] Creating Layer inception_5b/3x3
I0109 14:38:04.544816  4932 net.cpp:459] inception_5b/3x3 <- inception_5b/3x3_reduce_bn
I0109 14:38:04.544821  4932 net.cpp:415] inception_5b/3x3 -> inception_5b/3x3
I0109 14:38:04.544826  4932 net.cpp:160] Setting up inception_5b/3x3
I0109 14:38:04.547148  4932 net.cpp:167] Top shape: 3 320 7 7 (47040)
I0109 14:38:04.547155  4932 layer_factory.hpp:74] Creating layer inception_5b/3x3_bn
I0109 14:38:04.547158  4932 layer_factory.cpp:177] Layer inception_5b/3x3_bn is using CAFFE engine.
I0109 14:38:04.547163  4932 net.cpp:96] Creating Layer inception_5b/3x3_bn
I0109 14:38:04.547166  4932 net.cpp:459] inception_5b/3x3_bn <- inception_5b/3x3
I0109 14:38:04.547171  4932 net.cpp:415] inception_5b/3x3_bn -> inception_5b/3x3_bn
I0109 14:38:04.547176  4932 net.cpp:160] Setting up inception_5b/3x3_bn
I0109 14:38:04.547188  4932 net.cpp:167] Top shape: 3 320 7 7 (47040)
I0109 14:38:04.547194  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_3x3
I0109 14:38:04.547199  4932 net.cpp:96] Creating Layer inception_5b/relu_3x3
I0109 14:38:04.547201  4932 net.cpp:459] inception_5b/relu_3x3 <- inception_5b/3x3_bn
I0109 14:38:04.547205  4932 net.cpp:404] inception_5b/relu_3x3 -> inception_5b/3x3_bn (in-place)
I0109 14:38:04.547209  4932 net.cpp:160] Setting up inception_5b/relu_3x3
I0109 14:38:04.547212  4932 net.cpp:167] Top shape: 3 320 7 7 (47040)
I0109 14:38:04.547215  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_reduce
I0109 14:38:04.547220  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_reduce
I0109 14:38:04.547224  4932 net.cpp:459] inception_5b/double_3x3_reduce <- inception_5a/output_inception_5a/output_0_split_2
I0109 14:38:04.547229  4932 net.cpp:415] inception_5b/double_3x3_reduce -> inception_5b/double_3x3_reduce
I0109 14:38:04.547232  4932 net.cpp:160] Setting up inception_5b/double_3x3_reduce
I0109 14:38:04.548064  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.548070  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_reduce_bn
I0109 14:38:04.548074  4932 layer_factory.cpp:177] Layer inception_5b/double_3x3_reduce_bn is using CAFFE engine.
I0109 14:38:04.548079  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_reduce_bn
I0109 14:38:04.548081  4932 net.cpp:459] inception_5b/double_3x3_reduce_bn <- inception_5b/double_3x3_reduce
I0109 14:38:04.548086  4932 net.cpp:415] inception_5b/double_3x3_reduce_bn -> inception_5b/double_3x3_reduce_bn
I0109 14:38:04.548091  4932 net.cpp:160] Setting up inception_5b/double_3x3_reduce_bn
I0109 14:38:04.548102  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.548115  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_double_3x3_reduce
I0109 14:38:04.548120  4932 net.cpp:96] Creating Layer inception_5b/relu_double_3x3_reduce
I0109 14:38:04.548125  4932 net.cpp:459] inception_5b/relu_double_3x3_reduce <- inception_5b/double_3x3_reduce_bn
I0109 14:38:04.548128  4932 net.cpp:404] inception_5b/relu_double_3x3_reduce -> inception_5b/double_3x3_reduce_bn (in-place)
I0109 14:38:04.548132  4932 net.cpp:160] Setting up inception_5b/relu_double_3x3_reduce
I0109 14:38:04.548136  4932 net.cpp:167] Top shape: 3 192 7 7 (28224)
I0109 14:38:04.548140  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_1
I0109 14:38:04.548146  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_1
I0109 14:38:04.548153  4932 net.cpp:459] inception_5b/double_3x3_1 <- inception_5b/double_3x3_reduce_bn
I0109 14:38:04.548158  4932 net.cpp:415] inception_5b/double_3x3_1 -> inception_5b/double_3x3_1
I0109 14:38:04.548163  4932 net.cpp:160] Setting up inception_5b/double_3x3_1
I0109 14:38:04.549829  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.549842  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_1_bn
I0109 14:38:04.549849  4932 layer_factory.cpp:177] Layer inception_5b/double_3x3_1_bn is using CAFFE engine.
I0109 14:38:04.549857  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_1_bn
I0109 14:38:04.549862  4932 net.cpp:459] inception_5b/double_3x3_1_bn <- inception_5b/double_3x3_1
I0109 14:38:04.549870  4932 net.cpp:415] inception_5b/double_3x3_1_bn -> inception_5b/double_3x3_1_bn
I0109 14:38:04.549878  4932 net.cpp:160] Setting up inception_5b/double_3x3_1_bn
I0109 14:38:04.549896  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.549906  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_double_3x3_1
I0109 14:38:04.549913  4932 net.cpp:96] Creating Layer inception_5b/relu_double_3x3_1
I0109 14:38:04.549918  4932 net.cpp:459] inception_5b/relu_double_3x3_1 <- inception_5b/double_3x3_1_bn
I0109 14:38:04.549924  4932 net.cpp:404] inception_5b/relu_double_3x3_1 -> inception_5b/double_3x3_1_bn (in-place)
I0109 14:38:04.549932  4932 net.cpp:160] Setting up inception_5b/relu_double_3x3_1
I0109 14:38:04.549937  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.549942  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_2
I0109 14:38:04.549949  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_2
I0109 14:38:04.549954  4932 net.cpp:459] inception_5b/double_3x3_2 <- inception_5b/double_3x3_1_bn
I0109 14:38:04.549962  4932 net.cpp:415] inception_5b/double_3x3_2 -> inception_5b/double_3x3_2
I0109 14:38:04.549970  4932 net.cpp:160] Setting up inception_5b/double_3x3_2
I0109 14:38:04.553133  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.553148  4932 layer_factory.hpp:74] Creating layer inception_5b/double_3x3_2_bn
I0109 14:38:04.553154  4932 layer_factory.cpp:177] Layer inception_5b/double_3x3_2_bn is using CAFFE engine.
I0109 14:38:04.553164  4932 net.cpp:96] Creating Layer inception_5b/double_3x3_2_bn
I0109 14:38:04.553169  4932 net.cpp:459] inception_5b/double_3x3_2_bn <- inception_5b/double_3x3_2
I0109 14:38:04.553177  4932 net.cpp:415] inception_5b/double_3x3_2_bn -> inception_5b/double_3x3_2_bn
I0109 14:38:04.553186  4932 net.cpp:160] Setting up inception_5b/double_3x3_2_bn
I0109 14:38:04.553205  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.553215  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_double_3x3_2
I0109 14:38:04.553222  4932 net.cpp:96] Creating Layer inception_5b/relu_double_3x3_2
I0109 14:38:04.553227  4932 net.cpp:459] inception_5b/relu_double_3x3_2 <- inception_5b/double_3x3_2_bn
I0109 14:38:04.553234  4932 net.cpp:404] inception_5b/relu_double_3x3_2 -> inception_5b/double_3x3_2_bn (in-place)
I0109 14:38:04.553249  4932 net.cpp:160] Setting up inception_5b/relu_double_3x3_2
I0109 14:38:04.553256  4932 net.cpp:167] Top shape: 3 224 7 7 (32928)
I0109 14:38:04.553261  4932 layer_factory.hpp:74] Creating layer inception_5b/pool
I0109 14:38:04.553268  4932 net.cpp:96] Creating Layer inception_5b/pool
I0109 14:38:04.553273  4932 net.cpp:459] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3
I0109 14:38:04.553279  4932 net.cpp:415] inception_5b/pool -> inception_5b/pool
I0109 14:38:04.553287  4932 net.cpp:160] Setting up inception_5b/pool
I0109 14:38:04.553294  4932 net.cpp:167] Top shape: 3 1024 7 7 (150528)
I0109 14:38:04.553299  4932 layer_factory.hpp:74] Creating layer inception_5b/pool_proj
I0109 14:38:04.553308  4932 net.cpp:96] Creating Layer inception_5b/pool_proj
I0109 14:38:04.553313  4932 net.cpp:459] inception_5b/pool_proj <- inception_5b/pool
I0109 14:38:04.553324  4932 net.cpp:415] inception_5b/pool_proj -> inception_5b/pool_proj
I0109 14:38:04.553338  4932 net.cpp:160] Setting up inception_5b/pool_proj
I0109 14:38:04.554371  4932 net.cpp:167] Top shape: 3 128 7 7 (18816)
I0109 14:38:04.554383  4932 layer_factory.hpp:74] Creating layer inception_5b/pool_proj_bn
I0109 14:38:04.554389  4932 layer_factory.cpp:177] Layer inception_5b/pool_proj_bn is using CAFFE engine.
I0109 14:38:04.554397  4932 net.cpp:96] Creating Layer inception_5b/pool_proj_bn
I0109 14:38:04.554404  4932 net.cpp:459] inception_5b/pool_proj_bn <- inception_5b/pool_proj
I0109 14:38:04.554411  4932 net.cpp:415] inception_5b/pool_proj_bn -> inception_5b/pool_proj_bn
I0109 14:38:04.554419  4932 net.cpp:160] Setting up inception_5b/pool_proj_bn
I0109 14:38:04.554435  4932 net.cpp:167] Top shape: 3 128 7 7 (18816)
I0109 14:38:04.554443  4932 layer_factory.hpp:74] Creating layer inception_5b/relu_pool_proj
I0109 14:38:04.554450  4932 net.cpp:96] Creating Layer inception_5b/relu_pool_proj
I0109 14:38:04.554453  4932 net.cpp:459] inception_5b/relu_pool_proj <- inception_5b/pool_proj_bn
I0109 14:38:04.554461  4932 net.cpp:404] inception_5b/relu_pool_proj -> inception_5b/pool_proj_bn (in-place)
I0109 14:38:04.554466  4932 net.cpp:160] Setting up inception_5b/relu_pool_proj
I0109 14:38:04.554472  4932 net.cpp:167] Top shape: 3 128 7 7 (18816)
I0109 14:38:04.554476  4932 layer_factory.hpp:74] Creating layer inception_5b/output
I0109 14:38:04.554482  4932 net.cpp:96] Creating Layer inception_5b/output
I0109 14:38:04.554487  4932 net.cpp:459] inception_5b/output <- inception_5b/1x1_bn
I0109 14:38:04.554492  4932 net.cpp:459] inception_5b/output <- inception_5b/3x3_bn
I0109 14:38:04.554498  4932 net.cpp:459] inception_5b/output <- inception_5b/double_3x3_2_bn
I0109 14:38:04.554503  4932 net.cpp:459] inception_5b/output <- inception_5b/pool_proj_bn
I0109 14:38:04.554508  4932 net.cpp:415] inception_5b/output -> inception_5b/output
I0109 14:38:04.554515  4932 net.cpp:160] Setting up inception_5b/output
I0109 14:38:04.554522  4932 net.cpp:167] Top shape: 3 1024 7 7 (150528)
I0109 14:38:04.554527  4932 layer_factory.hpp:74] Creating layer global_pool
I0109 14:38:04.554534  4932 net.cpp:96] Creating Layer global_pool
I0109 14:38:04.554539  4932 net.cpp:459] global_pool <- inception_5b/output
I0109 14:38:04.554545  4932 net.cpp:415] global_pool -> global_pool
I0109 14:38:04.554551  4932 net.cpp:160] Setting up global_pool
I0109 14:38:04.554558  4932 net.cpp:167] Top shape: 3 1024 1 1 (3072)
I0109 14:38:04.554563  4932 layer_factory.hpp:74] Creating layer dropout
I0109 14:38:04.554569  4932 net.cpp:96] Creating Layer dropout
I0109 14:38:04.554574  4932 net.cpp:459] dropout <- global_pool
I0109 14:38:04.554579  4932 net.cpp:404] dropout -> global_pool (in-place)
I0109 14:38:04.554585  4932 net.cpp:160] Setting up dropout
I0109 14:38:04.554592  4932 net.cpp:167] Top shape: 3 1024 1 1 (3072)
I0109 14:38:04.554597  4932 layer_factory.hpp:74] Creating layer fc-action
I0109 14:38:04.554605  4932 net.cpp:96] Creating Layer fc-action
I0109 14:38:04.554608  4932 net.cpp:459] fc-action <- global_pool
I0109 14:38:04.554616  4932 net.cpp:415] fc-action -> fc
I0109 14:38:04.554622  4932 net.cpp:160] Setting up fc-action
I0109 14:38:04.557600  4932 net.cpp:167] Top shape: 3 101 (303)
I0109 14:38:04.557613  4932 layer_factory.hpp:74] Creating layer reshape_fc
I0109 14:38:04.557623  4932 net.cpp:96] Creating Layer reshape_fc
I0109 14:38:04.557629  4932 net.cpp:459] reshape_fc <- fc
I0109 14:38:04.557637  4932 net.cpp:415] reshape_fc -> reshape_fc
I0109 14:38:04.557646  4932 net.cpp:160] Setting up reshape_fc
I0109 14:38:04.557656  4932 net.cpp:167] Top shape: 1 1 3 101 (303)
I0109 14:38:04.557662  4932 layer_factory.hpp:74] Creating layer pool_fusion
I0109 14:38:04.557677  4932 net.cpp:96] Creating Layer pool_fusion
I0109 14:38:04.557684  4932 net.cpp:459] pool_fusion <- reshape_fc
I0109 14:38:04.557693  4932 net.cpp:415] pool_fusion -> pool_fc
I0109 14:38:04.557699  4932 net.cpp:160] Setting up pool_fusion
I0109 14:38:04.557713  4932 net.cpp:167] Top shape: 1 1 1 101 (101)
I0109 14:38:04.557723  4932 layer_factory.hpp:74] Creating layer pool_fc_pool_fusion_0_split
I0109 14:38:04.557730  4932 net.cpp:96] Creating Layer pool_fc_pool_fusion_0_split
I0109 14:38:04.557735  4932 net.cpp:459] pool_fc_pool_fusion_0_split <- pool_fc
I0109 14:38:04.557744  4932 net.cpp:415] pool_fc_pool_fusion_0_split -> pool_fc_pool_fusion_0_split_0
I0109 14:38:04.557751  4932 net.cpp:415] pool_fc_pool_fusion_0_split -> pool_fc_pool_fusion_0_split_1
I0109 14:38:04.557759  4932 net.cpp:160] Setting up pool_fc_pool_fusion_0_split
I0109 14:38:04.557766  4932 net.cpp:167] Top shape: 1 1 1 101 (101)
I0109 14:38:04.557772  4932 net.cpp:167] Top shape: 1 1 1 101 (101)
I0109 14:38:04.557777  4932 layer_factory.hpp:74] Creating layer loss
I0109 14:38:04.557785  4932 net.cpp:96] Creating Layer loss
I0109 14:38:04.557790  4932 net.cpp:459] loss <- pool_fc_pool_fusion_0_split_0
I0109 14:38:04.557796  4932 net.cpp:459] loss <- label_data_1_split_0
I0109 14:38:04.557804  4932 net.cpp:415] loss -> loss
I0109 14:38:04.557811  4932 net.cpp:160] Setting up loss
I0109 14:38:04.557818  4932 layer_factory.hpp:74] Creating layer loss
I0109 14:38:04.557833  4932 net.cpp:167] Top shape: (1)
I0109 14:38:04.557840  4932 net.cpp:169]     with loss weight 1
I0109 14:38:04.557850  4932 layer_factory.hpp:74] Creating layer accuracy_top1
I0109 14:38:04.557858  4932 net.cpp:96] Creating Layer accuracy_top1
I0109 14:38:04.557864  4932 net.cpp:459] accuracy_top1 <- pool_fc_pool_fusion_0_split_1
I0109 14:38:04.557870  4932 net.cpp:459] accuracy_top1 <- label_data_1_split_1
I0109 14:38:04.557878  4932 net.cpp:415] accuracy_top1 -> accuracy
I0109 14:38:04.557884  4932 net.cpp:160] Setting up accuracy_top1
I0109 14:38:04.557891  4932 net.cpp:167] Top shape: (1)
I0109 14:38:04.557896  4932 net.cpp:241] accuracy_top1 does not need backward computation.
I0109 14:38:04.557900  4932 net.cpp:239] loss needs backward computation.
I0109 14:38:04.557905  4932 net.cpp:239] pool_fc_pool_fusion_0_split needs backward computation.
I0109 14:38:04.557910  4932 net.cpp:239] pool_fusion needs backward computation.
I0109 14:38:04.557914  4932 net.cpp:239] reshape_fc needs backward computation.
I0109 14:38:04.557919  4932 net.cpp:239] fc-action needs backward computation.
I0109 14:38:04.557924  4932 net.cpp:239] dropout needs backward computation.
I0109 14:38:04.557927  4932 net.cpp:239] global_pool needs backward computation.
I0109 14:38:04.557932  4932 net.cpp:239] inception_5b/output needs backward computation.
I0109 14:38:04.557937  4932 net.cpp:239] inception_5b/relu_pool_proj needs backward computation.
I0109 14:38:04.557942  4932 net.cpp:239] inception_5b/pool_proj_bn needs backward computation.
I0109 14:38:04.557946  4932 net.cpp:239] inception_5b/pool_proj needs backward computation.
I0109 14:38:04.557950  4932 net.cpp:239] inception_5b/pool needs backward computation.
I0109 14:38:04.557955  4932 net.cpp:239] inception_5b/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.557960  4932 net.cpp:239] inception_5b/double_3x3_2_bn needs backward computation.
I0109 14:38:04.557963  4932 net.cpp:239] inception_5b/double_3x3_2 needs backward computation.
I0109 14:38:04.557968  4932 net.cpp:239] inception_5b/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.557972  4932 net.cpp:239] inception_5b/double_3x3_1_bn needs backward computation.
I0109 14:38:04.557976  4932 net.cpp:239] inception_5b/double_3x3_1 needs backward computation.
I0109 14:38:04.557981  4932 net.cpp:239] inception_5b/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.557986  4932 net.cpp:239] inception_5b/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.557989  4932 net.cpp:239] inception_5b/double_3x3_reduce needs backward computation.
I0109 14:38:04.557994  4932 net.cpp:239] inception_5b/relu_3x3 needs backward computation.
I0109 14:38:04.557998  4932 net.cpp:239] inception_5b/3x3_bn needs backward computation.
I0109 14:38:04.558003  4932 net.cpp:239] inception_5b/3x3 needs backward computation.
I0109 14:38:04.558010  4932 net.cpp:239] inception_5b/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558019  4932 net.cpp:239] inception_5b/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558023  4932 net.cpp:239] inception_5b/3x3_reduce needs backward computation.
I0109 14:38:04.558028  4932 net.cpp:239] inception_5b/relu_1x1 needs backward computation.
I0109 14:38:04.558032  4932 net.cpp:239] inception_5b/1x1_bn needs backward computation.
I0109 14:38:04.558037  4932 net.cpp:239] inception_5b/1x1 needs backward computation.
I0109 14:38:04.558042  4932 net.cpp:239] inception_5a/output_inception_5a/output_0_split needs backward computation.
I0109 14:38:04.558046  4932 net.cpp:239] inception_5a/output needs backward computation.
I0109 14:38:04.558053  4932 net.cpp:239] inception_5a/relu_pool_proj needs backward computation.
I0109 14:38:04.558058  4932 net.cpp:239] inception_5a/pool_proj_bn needs backward computation.
I0109 14:38:04.558061  4932 net.cpp:239] inception_5a/pool_proj needs backward computation.
I0109 14:38:04.558066  4932 net.cpp:239] inception_5a/pool needs backward computation.
I0109 14:38:04.558070  4932 net.cpp:239] inception_5a/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558075  4932 net.cpp:239] inception_5a/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558080  4932 net.cpp:239] inception_5a/double_3x3_2 needs backward computation.
I0109 14:38:04.558084  4932 net.cpp:239] inception_5a/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558089  4932 net.cpp:239] inception_5a/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558094  4932 net.cpp:239] inception_5a/double_3x3_1 needs backward computation.
I0109 14:38:04.558099  4932 net.cpp:239] inception_5a/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558102  4932 net.cpp:239] inception_5a/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558109  4932 net.cpp:239] inception_5a/double_3x3_reduce needs backward computation.
I0109 14:38:04.558114  4932 net.cpp:239] inception_5a/relu_3x3 needs backward computation.
I0109 14:38:04.558117  4932 net.cpp:239] inception_5a/3x3_bn needs backward computation.
I0109 14:38:04.558122  4932 net.cpp:239] inception_5a/3x3 needs backward computation.
I0109 14:38:04.558127  4932 net.cpp:239] inception_5a/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558131  4932 net.cpp:239] inception_5a/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558135  4932 net.cpp:239] inception_5a/3x3_reduce needs backward computation.
I0109 14:38:04.558140  4932 net.cpp:239] inception_5a/relu_1x1 needs backward computation.
I0109 14:38:04.558145  4932 net.cpp:239] inception_5a/1x1_bn needs backward computation.
I0109 14:38:04.558149  4932 net.cpp:239] inception_5a/1x1 needs backward computation.
I0109 14:38:04.558153  4932 net.cpp:239] inception_4e/output_inception_4e/output_0_split needs backward computation.
I0109 14:38:04.558158  4932 net.cpp:239] inception_4e/output needs backward computation.
I0109 14:38:04.558164  4932 net.cpp:239] inception_4e/pool needs backward computation.
I0109 14:38:04.558168  4932 net.cpp:239] inception_4e/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558173  4932 net.cpp:239] inception_4e/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558177  4932 net.cpp:239] inception_4e/double_3x3_2 needs backward computation.
I0109 14:38:04.558182  4932 net.cpp:239] inception_4e/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558187  4932 net.cpp:239] inception_4e/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558192  4932 net.cpp:239] inception_4e/double_3x3_1 needs backward computation.
I0109 14:38:04.558197  4932 net.cpp:239] inception_4e/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558200  4932 net.cpp:239] inception_4e/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558205  4932 net.cpp:239] inception_4e/double_3x3_reduce needs backward computation.
I0109 14:38:04.558209  4932 net.cpp:239] inception_4e/relu_3x3 needs backward computation.
I0109 14:38:04.558217  4932 net.cpp:239] inception_4e/3x3_bn needs backward computation.
I0109 14:38:04.558226  4932 net.cpp:239] inception_4e/3x3 needs backward computation.
I0109 14:38:04.558231  4932 net.cpp:239] inception_4e/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558235  4932 net.cpp:239] inception_4e/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558240  4932 net.cpp:239] inception_4e/3x3_reduce needs backward computation.
I0109 14:38:04.558244  4932 net.cpp:239] inception_4d/output_inception_4d/output_0_split needs backward computation.
I0109 14:38:04.558249  4932 net.cpp:239] inception_4d/output needs backward computation.
I0109 14:38:04.558255  4932 net.cpp:239] inception_4d/relu_pool_proj needs backward computation.
I0109 14:38:04.558259  4932 net.cpp:239] inception_4d/pool_proj_bn needs backward computation.
I0109 14:38:04.558264  4932 net.cpp:239] inception_4d/pool_proj needs backward computation.
I0109 14:38:04.558269  4932 net.cpp:239] inception_4d/pool needs backward computation.
I0109 14:38:04.558274  4932 net.cpp:239] inception_4d/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558279  4932 net.cpp:239] inception_4d/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558284  4932 net.cpp:239] inception_4d/double_3x3_2 needs backward computation.
I0109 14:38:04.558287  4932 net.cpp:239] inception_4d/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558291  4932 net.cpp:239] inception_4d/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558296  4932 net.cpp:239] inception_4d/double_3x3_1 needs backward computation.
I0109 14:38:04.558302  4932 net.cpp:239] inception_4d/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558306  4932 net.cpp:239] inception_4d/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558311  4932 net.cpp:239] inception_4d/double_3x3_reduce needs backward computation.
I0109 14:38:04.558316  4932 net.cpp:239] inception_4d/relu_3x3 needs backward computation.
I0109 14:38:04.558321  4932 net.cpp:239] inception_4d/3x3_bn needs backward computation.
I0109 14:38:04.558326  4932 net.cpp:239] inception_4d/3x3 needs backward computation.
I0109 14:38:04.558331  4932 net.cpp:239] inception_4d/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558336  4932 net.cpp:239] inception_4d/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558339  4932 net.cpp:239] inception_4d/3x3_reduce needs backward computation.
I0109 14:38:04.558344  4932 net.cpp:239] inception_4d/relu_1x1 needs backward computation.
I0109 14:38:04.558348  4932 net.cpp:239] inception_4d/1x1_bn needs backward computation.
I0109 14:38:04.558353  4932 net.cpp:239] inception_4d/1x1 needs backward computation.
I0109 14:38:04.558358  4932 net.cpp:239] inception_4c/output_inception_4c/output_0_split needs backward computation.
I0109 14:38:04.558363  4932 net.cpp:239] inception_4c/output needs backward computation.
I0109 14:38:04.558368  4932 net.cpp:239] inception_4c/relu_pool_proj needs backward computation.
I0109 14:38:04.558373  4932 net.cpp:239] inception_4c/pool_proj_bn needs backward computation.
I0109 14:38:04.558378  4932 net.cpp:239] inception_4c/pool_proj needs backward computation.
I0109 14:38:04.558383  4932 net.cpp:239] inception_4c/pool needs backward computation.
I0109 14:38:04.558389  4932 net.cpp:239] inception_4c/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558394  4932 net.cpp:239] inception_4c/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558400  4932 net.cpp:239] inception_4c/double_3x3_2 needs backward computation.
I0109 14:38:04.558403  4932 net.cpp:239] inception_4c/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558406  4932 net.cpp:239] inception_4c/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558409  4932 net.cpp:239] inception_4c/double_3x3_1 needs backward computation.
I0109 14:38:04.558413  4932 net.cpp:239] inception_4c/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558416  4932 net.cpp:239] inception_4c/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558424  4932 net.cpp:239] inception_4c/double_3x3_reduce needs backward computation.
I0109 14:38:04.558428  4932 net.cpp:239] inception_4c/relu_3x3 needs backward computation.
I0109 14:38:04.558430  4932 net.cpp:239] inception_4c/3x3_bn needs backward computation.
I0109 14:38:04.558434  4932 net.cpp:239] inception_4c/3x3 needs backward computation.
I0109 14:38:04.558437  4932 net.cpp:239] inception_4c/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558440  4932 net.cpp:239] inception_4c/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558444  4932 net.cpp:239] inception_4c/3x3_reduce needs backward computation.
I0109 14:38:04.558446  4932 net.cpp:239] inception_4c/relu_1x1 needs backward computation.
I0109 14:38:04.558449  4932 net.cpp:239] inception_4c/1x1_bn needs backward computation.
I0109 14:38:04.558452  4932 net.cpp:239] inception_4c/1x1 needs backward computation.
I0109 14:38:04.558456  4932 net.cpp:239] inception_4b/output_inception_4b/output_0_split needs backward computation.
I0109 14:38:04.558459  4932 net.cpp:239] inception_4b/output needs backward computation.
I0109 14:38:04.558464  4932 net.cpp:239] inception_4b/relu_pool_proj needs backward computation.
I0109 14:38:04.558468  4932 net.cpp:239] inception_4b/pool_proj_bn needs backward computation.
I0109 14:38:04.558475  4932 net.cpp:239] inception_4b/pool_proj needs backward computation.
I0109 14:38:04.558480  4932 net.cpp:239] inception_4b/pool needs backward computation.
I0109 14:38:04.558486  4932 net.cpp:239] inception_4b/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558491  4932 net.cpp:239] inception_4b/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558497  4932 net.cpp:239] inception_4b/double_3x3_2 needs backward computation.
I0109 14:38:04.558502  4932 net.cpp:239] inception_4b/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558507  4932 net.cpp:239] inception_4b/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558512  4932 net.cpp:239] inception_4b/double_3x3_1 needs backward computation.
I0109 14:38:04.558517  4932 net.cpp:239] inception_4b/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558522  4932 net.cpp:239] inception_4b/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558527  4932 net.cpp:239] inception_4b/double_3x3_reduce needs backward computation.
I0109 14:38:04.558532  4932 net.cpp:239] inception_4b/relu_3x3 needs backward computation.
I0109 14:38:04.558537  4932 net.cpp:239] inception_4b/3x3_bn needs backward computation.
I0109 14:38:04.558542  4932 net.cpp:239] inception_4b/3x3 needs backward computation.
I0109 14:38:04.558548  4932 net.cpp:239] inception_4b/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558552  4932 net.cpp:239] inception_4b/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558558  4932 net.cpp:239] inception_4b/3x3_reduce needs backward computation.
I0109 14:38:04.558563  4932 net.cpp:239] inception_4b/relu_1x1 needs backward computation.
I0109 14:38:04.558568  4932 net.cpp:239] inception_4b/1x1_bn needs backward computation.
I0109 14:38:04.558573  4932 net.cpp:239] inception_4b/1x1 needs backward computation.
I0109 14:38:04.558578  4932 net.cpp:239] inception_4a/output_inception_4a/output_0_split needs backward computation.
I0109 14:38:04.558583  4932 net.cpp:239] inception_4a/output needs backward computation.
I0109 14:38:04.558593  4932 net.cpp:239] inception_4a/relu_pool_proj needs backward computation.
I0109 14:38:04.558598  4932 net.cpp:239] inception_4a/pool_proj_bn needs backward computation.
I0109 14:38:04.558603  4932 net.cpp:239] inception_4a/pool_proj needs backward computation.
I0109 14:38:04.558607  4932 net.cpp:239] inception_4a/pool needs backward computation.
I0109 14:38:04.558614  4932 net.cpp:239] inception_4a/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558619  4932 net.cpp:239] inception_4a/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558624  4932 net.cpp:239] inception_4a/double_3x3_2 needs backward computation.
I0109 14:38:04.558632  4932 net.cpp:239] inception_4a/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558641  4932 net.cpp:239] inception_4a/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558646  4932 net.cpp:239] inception_4a/double_3x3_1 needs backward computation.
I0109 14:38:04.558651  4932 net.cpp:239] inception_4a/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558656  4932 net.cpp:239] inception_4a/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558661  4932 net.cpp:239] inception_4a/double_3x3_reduce needs backward computation.
I0109 14:38:04.558667  4932 net.cpp:239] inception_4a/relu_3x3 needs backward computation.
I0109 14:38:04.558672  4932 net.cpp:239] inception_4a/3x3_bn needs backward computation.
I0109 14:38:04.558677  4932 net.cpp:239] inception_4a/3x3 needs backward computation.
I0109 14:38:04.558682  4932 net.cpp:239] inception_4a/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558687  4932 net.cpp:239] inception_4a/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558692  4932 net.cpp:239] inception_4a/3x3_reduce needs backward computation.
I0109 14:38:04.558697  4932 net.cpp:239] inception_4a/relu_1x1 needs backward computation.
I0109 14:38:04.558703  4932 net.cpp:239] inception_4a/1x1_bn needs backward computation.
I0109 14:38:04.558708  4932 net.cpp:239] inception_4a/1x1 needs backward computation.
I0109 14:38:04.558714  4932 net.cpp:239] inception_3c/output_inception_3c/output_0_split needs backward computation.
I0109 14:38:04.558718  4932 net.cpp:239] inception_3c/output needs backward computation.
I0109 14:38:04.558723  4932 net.cpp:239] inception_3c/pool needs backward computation.
I0109 14:38:04.558727  4932 net.cpp:239] inception_3c/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558729  4932 net.cpp:239] inception_3c/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558732  4932 net.cpp:239] inception_3c/double_3x3_2 needs backward computation.
I0109 14:38:04.558737  4932 net.cpp:239] inception_3c/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558738  4932 net.cpp:239] inception_3c/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558743  4932 net.cpp:239] inception_3c/double_3x3_1 needs backward computation.
I0109 14:38:04.558745  4932 net.cpp:239] inception_3c/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558748  4932 net.cpp:239] inception_3c/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558751  4932 net.cpp:239] inception_3c/double_3x3_reduce needs backward computation.
I0109 14:38:04.558754  4932 net.cpp:239] inception_3c/relu_3x3 needs backward computation.
I0109 14:38:04.558758  4932 net.cpp:239] inception_3c/3x3_bn needs backward computation.
I0109 14:38:04.558760  4932 net.cpp:239] inception_3c/3x3 needs backward computation.
I0109 14:38:04.558764  4932 net.cpp:239] inception_3c/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558768  4932 net.cpp:239] inception_3c/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558770  4932 net.cpp:239] inception_3c/3x3_reduce needs backward computation.
I0109 14:38:04.558773  4932 net.cpp:239] inception_3b/output_inception_3b/output_0_split needs backward computation.
I0109 14:38:04.558778  4932 net.cpp:239] inception_3b/output needs backward computation.
I0109 14:38:04.558786  4932 net.cpp:239] inception_3b/relu_pool_proj needs backward computation.
I0109 14:38:04.558792  4932 net.cpp:239] inception_3b/pool_proj_bn needs backward computation.
I0109 14:38:04.558799  4932 net.cpp:239] inception_3b/pool_proj needs backward computation.
I0109 14:38:04.558805  4932 net.cpp:239] inception_3b/pool needs backward computation.
I0109 14:38:04.558810  4932 net.cpp:239] inception_3b/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558815  4932 net.cpp:239] inception_3b/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558821  4932 net.cpp:239] inception_3b/double_3x3_2 needs backward computation.
I0109 14:38:04.558826  4932 net.cpp:239] inception_3b/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558838  4932 net.cpp:239] inception_3b/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558843  4932 net.cpp:239] inception_3b/double_3x3_1 needs backward computation.
I0109 14:38:04.558850  4932 net.cpp:239] inception_3b/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558853  4932 net.cpp:239] inception_3b/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558859  4932 net.cpp:239] inception_3b/double_3x3_reduce needs backward computation.
I0109 14:38:04.558864  4932 net.cpp:239] inception_3b/relu_3x3 needs backward computation.
I0109 14:38:04.558869  4932 net.cpp:239] inception_3b/3x3_bn needs backward computation.
I0109 14:38:04.558874  4932 net.cpp:239] inception_3b/3x3 needs backward computation.
I0109 14:38:04.558879  4932 net.cpp:239] inception_3b/relu_3x3_reduce needs backward computation.
I0109 14:38:04.558884  4932 net.cpp:239] inception_3b/3x3_reduce_bn needs backward computation.
I0109 14:38:04.558889  4932 net.cpp:239] inception_3b/3x3_reduce needs backward computation.
I0109 14:38:04.558895  4932 net.cpp:239] inception_3b/relu_1x1 needs backward computation.
I0109 14:38:04.558900  4932 net.cpp:239] inception_3b/1x1_bn needs backward computation.
I0109 14:38:04.558905  4932 net.cpp:239] inception_3b/1x1 needs backward computation.
I0109 14:38:04.558910  4932 net.cpp:239] inception_3a/output_inception_3a/output_0_split needs backward computation.
I0109 14:38:04.558915  4932 net.cpp:239] inception_3a/output needs backward computation.
I0109 14:38:04.558921  4932 net.cpp:239] inception_3a/relu_pool_proj needs backward computation.
I0109 14:38:04.558926  4932 net.cpp:239] inception_3a/pool_proj_bn needs backward computation.
I0109 14:38:04.558931  4932 net.cpp:239] inception_3a/pool_proj needs backward computation.
I0109 14:38:04.558938  4932 net.cpp:239] inception_3a/pool needs backward computation.
I0109 14:38:04.558943  4932 net.cpp:239] inception_3a/relu_double_3x3_2 needs backward computation.
I0109 14:38:04.558948  4932 net.cpp:239] inception_3a/double_3x3_2_bn needs backward computation.
I0109 14:38:04.558953  4932 net.cpp:239] inception_3a/double_3x3_2 needs backward computation.
I0109 14:38:04.558957  4932 net.cpp:239] inception_3a/relu_double_3x3_1 needs backward computation.
I0109 14:38:04.558962  4932 net.cpp:239] inception_3a/double_3x3_1_bn needs backward computation.
I0109 14:38:04.558967  4932 net.cpp:239] inception_3a/double_3x3_1 needs backward computation.
I0109 14:38:04.558972  4932 net.cpp:239] inception_3a/relu_double_3x3_reduce needs backward computation.
I0109 14:38:04.558977  4932 net.cpp:239] inception_3a/double_3x3_reduce_bn needs backward computation.
I0109 14:38:04.558982  4932 net.cpp:239] inception_3a/double_3x3_reduce needs backward computation.
I0109 14:38:04.558989  4932 net.cpp:239] inception_3a/relu_3x3 needs backward computation.
I0109 14:38:04.558993  4932 net.cpp:239] inception_3a/3x3_bn needs backward computation.
I0109 14:38:04.558998  4932 net.cpp:239] inception_3a/3x3 needs backward computation.
I0109 14:38:04.559003  4932 net.cpp:239] inception_3a/relu_3x3_reduce needs backward computation.
I0109 14:38:04.559008  4932 net.cpp:239] inception_3a/3x3_reduce_bn needs backward computation.
I0109 14:38:04.559013  4932 net.cpp:239] inception_3a/3x3_reduce needs backward computation.
I0109 14:38:04.559017  4932 net.cpp:239] inception_3a/relu_1x1 needs backward computation.
I0109 14:38:04.559022  4932 net.cpp:239] inception_3a/1x1_bn needs backward computation.
I0109 14:38:04.559026  4932 net.cpp:239] inception_3a/1x1 needs backward computation.
I0109 14:38:04.559031  4932 net.cpp:239] pool2/3x3_s2_pool2/3x3_s2_0_split needs backward computation.
I0109 14:38:04.559036  4932 net.cpp:239] pool2/3x3_s2 needs backward computation.
I0109 14:38:04.559041  4932 net.cpp:239] conv2/relu_3x3 needs backward computation.
I0109 14:38:04.559046  4932 net.cpp:239] conv2/3x3_bn needs backward computation.
I0109 14:38:04.559049  4932 net.cpp:239] conv2/3x3 needs backward computation.
I0109 14:38:04.559057  4932 net.cpp:239] conv2/relu_3x3_reduce needs backward computation.
I0109 14:38:04.559065  4932 net.cpp:239] conv2/3x3_reduce_bn needs backward computation.
I0109 14:38:04.559070  4932 net.cpp:239] conv2/3x3_reduce needs backward computation.
I0109 14:38:04.559075  4932 net.cpp:239] pool1/3x3_s2 needs backward computation.
I0109 14:38:04.559079  4932 net.cpp:239] conv1/relu_7x7 needs backward computation.
I0109 14:38:04.559084  4932 net.cpp:239] conv1/7x7_s2_bn needs backward computation.
I0109 14:38:04.559088  4932 net.cpp:239] conv1/7x7_s2 needs backward computation.
I0109 14:38:04.559093  4932 net.cpp:241] data_reshape does not need backward computation.
I0109 14:38:04.559098  4932 net.cpp:241] label_data_1_split does not need backward computation.
I0109 14:38:04.559105  4932 net.cpp:241] data does not need backward computation.
I0109 14:38:04.559109  4932 net.cpp:282] This network produces output accuracy
I0109 14:38:04.559114  4932 net.cpp:282] This network produces output loss
I0109 14:38:04.559249  4932 net.cpp:531] Collecting Learning Rate and Weight Decay.
I0109 14:38:04.559284  4932 net.cpp:294] Network initialization done.
I0109 14:38:04.559289  4932 net.cpp:295] Memory required for data: 234061640
I0109 14:38:04.560371  4932 solver.cpp:47] Solver scaffolding done.
I0109 14:38:04.560945  4932 caffe.cpp:86] Finetuning from ../temporal-segment-networks/models/ucf101_split_1_tsn_flow_reference_bn_inception.caffemodel
I0109 14:38:04.611253  4932 solver.cpp:363] Solving BN-Inception
I0109 14:38:04.611279  4932 solver.cpp:364] Learning Rate Policy: multistep
I0109 14:38:04.624958  4932 solver.cpp:424] Iteration 0, Testing net (#0)
I0109 14:38:43.198575  4932 solver.cpp:481]     Test net output #0: accuracy = 0.817895
I0109 14:38:43.198802  4932 solver.cpp:481]     Test net output #1: loss = 0.872473 (* 1 = 0.872473 loss)
I0109 14:38:45.131376  4932 solver.cpp:240] Iteration 0, loss = 0.00682461
I0109 14:38:45.131414  4932 solver.cpp:255]     Train net output #0: loss = 0.00682461 (* 1 = 0.00682461 loss)
I0109 14:38:45.131431  4932 solver.cpp:631] Iteration 0, lr = 0.0001
I0109 14:38:49.926360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5347 > 20) by scale factor 0.973961
I0109 14:39:25.083752  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7774 > 20) by scale factor 0.671649
I0109 14:39:31.401507  4932 solver.cpp:240] Iteration 20, loss = 0.115987
I0109 14:39:31.401546  4932 solver.cpp:255]     Train net output #0: loss = 0.0279126 (* 1 = 0.0279126 loss)
I0109 14:39:31.401553  4932 solver.cpp:631] Iteration 20, lr = 0.0001
I0109 14:39:40.616996  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4997 > 20) by scale factor 0.72728
I0109 14:39:49.498246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6082 > 20) by scale factor 0.925577
I0109 14:39:53.940474  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4626 > 20) by scale factor 0.977391
I0109 14:40:16.990589  4932 solver.cpp:240] Iteration 40, loss = 0.0999629
I0109 14:40:16.990691  4932 solver.cpp:255]     Train net output #0: loss = 0.00557306 (* 1 = 0.00557306 loss)
I0109 14:40:16.990705  4932 solver.cpp:631] Iteration 40, lr = 0.0001
I0109 14:40:34.470393  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2773 > 20) by scale factor 0.986322
I0109 14:41:02.985918  4932 solver.cpp:240] Iteration 60, loss = 0.0769791
I0109 14:41:02.986014  4932 solver.cpp:255]     Train net output #0: loss = 0.0442274 (* 1 = 0.0442274 loss)
I0109 14:41:02.986027  4932 solver.cpp:631] Iteration 60, lr = 0.0001
I0109 14:41:05.545598  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9348 > 20) by scale factor 0.771165
I0109 14:41:18.304416  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5492 > 20) by scale factor 0.849287
I0109 14:41:50.694953  4932 solver.cpp:240] Iteration 80, loss = 0.0645749
I0109 14:41:50.695067  4932 solver.cpp:255]     Train net output #0: loss = 0.0822326 (* 1 = 0.0822326 loss)
I0109 14:41:50.695083  4932 solver.cpp:631] Iteration 80, lr = 0.0001
I0109 14:41:53.251914  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.0908 > 20) by scale factor 0.643276
I0109 14:42:36.200913  4932 solver.cpp:240] Iteration 100, loss = 0.0618335
I0109 14:42:36.201009  4932 solver.cpp:255]     Train net output #0: loss = 0.0372943 (* 1 = 0.0372943 loss)
I0109 14:42:36.201021  4932 solver.cpp:631] Iteration 100, lr = 0.0001
I0109 14:42:57.830773  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1322 > 20) by scale factor 0.795791
I0109 14:43:21.906888  4932 solver.cpp:240] Iteration 120, loss = 0.103106
I0109 14:43:21.906973  4932 solver.cpp:255]     Train net output #0: loss = 0.102426 (* 1 = 0.102426 loss)
I0109 14:43:21.906985  4932 solver.cpp:631] Iteration 120, lr = 0.0001
I0109 14:43:22.247282  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2156 > 20) by scale factor 0.989333
I0109 14:43:48.747980  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7541 > 20) by scale factor 0.919367
I0109 14:44:10.348996  4932 solver.cpp:240] Iteration 140, loss = 0.0572102
I0109 14:44:10.349087  4932 solver.cpp:255]     Train net output #0: loss = 0.00842019 (* 1 = 0.00842019 loss)
I0109 14:44:10.349100  4932 solver.cpp:631] Iteration 140, lr = 0.0001
I0109 14:44:21.787583  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5245 > 20) by scale factor 0.929172
I0109 14:44:39.552402  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3369 > 20) by scale factor 0.731612
I0109 14:44:41.777786  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6053 > 20) by scale factor 0.781089
I0109 14:44:49.807374  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5569 > 20) by scale factor 0.814433
I0109 14:44:56.125473  4932 solver.cpp:240] Iteration 160, loss = 0.104514
I0109 14:44:56.125505  4932 solver.cpp:255]     Train net output #0: loss = 0.0168801 (* 1 = 0.0168801 loss)
I0109 14:44:56.125514  4932 solver.cpp:631] Iteration 160, lr = 0.0001
I0109 14:45:17.133889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5992 > 20) by scale factor 0.699321
I0109 14:45:41.217649  4932 solver.cpp:240] Iteration 180, loss = 0.0872393
I0109 14:45:41.217689  4932 solver.cpp:255]     Train net output #0: loss = 0.0147661 (* 1 = 0.0147661 loss)
I0109 14:45:41.217696  4932 solver.cpp:631] Iteration 180, lr = 0.0001
I0109 14:46:01.085443  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.4217 > 20) by scale factor 0.564626
I0109 14:46:05.530202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7051 > 20) by scale factor 0.8437
I0109 14:46:28.436236  4932 solver.cpp:240] Iteration 200, loss = 0.0728658
I0109 14:46:28.436274  4932 solver.cpp:255]     Train net output #0: loss = 0.139878 (* 1 = 0.139878 loss)
I0109 14:46:28.436282  4932 solver.cpp:631] Iteration 200, lr = 0.0001
I0109 14:46:39.875650  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0681 > 20) by scale factor 0.996608
I0109 14:47:14.375561  4932 solver.cpp:240] Iteration 220, loss = 0.0979912
I0109 14:47:14.375646  4932 solver.cpp:255]     Train net output #0: loss = 0.136255 (* 1 = 0.136255 loss)
I0109 14:47:14.375658  4932 solver.cpp:631] Iteration 220, lr = 0.0001
I0109 14:47:26.262321  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7003 > 20) by scale factor 0.966169
I0109 14:47:46.245185  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4105 > 20) by scale factor 0.657667
I0109 14:48:00.276909  4932 solver.cpp:240] Iteration 240, loss = 0.121562
I0109 14:48:00.276954  4932 solver.cpp:255]     Train net output #0: loss = 0.110421 (* 1 = 0.110421 loss)
I0109 14:48:00.276965  4932 solver.cpp:631] Iteration 240, lr = 0.0001
I0109 14:48:11.717232  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5431 > 20) by scale factor 0.928373
I0109 14:48:45.413373  4932 solver.cpp:240] Iteration 260, loss = 0.0826953
I0109 14:48:45.413475  4932 solver.cpp:255]     Train net output #0: loss = 0.28185 (* 1 = 0.28185 loss)
I0109 14:48:45.413486  4932 solver.cpp:631] Iteration 260, lr = 0.0001
I0109 14:48:45.753011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6843 > 20) by scale factor 0.778684
I0109 14:48:50.273002  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8798 > 20) by scale factor 0.957864
I0109 14:48:56.935631  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9646 > 20) by scale factor 0.801136
I0109 14:49:24.097307  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.523 > 20) by scale factor 0.929237
I0109 14:49:30.417939  4932 solver.cpp:240] Iteration 280, loss = 0.127801
I0109 14:49:30.417984  4932 solver.cpp:255]     Train net output #0: loss = 0.0766058 (* 1 = 0.0766058 loss)
I0109 14:49:30.417996  4932 solver.cpp:631] Iteration 280, lr = 0.0001
I0109 14:49:48.517015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3642 > 20) by scale factor 0.894286
I0109 14:50:16.264207  4932 solver.cpp:240] Iteration 300, loss = 0.0978791
I0109 14:50:16.264317  4932 solver.cpp:255]     Train net output #0: loss = 0.0754107 (* 1 = 0.0754107 loss)
I0109 14:50:16.264330  4932 solver.cpp:631] Iteration 300, lr = 0.0001
I0109 14:50:23.267724  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4467 > 20) by scale factor 0.978154
I0109 14:51:03.132517  4932 solver.cpp:240] Iteration 320, loss = 0.0523488
I0109 14:51:03.132606  4932 solver.cpp:255]     Train net output #0: loss = 0.00284411 (* 1 = 0.00284411 loss)
I0109 14:51:03.132616  4932 solver.cpp:631] Iteration 320, lr = 0.0001
I0109 14:51:19.008019  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1997 > 20) by scale factor 0.709227
I0109 14:51:33.527494  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.847 > 20) by scale factor 0.959369
I0109 14:51:42.414114  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4635 > 20) by scale factor 0.977351
I0109 14:51:44.637100  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2072 > 20) by scale factor 0.900608
I0109 14:51:48.738643  4932 solver.cpp:240] Iteration 340, loss = 0.0964712
I0109 14:51:48.738682  4932 solver.cpp:255]     Train net output #0: loss = 0.107576 (* 1 = 0.107576 loss)
I0109 14:51:48.738692  4932 solver.cpp:631] Iteration 340, lr = 0.0001
I0109 14:52:16.568181  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.671 > 20) by scale factor 0.967541
I0109 14:52:33.992241  4932 solver.cpp:240] Iteration 360, loss = 0.0920405
I0109 14:52:33.992286  4932 solver.cpp:255]     Train net output #0: loss = 0.060905 (* 1 = 0.060905 loss)
I0109 14:52:33.992297  4932 solver.cpp:631] Iteration 360, lr = 0.0001
I0109 14:53:14.490108  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3515 > 20) by scale factor 0.894794
I0109 14:53:20.443958  4932 solver.cpp:240] Iteration 380, loss = 0.0639393
I0109 14:53:20.444003  4932 solver.cpp:255]     Train net output #0: loss = 0.174571 (* 1 = 0.174571 loss)
I0109 14:53:20.444015  4932 solver.cpp:631] Iteration 380, lr = 0.0001
I0109 14:53:45.200814  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2153 > 20) by scale factor 0.98935
I0109 14:53:54.086083  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2085 > 20) by scale factor 0.900558
I0109 14:54:04.940441  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9153 > 20) by scale factor 0.771745
I0109 14:54:06.823083  4932 solver.cpp:240] Iteration 400, loss = 0.113984
I0109 14:54:06.823120  4932 solver.cpp:255]     Train net output #0: loss = 0.0958098 (* 1 = 0.0958098 loss)
I0109 14:54:06.823129  4932 solver.cpp:631] Iteration 400, lr = 0.0001
I0109 14:54:11.607405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5597 > 20) by scale factor 0.814343
I0109 14:54:20.489588  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5994 > 20) by scale factor 0.675689
I0109 14:54:52.766244  4932 solver.cpp:240] Iteration 420, loss = 0.0923193
I0109 14:54:52.766343  4932 solver.cpp:255]     Train net output #0: loss = 0.0204393 (* 1 = 0.0204393 loss)
I0109 14:54:52.766355  4932 solver.cpp:631] Iteration 420, lr = 0.0001
I0109 14:55:34.805068  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3863 > 20) by scale factor 0.981053
I0109 14:55:37.026321  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0702 > 20) by scale factor 0.949207
I0109 14:55:38.909590  4932 solver.cpp:240] Iteration 440, loss = 0.0877968
I0109 14:55:38.909631  4932 solver.cpp:255]     Train net output #0: loss = 0.192047 (* 1 = 0.192047 loss)
I0109 14:55:38.909757  4932 solver.cpp:631] Iteration 440, lr = 0.0001
I0109 14:55:39.249119  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5073 > 20) by scale factor 0.975263
I0109 14:55:45.643537  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4779 > 20) by scale factor 0.976665
I0109 14:55:56.742128  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7133 > 20) by scale factor 0.965563
I0109 14:56:25.916849  4932 solver.cpp:240] Iteration 460, loss = 0.0811922
I0109 14:56:25.916934  4932 solver.cpp:255]     Train net output #0: loss = 0.0161992 (* 1 = 0.0161992 loss)
I0109 14:56:25.916945  4932 solver.cpp:631] Iteration 460, lr = 0.0001
I0109 14:56:37.355586  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2337 > 20) by scale factor 0.988449
I0109 14:56:41.798696  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.126 > 20) by scale factor 0.864826
I0109 14:56:57.133787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0198 > 20) by scale factor 0.713781
I0109 14:57:12.329686  4932 solver.cpp:240] Iteration 480, loss = 0.105424
I0109 14:57:12.329721  4932 solver.cpp:255]     Train net output #0: loss = 0.0193051 (* 1 = 0.0193051 loss)
I0109 14:57:12.329730  4932 solver.cpp:631] Iteration 480, lr = 0.0001
I0109 14:57:19.325702  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6637 > 20) by scale factor 0.750084
I0109 14:57:52.387032  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4685 > 20) by scale factor 0.656415
I0109 14:57:58.707548  4932 solver.cpp:240] Iteration 500, loss = 0.122247
I0109 14:57:58.707597  4932 solver.cpp:255]     Train net output #0: loss = 0.0162878 (* 1 = 0.0162878 loss)
I0109 14:57:58.707609  4932 solver.cpp:631] Iteration 500, lr = 0.0001
I0109 14:58:18.369369  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3911 > 20) by scale factor 0.855028
I0109 14:58:38.352571  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5435 > 20) by scale factor 0.973543
I0109 14:58:46.531327  4932 solver.cpp:240] Iteration 520, loss = 0.101209
I0109 14:58:46.531364  4932 solver.cpp:255]     Train net output #0: loss = 0.125605 (* 1 = 0.125605 loss)
I0109 14:58:46.531373  4932 solver.cpp:631] Iteration 520, lr = 0.0001
I0109 14:59:22.723978  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.883 > 20) by scale factor 0.957719
I0109 14:59:31.262639  4932 solver.cpp:240] Iteration 540, loss = 0.0477223
I0109 14:59:31.262678  4932 solver.cpp:255]     Train net output #0: loss = 0.0850905 (* 1 = 0.0850905 loss)
I0109 14:59:31.262687  4932 solver.cpp:631] Iteration 540, lr = 0.0001
I0109 15:00:17.138974  4932 solver.cpp:240] Iteration 560, loss = 0.089299
I0109 15:00:17.139077  4932 solver.cpp:255]     Train net output #0: loss = 0.206273 (* 1 = 0.206273 loss)
I0109 15:00:17.139091  4932 solver.cpp:631] Iteration 560, lr = 0.0001
I0109 15:00:17.479506  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8877 > 20) by scale factor 0.9575
I0109 15:00:45.090243  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7756 > 20) by scale factor 0.775928
I0109 15:00:56.190923  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4781 > 20) by scale factor 0.931183
I0109 15:01:00.629855  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2033 > 20) by scale factor 0.861945
I0109 15:01:04.366065  4932 solver.cpp:240] Iteration 580, loss = 0.105576
I0109 15:01:04.366104  4932 solver.cpp:255]     Train net output #0: loss = 0.000987469 (* 1 = 0.000987469 loss)
I0109 15:01:04.366112  4932 solver.cpp:631] Iteration 580, lr = 0.0001
I0109 15:01:38.665798  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8699 > 20) by scale factor 0.744328
I0109 15:01:49.426486  4932 solver.cpp:240] Iteration 600, loss = 0.0996471
I0109 15:01:49.426527  4932 solver.cpp:255]     Train net output #0: loss = 0.144133 (* 1 = 0.144133 loss)
I0109 15:01:49.426535  4932 solver.cpp:631] Iteration 600, lr = 0.0001
I0109 15:01:49.765893  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9149 > 20) by scale factor 0.771756
I0109 15:01:58.664520  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3509 > 20) by scale factor 0.731238
I0109 15:02:34.083950  4932 solver.cpp:240] Iteration 620, loss = 0.0413221
I0109 15:02:34.084038  4932 solver.cpp:255]     Train net output #0: loss = 0.0115158 (* 1 = 0.0115158 loss)
I0109 15:02:34.084050  4932 solver.cpp:631] Iteration 620, lr = 0.0001
I0109 15:02:38.860774  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2765 > 20) by scale factor 0.986363
I0109 15:02:45.525419  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7138 > 20) by scale factor 0.777792
I0109 15:02:49.969244  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.242 > 20) by scale factor 0.762137
I0109 15:02:56.625638  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9701 > 20) by scale factor 0.95374
I0109 15:03:11.661393  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5972 > 20) by scale factor 0.751958
I0109 15:03:20.201477  4932 solver.cpp:240] Iteration 640, loss = 0.116111
I0109 15:03:20.201522  4932 solver.cpp:255]     Train net output #0: loss = 0.00552582 (* 1 = 0.00552582 loss)
I0109 15:03:20.201534  4932 solver.cpp:631] Iteration 640, lr = 0.0001
I0109 15:03:54.387789  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4396 > 20) by scale factor 0.657038
I0109 15:04:05.150653  4932 solver.cpp:240] Iteration 660, loss = 0.0948489
I0109 15:04:05.150694  4932 solver.cpp:255]     Train net output #0: loss = 0.024273 (* 1 = 0.024273 loss)
I0109 15:04:05.150707  4932 solver.cpp:631] Iteration 660, lr = 0.0001
I0109 15:04:27.333276  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6397 > 20) by scale factor 0.883403
I0109 15:04:53.355406  4932 solver.cpp:240] Iteration 680, loss = 0.091806
I0109 15:04:53.355444  4932 solver.cpp:255]     Train net output #0: loss = 0.255196 (* 1 = 0.255196 loss)
I0109 15:04:53.355453  4932 solver.cpp:631] Iteration 680, lr = 0.0001
I0109 15:04:53.695209  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5309 > 20) by scale factor 0.974141
I0109 15:04:55.918411  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5848 > 20) by scale factor 0.81351
I0109 15:05:15.909238  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2169 > 20) by scale factor 0.86144
I0109 15:05:38.442673  4932 solver.cpp:240] Iteration 700, loss = 0.0827003
I0109 15:05:38.442713  4932 solver.cpp:255]     Train net output #0: loss = 0.0254646 (* 1 = 0.0254646 loss)
I0109 15:05:38.442721  4932 solver.cpp:631] Iteration 700, lr = 0.0001
I0109 15:05:41.001440  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5946 > 20) by scale factor 0.752032
I0109 15:06:12.758543  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4893 > 20) by scale factor 0.930694
I0109 15:06:23.518492  4932 solver.cpp:240] Iteration 720, loss = 0.0955955
I0109 15:06:23.518522  4932 solver.cpp:255]     Train net output #0: loss = 0.193879 (* 1 = 0.193879 loss)
I0109 15:06:23.518530  4932 solver.cpp:631] Iteration 720, lr = 0.0001
I0109 15:06:49.850788  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4326 > 20) by scale factor 0.978826
I0109 15:07:11.328989  4932 solver.cpp:240] Iteration 740, loss = 0.0726855
I0109 15:07:11.329035  4932 solver.cpp:255]     Train net output #0: loss = 0.031791 (* 1 = 0.031791 loss)
I0109 15:07:11.329046  4932 solver.cpp:631] Iteration 740, lr = 0.0001
I0109 15:07:36.082005  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5992 > 20) by scale factor 0.92596
I0109 15:07:40.528899  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8277 > 20) by scale factor 0.96026
I0109 15:07:57.262645  4932 solver.cpp:240] Iteration 760, loss = 0.0971111
I0109 15:07:57.262684  4932 solver.cpp:255]     Train net output #0: loss = 0.0736528 (* 1 = 0.0736528 loss)
I0109 15:07:57.262693  4932 solver.cpp:631] Iteration 760, lr = 0.0001
I0109 15:08:02.041751  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2782 > 20) by scale factor 0.791197
I0109 15:08:26.020304  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5766 > 20) by scale factor 0.8483
I0109 15:08:43.444792  4932 solver.cpp:240] Iteration 780, loss = 0.125276
I0109 15:08:43.444829  4932 solver.cpp:255]     Train net output #0: loss = 0.00406102 (* 1 = 0.00406102 loss)
I0109 15:08:43.444840  4932 solver.cpp:631] Iteration 780, lr = 0.0001
I0109 15:08:51.212127  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9922 > 20) by scale factor 0.714486
I0109 15:09:08.974740  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7744 > 20) by scale factor 0.962725
I0109 15:09:30.562650  4932 solver.cpp:240] Iteration 800, loss = 0.0926474
I0109 15:09:30.562688  4932 solver.cpp:255]     Train net output #0: loss = 0.026521 (* 1 = 0.026521 loss)
I0109 15:09:30.562696  4932 solver.cpp:631] Iteration 800, lr = 0.0001
I0109 15:09:50.882050  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4766 > 20) by scale factor 0.755385
I0109 15:10:10.342780  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0591 > 20) by scale factor 0.997054
I0109 15:10:16.665560  4932 solver.cpp:240] Iteration 820, loss = 0.0995882
I0109 15:10:16.665598  4932 solver.cpp:255]     Train net output #0: loss = 0.11938 (* 1 = 0.11938 loss)
I0109 15:10:16.665608  4932 solver.cpp:631] Iteration 820, lr = 0.0001
I0109 15:11:02.756052  4932 solver.cpp:240] Iteration 840, loss = 0.086464
I0109 15:11:02.756141  4932 solver.cpp:255]     Train net output #0: loss = 0.0190894 (* 1 = 0.0190894 loss)
I0109 15:11:02.756155  4932 solver.cpp:631] Iteration 840, lr = 0.0001
I0109 15:11:24.140585  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6778 > 20) by scale factor 0.844672
I0109 15:11:28.581076  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0173 > 20) by scale factor 0.908377
I0109 15:11:35.247901  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0571 > 20) by scale factor 0.712833
I0109 15:11:39.690318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8262 > 20) by scale factor 0.916331
I0109 15:11:48.234490  4932 solver.cpp:240] Iteration 860, loss = 0.106443
I0109 15:11:48.234539  4932 solver.cpp:255]     Train net output #0: loss = 0.0211507 (* 1 = 0.0211507 loss)
I0109 15:11:48.234550  4932 solver.cpp:631] Iteration 860, lr = 0.0001
I0109 15:11:59.214331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1975 > 20) by scale factor 0.763432
I0109 15:12:34.536515  4932 solver.cpp:240] Iteration 880, loss = 0.0886336
I0109 15:12:34.536639  4932 solver.cpp:255]     Train net output #0: loss = 0.0140524 (* 1 = 0.0140524 loss)
I0109 15:12:34.536654  4932 solver.cpp:631] Iteration 880, lr = 0.0001
I0109 15:13:20.181821  4932 solver.cpp:240] Iteration 900, loss = 0.0648379
I0109 15:13:20.181912  4932 solver.cpp:255]     Train net output #0: loss = 0.100235 (* 1 = 0.100235 loss)
I0109 15:13:20.181924  4932 solver.cpp:631] Iteration 900, lr = 0.0001
I0109 15:14:02.141376  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.8934 > 20) by scale factor 0.669043
I0109 15:14:06.241587  4932 solver.cpp:240] Iteration 920, loss = 0.0813487
I0109 15:14:06.241622  4932 solver.cpp:255]     Train net output #0: loss = 0.0517554 (* 1 = 0.0517554 loss)
I0109 15:14:06.241631  4932 solver.cpp:631] Iteration 920, lr = 0.0001
I0109 15:14:15.458818  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2058 > 20) by scale factor 0.900665
I0109 15:14:19.981698  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1734 > 20) by scale factor 0.991405
I0109 15:14:23.518301  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1079 > 20) by scale factor 0.904656
I0109 15:14:34.616514  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1847 > 20) by scale factor 0.82697
I0109 15:14:36.836992  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4726 > 20) by scale factor 0.889973
I0109 15:14:52.041555  4932 solver.cpp:240] Iteration 940, loss = 0.114056
I0109 15:14:52.041592  4932 solver.cpp:255]     Train net output #0: loss = 0.0926529 (* 1 = 0.0926529 loss)
I0109 15:14:52.041601  4932 solver.cpp:631] Iteration 940, lr = 0.0001
I0109 15:15:07.235060  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4145 > 20) by scale factor 0.892279
I0109 15:15:18.339998  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7349 > 20) by scale factor 0.964556
I0109 15:15:38.402709  4932 solver.cpp:240] Iteration 960, loss = 0.11087
I0109 15:15:38.402808  4932 solver.cpp:255]     Train net output #0: loss = 0.259807 (* 1 = 0.259807 loss)
I0109 15:15:38.402822  4932 solver.cpp:631] Iteration 960, lr = 0.0001
I0109 15:15:52.063071  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9854 > 20) by scale factor 0.645464
I0109 15:16:24.863332  4932 solver.cpp:240] Iteration 980, loss = 0.121226
I0109 15:16:24.863430  4932 solver.cpp:255]     Train net output #0: loss = 0.334303 (* 1 = 0.334303 loss)
I0109 15:16:24.863442  4932 solver.cpp:631] Iteration 980, lr = 0.0001
I0109 15:16:25.202703  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9569 > 20) by scale factor 0.910874
I0109 15:16:36.310400  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.9858 > 20) by scale factor 0.57166
I0109 15:16:45.186434  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.617 > 20) by scale factor 0.970073
I0109 15:16:47.406555  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2699 > 20) by scale factor 0.898074
I0109 15:17:09.124135  4932 solver.cpp:424] Iteration 1000, Testing net (#0)
I0109 15:18:10.230485  4932 solver.cpp:481]     Test net output #0: accuracy = 0.805263
I0109 15:18:10.230577  4932 solver.cpp:481]     Test net output #1: loss = 0.961173 (* 1 = 0.961173 loss)
I0109 15:18:12.098395  4932 solver.cpp:240] Iteration 1000, loss = 0.10569
I0109 15:18:12.098429  4932 solver.cpp:255]     Train net output #0: loss = 0.0839917 (* 1 = 0.0839917 loss)
I0109 15:18:12.098438  4932 solver.cpp:631] Iteration 1000, lr = 0.0001
I0109 15:18:34.625205  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3707 > 20) by scale factor 0.820659
I0109 15:18:58.210903  4932 solver.cpp:240] Iteration 1020, loss = 0.0693731
I0109 15:18:58.211014  4932 solver.cpp:255]     Train net output #0: loss = 0.00776094 (* 1 = 0.00776094 loss)
I0109 15:18:58.211031  4932 solver.cpp:631] Iteration 1020, lr = 0.0001
I0109 15:19:02.990881  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2139 > 20) by scale factor 0.98942
I0109 15:19:11.875859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9719 > 20) by scale factor 0.953658
I0109 15:19:43.082819  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.4725 > 20) by scale factor 0.615906
I0109 15:19:44.966567  4932 solver.cpp:240] Iteration 1040, loss = 0.13659
I0109 15:19:44.966612  4932 solver.cpp:255]     Train net output #0: loss = 0.0128854 (* 1 = 0.0128854 loss)
I0109 15:19:44.966624  4932 solver.cpp:631] Iteration 1040, lr = 0.0001
I0109 15:19:47.525954  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5434 > 20) by scale factor 0.973548
I0109 15:19:51.965894  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3548 > 20) by scale factor 0.936559
I0109 15:20:03.757181  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3356 > 20) by scale factor 0.983495
I0109 15:20:30.055198  4932 solver.cpp:240] Iteration 1060, loss = 0.0929752
I0109 15:20:30.055297  4932 solver.cpp:255]     Train net output #0: loss = 0.164287 (* 1 = 0.164287 loss)
I0109 15:20:30.055311  4932 solver.cpp:631] Iteration 1060, lr = 0.0001
I0109 15:20:34.836622  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0889 > 20) by scale factor 0.948364
I0109 15:20:37.057716  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4024 > 20) by scale factor 0.704167
I0109 15:20:47.682435  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2253 > 20) by scale factor 0.899874
I0109 15:21:17.299350  4932 solver.cpp:240] Iteration 1080, loss = 0.104715
I0109 15:21:17.299444  4932 solver.cpp:255]     Train net output #0: loss = 0.00324153 (* 1 = 0.00324153 loss)
I0109 15:21:17.299455  4932 solver.cpp:631] Iteration 1080, lr = 0.0001
I0109 15:21:19.856135  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6835 > 20) by scale factor 0.966955
I0109 15:21:22.078094  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7851 > 20) by scale factor 0.962226
I0109 15:21:35.399979  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6165 > 20) by scale factor 0.846867
I0109 15:21:56.797075  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4963 > 20) by scale factor 0.975786
I0109 15:22:03.117172  4932 solver.cpp:240] Iteration 1100, loss = 0.0882281
I0109 15:22:03.117202  4932 solver.cpp:255]     Train net output #0: loss = 0.0643327 (* 1 = 0.0643327 loss)
I0109 15:22:03.117209  4932 solver.cpp:631] Iteration 1100, lr = 0.0001
I0109 15:22:07.892714  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0055 > 20) by scale factor 0.799824
I0109 15:22:18.990942  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2076 > 20) by scale factor 0.900591
I0109 15:22:21.211637  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9185 > 20) by scale factor 0.77165
I0109 15:22:47.518931  4932 solver.cpp:240] Iteration 1120, loss = 0.131292
I0109 15:22:47.519026  4932 solver.cpp:255]     Train net output #0: loss = 0.0239859 (* 1 = 0.0239859 loss)
I0109 15:22:47.519039  4932 solver.cpp:631] Iteration 1120, lr = 0.0001
I0109 15:22:52.482064  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8297 > 20) by scale factor 0.774301
I0109 15:23:14.680527  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2785 > 20) by scale factor 0.70725
I0109 15:23:32.189280  4932 solver.cpp:240] Iteration 1140, loss = 0.0851624
I0109 15:23:32.189386  4932 solver.cpp:255]     Train net output #0: loss = 0.0164715 (* 1 = 0.0164715 loss)
I0109 15:23:32.189401  4932 solver.cpp:631] Iteration 1140, lr = 0.0001
I0109 15:23:52.507967  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.438 > 20) by scale factor 0.728915
I0109 15:23:59.168445  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3872 > 20) by scale factor 0.981007
I0109 15:24:17.411423  4932 solver.cpp:240] Iteration 1160, loss = 0.101389
I0109 15:24:17.411535  4932 solver.cpp:255]     Train net output #0: loss = 0.0212313 (* 1 = 0.0212313 loss)
I0109 15:24:17.411547  4932 solver.cpp:631] Iteration 1160, lr = 0.0001
I0109 15:24:22.187100  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9345 > 20) by scale factor 0.771173
I0109 15:24:31.069475  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6473 > 20) by scale factor 0.883108
I0109 15:25:03.833729  4932 solver.cpp:240] Iteration 1180, loss = 0.110761
I0109 15:25:03.833829  4932 solver.cpp:255]     Train net output #0: loss = 0.00206529 (* 1 = 0.00206529 loss)
I0109 15:25:03.833840  4932 solver.cpp:631] Iteration 1180, lr = 0.0001
I0109 15:25:19.108451  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9047 > 20) by scale factor 0.913045
I0109 15:25:49.854050  4932 solver.cpp:240] Iteration 1200, loss = 0.0915805
I0109 15:25:49.854136  4932 solver.cpp:255]     Train net output #0: loss = 0.0154558 (* 1 = 0.0154558 loss)
I0109 15:25:49.854148  4932 solver.cpp:631] Iteration 1200, lr = 0.0001
I0109 15:25:56.764832  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6183 > 20) by scale factor 0.92514
I0109 15:26:26.524989  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0404 > 20) by scale factor 0.950551
I0109 15:26:33.183890  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8842 > 20) by scale factor 0.913901
I0109 15:26:37.290212  4932 solver.cpp:240] Iteration 1220, loss = 0.114063
I0109 15:26:37.290251  4932 solver.cpp:255]     Train net output #0: loss = 0.0036454 (* 1 = 0.0036454 loss)
I0109 15:26:37.290261  4932 solver.cpp:631] Iteration 1220, lr = 0.0001
I0109 15:27:06.857177  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1084 > 20) by scale factor 0.829585
I0109 15:27:15.736193  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4919 > 20) by scale factor 0.889209
I0109 15:27:22.059898  4932 solver.cpp:240] Iteration 1240, loss = 0.0810344
I0109 15:27:22.059943  4932 solver.cpp:255]     Train net output #0: loss = 0.027135 (* 1 = 0.027135 loss)
I0109 15:27:22.059954  4932 solver.cpp:631] Iteration 1240, lr = 0.0001
I0109 15:27:26.837971  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6769 > 20) by scale factor 0.697426
I0109 15:27:31.279001  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9034 > 20) by scale factor 0.956784
I0109 15:27:59.648746  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7461 > 20) by scale factor 0.720823
I0109 15:28:01.871410  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2577 > 20) by scale factor 0.824481
I0109 15:28:08.190789  4932 solver.cpp:240] Iteration 1260, loss = 0.114395
I0109 15:28:08.190827  4932 solver.cpp:255]     Train net output #0: loss = 0.00328425 (* 1 = 0.00328425 loss)
I0109 15:28:08.190840  4932 solver.cpp:631] Iteration 1260, lr = 0.0001
I0109 15:28:23.497622  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2185 > 20) by scale factor 0.861381
I0109 15:28:27.936507  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9459 > 20) by scale factor 0.954841
I0109 15:28:54.357218  4932 solver.cpp:240] Iteration 1280, loss = 0.111748
I0109 15:28:54.357314  4932 solver.cpp:255]     Train net output #0: loss = 0.0491224 (* 1 = 0.0491224 loss)
I0109 15:28:54.357326  4932 solver.cpp:631] Iteration 1280, lr = 0.0001
I0109 15:29:01.352946  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.19 > 20) by scale factor 0.943842
I0109 15:29:05.794544  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2062 > 20) by scale factor 0.826233
I0109 15:29:10.235441  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3999 > 20) by scale factor 0.892863
I0109 15:29:23.178620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7371 > 20) by scale factor 0.808501
I0109 15:29:40.604301  4932 solver.cpp:240] Iteration 1300, loss = 0.1492
I0109 15:29:40.604409  4932 solver.cpp:255]     Train net output #0: loss = 0.0308098 (* 1 = 0.0308098 loss)
I0109 15:29:40.604423  4932 solver.cpp:631] Iteration 1300, lr = 0.0001
I0109 15:30:26.604265  4932 solver.cpp:240] Iteration 1320, loss = 0.0866268
I0109 15:30:26.604360  4932 solver.cpp:255]     Train net output #0: loss = 0.0650049 (* 1 = 0.0650049 loss)
I0109 15:30:26.604374  4932 solver.cpp:631] Iteration 1320, lr = 0.0001
I0109 15:30:59.054689  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.355 > 20) by scale factor 0.788799
I0109 15:31:05.714134  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1067 > 20) by scale factor 0.994693
I0109 15:31:13.982655  4932 solver.cpp:240] Iteration 1340, loss = 0.0534964
I0109 15:31:13.982689  4932 solver.cpp:255]     Train net output #0: loss = 0.0670423 (* 1 = 0.0670423 loss)
I0109 15:31:13.982697  4932 solver.cpp:631] Iteration 1340, lr = 0.0001
I0109 15:31:25.415804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3242 > 20) by scale factor 0.78976
I0109 15:31:59.905118  4932 solver.cpp:240] Iteration 1360, loss = 0.0515816
I0109 15:31:59.905207  4932 solver.cpp:255]     Train net output #0: loss = 0.0038578 (* 1 = 0.0038578 loss)
I0109 15:31:59.905220  4932 solver.cpp:631] Iteration 1360, lr = 0.0001
I0109 15:32:44.337584  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3149 > 20) by scale factor 0.984501
I0109 15:32:46.221540  4932 solver.cpp:240] Iteration 1380, loss = 0.0506514
I0109 15:32:46.221586  4932 solver.cpp:255]     Train net output #0: loss = 0.010904 (* 1 = 0.010904 loss)
I0109 15:32:46.221598  4932 solver.cpp:631] Iteration 1380, lr = 0.0001
I0109 15:33:07.958571  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8716 > 20) by scale factor 0.717575
I0109 15:33:30.154939  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7652 > 20) by scale factor 0.671925
I0109 15:33:32.037457  4932 solver.cpp:240] Iteration 1400, loss = 0.0885544
I0109 15:33:32.037497  4932 solver.cpp:255]     Train net output #0: loss = 0.00544498 (* 1 = 0.00544498 loss)
I0109 15:33:32.037511  4932 solver.cpp:631] Iteration 1400, lr = 0.0001
I0109 15:33:51.127651  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4601 > 20) by scale factor 0.890467
I0109 15:34:19.700304  4932 solver.cpp:240] Iteration 1420, loss = 0.0705037
I0109 15:34:19.700412  4932 solver.cpp:255]     Train net output #0: loss = 0.151674 (* 1 = 0.151674 loss)
I0109 15:34:19.700426  4932 solver.cpp:631] Iteration 1420, lr = 0.0001
I0109 15:35:02.723975  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1873 > 20) by scale factor 0.901418
I0109 15:35:04.605839  4932 solver.cpp:240] Iteration 1440, loss = 0.0542635
I0109 15:35:04.605875  4932 solver.cpp:255]     Train net output #0: loss = 0.0459924 (* 1 = 0.0459924 loss)
I0109 15:35:04.605885  4932 solver.cpp:631] Iteration 1440, lr = 0.0001
I0109 15:35:50.064555  4932 solver.cpp:240] Iteration 1460, loss = 0.099201
I0109 15:35:50.064645  4932 solver.cpp:255]     Train net output #0: loss = 0.428102 (* 1 = 0.428102 loss)
I0109 15:35:50.064657  4932 solver.cpp:631] Iteration 1460, lr = 0.0001
I0109 15:35:50.404253  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.9532 > 20) by scale factor 0.572194
I0109 15:35:52.625028  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.095 > 20) by scale factor 0.830047
I0109 15:36:19.001499  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7124 > 20) by scale factor 0.696563
I0109 15:36:30.109205  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2327 > 20) by scale factor 0.988499
I0109 15:36:36.431187  4932 solver.cpp:240] Iteration 1480, loss = 0.0862755
I0109 15:36:36.431236  4932 solver.cpp:255]     Train net output #0: loss = 0.0536395 (* 1 = 0.0536395 loss)
I0109 15:36:36.431248  4932 solver.cpp:631] Iteration 1480, lr = 0.0001
I0109 15:36:50.092221  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1041 > 20) by scale factor 0.829736
I0109 15:37:03.414888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0944 > 20) by scale factor 0.687416
I0109 15:37:21.846292  4932 solver.cpp:240] Iteration 1500, loss = 0.0784152
I0109 15:37:21.846331  4932 solver.cpp:255]     Train net output #0: loss = 0.00429452 (* 1 = 0.00429452 loss)
I0109 15:37:21.846340  4932 solver.cpp:631] Iteration 1500, lr = 0.0001
I0109 15:37:42.166030  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.553 > 20) by scale factor 0.633855
I0109 15:37:59.095048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7637 > 20) by scale factor 0.776287
I0109 15:38:07.636018  4932 solver.cpp:240] Iteration 1520, loss = 0.0725163
I0109 15:38:07.636057  4932 solver.cpp:255]     Train net output #0: loss = 0.0692502 (* 1 = 0.0692502 loss)
I0109 15:38:07.636066  4932 solver.cpp:631] Iteration 1520, lr = 0.0001
I0109 15:38:25.307018  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9468 > 20) by scale factor 0.911295
I0109 15:38:38.624464  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7585 > 20) by scale factor 0.91918
I0109 15:38:53.826433  4932 solver.cpp:240] Iteration 1540, loss = 0.124857
I0109 15:38:53.826483  4932 solver.cpp:255]     Train net output #0: loss = 0.0288836 (* 1 = 0.0288836 loss)
I0109 15:38:53.826494  4932 solver.cpp:631] Iteration 1540, lr = 0.0001
I0109 15:38:56.389303  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8126 > 20) by scale factor 0.745917
I0109 15:38:58.613301  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3899 > 20) by scale factor 0.98088
I0109 15:39:41.232800  4932 solver.cpp:240] Iteration 1560, loss = 0.0718612
I0109 15:39:41.232888  4932 solver.cpp:255]     Train net output #0: loss = 0.206825 (* 1 = 0.206825 loss)
I0109 15:39:41.232899  4932 solver.cpp:631] Iteration 1560, lr = 0.0001
I0109 15:39:41.573289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1375 > 20) by scale factor 0.828587
I0109 15:39:50.451385  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0714 > 20) by scale factor 0.996443
I0109 15:39:59.330231  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4092 > 20) by scale factor 0.819362
I0109 15:40:12.647567  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2489 > 20) by scale factor 0.941223
I0109 15:40:27.438333  4932 solver.cpp:240] Iteration 1580, loss = 0.0926372
I0109 15:40:27.438381  4932 solver.cpp:255]     Train net output #0: loss = 0.0530771 (* 1 = 0.0530771 loss)
I0109 15:40:27.438395  4932 solver.cpp:631] Iteration 1580, lr = 0.0001
I0109 15:40:45.535559  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4066 > 20) by scale factor 0.934291
I0109 15:40:58.698596  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4355 > 20) by scale factor 0.756557
I0109 15:41:07.576408  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6526 > 20) by scale factor 0.674476
I0109 15:41:13.899240  4932 solver.cpp:240] Iteration 1600, loss = 0.0864683
I0109 15:41:13.899276  4932 solver.cpp:255]     Train net output #0: loss = 0.0117012 (* 1 = 0.0117012 loss)
I0109 15:41:13.899286  4932 solver.cpp:631] Iteration 1600, lr = 0.0001
I0109 15:42:00.039284  4932 solver.cpp:240] Iteration 1620, loss = 0.0674682
I0109 15:42:00.039412  4932 solver.cpp:255]     Train net output #0: loss = 0.0973658 (* 1 = 0.0973658 loss)
I0109 15:42:00.039432  4932 solver.cpp:631] Iteration 1620, lr = 0.0001
I0109 15:42:23.933117  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0721 > 20) by scale factor 0.738767
I0109 15:42:37.253623  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5128 > 20) by scale factor 0.815901
I0109 15:42:46.391849  4932 solver.cpp:240] Iteration 1640, loss = 0.112733
I0109 15:42:46.391894  4932 solver.cpp:255]     Train net output #0: loss = 0.126649 (* 1 = 0.126649 loss)
I0109 15:42:46.391906  4932 solver.cpp:631] Iteration 1640, lr = 0.0001
I0109 15:43:17.812286  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5557 > 20) by scale factor 0.753133
I0109 15:43:28.385206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0004 > 20) by scale factor 0.799986
I0109 15:43:32.488307  4932 solver.cpp:240] Iteration 1660, loss = 0.0785136
I0109 15:43:32.488353  4932 solver.cpp:255]     Train net output #0: loss = 0.0448513 (* 1 = 0.0448513 loss)
I0109 15:43:32.488364  4932 solver.cpp:631] Iteration 1660, lr = 0.0001
I0109 15:44:12.011143  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6313 > 20) by scale factor 0.969399
I0109 15:44:18.334113  4932 solver.cpp:240] Iteration 1680, loss = 0.0888187
I0109 15:44:18.334161  4932 solver.cpp:255]     Train net output #0: loss = 0.216262 (* 1 = 0.216262 loss)
I0109 15:44:18.334173  4932 solver.cpp:631] Iteration 1680, lr = 0.0001
I0109 15:44:18.675390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9417 > 20) by scale factor 0.715777
I0109 15:44:25.337271  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9335 > 20) by scale factor 0.955405
I0109 15:44:27.557663  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6582 > 20) by scale factor 0.845374
I0109 15:44:34.214831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9114 > 20) by scale factor 0.956415
I0109 15:44:42.089504  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1525 > 20) by scale factor 0.710417
I0109 15:44:50.969785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7267 > 20) by scale factor 0.964941
I0109 15:44:55.409713  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5524 > 20) by scale factor 0.886823
I0109 15:45:03.954684  4932 solver.cpp:240] Iteration 1700, loss = 0.117167
I0109 15:45:03.954720  4932 solver.cpp:255]     Train net output #0: loss = 0.0900308 (* 1 = 0.0900308 loss)
I0109 15:45:03.954728  4932 solver.cpp:631] Iteration 1700, lr = 0.0001
I0109 15:45:41.460727  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1498 > 20) by scale factor 0.863939
I0109 15:45:45.901417  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0666 > 20) by scale factor 0.831027
I0109 15:45:51.321962  4932 solver.cpp:240] Iteration 1720, loss = 0.0750609
I0109 15:45:51.322015  4932 solver.cpp:255]     Train net output #0: loss = 0.0766038 (* 1 = 0.0766038 loss)
I0109 15:45:51.360831  4932 solver.cpp:631] Iteration 1720, lr = 0.0001
I0109 15:46:09.419998  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9387 > 20) by scale factor 0.955171
I0109 15:46:27.818099  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2234 > 20) by scale factor 0.899951
I0109 15:46:36.358132  4932 solver.cpp:240] Iteration 1740, loss = 0.0566726
I0109 15:46:36.358180  4932 solver.cpp:255]     Train net output #0: loss = 0.0126974 (* 1 = 0.0126974 loss)
I0109 15:46:36.358194  4932 solver.cpp:631] Iteration 1740, lr = 0.0001
I0109 15:47:03.314787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3267 > 20) by scale factor 0.857387
I0109 15:47:05.536197  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3745 > 20) by scale factor 0.855634
I0109 15:47:07.756011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8443 > 20) by scale factor 0.718279
I0109 15:47:22.952462  4932 solver.cpp:240] Iteration 1760, loss = 0.0707226
I0109 15:47:22.952508  4932 solver.cpp:255]     Train net output #0: loss = 0.00251377 (* 1 = 0.00251377 loss)
I0109 15:47:22.952520  4932 solver.cpp:631] Iteration 1760, lr = 0.0001
I0109 15:47:27.735910  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7942 > 20) by scale factor 0.877416
I0109 15:48:00.159426  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3738 > 20) by scale factor 0.935726
I0109 15:48:10.251513  4932 solver.cpp:240] Iteration 1780, loss = 0.0876694
I0109 15:48:10.251549  4932 solver.cpp:255]     Train net output #0: loss = 0.013275 (* 1 = 0.013275 loss)
I0109 15:48:10.251557  4932 solver.cpp:631] Iteration 1780, lr = 0.0001
I0109 15:48:12.807945  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4917 > 20) by scale factor 0.976003
I0109 15:48:26.126621  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9522 > 20) by scale factor 0.871376
I0109 15:48:35.006059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6344 > 20) by scale factor 0.811874
I0109 15:48:41.666532  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0703 > 20) by scale factor 0.996496
I0109 15:48:56.025357  4932 solver.cpp:240] Iteration 1800, loss = 0.104061
I0109 15:48:56.025390  4932 solver.cpp:255]     Train net output #0: loss = 0.266908 (* 1 = 0.266908 loss)
I0109 15:48:56.025399  4932 solver.cpp:631] Iteration 1800, lr = 0.0001
I0109 15:48:56.364511  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0487 > 20) by scale factor 0.798446
I0109 15:49:03.027784  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2544 > 20) by scale factor 0.987441
I0109 15:49:05.250558  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.8095 > 20) by scale factor 0.628744
I0109 15:49:41.916468  4932 solver.cpp:240] Iteration 1820, loss = 0.0918792
I0109 15:49:41.916563  4932 solver.cpp:255]     Train net output #0: loss = 0.0135122 (* 1 = 0.0135122 loss)
I0109 15:49:41.916575  4932 solver.cpp:631] Iteration 1820, lr = 0.0001
I0109 15:50:00.018592  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1017 > 20) by scale factor 0.904909
I0109 15:50:07.668241  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9682 > 20) by scale factor 0.953824
I0109 15:50:27.300909  4932 solver.cpp:240] Iteration 1840, loss = 0.101618
I0109 15:50:27.301000  4932 solver.cpp:255]     Train net output #0: loss = 0.370394 (* 1 = 0.370394 loss)
I0109 15:50:27.301012  4932 solver.cpp:631] Iteration 1840, lr = 0.0001
I0109 15:50:27.639987  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6314 > 20) by scale factor 0.811971
I0109 15:50:43.950330  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2537 > 20) by scale factor 0.898726
I0109 15:50:48.394187  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7743 > 20) by scale factor 0.807289
I0109 15:51:01.714954  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3702 > 20) by scale factor 0.788327
I0109 15:51:06.155328  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4 > 20) by scale factor 0.934579
I0109 15:51:13.880584  4932 solver.cpp:240] Iteration 1860, loss = 0.116648
I0109 15:51:13.880622  4932 solver.cpp:255]     Train net output #0: loss = 0.04761 (* 1 = 0.04761 loss)
I0109 15:51:13.880630  4932 solver.cpp:631] Iteration 1860, lr = 0.0001
I0109 15:51:58.267901  4932 solver.cpp:240] Iteration 1880, loss = 0.0741247
I0109 15:51:58.267990  4932 solver.cpp:255]     Train net output #0: loss = 0.128672 (* 1 = 0.128672 loss)
I0109 15:51:58.268002  4932 solver.cpp:631] Iteration 1880, lr = 0.0001
I0109 15:52:15.168728  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3306 > 20) by scale factor 0.937619
I0109 15:52:43.698787  4932 solver.cpp:240] Iteration 1900, loss = 0.055013
I0109 15:52:43.698894  4932 solver.cpp:255]     Train net output #0: loss = 0.0813257 (* 1 = 0.0813257 loss)
I0109 15:52:43.698906  4932 solver.cpp:631] Iteration 1900, lr = 0.0001
I0109 15:52:59.209179  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4263 > 20) by scale factor 0.818788
I0109 15:53:01.430002  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2537 > 20) by scale factor 0.941012
I0109 15:53:10.307266  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0718 > 20) by scale factor 0.906135
I0109 15:53:31.479112  4932 solver.cpp:240] Iteration 1920, loss = 0.0840537
I0109 15:53:31.479199  4932 solver.cpp:255]     Train net output #0: loss = 0.118375 (* 1 = 0.118375 loss)
I0109 15:53:31.479210  4932 solver.cpp:631] Iteration 1920, lr = 0.0001
I0109 15:53:36.255694  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5896 > 20) by scale factor 0.92637
I0109 15:53:45.135146  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6164 > 20) by scale factor 0.925225
I0109 15:54:18.128307  4932 solver.cpp:240] Iteration 1940, loss = 0.0803644
I0109 15:54:18.128401  4932 solver.cpp:255]     Train net output #0: loss = 0.00657928 (* 1 = 0.00657928 loss)
I0109 15:54:18.128413  4932 solver.cpp:631] Iteration 1940, lr = 0.0001
I0109 15:54:22.906482  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9544 > 20) by scale factor 0.834919
I0109 15:54:25.131523  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3465 > 20) by scale factor 0.759115
I0109 15:54:51.422894  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5701 > 20) by scale factor 0.972283
I0109 15:55:04.410187  4932 solver.cpp:240] Iteration 1960, loss = 0.13616
I0109 15:55:04.410228  4932 solver.cpp:255]     Train net output #0: loss = 0.521365 (* 1 = 0.521365 loss)
I0109 15:55:04.410235  4932 solver.cpp:631] Iteration 1960, lr = 0.0001
I0109 15:55:28.706241  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.912 > 20) by scale factor 0.956387
I0109 15:55:46.466651  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6797 > 20) by scale factor 0.881845
I0109 15:55:50.569331  4932 solver.cpp:240] Iteration 1980, loss = 0.0841889
I0109 15:55:50.569375  4932 solver.cpp:255]     Train net output #0: loss = 0.0139752 (* 1 = 0.0139752 loss)
I0109 15:55:50.569386  4932 solver.cpp:631] Iteration 1980, lr = 0.0001
I0109 15:56:05.465327  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7332 > 20) by scale factor 0.748132
I0109 15:56:32.103020  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2133 > 20) by scale factor 0.861576
I0109 15:56:36.270032  4932 solver.cpp:424] Iteration 2000, Testing net (#0)
I0109 15:57:32.871469  4932 solver.cpp:481]     Test net output #0: accuracy = 0.828421
I0109 15:57:32.871552  4932 solver.cpp:481]     Test net output #1: loss = 0.799612 (* 1 = 0.799612 loss)
I0109 15:57:34.738087  4932 solver.cpp:240] Iteration 2000, loss = 0.0747109
I0109 15:57:34.738126  4932 solver.cpp:255]     Train net output #0: loss = 0.118064 (* 1 = 0.118064 loss)
I0109 15:57:34.738134  4932 solver.cpp:631] Iteration 2000, lr = 0.0001
I0109 15:58:21.163065  4932 solver.cpp:240] Iteration 2020, loss = 0.0744005
I0109 15:58:21.163162  4932 solver.cpp:255]     Train net output #0: loss = 0.122298 (* 1 = 0.122298 loss)
I0109 15:58:21.163177  4932 solver.cpp:631] Iteration 2020, lr = 0.0001
I0109 15:58:46.410974  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.126 > 20) by scale factor 0.663879
I0109 15:59:07.791987  4932 solver.cpp:240] Iteration 2040, loss = 0.07098
I0109 15:59:07.792088  4932 solver.cpp:255]     Train net output #0: loss = 0.0282899 (* 1 = 0.0282899 loss)
I0109 15:59:07.792102  4932 solver.cpp:631] Iteration 2040, lr = 0.0001
I0109 15:59:10.349280  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5849 > 20) by scale factor 0.971585
I0109 15:59:21.453490  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1761 > 20) by scale factor 0.99127
I0109 15:59:32.552249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2807 > 20) by scale factor 0.897639
I0109 15:59:53.999778  4932 solver.cpp:240] Iteration 2060, loss = 0.132678
I0109 15:59:53.999879  4932 solver.cpp:255]     Train net output #0: loss = 0.0344321 (* 1 = 0.0344321 loss)
I0109 15:59:53.999891  4932 solver.cpp:631] Iteration 2060, lr = 0.0001
I0109 16:00:12.088719  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1634 > 20) by scale factor 0.991897
I0109 16:00:16.529124  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2127 > 20) by scale factor 0.942832
I0109 16:00:31.491111  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0921 > 20) by scale factor 0.830148
I0109 16:00:40.025189  4932 solver.cpp:240] Iteration 2080, loss = 0.105363
I0109 16:00:40.025228  4932 solver.cpp:255]     Train net output #0: loss = 0.0459391 (* 1 = 0.0459391 loss)
I0109 16:00:40.025236  4932 solver.cpp:631] Iteration 2080, lr = 0.0001
I0109 16:00:42.583386  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7363 > 20) by scale factor 0.842591
I0109 16:00:47.024745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6429 > 20) by scale factor 0.723514
I0109 16:01:19.582803  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3508 > 20) by scale factor 0.982764
I0109 16:01:25.901746  4932 solver.cpp:240] Iteration 2100, loss = 0.110304
I0109 16:01:25.901782  4932 solver.cpp:255]     Train net output #0: loss = 0.21069 (* 1 = 0.21069 loss)
I0109 16:01:25.901792  4932 solver.cpp:631] Iteration 2100, lr = 0.0001
I0109 16:01:32.898007  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.362 > 20) by scale factor 0.936242
I0109 16:01:38.729171  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6029 > 20) by scale factor 0.884843
I0109 16:01:43.169641  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2103 > 20) by scale factor 0.76306
I0109 16:01:49.834503  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0443 > 20) by scale factor 0.767923
I0109 16:02:11.696264  4932 solver.cpp:240] Iteration 2120, loss = 0.124013
I0109 16:02:11.696305  4932 solver.cpp:255]     Train net output #0: loss = 0.149482 (* 1 = 0.149482 loss)
I0109 16:02:11.696313  4932 solver.cpp:631] Iteration 2120, lr = 0.0001
I0109 16:02:39.024019  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7163 > 20) by scale factor 0.920968
I0109 16:02:58.009937  4932 solver.cpp:240] Iteration 2140, loss = 0.0690792
I0109 16:02:58.009976  4932 solver.cpp:255]     Train net output #0: loss = 0.141373 (* 1 = 0.141373 loss)
I0109 16:02:58.009986  4932 solver.cpp:631] Iteration 2140, lr = 0.0001
I0109 16:03:13.878798  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6156 > 20) by scale factor 0.97014
I0109 16:03:29.098889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7771 > 20) by scale factor 0.878077
I0109 16:03:44.298130  4932 solver.cpp:240] Iteration 2160, loss = 0.0890509
I0109 16:03:44.298226  4932 solver.cpp:255]     Train net output #0: loss = 0.0523194 (* 1 = 0.0523194 loss)
I0109 16:03:44.298239  4932 solver.cpp:631] Iteration 2160, lr = 0.0001
I0109 16:04:19.308408  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3092 > 20) by scale factor 0.732354
I0109 16:04:30.065834  4932 solver.cpp:240] Iteration 2180, loss = 0.096031
I0109 16:04:30.065883  4932 solver.cpp:255]     Train net output #0: loss = 0.156419 (* 1 = 0.156419 loss)
I0109 16:04:30.065904  4932 solver.cpp:631] Iteration 2180, lr = 0.0001
I0109 16:04:30.407156  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4568 > 20) by scale factor 0.890597
I0109 16:04:32.630872  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.1204 > 20) by scale factor 0.538787
I0109 16:04:34.854188  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1954 > 20) by scale factor 0.793795
I0109 16:04:37.075042  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3069 > 20) by scale factor 0.984887
I0109 16:04:45.128376  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8881 > 20) by scale factor 0.957481
I0109 16:05:07.326211  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3801 > 20) by scale factor 0.85543
I0109 16:05:15.868253  4932 solver.cpp:240] Iteration 2200, loss = 0.119156
I0109 16:05:15.868294  4932 solver.cpp:255]     Train net output #0: loss = 0.0201163 (* 1 = 0.0201163 loss)
I0109 16:05:15.868302  4932 solver.cpp:631] Iteration 2200, lr = 0.0001
I0109 16:05:35.096530  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.2916 > 20) by scale factor 0.536313
I0109 16:05:46.192131  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0083 > 20) by scale factor 0.999583
I0109 16:05:58.563446  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8634 > 20) by scale factor 0.874762
I0109 16:06:02.664909  4932 solver.cpp:240] Iteration 2220, loss = 0.115434
I0109 16:06:02.664947  4932 solver.cpp:255]     Train net output #0: loss = 0.336098 (* 1 = 0.336098 loss)
I0109 16:06:02.664955  4932 solver.cpp:631] Iteration 2220, lr = 0.0001
I0109 16:06:48.960180  4932 solver.cpp:240] Iteration 2240, loss = 0.0535023
I0109 16:06:48.960265  4932 solver.cpp:255]     Train net output #0: loss = 0.0919695 (* 1 = 0.0919695 loss)
I0109 16:06:48.960278  4932 solver.cpp:631] Iteration 2240, lr = 0.0001
I0109 16:06:55.958180  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9624 > 20) by scale factor 0.667504
I0109 16:07:00.404062  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1069 > 20) by scale factor 0.947559
I0109 16:07:24.042009  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5687 > 20) by scale factor 0.782208
I0109 16:07:34.805483  4932 solver.cpp:240] Iteration 2260, loss = 0.0932475
I0109 16:07:34.805527  4932 solver.cpp:255]     Train net output #0: loss = 0.120591 (* 1 = 0.120591 loss)
I0109 16:07:34.805538  4932 solver.cpp:631] Iteration 2260, lr = 0.0001
I0109 16:07:37.364969  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0778 > 20) by scale factor 0.996126
I0109 16:08:03.435276  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.458 > 20) by scale factor 0.785608
I0109 16:08:12.314307  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2888 > 20) by scale factor 0.897311
I0109 16:08:16.751868  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2379 > 20) by scale factor 0.988243
I0109 16:08:20.855571  4932 solver.cpp:240] Iteration 2280, loss = 0.0808414
I0109 16:08:20.855610  4932 solver.cpp:255]     Train net output #0: loss = 0.0162818 (* 1 = 0.0162818 loss)
I0109 16:08:20.855623  4932 solver.cpp:631] Iteration 2280, lr = 0.0001
I0109 16:09:08.557098  4932 solver.cpp:240] Iteration 2300, loss = 0.0604906
I0109 16:09:08.557191  4932 solver.cpp:255]     Train net output #0: loss = 0.0376884 (* 1 = 0.0376884 loss)
I0109 16:09:08.557204  4932 solver.cpp:631] Iteration 2300, lr = 0.0001
I0109 16:09:17.772953  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.412 > 20) by scale factor 0.979818
I0109 16:09:41.548300  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3278 > 20) by scale factor 0.759652
I0109 16:09:54.524540  4932 solver.cpp:240] Iteration 2320, loss = 0.123837
I0109 16:09:54.524586  4932 solver.cpp:255]     Train net output #0: loss = 0.031365 (* 1 = 0.031365 loss)
I0109 16:09:54.524595  4932 solver.cpp:631] Iteration 2320, lr = 0.0001
I0109 16:10:39.824654  4932 solver.cpp:240] Iteration 2340, loss = 0.0543003
I0109 16:10:39.824749  4932 solver.cpp:255]     Train net output #0: loss = 0.0075316 (* 1 = 0.0075316 loss)
I0109 16:10:39.824761  4932 solver.cpp:631] Iteration 2340, lr = 0.0001
I0109 16:11:26.061533  4932 solver.cpp:240] Iteration 2360, loss = 0.0580657
I0109 16:11:26.061624  4932 solver.cpp:255]     Train net output #0: loss = 0.0383434 (* 1 = 0.0383434 loss)
I0109 16:11:26.061636  4932 solver.cpp:631] Iteration 2360, lr = 0.0001
I0109 16:11:54.503362  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9326 > 20) by scale factor 0.911883
I0109 16:12:13.854496  4932 solver.cpp:240] Iteration 2380, loss = 0.0517415
I0109 16:12:13.854584  4932 solver.cpp:255]     Train net output #0: loss = 0.0141718 (* 1 = 0.0141718 loss)
I0109 16:12:13.854598  4932 solver.cpp:631] Iteration 2380, lr = 0.0001
I0109 16:12:25.295382  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9462 > 20) by scale factor 0.871606
I0109 16:12:59.825317  4932 solver.cpp:240] Iteration 2400, loss = 0.0618149
I0109 16:12:59.825404  4932 solver.cpp:255]     Train net output #0: loss = 0.037476 (* 1 = 0.037476 loss)
I0109 16:12:59.825417  4932 solver.cpp:631] Iteration 2400, lr = 0.0001
I0109 16:13:30.878718  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4944 > 20) by scale factor 0.930476
I0109 16:13:33.101382  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2755 > 20) by scale factor 0.897848
I0109 16:13:46.080826  4932 solver.cpp:240] Iteration 2420, loss = 0.115782
I0109 16:13:46.080873  4932 solver.cpp:255]     Train net output #0: loss = 0.0293725 (* 1 = 0.0293725 loss)
I0109 16:13:46.080890  4932 solver.cpp:631] Iteration 2420, lr = 0.0001
I0109 16:13:59.734439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5591 > 20) by scale factor 0.886561
I0109 16:14:25.591121  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4204 > 20) by scale factor 0.979413
I0109 16:14:31.910979  4932 solver.cpp:240] Iteration 2440, loss = 0.112255
I0109 16:14:31.911015  4932 solver.cpp:255]     Train net output #0: loss = 0.0780424 (* 1 = 0.0780424 loss)
I0109 16:14:31.911025  4932 solver.cpp:631] Iteration 2440, lr = 0.0001
I0109 16:14:43.702128  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8345 > 20) by scale factor 0.774157
I0109 16:15:18.246167  4932 solver.cpp:240] Iteration 2460, loss = 0.083163
I0109 16:15:18.246254  4932 solver.cpp:255]     Train net output #0: loss = 0.166306 (* 1 = 0.166306 loss)
I0109 16:15:18.246264  4932 solver.cpp:631] Iteration 2460, lr = 0.0001
I0109 16:16:04.341367  4932 solver.cpp:240] Iteration 2480, loss = 0.0574494
I0109 16:16:04.341462  4932 solver.cpp:255]     Train net output #0: loss = 0.00281448 (* 1 = 0.00281448 loss)
I0109 16:16:04.341475  4932 solver.cpp:631] Iteration 2480, lr = 0.0001
I0109 16:16:50.044728  4932 solver.cpp:240] Iteration 2500, loss = 0.0593795
I0109 16:16:50.044802  4932 solver.cpp:255]     Train net output #0: loss = 0.0210842 (* 1 = 0.0210842 loss)
I0109 16:16:50.044812  4932 solver.cpp:631] Iteration 2500, lr = 0.0001
I0109 16:16:57.047328  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2841 > 20) by scale factor 0.791012
I0109 16:17:34.936910  4932 solver.cpp:240] Iteration 2520, loss = 0.0817239
I0109 16:17:34.936991  4932 solver.cpp:255]     Train net output #0: loss = 0.068993 (* 1 = 0.068993 loss)
I0109 16:17:34.937001  4932 solver.cpp:631] Iteration 2520, lr = 0.0001
I0109 16:18:11.517616  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6315 > 20) by scale factor 0.81197
I0109 16:18:19.750613  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2624 > 20) by scale factor 0.859755
I0109 16:18:21.631695  4932 solver.cpp:240] Iteration 2540, loss = 0.0899035
I0109 16:18:21.631733  4932 solver.cpp:255]     Train net output #0: loss = 0.0494567 (* 1 = 0.0494567 loss)
I0109 16:18:21.631742  4932 solver.cpp:631] Iteration 2540, lr = 0.0001
I0109 16:18:35.289453  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.8468 > 20) by scale factor 0.608887
I0109 16:18:46.389961  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0625 > 20) by scale factor 0.906517
I0109 16:18:48.612854  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3269 > 20) by scale factor 0.983918
I0109 16:19:07.779690  4932 solver.cpp:240] Iteration 2560, loss = 0.121694
I0109 16:19:07.779724  4932 solver.cpp:255]     Train net output #0: loss = 0.231107 (* 1 = 0.231107 loss)
I0109 16:19:07.779733  4932 solver.cpp:631] Iteration 2560, lr = 0.0001
I0109 16:19:10.338609  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7818 > 20) by scale factor 0.962379
I0109 16:19:12.559648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8086 > 20) by scale factor 0.917069
I0109 16:19:17.002661  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8317 > 20) by scale factor 0.875974
I0109 16:19:30.321725  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5533 > 20) by scale factor 0.97308
I0109 16:19:51.869845  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1879 > 20) by scale factor 0.794033
I0109 16:19:53.751097  4932 solver.cpp:240] Iteration 2580, loss = 0.119389
I0109 16:19:53.751138  4932 solver.cpp:255]     Train net output #0: loss = 0.00775797 (* 1 = 0.00775797 loss)
I0109 16:19:53.751147  4932 solver.cpp:631] Iteration 2580, lr = 0.0001
I0109 16:20:15.371819  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5651 > 20) by scale factor 0.676473
I0109 16:20:39.454344  4932 solver.cpp:240] Iteration 2600, loss = 0.0831516
I0109 16:20:39.454437  4932 solver.cpp:255]     Train net output #0: loss = 0.076272 (* 1 = 0.076272 loss)
I0109 16:20:39.454449  4932 solver.cpp:631] Iteration 2600, lr = 0.0001
I0109 16:20:42.014359  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8439 > 20) by scale factor 0.875507
I0109 16:20:58.894680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.488 > 20) by scale factor 0.851499
I0109 16:21:01.115345  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7337 > 20) by scale factor 0.920229
I0109 16:21:07.783620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5072 > 20) by scale factor 0.784091
I0109 16:21:21.100487  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.464 > 20) by scale factor 0.656512
I0109 16:21:26.224254  4932 solver.cpp:240] Iteration 2620, loss = 0.117432
I0109 16:21:26.224287  4932 solver.cpp:255]     Train net output #0: loss = 0.083873 (* 1 = 0.083873 loss)
I0109 16:21:26.224422  4932 solver.cpp:631] Iteration 2620, lr = 0.0001
I0109 16:22:03.406720  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2253 > 20) by scale factor 0.988859
I0109 16:22:11.948565  4932 solver.cpp:240] Iteration 2640, loss = 0.0615197
I0109 16:22:11.948604  4932 solver.cpp:255]     Train net output #0: loss = 0.0144669 (* 1 = 0.0144669 loss)
I0109 16:22:11.948612  4932 solver.cpp:631] Iteration 2640, lr = 0.0001
I0109 16:22:23.387931  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.6345 > 20) by scale factor 0.612848
I0109 16:22:30.048615  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6594 > 20) by scale factor 0.923387
I0109 16:22:51.915460  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4452 > 20) by scale factor 0.891061
I0109 16:22:58.240217  4932 solver.cpp:240] Iteration 2660, loss = 0.0934552
I0109 16:22:58.240260  4932 solver.cpp:255]     Train net output #0: loss = 0.0599883 (* 1 = 0.0599883 loss)
I0109 16:22:58.240279  4932 solver.cpp:631] Iteration 2660, lr = 0.0001
I0109 16:23:00.800871  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3709 > 20) by scale factor 0.894019
I0109 16:23:25.998353  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7426 > 20) by scale factor 0.720913
I0109 16:23:43.424015  4932 solver.cpp:240] Iteration 2680, loss = 0.110202
I0109 16:23:43.424052  4932 solver.cpp:255]     Train net output #0: loss = 0.016611 (* 1 = 0.016611 loss)
I0109 16:23:43.424062  4932 solver.cpp:631] Iteration 2680, lr = 0.0001
I0109 16:24:14.291206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.9183 > 20) by scale factor 0.572765
I0109 16:24:18.735841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2228 > 20) by scale factor 0.861223
I0109 16:24:31.279109  4932 solver.cpp:240] Iteration 2700, loss = 0.0849912
I0109 16:24:31.279155  4932 solver.cpp:255]     Train net output #0: loss = 0.234338 (* 1 = 0.234338 loss)
I0109 16:24:31.279165  4932 solver.cpp:631] Iteration 2700, lr = 0.0001
I0109 16:24:44.940443  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1 > 20) by scale factor 0.904978
I0109 16:24:49.384474  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4286 > 20) by scale factor 0.756756
I0109 16:25:17.636703  4932 solver.cpp:240] Iteration 2720, loss = 0.0805569
I0109 16:25:17.636824  4932 solver.cpp:255]     Train net output #0: loss = 0.0357575 (* 1 = 0.0357575 loss)
I0109 16:25:17.636842  4932 solver.cpp:631] Iteration 2720, lr = 0.0001
I0109 16:25:20.199403  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3732 > 20) by scale factor 0.758346
I0109 16:26:03.624531  4932 solver.cpp:240] Iteration 2740, loss = 0.0684793
I0109 16:26:03.624630  4932 solver.cpp:255]     Train net output #0: loss = 0.205134 (* 1 = 0.205134 loss)
I0109 16:26:03.624645  4932 solver.cpp:631] Iteration 2740, lr = 0.0001
I0109 16:26:03.965744  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0161 > 20) by scale factor 0.832776
I0109 16:26:10.629701  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9867 > 20) by scale factor 0.952985
I0109 16:26:49.617302  4932 solver.cpp:240] Iteration 2760, loss = 0.089859
I0109 16:26:49.617398  4932 solver.cpp:255]     Train net output #0: loss = 0.0370483 (* 1 = 0.0370483 loss)
I0109 16:26:49.617410  4932 solver.cpp:631] Iteration 2760, lr = 0.0001
I0109 16:27:14.031568  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8348 > 20) by scale factor 0.875857
I0109 16:27:25.129314  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5894 > 20) by scale factor 0.813357
I0109 16:27:37.745659  4932 solver.cpp:240] Iteration 2780, loss = 0.0689393
I0109 16:27:37.745698  4932 solver.cpp:255]     Train net output #0: loss = 0.00260875 (* 1 = 0.00260875 loss)
I0109 16:27:37.745708  4932 solver.cpp:631] Iteration 2780, lr = 0.0001
I0109 16:27:40.302966  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5476 > 20) by scale factor 0.849343
I0109 16:27:49.180513  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.8782 > 20) by scale factor 0.608306
I0109 16:28:04.721668  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1605 > 20) by scale factor 0.945159
I0109 16:28:23.704766  4932 solver.cpp:240] Iteration 2800, loss = 0.131902
I0109 16:28:23.704810  4932 solver.cpp:255]     Train net output #0: loss = 0.135501 (* 1 = 0.135501 loss)
I0109 16:28:23.704821  4932 solver.cpp:631] Iteration 2800, lr = 0.0001
I0109 16:28:26.265262  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0702 > 20) by scale factor 0.712498
I0109 16:28:55.879655  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9065 > 20) by scale factor 0.956639
I0109 16:29:08.857630  4932 solver.cpp:240] Iteration 2820, loss = 0.0707504
I0109 16:29:08.857671  4932 solver.cpp:255]     Train net output #0: loss = 0.0297054 (* 1 = 0.0297054 loss)
I0109 16:29:08.857679  4932 solver.cpp:631] Iteration 2820, lr = 0.0001
I0109 16:29:38.867660  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7997 > 20) by scale factor 0.877203
I0109 16:29:41.091156  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8989 > 20) by scale factor 0.956989
I0109 16:29:54.075804  4932 solver.cpp:240] Iteration 2840, loss = 0.0436979
I0109 16:29:54.075839  4932 solver.cpp:255]     Train net output #0: loss = 0.00513437 (* 1 = 0.00513437 loss)
I0109 16:29:54.075847  4932 solver.cpp:631] Iteration 2840, lr = 0.0001
I0109 16:30:16.033236  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.23 > 20) by scale factor 0.988633
I0109 16:30:18.256635  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6645 > 20) by scale factor 0.923168
I0109 16:30:41.552986  4932 solver.cpp:240] Iteration 2860, loss = 0.110637
I0109 16:30:41.553030  4932 solver.cpp:255]     Train net output #0: loss = 0.132522 (* 1 = 0.132522 loss)
I0109 16:30:41.553041  4932 solver.cpp:631] Iteration 2860, lr = 0.0001
I0109 16:31:08.526664  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2272 > 20) by scale factor 0.988769
I0109 16:31:14.313206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.9072 > 20) by scale factor 0.589845
I0109 16:31:23.192010  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2886 > 20) by scale factor 0.732907
I0109 16:31:27.291936  4932 solver.cpp:240] Iteration 2880, loss = 0.110512
I0109 16:31:27.291978  4932 solver.cpp:255]     Train net output #0: loss = 0.0244697 (* 1 = 0.0244697 loss)
I0109 16:31:27.291987  4932 solver.cpp:631] Iteration 2880, lr = 0.0001
I0109 16:31:29.852022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3686 > 20) by scale factor 0.935954
I0109 16:31:36.517138  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6879 > 20) by scale factor 0.749404
I0109 16:32:12.362689  4932 solver.cpp:240] Iteration 2900, loss = 0.113848
I0109 16:32:12.362782  4932 solver.cpp:255]     Train net output #0: loss = 0.130628 (* 1 = 0.130628 loss)
I0109 16:32:12.362795  4932 solver.cpp:631] Iteration 2900, lr = 0.0001
I0109 16:32:58.206776  4932 solver.cpp:240] Iteration 2920, loss = 0.0728176
I0109 16:32:58.206856  4932 solver.cpp:255]     Train net output #0: loss = 0.03322 (* 1 = 0.03322 loss)
I0109 16:32:58.206867  4932 solver.cpp:631] Iteration 2920, lr = 0.0001
I0109 16:33:08.919051  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0532 > 20) by scale factor 0.688391
I0109 16:33:11.142576  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8804 > 20) by scale factor 0.803847
I0109 16:33:15.585400  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.5386 > 20) by scale factor 0.634143
I0109 16:33:22.246541  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2805 > 20) by scale factor 0.986168
I0109 16:33:31.134598  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5256 > 20) by scale factor 0.929126
I0109 16:33:45.742573  4932 solver.cpp:240] Iteration 2940, loss = 0.149795
I0109 16:33:45.742616  4932 solver.cpp:255]     Train net output #0: loss = 0.178612 (* 1 = 0.178612 loss)
I0109 16:33:45.742627  4932 solver.cpp:631] Iteration 2940, lr = 0.0001
I0109 16:33:59.404544  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0282 > 20) by scale factor 0.907927
I0109 16:34:01.627599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7157 > 20) by scale factor 0.673044
I0109 16:34:31.252151  4932 solver.cpp:240] Iteration 2960, loss = 0.0890689
I0109 16:34:31.252199  4932 solver.cpp:255]     Train net output #0: loss = 0.115394 (* 1 = 0.115394 loss)
I0109 16:34:31.252213  4932 solver.cpp:631] Iteration 2960, lr = 0.0001
I0109 16:34:42.691174  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6168 > 20) by scale factor 0.970085
I0109 16:34:51.570698  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8114 > 20) by scale factor 0.916952
I0109 16:35:17.680670  4932 solver.cpp:240] Iteration 2980, loss = 0.104655
I0109 16:35:17.680786  4932 solver.cpp:255]     Train net output #0: loss = 0.0244927 (* 1 = 0.0244927 loss)
I0109 16:35:17.680804  4932 solver.cpp:631] Iteration 2980, lr = 0.0001
I0109 16:35:20.242918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6771 > 20) by scale factor 0.810467
I0109 16:36:01.605996  4932 solver.cpp:424] Iteration 3000, Testing net (#0)
I0109 16:37:00.724331  4932 solver.cpp:481]     Test net output #0: accuracy = 0.836842
I0109 16:37:00.724427  4932 solver.cpp:481]     Test net output #1: loss = 0.786996 (* 1 = 0.786996 loss)
I0109 16:37:02.590121  4932 solver.cpp:240] Iteration 3000, loss = 0.0875682
I0109 16:37:02.590158  4932 solver.cpp:255]     Train net output #0: loss = 0.236112 (* 1 = 0.236112 loss)
I0109 16:37:02.590167  4932 solver.cpp:631] Iteration 3000, lr = 0.0001
I0109 16:37:02.929394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0891 > 20) by scale factor 0.995565
I0109 16:37:07.369688  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2597 > 20) by scale factor 0.761625
I0109 16:37:18.787768  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9602 > 20) by scale factor 0.801277
I0109 16:37:44.335428  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6551 > 20) by scale factor 0.882803
I0109 16:37:48.437060  4932 solver.cpp:240] Iteration 3020, loss = 0.139424
I0109 16:37:48.437100  4932 solver.cpp:255]     Train net output #0: loss = 0.0687267 (* 1 = 0.0687267 loss)
I0109 16:37:48.437109  4932 solver.cpp:631] Iteration 3020, lr = 0.0001
I0109 16:37:50.994850  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4363 > 20) by scale factor 0.978651
I0109 16:38:03.662298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8641 > 20) by scale factor 0.874734
I0109 16:38:25.859272  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0115 > 20) by scale factor 0.832936
I0109 16:38:35.761706  4932 solver.cpp:240] Iteration 3040, loss = 0.101399
I0109 16:38:35.761749  4932 solver.cpp:255]     Train net output #0: loss = 0.0817953 (* 1 = 0.0817953 loss)
I0109 16:38:35.761759  4932 solver.cpp:631] Iteration 3040, lr = 0.0001
I0109 16:38:49.420930  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.1173 > 20) by scale factor 0.664071
I0109 16:39:21.523954  4932 solver.cpp:240] Iteration 3060, loss = 0.0929944
I0109 16:39:21.524049  4932 solver.cpp:255]     Train net output #0: loss = 0.195129 (* 1 = 0.195129 loss)
I0109 16:39:21.524062  4932 solver.cpp:631] Iteration 3060, lr = 0.0001
I0109 16:39:28.520841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2378 > 20) by scale factor 0.860667
I0109 16:39:58.364985  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2711 > 20) by scale factor 0.940242
I0109 16:40:06.907577  4932 solver.cpp:240] Iteration 3080, loss = 0.0821885
I0109 16:40:06.907624  4932 solver.cpp:255]     Train net output #0: loss = 0.0574454 (* 1 = 0.0574454 loss)
I0109 16:40:06.907637  4932 solver.cpp:631] Iteration 3080, lr = 0.0001
I0109 16:40:22.825904  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1024 > 20) by scale factor 0.947759
I0109 16:40:53.562539  4932 solver.cpp:240] Iteration 3100, loss = 0.0919968
I0109 16:40:53.562635  4932 solver.cpp:255]     Train net output #0: loss = 0.0661452 (* 1 = 0.0661452 loss)
I0109 16:40:53.562649  4932 solver.cpp:631] Iteration 3100, lr = 0.0001
I0109 16:41:00.037876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0415 > 20) by scale factor 0.99793
I0109 16:41:22.240074  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3747 > 20) by scale factor 0.893868
I0109 16:41:33.338230  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7561 > 20) by scale factor 0.695504
I0109 16:41:41.523241  4932 solver.cpp:240] Iteration 3120, loss = 0.0721593
I0109 16:41:41.523289  4932 solver.cpp:255]     Train net output #0: loss = 0.00297433 (* 1 = 0.00297433 loss)
I0109 16:41:41.523303  4932 solver.cpp:631] Iteration 3120, lr = 0.0001
I0109 16:41:59.620409  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5721 > 20) by scale factor 0.72537
I0109 16:42:16.752046  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1029 > 20) by scale factor 0.79672
I0109 16:42:27.512596  4932 solver.cpp:240] Iteration 3140, loss = 0.141831
I0109 16:42:27.512635  4932 solver.cpp:255]     Train net output #0: loss = 0.838488 (* 1 = 0.838488 loss)
I0109 16:42:27.512645  4932 solver.cpp:631] Iteration 3140, lr = 0.0001
I0109 16:42:27.852154  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 39.8245 > 20) by scale factor 0.502203
I0109 16:43:11.719364  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5181 > 20) by scale factor 0.929452
I0109 16:43:13.602092  4932 solver.cpp:240] Iteration 3160, loss = 0.0473964
I0109 16:43:13.602134  4932 solver.cpp:255]     Train net output #0: loss = 0.0043852 (* 1 = 0.0043852 loss)
I0109 16:43:13.602145  4932 solver.cpp:631] Iteration 3160, lr = 0.0001
I0109 16:43:59.635463  4932 solver.cpp:240] Iteration 3180, loss = 0.0915786
I0109 16:43:59.635577  4932 solver.cpp:255]     Train net output #0: loss = 0.0762093 (* 1 = 0.0762093 loss)
I0109 16:43:59.635593  4932 solver.cpp:631] Iteration 3180, lr = 0.0001
I0109 16:44:41.638540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0432 > 20) by scale factor 0.831834
I0109 16:44:45.740241  4932 solver.cpp:240] Iteration 3200, loss = 0.0584916
I0109 16:44:45.740288  4932 solver.cpp:255]     Train net output #0: loss = 0.0100686 (* 1 = 0.0100686 loss)
I0109 16:44:45.740300  4932 solver.cpp:631] Iteration 3200, lr = 0.0001
I0109 16:45:30.845221  4932 solver.cpp:240] Iteration 3220, loss = 0.0576442
I0109 16:45:30.845314  4932 solver.cpp:255]     Train net output #0: loss = 0.307915 (* 1 = 0.307915 loss)
I0109 16:45:30.845327  4932 solver.cpp:631] Iteration 3220, lr = 0.0001
I0109 16:46:11.209689  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5848 > 20) by scale factor 0.926579
I0109 16:46:15.312085  4932 solver.cpp:240] Iteration 3240, loss = 0.0488217
I0109 16:46:15.312126  4932 solver.cpp:255]     Train net output #0: loss = 0.0250809 (* 1 = 0.0250809 loss)
I0109 16:46:15.312135  4932 solver.cpp:631] Iteration 3240, lr = 0.0001
I0109 16:46:33.411360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8804 > 20) by scale factor 0.957834
I0109 16:46:59.714010  4932 solver.cpp:240] Iteration 3260, loss = 0.0577022
I0109 16:46:59.714119  4932 solver.cpp:255]     Train net output #0: loss = 0.120314 (* 1 = 0.120314 loss)
I0109 16:46:59.714135  4932 solver.cpp:631] Iteration 3260, lr = 0.0001
I0109 16:47:13.372990  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2085 > 20) by scale factor 0.94302
I0109 16:47:20.902516  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.648 > 20) by scale factor 0.845738
I0109 16:47:44.983640  4932 solver.cpp:240] Iteration 3280, loss = 0.0987138
I0109 16:47:44.983736  4932 solver.cpp:255]     Train net output #0: loss = 0.0650959 (* 1 = 0.0650959 loss)
I0109 16:47:44.983750  4932 solver.cpp:631] Iteration 3280, lr = 0.0001
I0109 16:48:00.074450  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7735 > 20) by scale factor 0.918548
I0109 16:48:32.419677  4932 solver.cpp:240] Iteration 3300, loss = 0.116086
I0109 16:48:32.419777  4932 solver.cpp:255]     Train net output #0: loss = 0.0488122 (* 1 = 0.0488122 loss)
I0109 16:48:32.419793  4932 solver.cpp:631] Iteration 3300, lr = 0.0001
I0109 16:49:17.860282  4932 solver.cpp:240] Iteration 3320, loss = 0.0970918
I0109 16:49:17.860379  4932 solver.cpp:255]     Train net output #0: loss = 0.34429 (* 1 = 0.34429 loss)
I0109 16:49:17.860391  4932 solver.cpp:631] Iteration 3320, lr = 0.0001
I0109 16:49:18.199622  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9823 > 20) by scale factor 0.870236
I0109 16:49:47.561434  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6396 > 20) by scale factor 0.924233
I0109 16:50:02.764742  4932 solver.cpp:240] Iteration 3340, loss = 0.0791273
I0109 16:50:02.764830  4932 solver.cpp:255]     Train net output #0: loss = 0.240555 (* 1 = 0.240555 loss)
I0109 16:50:02.764843  4932 solver.cpp:631] Iteration 3340, lr = 0.0001
I0109 16:50:03.105123  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9262 > 20) by scale factor 0.835903
I0109 16:50:09.764612  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7605 > 20) by scale factor 0.807738
I0109 16:50:48.835829  4932 solver.cpp:240] Iteration 3360, loss = 0.0805024
I0109 16:50:48.835916  4932 solver.cpp:255]     Train net output #0: loss = 0.0174407 (* 1 = 0.0174407 loss)
I0109 16:50:48.835929  4932 solver.cpp:631] Iteration 3360, lr = 0.0001
I0109 16:51:26.316830  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1339 > 20) by scale factor 0.993347
I0109 16:51:34.860040  4932 solver.cpp:240] Iteration 3380, loss = 0.0437824
I0109 16:51:34.860081  4932 solver.cpp:255]     Train net output #0: loss = 0.208824 (* 1 = 0.208824 loss)
I0109 16:51:34.860090  4932 solver.cpp:631] Iteration 3380, lr = 0.0001
I0109 16:51:46.307082  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9258 > 20) by scale factor 0.835916
I0109 16:52:21.140555  4932 solver.cpp:240] Iteration 3400, loss = 0.0844969
I0109 16:52:21.140655  4932 solver.cpp:255]     Train net output #0: loss = 0.0428723 (* 1 = 0.0428723 loss)
I0109 16:52:21.140668  4932 solver.cpp:631] Iteration 3400, lr = 0.0001
I0109 16:52:54.436349  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.099 > 20) by scale factor 0.947911
I0109 16:52:58.875511  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5124 > 20) by scale factor 0.850617
I0109 16:53:07.425101  4932 solver.cpp:240] Iteration 3420, loss = 0.0952957
I0109 16:53:07.425143  4932 solver.cpp:255]     Train net output #0: loss = 0.0209432 (* 1 = 0.0209432 loss)
I0109 16:53:07.425154  4932 solver.cpp:631] Iteration 3420, lr = 0.0001
I0109 16:53:52.802099  4932 solver.cpp:240] Iteration 3440, loss = 0.0848866
I0109 16:53:52.802193  4932 solver.cpp:255]     Train net output #0: loss = 0.0407866 (* 1 = 0.0407866 loss)
I0109 16:53:52.802204  4932 solver.cpp:631] Iteration 3440, lr = 0.0001
I0109 16:54:08.682538  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.288 > 20) by scale factor 0.823453
I0109 16:54:17.564781  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.08 > 20) by scale factor 0.905796
I0109 16:54:32.585659  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.5658 > 20) by scale factor 0.633598
I0109 16:54:37.026556  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3402 > 20) by scale factor 0.731524
I0109 16:54:38.908514  4932 solver.cpp:240] Iteration 3460, loss = 0.143704
I0109 16:54:38.908551  4932 solver.cpp:255]     Train net output #0: loss = 0.304292 (* 1 = 0.304292 loss)
I0109 16:54:38.908560  4932 solver.cpp:631] Iteration 3460, lr = 0.0001
I0109 16:54:39.247654  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7026 > 20) by scale factor 0.77813
I0109 16:55:16.381402  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3715 > 20) by scale factor 0.981762
I0109 16:55:20.822466  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4032 > 20) by scale factor 0.704145
I0109 16:55:23.043370  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1171 > 20) by scale factor 0.829287
I0109 16:55:24.924787  4932 solver.cpp:240] Iteration 3480, loss = 0.113349
I0109 16:55:24.924827  4932 solver.cpp:255]     Train net output #0: loss = 0.135033 (* 1 = 0.135033 loss)
I0109 16:55:24.924836  4932 solver.cpp:631] Iteration 3480, lr = 0.0001
I0109 16:56:03.581200  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9622 > 20) by scale factor 0.954097
I0109 16:56:09.899935  4932 solver.cpp:240] Iteration 3500, loss = 0.0516843
I0109 16:56:09.899967  4932 solver.cpp:255]     Train net output #0: loss = 0.0421393 (* 1 = 0.0421393 loss)
I0109 16:56:09.899976  4932 solver.cpp:631] Iteration 3500, lr = 0.0001
I0109 16:56:22.924682  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9248 > 20) by scale factor 0.802415
I0109 16:56:36.245323  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8267 > 20) by scale factor 0.876166
I0109 16:56:47.343106  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9318 > 20) by scale factor 0.955486
I0109 16:56:57.449182  4932 solver.cpp:240] Iteration 3520, loss = 0.120385
I0109 16:56:57.449223  4932 solver.cpp:255]     Train net output #0: loss = 0.0768766 (* 1 = 0.0768766 loss)
I0109 16:56:57.449230  4932 solver.cpp:631] Iteration 3520, lr = 0.0001
I0109 16:57:11.108458  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2193 > 20) by scale factor 0.942539
I0109 16:57:43.433416  4932 solver.cpp:240] Iteration 3540, loss = 0.0868533
I0109 16:57:43.433516  4932 solver.cpp:255]     Train net output #0: loss = 0.0791035 (* 1 = 0.0791035 loss)
I0109 16:57:43.433531  4932 solver.cpp:631] Iteration 3540, lr = 0.0001
I0109 16:58:07.940371  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.085 > 20) by scale factor 0.664783
I0109 16:58:19.038452  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4205 > 20) by scale factor 0.933684
I0109 16:58:29.799509  4932 solver.cpp:240] Iteration 3560, loss = 0.123717
I0109 16:58:29.799542  4932 solver.cpp:255]     Train net output #0: loss = 0.209408 (* 1 = 0.209408 loss)
I0109 16:58:29.799551  4932 solver.cpp:631] Iteration 3560, lr = 0.0001
I0109 16:58:30.139061  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.9262 > 20) by scale factor 0.60742
I0109 16:59:16.227062  4932 solver.cpp:240] Iteration 3580, loss = 0.063053
I0109 16:59:16.227160  4932 solver.cpp:255]     Train net output #0: loss = 0.00703673 (* 1 = 0.00703673 loss)
I0109 16:59:16.227174  4932 solver.cpp:631] Iteration 3580, lr = 0.0001
I0109 16:59:40.547178  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0933 > 20) by scale factor 0.797025
I0109 17:00:03.437475  4932 solver.cpp:240] Iteration 3600, loss = 0.0725431
I0109 17:00:03.437572  4932 solver.cpp:255]     Train net output #0: loss = 0.0133441 (* 1 = 0.0133441 loss)
I0109 17:00:03.437587  4932 solver.cpp:631] Iteration 3600, lr = 0.0001
I0109 17:00:32.640648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5013 > 20) by scale factor 0.851017
I0109 17:00:49.783985  4932 solver.cpp:240] Iteration 3620, loss = 0.0749768
I0109 17:00:49.784081  4932 solver.cpp:255]     Train net output #0: loss = 0.00362624 (* 1 = 0.00362624 loss)
I0109 17:00:49.784093  4932 solver.cpp:631] Iteration 3620, lr = 0.0001
I0109 17:00:59.009531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3331 > 20) by scale factor 0.85715
I0109 17:01:31.863499  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0752 > 20) by scale factor 0.687871
I0109 17:01:35.965401  4932 solver.cpp:240] Iteration 3640, loss = 0.0618193
I0109 17:01:35.965440  4932 solver.cpp:255]     Train net output #0: loss = 0.0690248 (* 1 = 0.0690248 loss)
I0109 17:01:35.965450  4932 solver.cpp:631] Iteration 3640, lr = 0.0001
I0109 17:01:52.994258  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7289 > 20) by scale factor 0.777337
I0109 17:01:57.439815  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3139 > 20) by scale factor 0.938353
I0109 17:02:17.418922  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.876 > 20) by scale factor 0.772917
I0109 17:02:21.519778  4932 solver.cpp:240] Iteration 3660, loss = 0.0940828
I0109 17:02:21.519810  4932 solver.cpp:255]     Train net output #0: loss = 0.257096 (* 1 = 0.257096 loss)
I0109 17:02:21.519819  4932 solver.cpp:631] Iteration 3660, lr = 0.0001
I0109 17:02:30.323776  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9629 > 20) by scale factor 0.770329
I0109 17:02:41.421753  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3397 > 20) by scale factor 0.937219
I0109 17:03:04.716265  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6705 > 20) by scale factor 0.967564
I0109 17:03:08.816010  4932 solver.cpp:240] Iteration 3680, loss = 0.0954024
I0109 17:03:08.816051  4932 solver.cpp:255]     Train net output #0: loss = 0.00952762 (* 1 = 0.00952762 loss)
I0109 17:03:08.816058  4932 solver.cpp:631] Iteration 3680, lr = 0.0001
I0109 17:03:20.261031  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9387 > 20) by scale factor 0.835469
I0109 17:03:31.365557  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9274 > 20) by scale factor 0.912099
I0109 17:03:42.721114  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5574 > 20) by scale factor 0.84899
I0109 17:03:53.479630  4932 solver.cpp:240] Iteration 3700, loss = 0.0928788
I0109 17:03:53.479665  4932 solver.cpp:255]     Train net output #0: loss = 0.00898314 (* 1 = 0.00898314 loss)
I0109 17:03:53.479674  4932 solver.cpp:631] Iteration 3700, lr = 0.0001
I0109 17:04:07.141119  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4195 > 20) by scale factor 0.786797
I0109 17:04:21.866216  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9706 > 20) by scale factor 0.910308
I0109 17:04:35.184057  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7541 > 20) by scale factor 0.919366
I0109 17:04:39.285879  4932 solver.cpp:240] Iteration 3720, loss = 0.0934949
I0109 17:04:39.285933  4932 solver.cpp:255]     Train net output #0: loss = 0.0185649 (* 1 = 0.0185649 loss)
I0109 17:04:39.286062  4932 solver.cpp:631] Iteration 3720, lr = 0.0001
I0109 17:04:49.012223  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.7 > 20) by scale factor 0.560224
I0109 17:05:15.732620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4207 > 20) by scale factor 0.892032
I0109 17:05:24.271241  4932 solver.cpp:240] Iteration 3740, loss = 0.0693876
I0109 17:05:24.271275  4932 solver.cpp:255]     Train net output #0: loss = 0.0343537 (* 1 = 0.0343537 loss)
I0109 17:05:24.271282  4932 solver.cpp:631] Iteration 3740, lr = 0.0001
I0109 17:05:41.720094  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4565 > 20) by scale factor 0.932116
I0109 17:05:48.388649  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0463 > 20) by scale factor 0.907183
I0109 17:05:55.049338  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8188 > 20) by scale factor 0.718939
I0109 17:06:12.124686  4932 solver.cpp:240] Iteration 3760, loss = 0.0959683
I0109 17:06:12.124729  4932 solver.cpp:255]     Train net output #0: loss = 0.00608365 (* 1 = 0.00608365 loss)
I0109 17:06:12.124744  4932 solver.cpp:631] Iteration 3760, lr = 0.0001
I0109 17:06:23.568814  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.275 > 20) by scale factor 0.94007
I0109 17:06:25.816730  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7552 > 20) by scale factor 0.91932
I0109 17:06:28.038370  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7853 > 20) by scale factor 0.877758
I0109 17:06:52.521337  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6111 > 20) by scale factor 0.751567
I0109 17:06:56.624770  4932 solver.cpp:240] Iteration 3780, loss = 0.116312
I0109 17:06:56.624866  4932 solver.cpp:255]     Train net output #0: loss = 0.081902 (* 1 = 0.081902 loss)
I0109 17:06:56.624878  4932 solver.cpp:631] Iteration 3780, lr = 0.0001
I0109 17:07:01.402485  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6477 > 20) by scale factor 0.88309
I0109 17:07:23.608418  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8406 > 20) by scale factor 0.838905
I0109 17:07:30.270936  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2164 > 20) by scale factor 0.989297
I0109 17:07:41.521338  4932 solver.cpp:240] Iteration 3800, loss = 0.120844
I0109 17:07:41.521384  4932 solver.cpp:255]     Train net output #0: loss = 0.0375966 (* 1 = 0.0375966 loss)
I0109 17:07:41.521395  4932 solver.cpp:631] Iteration 3800, lr = 0.0001
I0109 17:08:27.937173  4932 solver.cpp:240] Iteration 3820, loss = 0.0493899
I0109 17:08:27.937255  4932 solver.cpp:255]     Train net output #0: loss = 0.0464171 (* 1 = 0.0464171 loss)
I0109 17:08:27.937268  4932 solver.cpp:631] Iteration 3820, lr = 0.0001
I0109 17:08:37.155226  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0723 > 20) by scale factor 0.797693
I0109 17:09:00.296547  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3673 > 20) by scale factor 0.758515
I0109 17:09:13.281240  4932 solver.cpp:240] Iteration 3840, loss = 0.0666908
I0109 17:09:13.281285  4932 solver.cpp:255]     Train net output #0: loss = 0.0166285 (* 1 = 0.0166285 loss)
I0109 17:09:13.281301  4932 solver.cpp:631] Iteration 3840, lr = 0.0001
I0109 17:09:28.495220  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8437 > 20) by scale factor 0.959523
I0109 17:09:46.258617  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3717 > 20) by scale factor 0.981753
I0109 17:09:57.357379  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8311 > 20) by scale factor 0.77426
I0109 17:09:59.241659  4932 solver.cpp:240] Iteration 3860, loss = 0.109409
I0109 17:09:59.241705  4932 solver.cpp:255]     Train net output #0: loss = 0.110782 (* 1 = 0.110782 loss)
I0109 17:09:59.241717  4932 solver.cpp:631] Iteration 3860, lr = 0.0001
I0109 17:10:25.435107  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9687 > 20) by scale factor 0.910384
I0109 17:10:45.550730  4932 solver.cpp:240] Iteration 3880, loss = 0.0800494
I0109 17:10:45.550765  4932 solver.cpp:255]     Train net output #0: loss = 0.00328706 (* 1 = 0.00328706 loss)
I0109 17:10:45.550773  4932 solver.cpp:631] Iteration 3880, lr = 0.0001
I0109 17:11:30.569406  4932 solver.cpp:240] Iteration 3900, loss = 0.106945
I0109 17:11:30.569501  4932 solver.cpp:255]     Train net output #0: loss = 0.0979514 (* 1 = 0.0979514 loss)
I0109 17:11:30.569514  4932 solver.cpp:631] Iteration 3900, lr = 0.0001
I0109 17:11:53.110893  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4122 > 20) by scale factor 0.854256
I0109 17:12:16.045225  4932 solver.cpp:240] Iteration 3920, loss = 0.0839919
I0109 17:12:16.045320  4932 solver.cpp:255]     Train net output #0: loss = 0.286091 (* 1 = 0.286091 loss)
I0109 17:12:16.045331  4932 solver.cpp:631] Iteration 3920, lr = 0.0001
I0109 17:13:01.413194  4932 solver.cpp:240] Iteration 3940, loss = 0.0775384
I0109 17:13:01.413306  4932 solver.cpp:255]     Train net output #0: loss = 0.128127 (* 1 = 0.128127 loss)
I0109 17:13:01.413322  4932 solver.cpp:631] Iteration 3940, lr = 0.0001
I0109 17:13:01.753664  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6991 > 20) by scale factor 0.921697
I0109 17:13:10.632889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7417 > 20) by scale factor 0.919893
I0109 17:13:23.957577  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.309 > 20) by scale factor 0.822739
I0109 17:13:30.620640  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6036 > 20) by scale factor 0.812889
I0109 17:13:35.065311  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2157 > 20) by scale factor 0.989331
I0109 17:13:45.827093  4932 solver.cpp:240] Iteration 3960, loss = 0.117163
I0109 17:13:45.827142  4932 solver.cpp:255]     Train net output #0: loss = 0.0988181 (* 1 = 0.0988181 loss)
I0109 17:13:45.827153  4932 solver.cpp:631] Iteration 3960, lr = 0.0001
I0109 17:14:16.521361  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7643 > 20) by scale factor 0.96319
I0109 17:14:32.521190  4932 solver.cpp:240] Iteration 3980, loss = 0.0932416
I0109 17:14:32.521232  4932 solver.cpp:255]     Train net output #0: loss = 0.243897 (* 1 = 0.243897 loss)
I0109 17:14:32.521241  4932 solver.cpp:631] Iteration 3980, lr = 0.0001
I0109 17:14:32.860785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9523 > 20) by scale factor 0.801528
I0109 17:14:46.269693  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.337 > 20) by scale factor 0.93734
I0109 17:15:04.029639  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5371 > 20) by scale factor 0.700842
I0109 17:15:15.141427  4932 solver.cpp:424] Iteration 4000, Testing net (#0)
I0109 17:16:05.359572  4932 solver.cpp:481]     Test net output #0: accuracy = 0.813684
I0109 17:16:05.359663  4932 solver.cpp:481]     Test net output #1: loss = 0.910579 (* 1 = 0.910579 loss)
I0109 17:16:07.226752  4932 solver.cpp:240] Iteration 4000, loss = 0.080357
I0109 17:16:07.226783  4932 solver.cpp:255]     Train net output #0: loss = 0.00791832 (* 1 = 0.00791832 loss)
I0109 17:16:07.226793  4932 solver.cpp:631] Iteration 4000, lr = 0.0001
I0109 17:16:14.222718  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3776 > 20) by scale factor 0.935559
I0109 17:16:53.002683  4932 solver.cpp:240] Iteration 4020, loss = 0.0708357
I0109 17:16:53.002768  4932 solver.cpp:255]     Train net output #0: loss = 0.0247801 (* 1 = 0.0247801 loss)
I0109 17:16:53.002779  4932 solver.cpp:631] Iteration 4020, lr = 0.0001
I0109 17:17:19.979033  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9844 > 20) by scale factor 0.800501
I0109 17:17:34.495158  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2937 > 20) by scale factor 0.985529
I0109 17:17:38.597121  4932 solver.cpp:240] Iteration 4040, loss = 0.0988411
I0109 17:17:38.597157  4932 solver.cpp:255]     Train net output #0: loss = 0.341552 (* 1 = 0.341552 loss)
I0109 17:17:38.597167  4932 solver.cpp:631] Iteration 4040, lr = 0.0001
I0109 17:17:58.915935  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2221 > 20) by scale factor 0.825692
I0109 17:18:15.910634  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9142 > 20) by scale factor 0.912651
I0109 17:18:24.457248  4932 solver.cpp:240] Iteration 4060, loss = 0.128781
I0109 17:18:24.457294  4932 solver.cpp:255]     Train net output #0: loss = 0.402832 (* 1 = 0.402832 loss)
I0109 17:18:24.457305  4932 solver.cpp:631] Iteration 4060, lr = 0.0001
I0109 17:18:24.797699  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.2652 > 20) by scale factor 0.619862
I0109 17:18:31.628072  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7491 > 20) by scale factor 0.963899
I0109 17:18:33.850991  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2221 > 20) by scale factor 0.762717
I0109 17:18:44.961015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9397 > 20) by scale factor 0.691093
I0109 17:19:11.108882  4932 solver.cpp:240] Iteration 4080, loss = 0.131783
I0109 17:19:11.108999  4932 solver.cpp:255]     Train net output #0: loss = 0.025665 (* 1 = 0.025665 loss)
I0109 17:19:11.109014  4932 solver.cpp:631] Iteration 4080, lr = 0.0001
I0109 17:19:22.547605  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9105 > 20) by scale factor 0.743205
I0109 17:19:38.090468  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4114 > 20) by scale factor 0.892401
I0109 17:19:50.879375  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2827 > 20) by scale factor 0.897559
I0109 17:19:57.199847  4932 solver.cpp:240] Iteration 4100, loss = 0.0972409
I0109 17:19:57.199879  4932 solver.cpp:255]     Train net output #0: loss = 0.0751319 (* 1 = 0.0751319 loss)
I0109 17:19:57.199888  4932 solver.cpp:631] Iteration 4100, lr = 0.0001
I0109 17:20:01.978373  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5881 > 20) by scale factor 0.847885
I0109 17:20:08.647058  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6132 > 20) by scale factor 0.884439
I0109 17:20:42.988126  4932 solver.cpp:240] Iteration 4120, loss = 0.114083
I0109 17:20:42.988214  4932 solver.cpp:255]     Train net output #0: loss = 0.00607676 (* 1 = 0.00607676 loss)
I0109 17:20:42.988226  4932 solver.cpp:631] Iteration 4120, lr = 0.0001
I0109 17:20:58.361110  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7524 > 20) by scale factor 0.808003
I0109 17:21:29.105880  4932 solver.cpp:240] Iteration 4140, loss = 0.0717641
I0109 17:21:29.106003  4932 solver.cpp:255]     Train net output #0: loss = 0.0583544 (* 1 = 0.0583544 loss)
I0109 17:21:29.106020  4932 solver.cpp:631] Iteration 4140, lr = 0.0001
I0109 17:22:13.906806  4932 solver.cpp:240] Iteration 4160, loss = 0.0550206
I0109 17:22:13.906894  4932 solver.cpp:255]     Train net output #0: loss = 0.0524127 (* 1 = 0.0524127 loss)
I0109 17:22:13.906906  4932 solver.cpp:631] Iteration 4160, lr = 0.0001
I0109 17:22:27.184881  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.119 > 20) by scale factor 0.711263
I0109 17:22:51.595489  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3935 > 20) by scale factor 0.730101
I0109 17:23:01.819965  4932 solver.cpp:240] Iteration 4180, loss = 0.0669722
I0109 17:23:01.820003  4932 solver.cpp:255]     Train net output #0: loss = 0.000509226 (* 1 = 0.000509226 loss)
I0109 17:23:01.820019  4932 solver.cpp:631] Iteration 4180, lr = 0.0001
I0109 17:23:17.689561  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8061 > 20) by scale factor 0.917174
I0109 17:23:47.687479  4932 solver.cpp:240] Iteration 4200, loss = 0.102724
I0109 17:23:47.687572  4932 solver.cpp:255]     Train net output #0: loss = 0.0575552 (* 1 = 0.0575552 loss)
I0109 17:23:47.687584  4932 solver.cpp:631] Iteration 4200, lr = 0.0001
I0109 17:23:56.903403  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5662 > 20) by scale factor 0.972471
I0109 17:24:10.379767  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8192 > 20) by scale factor 0.916625
I0109 17:24:25.924449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1694 > 20) by scale factor 0.709991
I0109 17:24:32.251232  4932 solver.cpp:240] Iteration 4220, loss = 0.0847017
I0109 17:24:32.251277  4932 solver.cpp:255]     Train net output #0: loss = 0.0347834 (* 1 = 0.0347834 loss)
I0109 17:24:32.251289  4932 solver.cpp:631] Iteration 4220, lr = 0.0001
I0109 17:25:09.409070  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3818 > 20) by scale factor 0.855365
I0109 17:25:17.948143  4932 solver.cpp:240] Iteration 4240, loss = 0.0723137
I0109 17:25:17.948185  4932 solver.cpp:255]     Train net output #0: loss = 0.133665 (* 1 = 0.133665 loss)
I0109 17:25:17.948197  4932 solver.cpp:631] Iteration 4240, lr = 0.0001
I0109 17:25:37.411885  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9556 > 20) by scale factor 0.954401
I0109 17:25:46.300887  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7908 > 20) by scale factor 0.840662
I0109 17:26:05.124635  4932 solver.cpp:240] Iteration 4260, loss = 0.10833
I0109 17:26:05.124670  4932 solver.cpp:255]     Train net output #0: loss = 0.00662921 (* 1 = 0.00662921 loss)
I0109 17:26:05.124680  4932 solver.cpp:631] Iteration 4260, lr = 0.0001
I0109 17:26:12.120692  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6891 > 20) by scale factor 0.922121
I0109 17:26:40.407922  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5355 > 20) by scale factor 0.973922
I0109 17:26:51.176235  4932 solver.cpp:240] Iteration 4280, loss = 0.0833199
I0109 17:26:51.176287  4932 solver.cpp:255]     Train net output #0: loss = 0.0238637 (* 1 = 0.0238637 loss)
I0109 17:26:51.176424  4932 solver.cpp:631] Iteration 4280, lr = 0.0001
I0109 17:26:58.180519  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4728 > 20) by scale factor 0.678591
I0109 17:27:12.916450  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1619 > 20) by scale factor 0.991968
I0109 17:27:21.796864  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1786 > 20) by scale factor 0.763983
I0109 17:27:37.033690  4932 solver.cpp:240] Iteration 4300, loss = 0.0984465
I0109 17:27:37.033730  4932 solver.cpp:255]     Train net output #0: loss = 0.00227891 (* 1 = 0.00227891 loss)
I0109 17:27:37.033740  4932 solver.cpp:631] Iteration 4300, lr = 0.0001
I0109 17:27:46.437561  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6178 > 20) by scale factor 0.724169
I0109 17:27:53.099947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5816 > 20) by scale factor 0.971741
I0109 17:28:23.247542  4932 solver.cpp:240] Iteration 4320, loss = 0.118519
I0109 17:28:23.247630  4932 solver.cpp:255]     Train net output #0: loss = 0.101625 (* 1 = 0.101625 loss)
I0109 17:28:23.247642  4932 solver.cpp:631] Iteration 4320, lr = 0.0001
I0109 17:29:00.536960  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5355 > 20) by scale factor 0.84978
I0109 17:29:07.198484  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3556 > 20) by scale factor 0.982532
I0109 17:29:09.079658  4932 solver.cpp:240] Iteration 4340, loss = 0.072723
I0109 17:29:09.079695  4932 solver.cpp:255]     Train net output #0: loss = 0.00192472 (* 1 = 0.00192472 loss)
I0109 17:29:09.079704  4932 solver.cpp:631] Iteration 4340, lr = 0.0001
I0109 17:29:16.079510  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0407 > 20) by scale factor 0.997969
I0109 17:29:18.302736  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6645 > 20) by scale factor 0.882437
I0109 17:29:24.963230  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.5146 > 20) by scale factor 0.634626
I0109 17:29:42.163199  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3451 > 20) by scale factor 0.983036
I0109 17:29:55.150374  4932 solver.cpp:240] Iteration 4360, loss = 0.0905801
I0109 17:29:55.150413  4932 solver.cpp:255]     Train net output #0: loss = 0.0794167 (* 1 = 0.0794167 loss)
I0109 17:29:55.150423  4932 solver.cpp:631] Iteration 4360, lr = 0.0001
I0109 17:30:41.186693  4932 solver.cpp:240] Iteration 4380, loss = 0.0649958
I0109 17:30:41.186769  4932 solver.cpp:255]     Train net output #0: loss = 0.0538613 (* 1 = 0.0538613 loss)
I0109 17:30:41.186779  4932 solver.cpp:631] Iteration 4380, lr = 0.0001
I0109 17:30:45.327457  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2492 > 20) by scale factor 0.987694
I0109 17:30:49.772351  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2236 > 20) by scale factor 0.762671
I0109 17:31:28.622342  4932 solver.cpp:240] Iteration 4400, loss = 0.0851452
I0109 17:31:28.622454  4932 solver.cpp:255]     Train net output #0: loss = 0.0261057 (* 1 = 0.0261057 loss)
I0109 17:31:28.622467  4932 solver.cpp:631] Iteration 4400, lr = 0.0001
I0109 17:32:14.161558  4932 solver.cpp:240] Iteration 4420, loss = 0.0546316
I0109 17:32:14.161643  4932 solver.cpp:255]     Train net output #0: loss = 0.0163667 (* 1 = 0.0163667 loss)
I0109 17:32:14.161653  4932 solver.cpp:631] Iteration 4420, lr = 0.0001
I0109 17:32:30.045003  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4446 > 20) by scale factor 0.679241
I0109 17:32:59.735152  4932 solver.cpp:240] Iteration 4440, loss = 0.0586852
I0109 17:32:59.735247  4932 solver.cpp:255]     Train net output #0: loss = 0.0142342 (* 1 = 0.0142342 loss)
I0109 17:32:59.735260  4932 solver.cpp:631] Iteration 4440, lr = 0.0001
I0109 17:33:08.953887  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.334 > 20) by scale factor 0.681803
I0109 17:33:24.135535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5706 > 20) by scale factor 0.97226
I0109 17:33:45.998849  4932 solver.cpp:240] Iteration 4460, loss = 0.0953723
I0109 17:33:45.998945  4932 solver.cpp:255]     Train net output #0: loss = 0.20952 (* 1 = 0.20952 loss)
I0109 17:33:45.998957  4932 solver.cpp:631] Iteration 4460, lr = 0.0001
I0109 17:34:28.289175  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7225 > 20) by scale factor 0.920706
I0109 17:34:32.390688  4932 solver.cpp:240] Iteration 4480, loss = 0.0575937
I0109 17:34:32.390727  4932 solver.cpp:255]     Train net output #0: loss = 0.0282278 (* 1 = 0.0282278 loss)
I0109 17:34:32.390736  4932 solver.cpp:631] Iteration 4480, lr = 0.0001
I0109 17:34:57.142536  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0242 > 20) by scale factor 0.99879
I0109 17:35:18.337323  4932 solver.cpp:240] Iteration 4500, loss = 0.123064
I0109 17:35:18.337414  4932 solver.cpp:255]     Train net output #0: loss = 0.247489 (* 1 = 0.247489 loss)
I0109 17:35:18.337427  4932 solver.cpp:631] Iteration 4500, lr = 0.0001
I0109 17:36:03.778825  4932 solver.cpp:240] Iteration 4520, loss = 0.0647921
I0109 17:36:03.778937  4932 solver.cpp:255]     Train net output #0: loss = 0.102295 (* 1 = 0.102295 loss)
I0109 17:36:03.778952  4932 solver.cpp:631] Iteration 4520, lr = 0.0001
I0109 17:36:23.677857  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0379 > 20) by scale factor 0.832021
I0109 17:36:49.985009  4932 solver.cpp:240] Iteration 4540, loss = 0.127688
I0109 17:36:49.985102  4932 solver.cpp:255]     Train net output #0: loss = 0.0119931 (* 1 = 0.0119931 loss)
I0109 17:36:49.985115  4932 solver.cpp:631] Iteration 4540, lr = 0.0001
I0109 17:37:11.770933  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2071 > 20) by scale factor 0.900612
I0109 17:37:36.651316  4932 solver.cpp:240] Iteration 4560, loss = 0.0674297
I0109 17:37:36.651407  4932 solver.cpp:255]     Train net output #0: loss = 0.0194432 (* 1 = 0.0194432 loss)
I0109 17:37:36.651419  4932 solver.cpp:631] Iteration 4560, lr = 0.0001
I0109 17:37:45.872241  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3057 > 20) by scale factor 0.984944
I0109 17:37:50.319165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.096 > 20) by scale factor 0.995221
I0109 17:38:22.779297  4932 solver.cpp:240] Iteration 4580, loss = 0.0727558
I0109 17:38:22.779386  4932 solver.cpp:255]     Train net output #0: loss = 0.00939457 (* 1 = 0.00939457 loss)
I0109 17:38:22.779397  4932 solver.cpp:631] Iteration 4580, lr = 0.0001
I0109 17:38:36.435984  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6107 > 20) by scale factor 0.699039
I0109 17:38:46.835894  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6253 > 20) by scale factor 0.969681
I0109 17:38:51.280382  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4856 > 20) by scale factor 0.678297
I0109 17:39:04.601577  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5708 > 20) by scale factor 0.972251
I0109 17:39:08.702297  4932 solver.cpp:240] Iteration 4600, loss = 0.111799
I0109 17:39:08.702333  4932 solver.cpp:255]     Train net output #0: loss = 0.0317468 (* 1 = 0.0317468 loss)
I0109 17:39:08.702342  4932 solver.cpp:631] Iteration 4600, lr = 0.0001
I0109 17:39:37.925078  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1554 > 20) by scale factor 0.945386
I0109 17:39:54.249120  4932 solver.cpp:240] Iteration 4620, loss = 0.0852505
I0109 17:39:54.249157  4932 solver.cpp:255]     Train net output #0: loss = 0.0608579 (* 1 = 0.0608579 loss)
I0109 17:39:54.249166  4932 solver.cpp:631] Iteration 4620, lr = 0.0001
I0109 17:40:39.570893  4932 solver.cpp:240] Iteration 4640, loss = 0.076999
I0109 17:40:39.570987  4932 solver.cpp:255]     Train net output #0: loss = 0.0404526 (* 1 = 0.0404526 loss)
I0109 17:40:39.571000  4932 solver.cpp:631] Iteration 4640, lr = 0.0001
I0109 17:40:44.347790  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0839 > 20) by scale factor 0.866403
I0109 17:40:55.455642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4625 > 20) by scale factor 0.755788
I0109 17:40:57.676959  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5797 > 20) by scale factor 0.926795
I0109 17:41:18.513669  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6203 > 20) by scale factor 0.780631
I0109 17:41:22.955397  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4819 > 20) by scale factor 0.931018
I0109 17:41:24.837785  4932 solver.cpp:240] Iteration 4660, loss = 0.115143
I0109 17:41:24.837817  4932 solver.cpp:255]     Train net output #0: loss = 0.0204055 (* 1 = 0.0204055 loss)
I0109 17:41:24.837827  4932 solver.cpp:631] Iteration 4660, lr = 0.0001
I0109 17:41:36.280439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9092 > 20) by scale factor 0.771928
I0109 17:41:55.162925  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.688 > 20) by scale factor 0.697156
I0109 17:41:57.384802  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3394 > 20) by scale factor 0.821712
I0109 17:42:04.052461  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7937 > 20) by scale factor 0.877435
I0109 17:42:10.374104  4932 solver.cpp:240] Iteration 4680, loss = 0.108533
I0109 17:42:10.374141  4932 solver.cpp:255]     Train net output #0: loss = 0.0479939 (* 1 = 0.0479939 loss)
I0109 17:42:10.374151  4932 solver.cpp:631] Iteration 4680, lr = 0.0001
I0109 17:42:32.237131  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3081 > 20) by scale factor 0.732382
I0109 17:42:36.683867  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5278 > 20) by scale factor 0.887793
I0109 17:42:56.318655  4932 solver.cpp:240] Iteration 4700, loss = 0.094149
I0109 17:42:56.318691  4932 solver.cpp:255]     Train net output #0: loss = 0.0987663 (* 1 = 0.0987663 loss)
I0109 17:42:56.318699  4932 solver.cpp:631] Iteration 4700, lr = 0.0001
I0109 17:43:43.994253  4932 solver.cpp:240] Iteration 4720, loss = 0.0843569
I0109 17:43:43.994351  4932 solver.cpp:255]     Train net output #0: loss = 0.0601008 (* 1 = 0.0601008 loss)
I0109 17:43:43.994364  4932 solver.cpp:631] Iteration 4720, lr = 0.0001
I0109 17:43:48.773183  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1319 > 20) by scale factor 0.946435
I0109 17:43:55.440805  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8251 > 20) by scale factor 0.839452
I0109 17:44:18.989821  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2473 > 20) by scale factor 0.987785
I0109 17:44:29.753273  4932 solver.cpp:240] Iteration 4740, loss = 0.143672
I0109 17:44:29.753321  4932 solver.cpp:255]     Train net output #0: loss = 0.0592139 (* 1 = 0.0592139 loss)
I0109 17:44:29.753455  4932 solver.cpp:631] Iteration 4740, lr = 0.0001
I0109 17:45:01.997939  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7025 > 20) by scale factor 0.966065
I0109 17:45:14.985519  4932 solver.cpp:240] Iteration 4760, loss = 0.0754448
I0109 17:45:14.985565  4932 solver.cpp:255]     Train net output #0: loss = 0.0712237 (* 1 = 0.0712237 loss)
I0109 17:45:14.985576  4932 solver.cpp:631] Iteration 4760, lr = 0.0001
I0109 17:45:59.911340  4932 solver.cpp:240] Iteration 4780, loss = 0.0476585
I0109 17:45:59.911458  4932 solver.cpp:255]     Train net output #0: loss = 0.00568531 (* 1 = 0.00568531 loss)
I0109 17:45:59.911476  4932 solver.cpp:631] Iteration 4780, lr = 0.0001
I0109 17:46:20.236606  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4136 > 20) by scale factor 0.933986
I0109 17:46:30.265409  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8831 > 20) by scale factor 0.913948
I0109 17:46:45.465883  4932 solver.cpp:240] Iteration 4800, loss = 0.074441
I0109 17:46:45.465934  4932 solver.cpp:255]     Train net output #0: loss = 0.0227194 (* 1 = 0.0227194 loss)
I0109 17:46:45.465946  4932 solver.cpp:631] Iteration 4800, lr = 0.0001
I0109 17:47:29.914347  4932 solver.cpp:240] Iteration 4820, loss = 0.0939014
I0109 17:47:29.914443  4932 solver.cpp:255]     Train net output #0: loss = 0.182519 (* 1 = 0.182519 loss)
I0109 17:47:29.914455  4932 solver.cpp:631] Iteration 4820, lr = 0.0001
I0109 17:47:30.253612  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2616 > 20) by scale factor 0.898409
I0109 17:47:50.237242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5385 > 20) by scale factor 0.887371
I0109 17:48:12.826642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6695 > 20) by scale factor 0.922958
I0109 17:48:14.708236  4932 solver.cpp:240] Iteration 4840, loss = 0.0738521
I0109 17:48:14.708279  4932 solver.cpp:255]     Train net output #0: loss = 0.0945114 (* 1 = 0.0945114 loss)
I0109 17:48:14.708290  4932 solver.cpp:631] Iteration 4840, lr = 0.0001
I0109 17:48:26.198284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1958 > 20) by scale factor 0.862225
I0109 17:48:59.156278  4932 solver.cpp:240] Iteration 4860, loss = 0.131998
I0109 17:48:59.156368  4932 solver.cpp:255]     Train net output #0: loss = 0.0197108 (* 1 = 0.0197108 loss)
I0109 17:48:59.156383  4932 solver.cpp:631] Iteration 4860, lr = 0.0001
I0109 17:49:32.095157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4077 > 20) by scale factor 0.98002
I0109 17:49:39.932741  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9874 > 20) by scale factor 0.909614
I0109 17:49:46.252231  4932 solver.cpp:240] Iteration 4880, loss = 0.0636332
I0109 17:49:46.252269  4932 solver.cpp:255]     Train net output #0: loss = 0.0729974 (* 1 = 0.0729974 loss)
I0109 17:49:46.252279  4932 solver.cpp:631] Iteration 4880, lr = 0.0001
I0109 17:50:28.334403  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7829 > 20) by scale factor 0.719867
I0109 17:50:32.435165  4932 solver.cpp:240] Iteration 4900, loss = 0.0456632
I0109 17:50:32.435214  4932 solver.cpp:255]     Train net output #0: loss = 0.0263273 (* 1 = 0.0263273 loss)
I0109 17:50:32.435226  4932 solver.cpp:631] Iteration 4900, lr = 0.0001
I0109 17:51:17.996568  4932 solver.cpp:240] Iteration 4920, loss = 0.0812608
I0109 17:51:17.996650  4932 solver.cpp:255]     Train net output #0: loss = 0.437793 (* 1 = 0.437793 loss)
I0109 17:51:17.996660  4932 solver.cpp:631] Iteration 4920, lr = 0.0001
I0109 17:51:18.336344  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4652 > 20) by scale factor 0.656487
I0109 17:51:46.489424  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6438 > 20) by scale factor 0.924051
I0109 17:51:55.371945  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6998 > 20) by scale factor 0.966195
I0109 17:52:05.089831  4932 solver.cpp:240] Iteration 4940, loss = 0.10945
I0109 17:52:05.089866  4932 solver.cpp:255]     Train net output #0: loss = 0.120364 (* 1 = 0.120364 loss)
I0109 17:52:05.089874  4932 solver.cpp:631] Iteration 4940, lr = 0.0001
I0109 17:52:14.311527  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4042 > 20) by scale factor 0.980189
I0109 17:52:29.850563  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2014 > 20) by scale factor 0.943335
I0109 17:52:50.004806  4932 solver.cpp:240] Iteration 4960, loss = 0.105774
I0109 17:52:50.004842  4932 solver.cpp:255]     Train net output #0: loss = 0.00208778 (* 1 = 0.00208778 loss)
I0109 17:52:50.004853  4932 solver.cpp:631] Iteration 4960, lr = 0.0001
I0109 17:53:03.670696  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4095 > 20) by scale factor 0.979937
I0109 17:53:11.545038  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.353 > 20) by scale factor 0.788861
I0109 17:53:18.205646  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.5548 > 20) by scale factor 0.562512
I0109 17:53:33.752665  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.832 > 20) by scale factor 0.916085
I0109 17:53:35.635742  4932 solver.cpp:240] Iteration 4980, loss = 0.105832
I0109 17:53:35.635782  4932 solver.cpp:255]     Train net output #0: loss = 0.0107992 (* 1 = 0.0107992 loss)
I0109 17:53:35.635790  4932 solver.cpp:631] Iteration 4980, lr = 0.0001
I0109 17:53:42.630884  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8996 > 20) by scale factor 0.956955
I0109 17:54:01.540989  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0726 > 20) by scale factor 0.996386
I0109 17:54:19.365366  4932 solver.cpp:424] Iteration 5000, Testing net (#0)
I0109 17:55:09.019567  4932 solver.cpp:481]     Test net output #0: accuracy = 0.807368
I0109 17:55:09.019659  4932 solver.cpp:481]     Test net output #1: loss = 0.97987 (* 1 = 0.97987 loss)
I0109 17:55:10.886700  4932 solver.cpp:240] Iteration 5000, loss = 0.0869422
I0109 17:55:10.886740  4932 solver.cpp:255]     Train net output #0: loss = 0.0184649 (* 1 = 0.0184649 loss)
I0109 17:55:10.886750  4932 solver.cpp:631] Iteration 5000, lr = 0.0001
I0109 17:55:15.664366  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.15 > 20) by scale factor 0.945628
I0109 17:55:55.501619  4932 solver.cpp:240] Iteration 5020, loss = 0.0754547
I0109 17:55:55.501710  4932 solver.cpp:255]     Train net output #0: loss = 0.00810724 (* 1 = 0.00810724 loss)
I0109 17:55:55.501724  4932 solver.cpp:631] Iteration 5020, lr = 0.0001
I0109 17:56:22.639600  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5351 > 20) by scale factor 0.815158
I0109 17:56:38.185405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6166 > 20) by scale factor 0.780745
I0109 17:56:40.068400  4932 solver.cpp:240] Iteration 5040, loss = 0.100379
I0109 17:56:40.068449  4932 solver.cpp:255]     Train net output #0: loss = 0.0667557 (* 1 = 0.0667557 loss)
I0109 17:56:40.068460  4932 solver.cpp:631] Iteration 5040, lr = 0.0001
I0109 17:57:24.269315  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.179 > 20) by scale factor 0.99113
I0109 17:57:26.151056  4932 solver.cpp:240] Iteration 5060, loss = 0.0519633
I0109 17:57:26.151095  4932 solver.cpp:255]     Train net output #0: loss = 0.129254 (* 1 = 0.129254 loss)
I0109 17:57:26.151104  4932 solver.cpp:631] Iteration 5060, lr = 0.0001
I0109 17:57:26.490463  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3766 > 20) by scale factor 0.981516
I0109 17:57:53.439364  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.498 > 20) by scale factor 0.851137
I0109 17:58:10.867039  4932 solver.cpp:240] Iteration 5080, loss = 0.0818605
I0109 17:58:10.867149  4932 solver.cpp:255]     Train net output #0: loss = 0.0599541 (* 1 = 0.0599541 loss)
I0109 17:58:10.867162  4932 solver.cpp:631] Iteration 5080, lr = 0.0001
I0109 17:58:13.426650  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8827 > 20) by scale factor 0.957731
I0109 17:58:22.307796  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0284 > 20) by scale factor 0.998583
I0109 17:58:24.532186  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7151 > 20) by scale factor 0.74864
I0109 17:58:31.197191  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8869 > 20) by scale factor 0.913788
I0109 17:58:36.345605  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1591 > 20) by scale factor 0.827845
I0109 17:58:55.986938  4932 solver.cpp:240] Iteration 5100, loss = 0.152394
I0109 17:58:55.987036  4932 solver.cpp:255]     Train net output #0: loss = 0.0497693 (* 1 = 0.0497693 loss)
I0109 17:58:55.987051  4932 solver.cpp:631] Iteration 5100, lr = 0.0001
I0109 17:59:05.206979  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8064 > 20) by scale factor 0.806243
I0109 17:59:31.104970  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.226 > 20) by scale factor 0.988829
I0109 17:59:41.866611  4932 solver.cpp:240] Iteration 5120, loss = 0.0873918
I0109 17:59:41.866649  4932 solver.cpp:255]     Train net output #0: loss = 0.066802 (* 1 = 0.066802 loss)
I0109 17:59:41.866658  4932 solver.cpp:631] Iteration 5120, lr = 0.0001
I0109 18:00:28.672562  4932 solver.cpp:240] Iteration 5140, loss = 0.0834617
I0109 18:00:28.672657  4932 solver.cpp:255]     Train net output #0: loss = 0.114722 (* 1 = 0.114722 loss)
I0109 18:00:28.672669  4932 solver.cpp:631] Iteration 5140, lr = 0.0001
I0109 18:01:03.961374  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.123 > 20) by scale factor 0.796084
I0109 18:01:06.182862  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4933 > 20) by scale factor 0.655882
I0109 18:01:14.723683  4932 solver.cpp:240] Iteration 5160, loss = 0.0977705
I0109 18:01:14.723723  4932 solver.cpp:255]     Train net output #0: loss = 0.191184 (* 1 = 0.191184 loss)
I0109 18:01:14.723732  4932 solver.cpp:631] Iteration 5160, lr = 0.0001
I0109 18:02:00.540144  4932 solver.cpp:240] Iteration 5180, loss = 0.0597864
I0109 18:02:00.540240  4932 solver.cpp:255]     Train net output #0: loss = 0.0163404 (* 1 = 0.0163404 loss)
I0109 18:02:00.540251  4932 solver.cpp:631] Iteration 5180, lr = 0.0001
I0109 18:02:30.982442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7905 > 20) by scale factor 0.77548
I0109 18:02:46.179980  4932 solver.cpp:240] Iteration 5200, loss = 0.0610674
I0109 18:02:46.180030  4932 solver.cpp:255]     Train net output #0: loss = 0.111022 (* 1 = 0.111022 loss)
I0109 18:02:46.180043  4932 solver.cpp:631] Iteration 5200, lr = 0.0001
I0109 18:03:01.475281  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1028 > 20) by scale factor 0.796725
I0109 18:03:23.682447  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6101 > 20) by scale factor 0.812675
I0109 18:03:33.625121  4932 solver.cpp:240] Iteration 5220, loss = 0.066156
I0109 18:03:33.625208  4932 solver.cpp:255]     Train net output #0: loss = 0.0295196 (* 1 = 0.0295196 loss)
I0109 18:03:33.625219  4932 solver.cpp:631] Iteration 5220, lr = 0.0001
I0109 18:04:18.979223  4932 solver.cpp:240] Iteration 5240, loss = 0.0485102
I0109 18:04:18.979311  4932 solver.cpp:255]     Train net output #0: loss = 0.0100157 (* 1 = 0.0100157 loss)
I0109 18:04:18.979323  4932 solver.cpp:631] Iteration 5240, lr = 0.0001
I0109 18:04:28.198768  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5172 > 20) by scale factor 0.888209
I0109 18:04:34.858145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9117 > 20) by scale factor 0.836411
I0109 18:04:41.525796  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7568 > 20) by scale factor 0.919254
I0109 18:05:04.698690  4932 solver.cpp:240] Iteration 5260, loss = 0.0704756
I0109 18:05:04.698791  4932 solver.cpp:255]     Train net output #0: loss = 0.00187947 (* 1 = 0.00187947 loss)
I0109 18:05:04.698802  4932 solver.cpp:631] Iteration 5260, lr = 0.0001
I0109 18:05:32.889142  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0503 > 20) by scale factor 0.83159
I0109 18:05:50.313582  4932 solver.cpp:240] Iteration 5280, loss = 0.082842
I0109 18:05:50.313678  4932 solver.cpp:255]     Train net output #0: loss = 0.150546 (* 1 = 0.150546 loss)
I0109 18:05:50.313690  4932 solver.cpp:631] Iteration 5280, lr = 0.0001
I0109 18:06:01.749197  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1316 > 20) by scale factor 0.737147
I0109 18:06:26.181586  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6505 > 20) by scale factor 0.845647
I0109 18:06:36.306715  4932 solver.cpp:240] Iteration 5300, loss = 0.0770377
I0109 18:06:36.306767  4932 solver.cpp:255]     Train net output #0: loss = 0.0827497 (* 1 = 0.0827497 loss)
I0109 18:06:36.306955  4932 solver.cpp:631] Iteration 5300, lr = 0.0001
I0109 18:06:49.966015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0337 > 20) by scale factor 0.768236
I0109 18:06:54.409260  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3379 > 20) by scale factor 0.983386
I0109 18:07:14.573809  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.7854 > 20) by scale factor 0.574954
I0109 18:07:20.894156  4932 solver.cpp:240] Iteration 5320, loss = 0.0858219
I0109 18:07:20.894194  4932 solver.cpp:255]     Train net output #0: loss = 0.0227106 (* 1 = 0.0227106 loss)
I0109 18:07:20.894203  4932 solver.cpp:631] Iteration 5320, lr = 0.0001
I0109 18:07:32.339244  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3222 > 20) by scale factor 0.895967
I0109 18:07:48.660476  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0652 > 20) by scale factor 0.949432
I0109 18:08:01.983187  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0926 > 20) by scale factor 0.83013
I0109 18:08:06.085700  4932 solver.cpp:240] Iteration 5340, loss = 0.102745
I0109 18:08:06.085736  4932 solver.cpp:255]     Train net output #0: loss = 0.0567527 (* 1 = 0.0567527 loss)
I0109 18:08:06.085747  4932 solver.cpp:631] Iteration 5340, lr = 0.0001
I0109 18:08:10.863149  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9754 > 20) by scale factor 0.800789
I0109 18:08:13.084745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.458 > 20) by scale factor 0.728385
I0109 18:08:20.845089  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2589 > 20) by scale factor 0.82444
I0109 18:08:51.933238  4932 solver.cpp:240] Iteration 5360, loss = 0.0820912
I0109 18:08:51.933332  4932 solver.cpp:255]     Train net output #0: loss = 0.00573169 (* 1 = 0.00573169 loss)
I0109 18:08:51.933346  4932 solver.cpp:631] Iteration 5360, lr = 0.0001
I0109 18:09:07.804504  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9641 > 20) by scale factor 0.910577
I0109 18:09:32.967164  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2756 > 20) by scale factor 0.859268
I0109 18:09:37.071236  4932 solver.cpp:240] Iteration 5380, loss = 0.0842748
I0109 18:09:37.071282  4932 solver.cpp:255]     Train net output #0: loss = 0.00761133 (* 1 = 0.00761133 loss)
I0109 18:09:37.071293  4932 solver.cpp:631] Iteration 5380, lr = 0.0001
I0109 18:09:41.849823  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3683 > 20) by scale factor 0.637587
I0109 18:09:46.291004  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7194 > 20) by scale factor 0.96528
I0109 18:09:52.961323  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3461 > 20) by scale factor 0.789077
I0109 18:09:58.775102  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9037 > 20) by scale factor 0.956768
I0109 18:10:05.437314  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1122 > 20) by scale factor 0.865344
I0109 18:10:12.095089  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5211 > 20) by scale factor 0.815624
I0109 18:10:14.316498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5497 > 20) by scale factor 0.973252
I0109 18:10:22.871048  4932 solver.cpp:240] Iteration 5400, loss = 0.0939782
I0109 18:10:22.871085  4932 solver.cpp:255]     Train net output #0: loss = 0.155466 (* 1 = 0.155466 loss)
I0109 18:10:22.904299  4932 solver.cpp:631] Iteration 5400, lr = 0.0001
I0109 18:10:41.311221  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7286 > 20) by scale factor 0.748262
I0109 18:11:07.619315  4932 solver.cpp:240] Iteration 5420, loss = 0.0805312
I0109 18:11:07.619355  4932 solver.cpp:255]     Train net output #0: loss = 0.145734 (* 1 = 0.145734 loss)
I0109 18:11:07.619535  4932 solver.cpp:631] Iteration 5420, lr = 0.0001
I0109 18:11:23.765715  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9216 > 20) by scale factor 0.912342
I0109 18:11:39.309978  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1079 > 20) by scale factor 0.994635
I0109 18:11:52.291847  4932 solver.cpp:240] Iteration 5440, loss = 0.0864781
I0109 18:11:52.291896  4932 solver.cpp:255]     Train net output #0: loss = 0.0131676 (* 1 = 0.0131676 loss)
I0109 18:11:52.291915  4932 solver.cpp:631] Iteration 5440, lr = 0.0001
I0109 18:12:37.240149  4932 solver.cpp:240] Iteration 5460, loss = 0.0550447
I0109 18:12:37.240247  4932 solver.cpp:255]     Train net output #0: loss = 0.0559271 (* 1 = 0.0559271 loss)
I0109 18:12:37.240259  4932 solver.cpp:631] Iteration 5460, lr = 0.0001
I0109 18:12:48.688117  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1122 > 20) by scale factor 0.829455
I0109 18:12:50.909932  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0793 > 20) by scale factor 0.996053
I0109 18:13:14.907444  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8843 > 20) by scale factor 0.772669
I0109 18:13:23.447860  4932 solver.cpp:240] Iteration 5480, loss = 0.0865534
I0109 18:13:23.447901  4932 solver.cpp:255]     Train net output #0: loss = 0.178 (* 1 = 0.178 loss)
I0109 18:13:23.447911  4932 solver.cpp:631] Iteration 5480, lr = 0.0001
I0109 18:13:36.016155  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2261 > 20) by scale factor 0.942236
I0109 18:13:51.552808  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4215 > 20) by scale factor 0.853916
I0109 18:13:58.268604  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6815 > 20) by scale factor 0.844541
I0109 18:14:09.047298  4932 solver.cpp:240] Iteration 5500, loss = 0.0930496
I0109 18:14:09.047345  4932 solver.cpp:255]     Train net output #0: loss = 0.319152 (* 1 = 0.319152 loss)
I0109 18:14:09.047356  4932 solver.cpp:631] Iteration 5500, lr = 0.0001
I0109 18:14:34.110661  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5937 > 20) by scale factor 0.724804
I0109 18:14:53.764394  4932 solver.cpp:240] Iteration 5520, loss = 0.0754972
I0109 18:14:53.764432  4932 solver.cpp:255]     Train net output #0: loss = 0.247411 (* 1 = 0.247411 loss)
I0109 18:14:53.764443  4932 solver.cpp:631] Iteration 5520, lr = 0.0001
I0109 18:15:07.860846  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2848 > 20) by scale factor 0.985958
I0109 18:15:36.722695  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2336 > 20) by scale factor 0.941905
I0109 18:15:38.604070  4932 solver.cpp:240] Iteration 5540, loss = 0.106842
I0109 18:15:38.604171  4932 solver.cpp:255]     Train net output #0: loss = 0.162075 (* 1 = 0.162075 loss)
I0109 18:15:38.604185  4932 solver.cpp:631] Iteration 5540, lr = 0.0001
I0109 18:16:16.075170  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6529 > 20) by scale factor 0.882888
I0109 18:16:24.612397  4932 solver.cpp:240] Iteration 5560, loss = 0.055586
I0109 18:16:24.612437  4932 solver.cpp:255]     Train net output #0: loss = 0.0798515 (* 1 = 0.0798515 loss)
I0109 18:16:24.612447  4932 solver.cpp:631] Iteration 5560, lr = 0.0001
I0109 18:16:27.171964  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.7234 > 20) by scale factor 0.63045
I0109 18:16:33.836916  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3117 > 20) by scale factor 0.984653
I0109 18:16:38.276492  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4481 > 20) by scale factor 0.852948
I0109 18:16:40.498463  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3302 > 20) by scale factor 0.937638
I0109 18:17:09.307627  4932 solver.cpp:240] Iteration 5580, loss = 0.0956196
I0109 18:17:09.307725  4932 solver.cpp:255]     Train net output #0: loss = 0.0129191 (* 1 = 0.0129191 loss)
I0109 18:17:09.307737  4932 solver.cpp:631] Iteration 5580, lr = 0.0001
I0109 18:17:14.087455  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7683 > 20) by scale factor 0.878416
I0109 18:17:24.021798  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9679 > 20) by scale factor 0.910421
I0109 18:17:26.245054  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8497 > 20) by scale factor 0.875286
I0109 18:17:46.221846  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.0162 > 20) by scale factor 0.587956
I0109 18:17:54.761091  4932 solver.cpp:240] Iteration 5600, loss = 0.127129
I0109 18:17:54.761138  4932 solver.cpp:255]     Train net output #0: loss = 0.315953 (* 1 = 0.315953 loss)
I0109 18:17:54.761152  4932 solver.cpp:631] Iteration 5600, lr = 0.0001
I0109 18:17:55.102325  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7672 > 20) by scale factor 0.878456
I0109 18:18:06.206769  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6183 > 20) by scale factor 0.88424
I0109 18:18:21.752610  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.121 > 20) by scale factor 0.946925
I0109 18:18:29.258695  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1887 > 20) by scale factor 0.763689
I0109 18:18:33.699156  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9971 > 20) by scale factor 0.666731
I0109 18:18:40.022631  4932 solver.cpp:240] Iteration 5620, loss = 0.11153
I0109 18:18:40.022670  4932 solver.cpp:255]     Train net output #0: loss = 0.0681349 (* 1 = 0.0681349 loss)
I0109 18:18:40.022680  4932 solver.cpp:631] Iteration 5620, lr = 0.0001
I0109 18:19:14.489198  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4607 > 20) by scale factor 0.977483
I0109 18:19:23.377786  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1759 > 20) by scale factor 0.94447
I0109 18:19:25.260385  4932 solver.cpp:240] Iteration 5640, loss = 0.12153
I0109 18:19:25.260421  4932 solver.cpp:255]     Train net output #0: loss = 0.0197913 (* 1 = 0.0197913 loss)
I0109 18:19:25.260431  4932 solver.cpp:631] Iteration 5640, lr = 0.0001
I0109 18:20:10.964602  4932 solver.cpp:240] Iteration 5660, loss = 0.0536315
I0109 18:20:10.964707  4932 solver.cpp:255]     Train net output #0: loss = 0.101572 (* 1 = 0.101572 loss)
I0109 18:20:10.964722  4932 solver.cpp:631] Iteration 5660, lr = 0.0001
I0109 18:20:32.442143  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1232 > 20) by scale factor 0.993878
I0109 18:20:50.206455  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3255 > 20) by scale factor 0.857431
I0109 18:20:54.648200  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.022 > 20) by scale factor 0.951384
I0109 18:20:56.531424  4932 solver.cpp:240] Iteration 5680, loss = 0.104532
I0109 18:20:56.531466  4932 solver.cpp:255]     Train net output #0: loss = 0.00231046 (* 1 = 0.00231046 loss)
I0109 18:20:56.531477  4932 solver.cpp:631] Iteration 5680, lr = 0.0001
I0109 18:21:01.308537  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.195 > 20) by scale factor 0.826618
I0109 18:21:41.068032  4932 solver.cpp:240] Iteration 5700, loss = 0.130653
I0109 18:21:41.068125  4932 solver.cpp:255]     Train net output #0: loss = 0.0153706 (* 1 = 0.0153706 loss)
I0109 18:21:41.068140  4932 solver.cpp:631] Iteration 5700, lr = 0.0001
I0109 18:22:03.628259  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0569 > 20) by scale factor 0.906745
I0109 18:22:14.729415  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9231 > 20) by scale factor 0.955881
I0109 18:22:25.488937  4932 solver.cpp:240] Iteration 5720, loss = 0.0873768
I0109 18:22:25.488979  4932 solver.cpp:255]     Train net output #0: loss = 0.0498239 (* 1 = 0.0498239 loss)
I0109 18:22:25.488991  4932 solver.cpp:631] Iteration 5720, lr = 0.0001
I0109 18:22:30.276280  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8689 > 20) by scale factor 0.837912
I0109 18:22:39.156035  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5595 > 20) by scale factor 0.972788
I0109 18:22:51.357064  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3166 > 20) by scale factor 0.938236
I0109 18:22:55.797164  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0201 > 20) by scale factor 0.666221
I0109 18:23:09.115715  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3347 > 20) by scale factor 0.93744
I0109 18:23:10.997112  4932 solver.cpp:240] Iteration 5740, loss = 0.145888
I0109 18:23:10.997150  4932 solver.cpp:255]     Train net output #0: loss = 0.00922097 (* 1 = 0.00922097 loss)
I0109 18:23:10.997159  4932 solver.cpp:631] Iteration 5740, lr = 0.0001
I0109 18:23:56.835005  4932 solver.cpp:240] Iteration 5760, loss = 0.0784535
I0109 18:23:56.835100  4932 solver.cpp:255]     Train net output #0: loss = 0.255688 (* 1 = 0.255688 loss)
I0109 18:23:56.835114  4932 solver.cpp:631] Iteration 5760, lr = 0.0001
I0109 18:24:42.416187  4932 solver.cpp:240] Iteration 5780, loss = 0.0579629
I0109 18:24:42.416272  4932 solver.cpp:255]     Train net output #0: loss = 0.000715863 (* 1 = 0.000715863 loss)
I0109 18:24:42.416283  4932 solver.cpp:631] Iteration 5780, lr = 0.0001
I0109 18:24:58.290825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.456 > 20) by scale factor 0.890629
I0109 18:25:08.146880  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4457 > 20) by scale factor 0.891041
I0109 18:25:27.785308  4932 solver.cpp:240] Iteration 5800, loss = 0.0848354
I0109 18:25:27.785408  4932 solver.cpp:255]     Train net output #0: loss = 0.00055671 (* 1 = 0.00055671 loss)
I0109 18:25:27.785419  4932 solver.cpp:631] Iteration 5800, lr = 0.0001
I0109 18:25:41.445051  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.504 > 20) by scale factor 0.975417
I0109 18:26:12.172622  4932 solver.cpp:240] Iteration 5820, loss = 0.0425491
I0109 18:26:12.172729  4932 solver.cpp:255]     Train net output #0: loss = 0.000810482 (* 1 = 0.000810482 loss)
I0109 18:26:12.172744  4932 solver.cpp:631] Iteration 5820, lr = 0.0001
I0109 18:26:34.042482  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6183 > 20) by scale factor 0.92514
I0109 18:26:58.121429  4932 solver.cpp:240] Iteration 5840, loss = 0.0940264
I0109 18:26:58.121551  4932 solver.cpp:255]     Train net output #0: loss = 0.00345931 (* 1 = 0.00345931 loss)
I0109 18:26:58.121567  4932 solver.cpp:631] Iteration 5840, lr = 0.0001
I0109 18:27:39.942633  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6308 > 20) by scale factor 0.883751
I0109 18:27:45.120389  4932 solver.cpp:240] Iteration 5860, loss = 0.0549932
I0109 18:27:45.120430  4932 solver.cpp:255]     Train net output #0: loss = 0.0982626 (* 1 = 0.0982626 loss)
I0109 18:27:45.135917  4932 solver.cpp:631] Iteration 5860, lr = 0.0001
I0109 18:27:49.897548  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9748 > 20) by scale factor 0.870519
I0109 18:27:56.559269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7821 > 20) by scale factor 0.840968
I0109 18:27:58.783483  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4558 > 20) by scale factor 0.89064
I0109 18:28:05.445392  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3797 > 20) by scale factor 0.981367
I0109 18:28:14.324056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.2638 > 20) by scale factor 0.61989
I0109 18:28:16.548380  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9475 > 20) by scale factor 0.835159
I0109 18:28:30.989410  4932 solver.cpp:240] Iteration 5880, loss = 0.128217
I0109 18:28:30.989460  4932 solver.cpp:255]     Train net output #0: loss = 0.0221321 (* 1 = 0.0221321 loss)
I0109 18:28:30.989473  4932 solver.cpp:631] Iteration 5880, lr = 0.0001
I0109 18:28:49.082685  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.088 > 20) by scale factor 0.643335
I0109 18:29:17.019034  4932 solver.cpp:240] Iteration 5900, loss = 0.0660889
I0109 18:29:17.019078  4932 solver.cpp:255]     Train net output #0: loss = 0.0285749 (* 1 = 0.0285749 loss)
I0109 18:29:17.019088  4932 solver.cpp:631] Iteration 5900, lr = 0.0001
I0109 18:29:21.797511  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4578 > 20) by scale factor 0.852595
I0109 18:30:02.950335  4932 solver.cpp:240] Iteration 5920, loss = 0.101157
I0109 18:30:02.950423  4932 solver.cpp:255]     Train net output #0: loss = 0.148587 (* 1 = 0.148587 loss)
I0109 18:30:02.950435  4932 solver.cpp:631] Iteration 5920, lr = 0.0001
I0109 18:30:29.306807  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1126 > 20) by scale factor 0.904462
I0109 18:30:33.746821  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9913 > 20) by scale factor 0.909449
I0109 18:30:50.734557  4932 solver.cpp:240] Iteration 5940, loss = 0.0812544
I0109 18:30:50.734602  4932 solver.cpp:255]     Train net output #0: loss = 0.0308359 (* 1 = 0.0308359 loss)
I0109 18:30:50.734614  4932 solver.cpp:631] Iteration 5940, lr = 0.0001
I0109 18:30:55.514272  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8235 > 20) by scale factor 0.916445
I0109 18:31:36.181926  4932 solver.cpp:240] Iteration 5960, loss = 0.0723637
I0109 18:31:36.182020  4932 solver.cpp:255]     Train net output #0: loss = 0.0746806 (* 1 = 0.0746806 loss)
I0109 18:31:36.182031  4932 solver.cpp:631] Iteration 5960, lr = 0.0001
I0109 18:31:47.616559  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1066 > 20) by scale factor 0.94757
I0109 18:32:21.603977  4932 solver.cpp:240] Iteration 5980, loss = 0.068013
I0109 18:32:21.604087  4932 solver.cpp:255]     Train net output #0: loss = 0.0345548 (* 1 = 0.0345548 loss)
I0109 18:32:21.604104  4932 solver.cpp:631] Iteration 5980, lr = 0.0001
I0109 18:33:05.189855  4932 solver.cpp:424] Iteration 6000, Testing net (#0)
I0109 18:33:55.152387  4932 solver.cpp:481]     Test net output #0: accuracy = 0.832632
I0109 18:33:55.152473  4932 solver.cpp:481]     Test net output #1: loss = 0.788713 (* 1 = 0.788713 loss)
I0109 18:33:57.018051  4932 solver.cpp:240] Iteration 6000, loss = 0.0576183
I0109 18:33:57.018088  4932 solver.cpp:255]     Train net output #0: loss = 0.0605692 (* 1 = 0.0605692 loss)
I0109 18:33:57.018098  4932 solver.cpp:631] Iteration 6000, lr = 0.0001
I0109 18:34:10.671103  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7022 > 20) by scale factor 0.778145
I0109 18:34:41.405256  4932 solver.cpp:240] Iteration 6020, loss = 0.0973427
I0109 18:34:41.405354  4932 solver.cpp:255]     Train net output #0: loss = 0.000707713 (* 1 = 0.000707713 loss)
I0109 18:34:41.405366  4932 solver.cpp:631] Iteration 6020, lr = 0.0001
I0109 18:35:03.931731  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8724 > 20) by scale factor 0.874418
I0109 18:35:10.589864  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2073 > 20) by scale factor 0.94307
I0109 18:35:24.789090  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1486 > 20) by scale factor 0.863984
I0109 18:35:26.671232  4932 solver.cpp:240] Iteration 6040, loss = 0.0835025
I0109 18:35:26.671277  4932 solver.cpp:255]     Train net output #0: loss = 0.0195389 (* 1 = 0.0195389 loss)
I0109 18:35:26.671288  4932 solver.cpp:631] Iteration 6040, lr = 0.0001
I0109 18:35:38.108693  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4305 > 20) by scale factor 0.679566
I0109 18:35:42.548779  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3003 > 20) by scale factor 0.985207
I0109 18:35:52.325667  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6049 > 20) by scale factor 0.970645
I0109 18:36:07.861227  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4614 > 20) by scale factor 0.931904
I0109 18:36:11.961372  4932 solver.cpp:240] Iteration 6060, loss = 0.101226
I0109 18:36:11.961408  4932 solver.cpp:255]     Train net output #0: loss = 0.00148573 (* 1 = 0.00148573 loss)
I0109 18:36:11.961417  4932 solver.cpp:631] Iteration 6060, lr = 0.0001
I0109 18:36:16.740800  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6167 > 20) by scale factor 0.925212
I0109 18:36:51.313748  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8361 > 20) by scale factor 0.80528
I0109 18:36:58.156394  4932 solver.cpp:240] Iteration 6080, loss = 0.0747437
I0109 18:36:58.156426  4932 solver.cpp:255]     Train net output #0: loss = 0.0420915 (* 1 = 0.0420915 loss)
I0109 18:36:58.156435  4932 solver.cpp:631] Iteration 6080, lr = 0.0001
I0109 18:37:22.910384  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3942 > 20) by scale factor 0.893089
I0109 18:37:43.664515  4932 solver.cpp:240] Iteration 6100, loss = 0.0945026
I0109 18:37:43.664556  4932 solver.cpp:255]     Train net output #0: loss = 0.191798 (* 1 = 0.191798 loss)
I0109 18:37:43.664566  4932 solver.cpp:631] Iteration 6100, lr = 0.0001
I0109 18:37:44.003983  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.051 > 20) by scale factor 0.950075
I0109 18:38:27.177137  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7596 > 20) by scale factor 0.776411
I0109 18:38:29.058996  4932 solver.cpp:240] Iteration 6120, loss = 0.0755319
I0109 18:38:29.059041  4932 solver.cpp:255]     Train net output #0: loss = 0.160423 (* 1 = 0.160423 loss)
I0109 18:38:29.059052  4932 solver.cpp:631] Iteration 6120, lr = 0.0001
I0109 18:38:38.275146  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2139 > 20) by scale factor 0.861554
I0109 18:39:14.384886  4932 solver.cpp:240] Iteration 6140, loss = 0.0714475
I0109 18:39:14.384970  4932 solver.cpp:255]     Train net output #0: loss = 0.174435 (* 1 = 0.174435 loss)
I0109 18:39:14.384982  4932 solver.cpp:631] Iteration 6140, lr = 0.0001
I0109 18:39:31.374516  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5004 > 20) by scale factor 0.7843
I0109 18:39:35.820696  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2779 > 20) by scale factor 0.859183
I0109 18:40:01.135881  4932 solver.cpp:240] Iteration 6160, loss = 0.0656301
I0109 18:40:01.135999  4932 solver.cpp:255]     Train net output #0: loss = 0.0346981 (* 1 = 0.0346981 loss)
I0109 18:40:01.136016  4932 solver.cpp:631] Iteration 6160, lr = 0.0001
I0109 18:40:12.567090  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1014 > 20) by scale factor 0.829828
I0109 18:40:47.135406  4932 solver.cpp:240] Iteration 6180, loss = 0.0631728
I0109 18:40:47.135501  4932 solver.cpp:255]     Train net output #0: loss = 0.0164179 (* 1 = 0.0164179 loss)
I0109 18:40:47.135514  4932 solver.cpp:631] Iteration 6180, lr = 0.0001
I0109 18:41:09.659883  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4029 > 20) by scale factor 0.980252
I0109 18:41:25.987845  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6602 > 20) by scale factor 0.779418
I0109 18:41:32.306756  4932 solver.cpp:240] Iteration 6200, loss = 0.125188
I0109 18:41:32.306794  4932 solver.cpp:255]     Train net output #0: loss = 0.102497 (* 1 = 0.102497 loss)
I0109 18:41:32.306804  4932 solver.cpp:631] Iteration 6200, lr = 0.0001
I0109 18:42:17.087965  4932 solver.cpp:240] Iteration 6220, loss = 0.0609085
I0109 18:42:17.088052  4932 solver.cpp:255]     Train net output #0: loss = 0.000869066 (* 1 = 0.000869066 loss)
I0109 18:42:17.088064  4932 solver.cpp:631] Iteration 6220, lr = 0.0001
I0109 18:42:19.645246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0839 > 20) by scale factor 0.995821
I0109 18:42:49.440884  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7294 > 20) by scale factor 0.920414
I0109 18:42:53.883579  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1057 > 20) by scale factor 0.994741
I0109 18:43:03.785106  4932 solver.cpp:240] Iteration 6240, loss = 0.0889182
I0109 18:43:03.785146  4932 solver.cpp:255]     Train net output #0: loss = 0.127004 (* 1 = 0.127004 loss)
I0109 18:43:03.785156  4932 solver.cpp:631] Iteration 6240, lr = 0.0001
I0109 18:43:37.405218  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 38.4728 > 20) by scale factor 0.519848
I0109 18:43:49.183792  4932 solver.cpp:240] Iteration 6260, loss = 0.122721
I0109 18:43:49.183837  4932 solver.cpp:255]     Train net output #0: loss = 0.091593 (* 1 = 0.091593 loss)
I0109 18:43:49.183850  4932 solver.cpp:631] Iteration 6260, lr = 0.0001
I0109 18:44:09.495028  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0511 > 20) by scale factor 0.867638
I0109 18:44:35.111701  4932 solver.cpp:240] Iteration 6280, loss = 0.09395
I0109 18:44:35.111742  4932 solver.cpp:255]     Train net output #0: loss = 0.123228 (* 1 = 0.123228 loss)
I0109 18:44:35.111862  4932 solver.cpp:631] Iteration 6280, lr = 0.0001
I0109 18:44:58.737360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4825 > 20) by scale factor 0.727737
I0109 18:45:00.958700  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6707 > 20) by scale factor 0.81068
I0109 18:45:20.602738  4932 solver.cpp:240] Iteration 6300, loss = 0.0758846
I0109 18:45:20.602777  4932 solver.cpp:255]     Train net output #0: loss = 0.0254033 (* 1 = 0.0254033 loss)
I0109 18:45:20.602787  4932 solver.cpp:631] Iteration 6300, lr = 0.0001
I0109 18:45:37.896984  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3694 > 20) by scale factor 0.788351
I0109 18:46:07.600226  4932 solver.cpp:240] Iteration 6320, loss = 0.0779928
I0109 18:46:07.600265  4932 solver.cpp:255]     Train net output #0: loss = 0.0207627 (* 1 = 0.0207627 loss)
I0109 18:46:07.600275  4932 solver.cpp:631] Iteration 6320, lr = 0.0001
I0109 18:46:52.988587  4932 solver.cpp:240] Iteration 6340, loss = 0.0727185
I0109 18:46:52.988680  4932 solver.cpp:255]     Train net output #0: loss = 0.0377135 (* 1 = 0.0377135 loss)
I0109 18:46:52.988693  4932 solver.cpp:631] Iteration 6340, lr = 0.0001
I0109 18:47:06.648442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3711 > 20) by scale factor 0.704942
I0109 18:47:38.699846  4932 solver.cpp:240] Iteration 6360, loss = 0.0788381
I0109 18:47:38.699964  4932 solver.cpp:255]     Train net output #0: loss = 0.0223025 (* 1 = 0.0223025 loss)
I0109 18:47:38.699980  4932 solver.cpp:631] Iteration 6360, lr = 0.0001
I0109 18:47:57.593547  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1784 > 20) by scale factor 0.944359
I0109 18:48:08.694022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2286 > 20) by scale factor 0.988698
I0109 18:48:23.888803  4932 solver.cpp:240] Iteration 6380, loss = 0.0821471
I0109 18:48:23.888900  4932 solver.cpp:255]     Train net output #0: loss = 0.0672077 (* 1 = 0.0672077 loss)
I0109 18:48:23.888912  4932 solver.cpp:631] Iteration 6380, lr = 0.0001
I0109 18:48:47.317405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5396 > 20) by scale factor 0.849632
I0109 18:48:49.541481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.3952 > 20) by scale factor 0.617376
I0109 18:49:09.181948  4932 solver.cpp:240] Iteration 6400, loss = 0.0988494
I0109 18:49:09.182040  4932 solver.cpp:255]     Train net output #0: loss = 0.0216999 (* 1 = 0.0216999 loss)
I0109 18:49:09.182054  4932 solver.cpp:631] Iteration 6400, lr = 0.0001
I0109 18:49:20.619348  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4962 > 20) by scale factor 0.816454
I0109 18:49:54.450264  4932 solver.cpp:240] Iteration 6420, loss = 0.107002
I0109 18:49:54.450351  4932 solver.cpp:255]     Train net output #0: loss = 0.0200403 (* 1 = 0.0200403 loss)
I0109 18:49:54.450362  4932 solver.cpp:631] Iteration 6420, lr = 0.0001
I0109 18:50:39.979710  4932 solver.cpp:240] Iteration 6440, loss = 0.0516572
I0109 18:50:39.979805  4932 solver.cpp:255]     Train net output #0: loss = 0.023422 (* 1 = 0.023422 loss)
I0109 18:50:39.979817  4932 solver.cpp:631] Iteration 6440, lr = 0.0001
I0109 18:50:51.417130  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.757 > 20) by scale factor 0.807851
I0109 18:50:53.638581  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9963 > 20) by scale factor 0.80012
I0109 18:51:01.577716  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0935 > 20) by scale factor 0.995345
I0109 18:51:21.557714  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3231 > 20) by scale factor 0.759789
I0109 18:51:25.661970  4932 solver.cpp:240] Iteration 6460, loss = 0.108037
I0109 18:51:25.662014  4932 solver.cpp:255]     Train net output #0: loss = 0.218591 (* 1 = 0.218591 loss)
I0109 18:51:25.662024  4932 solver.cpp:631] Iteration 6460, lr = 0.0001
I0109 18:51:28.221539  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6331 > 20) by scale factor 0.883663
I0109 18:51:51.775022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0001 > 20) by scale factor 0.740738
I0109 18:52:02.877218  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.9167 > 20) by scale factor 0.626631
I0109 18:52:11.412390  4932 solver.cpp:240] Iteration 6480, loss = 0.116521
I0109 18:52:11.412436  4932 solver.cpp:255]     Train net output #0: loss = 0.0494947 (* 1 = 0.0494947 loss)
I0109 18:52:11.412448  4932 solver.cpp:631] Iteration 6480, lr = 0.0001
I0109 18:52:32.811897  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6377 > 20) by scale factor 0.924311
I0109 18:52:57.900172  4932 solver.cpp:240] Iteration 6500, loss = 0.100143
I0109 18:52:57.900218  4932 solver.cpp:255]     Train net output #0: loss = 0.149145 (* 1 = 0.149145 loss)
I0109 18:52:57.900230  4932 solver.cpp:631] Iteration 6500, lr = 0.0001
I0109 18:53:07.117154  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9619 > 20) by scale factor 0.645955
I0109 18:53:36.976615  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4098 > 20) by scale factor 0.657683
I0109 18:53:43.302937  4932 solver.cpp:240] Iteration 6520, loss = 0.105847
I0109 18:53:43.303045  4932 solver.cpp:255]     Train net output #0: loss = 0.0170593 (* 1 = 0.0170593 loss)
I0109 18:53:43.303063  4932 solver.cpp:631] Iteration 6520, lr = 0.0001
I0109 18:54:27.707897  4932 solver.cpp:240] Iteration 6540, loss = 0.0616056
I0109 18:54:27.708017  4932 solver.cpp:255]     Train net output #0: loss = 0.0129115 (* 1 = 0.0129115 loss)
I0109 18:54:27.708034  4932 solver.cpp:631] Iteration 6540, lr = 0.0001
I0109 18:54:30.271456  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.3718 > 20) by scale factor 0.617821
I0109 18:55:08.770699  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4813 > 20) by scale factor 0.851742
I0109 18:55:12.871222  4932 solver.cpp:240] Iteration 6560, loss = 0.0894006
I0109 18:55:12.871263  4932 solver.cpp:255]     Train net output #0: loss = 0.00148115 (* 1 = 0.00148115 loss)
I0109 18:55:12.871271  4932 solver.cpp:631] Iteration 6560, lr = 0.0001
I0109 18:55:22.965148  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9997 > 20) by scale factor 0.909105
I0109 18:55:59.106637  4932 solver.cpp:240] Iteration 6580, loss = 0.0878872
I0109 18:55:59.106724  4932 solver.cpp:255]     Train net output #0: loss = 0.279063 (* 1 = 0.279063 loss)
I0109 18:55:59.106737  4932 solver.cpp:631] Iteration 6580, lr = 0.0001
I0109 18:56:17.204591  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1157 > 20) by scale factor 0.994249
I0109 18:56:43.500202  4932 solver.cpp:240] Iteration 6600, loss = 0.0642473
I0109 18:56:43.500293  4932 solver.cpp:255]     Train net output #0: loss = 0.00348181 (* 1 = 0.00348181 loss)
I0109 18:56:43.500308  4932 solver.cpp:631] Iteration 6600, lr = 0.0001
I0109 18:57:24.078385  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5842 > 20) by scale factor 0.813531
I0109 18:57:28.178118  4932 solver.cpp:240] Iteration 6620, loss = 0.0761467
I0109 18:57:28.178158  4932 solver.cpp:255]     Train net output #0: loss = 0.326388 (* 1 = 0.326388 loss)
I0109 18:57:28.178165  4932 solver.cpp:631] Iteration 6620, lr = 0.0001
I0109 18:57:28.517117  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0593 > 20) by scale factor 0.798106
I0109 18:57:35.176964  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5401 > 20) by scale factor 0.887308
I0109 18:58:13.437990  4932 solver.cpp:240] Iteration 6640, loss = 0.0925497
I0109 18:58:13.438098  4932 solver.cpp:255]     Train net output #0: loss = 0.00330886 (* 1 = 0.00330886 loss)
I0109 18:58:13.438113  4932 solver.cpp:631] Iteration 6640, lr = 0.0001
I0109 18:58:52.618182  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1847 > 20) by scale factor 0.944079
I0109 18:59:00.144454  4932 solver.cpp:240] Iteration 6660, loss = 0.0746588
I0109 18:59:00.144498  4932 solver.cpp:255]     Train net output #0: loss = 0.0194962 (* 1 = 0.0194962 loss)
I0109 18:59:00.144510  4932 solver.cpp:631] Iteration 6660, lr = 0.0001
I0109 18:59:04.922430  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6559 > 20) by scale factor 0.882772
I0109 18:59:29.336791  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7615 > 20) by scale factor 0.919056
I0109 18:59:39.298331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8762 > 20) by scale factor 0.772911
I0109 18:59:45.614614  4932 solver.cpp:240] Iteration 6680, loss = 0.0677035
I0109 18:59:45.614652  4932 solver.cpp:255]     Train net output #0: loss = 0.12171 (* 1 = 0.12171 loss)
I0109 18:59:45.614660  4932 solver.cpp:631] Iteration 6680, lr = 0.0001
I0109 19:00:15.721901  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2221 > 20) by scale factor 0.989016
I0109 19:00:30.918473  4932 solver.cpp:240] Iteration 6700, loss = 0.0753731
I0109 19:00:30.918517  4932 solver.cpp:255]     Train net output #0: loss = 0.0158962 (* 1 = 0.0158962 loss)
I0109 19:00:30.918529  4932 solver.cpp:631] Iteration 6700, lr = 0.0001
I0109 19:00:42.351686  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3003 > 20) by scale factor 0.638972
I0109 19:00:49.848063  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5499 > 20) by scale factor 0.753298
I0109 19:00:56.506726  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.978 > 20) by scale factor 0.953381
I0109 19:01:05.396500  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6363 > 20) by scale factor 0.92437
I0109 19:01:16.153988  4932 solver.cpp:240] Iteration 6720, loss = 0.127277
I0109 19:01:16.154036  4932 solver.cpp:255]     Train net output #0: loss = 0.116777 (* 1 = 0.116777 loss)
I0109 19:01:16.154047  4932 solver.cpp:631] Iteration 6720, lr = 0.0001
I0109 19:01:16.495158  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6756 > 20) by scale factor 0.967322
I0109 19:01:28.555042  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0921 > 20) by scale factor 0.995414
I0109 19:01:50.747666  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.4096 > 20) by scale factor 0.636747
I0109 19:01:55.191504  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3251 > 20) by scale factor 0.895854
I0109 19:02:01.825935  4932 solver.cpp:240] Iteration 6740, loss = 0.0904235
I0109 19:02:01.826015  4932 solver.cpp:255]     Train net output #0: loss = 0.103421 (* 1 = 0.103421 loss)
I0109 19:02:01.826026  4932 solver.cpp:631] Iteration 6740, lr = 0.0001
I0109 19:02:13.257825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2906 > 20) by scale factor 0.939383
I0109 19:02:46.949041  4932 solver.cpp:240] Iteration 6760, loss = 0.128326
I0109 19:02:46.949131  4932 solver.cpp:255]     Train net output #0: loss = 0.0359388 (* 1 = 0.0359388 loss)
I0109 19:02:46.949142  4932 solver.cpp:631] Iteration 6760, lr = 0.0001
I0109 19:02:56.162420  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8017 > 20) by scale factor 0.806398
I0109 19:03:32.387733  4932 solver.cpp:240] Iteration 6780, loss = 0.078225
I0109 19:03:32.387828  4932 solver.cpp:255]     Train net output #0: loss = 0.0885557 (* 1 = 0.0885557 loss)
I0109 19:03:32.387840  4932 solver.cpp:631] Iteration 6780, lr = 0.0001
I0109 19:04:06.999421  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2834 > 20) by scale factor 0.70713
I0109 19:04:15.884090  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4355 > 20) by scale factor 0.818481
I0109 19:04:17.765470  4932 solver.cpp:240] Iteration 6800, loss = 0.0816669
I0109 19:04:17.765509  4932 solver.cpp:255]     Train net output #0: loss = 0.0342267 (* 1 = 0.0342267 loss)
I0109 19:04:17.765519  4932 solver.cpp:631] Iteration 6800, lr = 0.0001
I0109 19:05:03.869834  4932 solver.cpp:240] Iteration 6820, loss = 0.0383734
I0109 19:05:03.869942  4932 solver.cpp:255]     Train net output #0: loss = 0.0319173 (* 1 = 0.0319173 loss)
I0109 19:05:03.869958  4932 solver.cpp:631] Iteration 6820, lr = 0.0001
I0109 19:05:13.087122  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1116 > 20) by scale factor 0.765944
I0109 19:05:49.044189  4932 solver.cpp:240] Iteration 6840, loss = 0.0684978
I0109 19:05:49.044291  4932 solver.cpp:255]     Train net output #0: loss = 0.0310484 (* 1 = 0.0310484 loss)
I0109 19:05:49.044306  4932 solver.cpp:631] Iteration 6840, lr = 0.0001
I0109 19:06:11.584205  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3213 > 20) by scale factor 0.938029
I0109 19:06:33.432682  4932 solver.cpp:240] Iteration 6860, loss = 0.0627889
I0109 19:06:33.432775  4932 solver.cpp:255]     Train net output #0: loss = 0.0437127 (* 1 = 0.0437127 loss)
I0109 19:06:33.432787  4932 solver.cpp:631] Iteration 6860, lr = 0.0001
I0109 19:06:47.095798  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8395 > 20) by scale factor 0.915772
I0109 19:07:14.800240  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.837 > 20) by scale factor 0.959829
I0109 19:07:18.902411  4932 solver.cpp:240] Iteration 6880, loss = 0.0675036
I0109 19:07:18.902448  4932 solver.cpp:255]     Train net output #0: loss = 0.115204 (* 1 = 0.115204 loss)
I0109 19:07:18.902457  4932 solver.cpp:631] Iteration 6880, lr = 0.0001
I0109 19:07:19.242022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1175 > 20) by scale factor 0.865147
I0109 19:07:25.899148  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0227 > 20) by scale factor 0.832546
I0109 19:07:33.350595  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0264 > 20) by scale factor 0.76845
I0109 19:07:37.788898  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0659 > 20) by scale factor 0.906377
I0109 19:07:46.674826  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3132 > 20) by scale factor 0.638707
I0109 19:07:57.770493  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8604 > 20) by scale factor 0.692991
I0109 19:08:04.093504  4932 solver.cpp:240] Iteration 6900, loss = 0.126485
I0109 19:08:04.093538  4932 solver.cpp:255]     Train net output #0: loss = 0.0285227 (* 1 = 0.0285227 loss)
I0109 19:08:04.093547  4932 solver.cpp:631] Iteration 6900, lr = 0.0001
I0109 19:08:43.931073  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8675 > 20) by scale factor 0.95843
I0109 19:08:48.369714  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.2853 > 20) by scale factor 0.639277
I0109 19:08:50.252051  4932 solver.cpp:240] Iteration 6920, loss = 0.084539
I0109 19:08:50.252082  4932 solver.cpp:255]     Train net output #0: loss = 0.0397334 (* 1 = 0.0397334 loss)
I0109 19:08:50.252091  4932 solver.cpp:631] Iteration 6920, lr = 0.0001
I0109 19:08:52.811216  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5049 > 20) by scale factor 0.850887
I0109 19:08:57.251343  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2037 > 20) by scale factor 0.826319
I0109 19:09:24.763900  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7042 > 20) by scale factor 0.748947
I0109 19:09:29.203433  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0863 > 20) by scale factor 0.905537
I0109 19:09:35.521829  4932 solver.cpp:240] Iteration 6940, loss = 0.122813
I0109 19:09:35.521870  4932 solver.cpp:255]     Train net output #0: loss = 0.0500811 (* 1 = 0.0500811 loss)
I0109 19:09:35.521879  4932 solver.cpp:631] Iteration 6940, lr = 0.0001
I0109 19:09:44.744508  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7818 > 20) by scale factor 0.775742
I0109 19:09:46.966876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4425 > 20) by scale factor 0.818249
I0109 19:10:12.009420  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1162 > 20) by scale factor 0.904313
I0109 19:10:16.447419  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2272 > 20) by scale factor 0.792794
I0109 19:10:20.550880  4932 solver.cpp:240] Iteration 6960, loss = 0.0838485
I0109 19:10:20.550922  4932 solver.cpp:255]     Train net output #0: loss = 0.225648 (* 1 = 0.225648 loss)
I0109 19:10:20.550933  4932 solver.cpp:631] Iteration 6960, lr = 0.0001
I0109 19:10:20.891219  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0781 > 20) by scale factor 0.866624
I0109 19:11:05.332142  4932 solver.cpp:240] Iteration 6980, loss = 0.0669565
I0109 19:11:05.332234  4932 solver.cpp:255]     Train net output #0: loss = 0.00111516 (* 1 = 0.00111516 loss)
I0109 19:11:05.332247  4932 solver.cpp:631] Iteration 6980, lr = 0.0001
I0109 19:11:15.279013  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9602 > 20) by scale factor 0.871072
I0109 19:11:33.037926  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5812 > 20) by scale factor 0.971762
I0109 19:11:49.348120  4932 solver.cpp:424] Iteration 7000, Testing net (#0)
I0109 19:12:39.222431  4932 solver.cpp:481]     Test net output #0: accuracy = 0.832632
I0109 19:12:39.222542  4932 solver.cpp:481]     Test net output #1: loss = 0.791033 (* 1 = 0.791033 loss)
I0109 19:12:41.089432  4932 solver.cpp:240] Iteration 7000, loss = 0.0591537
I0109 19:12:41.089476  4932 solver.cpp:255]     Train net output #0: loss = 0.030347 (* 1 = 0.030347 loss)
I0109 19:12:41.089488  4932 solver.cpp:631] Iteration 7000, lr = 0.0001
I0109 19:13:03.625705  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7582 > 20) by scale factor 0.963475
I0109 19:13:05.845986  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1159 > 20) by scale factor 0.904327
I0109 19:13:16.953542  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4142 > 20) by scale factor 0.854183
I0109 19:13:26.007699  4932 solver.cpp:240] Iteration 7020, loss = 0.105796
I0109 19:13:26.007741  4932 solver.cpp:255]     Train net output #0: loss = 0.0783496 (* 1 = 0.0783496 loss)
I0109 19:13:26.007750  4932 solver.cpp:631] Iteration 7020, lr = 0.0001
I0109 19:13:33.008219  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0321 > 20) by scale factor 0.998398
I0109 19:13:39.668009  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9795 > 20) by scale factor 0.769839
I0109 19:13:44.113543  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6848 > 20) by scale factor 0.749491
I0109 19:14:11.616454  4932 solver.cpp:240] Iteration 7040, loss = 0.0971294
I0109 19:14:11.616555  4932 solver.cpp:255]     Train net output #0: loss = 0.0585773 (* 1 = 0.0585773 loss)
I0109 19:14:11.616569  4932 solver.cpp:631] Iteration 7040, lr = 0.0001
I0109 19:14:31.936432  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.039 > 20) by scale factor 0.554954
I0109 19:14:57.291203  4932 solver.cpp:240] Iteration 7060, loss = 0.106768
I0109 19:14:57.291301  4932 solver.cpp:255]     Train net output #0: loss = 0.213924 (* 1 = 0.213924 loss)
I0109 19:14:57.291316  4932 solver.cpp:631] Iteration 7060, lr = 0.0001
I0109 19:15:20.816197  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.5725 > 20) by scale factor 0.633462
I0109 19:15:31.911485  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4328 > 20) by scale factor 0.891551
I0109 19:15:42.670380  4932 solver.cpp:240] Iteration 7080, loss = 0.11235
I0109 19:15:42.670413  4932 solver.cpp:255]     Train net output #0: loss = 0.11479 (* 1 = 0.11479 loss)
I0109 19:15:42.670421  4932 solver.cpp:631] Iteration 7080, lr = 0.0001
I0109 19:16:17.436800  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.912 > 20) by scale factor 0.95639
I0109 19:16:28.692241  4932 solver.cpp:240] Iteration 7100, loss = 0.0879091
I0109 19:16:28.692283  4932 solver.cpp:255]     Train net output #0: loss = 0.100922 (* 1 = 0.100922 loss)
I0109 19:16:28.692292  4932 solver.cpp:631] Iteration 7100, lr = 0.0001
I0109 19:16:31.249917  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2024 > 20) by scale factor 0.793574
I0109 19:17:14.156102  4932 solver.cpp:240] Iteration 7120, loss = 0.0752057
I0109 19:17:14.156198  4932 solver.cpp:255]     Train net output #0: loss = 0.0922234 (* 1 = 0.0922234 loss)
I0109 19:17:14.156210  4932 solver.cpp:631] Iteration 7120, lr = 0.0001
I0109 19:17:18.935639  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5004 > 20) by scale factor 0.85105
I0109 19:17:37.762398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6093 > 20) by scale factor 0.847123
I0109 19:17:53.297391  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2483 > 20) by scale factor 0.8248
I0109 19:17:59.619108  4932 solver.cpp:240] Iteration 7140, loss = 0.0915875
I0109 19:17:59.619165  4932 solver.cpp:255]     Train net output #0: loss = 0.00556246 (* 1 = 0.00556246 loss)
I0109 19:17:59.619179  4932 solver.cpp:631] Iteration 7140, lr = 0.0001
I0109 19:18:31.925693  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1162 > 20) by scale factor 0.994225
I0109 19:18:40.806831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9592 > 20) by scale factor 0.954234
I0109 19:18:44.912073  4932 solver.cpp:240] Iteration 7160, loss = 0.0824434
I0109 19:18:44.912127  4932 solver.cpp:255]     Train net output #0: loss = 0.00228814 (* 1 = 0.00228814 loss)
I0109 19:18:44.912144  4932 solver.cpp:631] Iteration 7160, lr = 0.0001
I0109 19:19:17.406661  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9055 > 20) by scale factor 0.803036
I0109 19:19:31.096765  4932 solver.cpp:240] Iteration 7180, loss = 0.114577
I0109 19:19:31.096798  4932 solver.cpp:255]     Train net output #0: loss = 0.12522 (* 1 = 0.12522 loss)
I0109 19:19:31.096807  4932 solver.cpp:631] Iteration 7180, lr = 0.0001
I0109 19:19:51.407702  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1726 > 20) by scale factor 0.991442
I0109 19:20:16.678730  4932 solver.cpp:240] Iteration 7200, loss = 0.0908225
I0109 19:20:16.678774  4932 solver.cpp:255]     Train net output #0: loss = 0.00686457 (* 1 = 0.00686457 loss)
I0109 19:20:16.678895  4932 solver.cpp:631] Iteration 7200, lr = 0.0001
I0109 19:20:19.237264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0963 > 20) by scale factor 0.865938
I0109 19:20:34.773411  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.0191 > 20) by scale factor 0.555261
I0109 19:21:01.802500  4932 solver.cpp:240] Iteration 7220, loss = 0.0728503
I0109 19:21:01.802542  4932 solver.cpp:255]     Train net output #0: loss = 0.044057 (* 1 = 0.044057 loss)
I0109 19:21:01.802553  4932 solver.cpp:631] Iteration 7220, lr = 0.0001
I0109 19:21:33.967942  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7256 > 20) by scale factor 0.84297
I0109 19:21:46.949452  4932 solver.cpp:240] Iteration 7240, loss = 0.0800599
I0109 19:21:47.700134  4932 solver.cpp:255]     Train net output #0: loss = 0.0699344 (* 1 = 0.0699344 loss)
I0109 19:21:47.700150  4932 solver.cpp:631] Iteration 7240, lr = 0.0001
I0109 19:21:49.935595  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1191 > 20) by scale factor 0.94701
I0109 19:22:14.357018  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.906 > 20) by scale factor 0.607791
I0109 19:22:31.920434  4932 solver.cpp:240] Iteration 7260, loss = 0.0775753
I0109 19:22:31.920469  4932 solver.cpp:255]     Train net output #0: loss = 0.0656124 (* 1 = 0.0656124 loss)
I0109 19:22:31.920478  4932 solver.cpp:631] Iteration 7260, lr = 0.0001
I0109 19:23:13.473541  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5669 > 20) by scale factor 0.972437
I0109 19:23:17.573168  4932 solver.cpp:240] Iteration 7280, loss = 0.106881
I0109 19:23:17.573206  4932 solver.cpp:255]     Train net output #0: loss = 0.0232275 (* 1 = 0.0232275 loss)
I0109 19:23:17.573215  4932 solver.cpp:631] Iteration 7280, lr = 0.0001
I0109 19:24:02.848620  4932 solver.cpp:240] Iteration 7300, loss = 0.0483907
I0109 19:24:02.848701  4932 solver.cpp:255]     Train net output #0: loss = 0.232341 (* 1 = 0.232341 loss)
I0109 19:24:02.848712  4932 solver.cpp:631] Iteration 7300, lr = 0.0001
I0109 19:24:03.187912  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4373 > 20) by scale factor 0.978601
I0109 19:24:17.380558  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3238 > 20) by scale factor 0.895905
I0109 19:24:26.261889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6329 > 20) by scale factor 0.924518
I0109 19:24:48.123116  4932 solver.cpp:240] Iteration 7320, loss = 0.0655579
I0109 19:24:48.123215  4932 solver.cpp:255]     Train net output #0: loss = 0.0049758 (* 1 = 0.0049758 loss)
I0109 19:24:48.123229  4932 solver.cpp:631] Iteration 7320, lr = 0.0001
I0109 19:24:50.681110  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7085 > 20) by scale factor 0.777954
I0109 19:24:53.327045  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4604 > 20) by scale factor 0.931947
I0109 19:25:33.775084  4932 solver.cpp:240] Iteration 7340, loss = 0.0862888
I0109 19:25:33.775180  4932 solver.cpp:255]     Train net output #0: loss = 0.0863663 (* 1 = 0.0863663 loss)
I0109 19:25:33.775192  4932 solver.cpp:631] Iteration 7340, lr = 0.0001
I0109 19:25:42.993904  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.239 > 20) by scale factor 0.988189
I0109 19:26:18.173748  4932 solver.cpp:240] Iteration 7360, loss = 0.0485402
I0109 19:26:18.173825  4932 solver.cpp:255]     Train net output #0: loss = 0.0453404 (* 1 = 0.0453404 loss)
I0109 19:26:18.173835  4932 solver.cpp:631] Iteration 7360, lr = 0.0001
I0109 19:26:45.749255  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.4245 > 20) by scale factor 0.534409
I0109 19:26:56.843139  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8959 > 20) by scale factor 0.913415
I0109 19:27:01.284528  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1849 > 20) by scale factor 0.901516
I0109 19:27:03.165215  4932 solver.cpp:240] Iteration 7380, loss = 0.0734162
I0109 19:27:03.165247  4932 solver.cpp:255]     Train net output #0: loss = 0.00168018 (* 1 = 0.00168018 loss)
I0109 19:27:03.165256  4932 solver.cpp:631] Iteration 7380, lr = 0.0001
I0109 19:27:05.721412  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6391 > 20) by scale factor 0.750776
I0109 19:27:21.261153  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2205 > 20) by scale factor 0.90007
I0109 19:27:39.485062  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3067 > 20) by scale factor 0.938672
I0109 19:27:48.033344  4932 solver.cpp:240] Iteration 7400, loss = 0.113802
I0109 19:27:48.033383  4932 solver.cpp:255]     Train net output #0: loss = 0.0023963 (* 1 = 0.0023963 loss)
I0109 19:27:48.033392  4932 solver.cpp:631] Iteration 7400, lr = 0.0001
I0109 19:27:52.809644  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.3822 > 20) by scale factor 0.617623
I0109 19:28:06.901990  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5139 > 20) by scale factor 0.677647
I0109 19:28:22.439594  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9466 > 20) by scale factor 0.87159
I0109 19:28:24.661217  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7453 > 20) by scale factor 0.964075
I0109 19:28:33.196210  4932 solver.cpp:240] Iteration 7420, loss = 0.163946
I0109 19:28:33.196245  4932 solver.cpp:255]     Train net output #0: loss = 0.08544 (* 1 = 0.08544 loss)
I0109 19:28:33.196254  4932 solver.cpp:631] Iteration 7420, lr = 0.0001
I0109 19:28:46.850922  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3401 > 20) by scale factor 0.983277
I0109 19:28:49.076185  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1765 > 20) by scale factor 0.901856
I0109 19:29:11.273700  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1226 > 20) by scale factor 0.686751
I0109 19:29:18.604251  4932 solver.cpp:240] Iteration 7440, loss = 0.0763578
I0109 19:29:18.604295  4932 solver.cpp:255]     Train net output #0: loss = 0.00168773 (* 1 = 0.00168773 loss)
I0109 19:29:18.604305  4932 solver.cpp:631] Iteration 7440, lr = 0.0001
I0109 19:29:50.927764  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5772 > 20) by scale factor 0.926904
I0109 19:30:03.904470  4932 solver.cpp:240] Iteration 7460, loss = 0.083634
I0109 19:30:03.904508  4932 solver.cpp:255]     Train net output #0: loss = 0.073947 (* 1 = 0.073947 loss)
I0109 19:30:03.904523  4932 solver.cpp:631] Iteration 7460, lr = 0.0001
I0109 19:30:24.220204  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1871 > 20) by scale factor 0.826888
I0109 19:30:49.417424  4932 solver.cpp:240] Iteration 7480, loss = 0.0643906
I0109 19:30:49.417471  4932 solver.cpp:255]     Train net output #0: loss = 0.00290692 (* 1 = 0.00290692 loss)
I0109 19:30:49.417482  4932 solver.cpp:631] Iteration 7480, lr = 0.0001
I0109 19:31:06.198297  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5546 > 20) by scale factor 0.782637
I0109 19:31:17.294100  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4743 > 20) by scale factor 0.889906
I0109 19:31:23.954089  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.016 > 20) by scale factor 0.689274
I0109 19:31:34.712404  4932 solver.cpp:240] Iteration 7500, loss = 0.118503
I0109 19:31:34.712450  4932 solver.cpp:255]     Train net output #0: loss = 0.333189 (* 1 = 0.333189 loss)
I0109 19:31:34.712462  4932 solver.cpp:631] Iteration 7500, lr = 0.0001
I0109 19:31:58.619840  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8668 > 20) by scale factor 0.692838
I0109 19:32:00.841289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.198 > 20) by scale factor 0.943486
I0109 19:32:09.722491  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1643 > 20) by scale factor 0.827667
I0109 19:32:21.616725  4932 solver.cpp:240] Iteration 7520, loss = 0.114467
I0109 19:32:21.616766  4932 solver.cpp:255]     Train net output #0: loss = 0.234252 (* 1 = 0.234252 loss)
I0109 19:32:21.616775  4932 solver.cpp:631] Iteration 7520, lr = 0.0001
I0109 19:32:30.828438  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1186 > 20) by scale factor 0.865106
I0109 19:33:06.559343  4932 solver.cpp:240] Iteration 7540, loss = 0.0790975
I0109 19:33:06.559453  4932 solver.cpp:255]     Train net output #0: loss = 0.0583904 (* 1 = 0.0583904 loss)
I0109 19:33:06.559468  4932 solver.cpp:631] Iteration 7540, lr = 0.0001
I0109 19:33:09.118535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8563 > 20) by scale factor 0.958941
I0109 19:33:51.928477  4932 solver.cpp:240] Iteration 7560, loss = 0.0975901
I0109 19:33:51.928565  4932 solver.cpp:255]     Train net output #0: loss = 0.00770574 (* 1 = 0.00770574 loss)
I0109 19:33:51.928577  4932 solver.cpp:631] Iteration 7560, lr = 0.0001
I0109 19:34:10.606207  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4465 > 20) by scale factor 0.818112
I0109 19:34:17.267109  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5787 > 20) by scale factor 0.971879
I0109 19:34:30.584460  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2001 > 20) by scale factor 0.826444
I0109 19:34:36.904523  4932 solver.cpp:240] Iteration 7580, loss = 0.0736502
I0109 19:34:36.904573  4932 solver.cpp:255]     Train net output #0: loss = 0.231677 (* 1 = 0.231677 loss)
I0109 19:34:36.904587  4932 solver.cpp:631] Iteration 7580, lr = 0.0001
I0109 19:34:37.245688  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.143 > 20) by scale factor 0.736838
I0109 19:34:49.276808  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1089 > 20) by scale factor 0.865467
I0109 19:35:09.257437  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5529 > 20) by scale factor 0.886804
I0109 19:35:23.122598  4932 solver.cpp:240] Iteration 7600, loss = 0.0998184
I0109 19:35:23.122633  4932 solver.cpp:255]     Train net output #0: loss = 0.041077 (* 1 = 0.041077 loss)
I0109 19:35:23.122642  4932 solver.cpp:631] Iteration 7600, lr = 0.0001
I0109 19:35:25.679535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3016 > 20) by scale factor 0.985146
I0109 19:35:45.661226  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.9723 > 20) by scale factor 0.625542
I0109 19:35:47.884542  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5803 > 20) by scale factor 0.752438
I0109 19:36:08.421067  4932 solver.cpp:240] Iteration 7620, loss = 0.128399
I0109 19:36:08.421106  4932 solver.cpp:255]     Train net output #0: loss = 0.0210429 (* 1 = 0.0210429 loss)
I0109 19:36:08.421114  4932 solver.cpp:631] Iteration 7620, lr = 0.0001
I0109 19:36:47.041188  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0205 > 20) by scale factor 0.951454
I0109 19:36:53.360682  4932 solver.cpp:240] Iteration 7640, loss = 0.0797768
I0109 19:36:53.360719  4932 solver.cpp:255]     Train net output #0: loss = 0.380749 (* 1 = 0.380749 loss)
I0109 19:36:53.360728  4932 solver.cpp:631] Iteration 7640, lr = 0.0001
I0109 19:36:53.700188  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1323 > 20) by scale factor 0.710927
I0109 19:37:23.636219  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9876 > 20) by scale factor 0.952944
I0109 19:37:39.880383  4932 solver.cpp:240] Iteration 7660, loss = 0.0716299
I0109 19:37:39.880430  4932 solver.cpp:255]     Train net output #0: loss = 0.130275 (* 1 = 0.130275 loss)
I0109 19:37:39.880441  4932 solver.cpp:631] Iteration 7660, lr = 0.0001
I0109 19:38:02.413691  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2207 > 20) by scale factor 0.942475
I0109 19:38:24.664577  4932 solver.cpp:240] Iteration 7680, loss = 0.0962392
I0109 19:38:24.664615  4932 solver.cpp:255]     Train net output #0: loss = 0.147663 (* 1 = 0.147663 loss)
I0109 19:38:24.664623  4932 solver.cpp:631] Iteration 7680, lr = 0.0001
I0109 19:38:31.660287  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5551 > 20) by scale factor 0.972994
I0109 19:39:10.115785  4932 solver.cpp:240] Iteration 7700, loss = 0.0435191
I0109 19:39:10.115881  4932 solver.cpp:255]     Train net output #0: loss = 0.0187552 (* 1 = 0.0187552 loss)
I0109 19:39:10.115893  4932 solver.cpp:631] Iteration 7700, lr = 0.0001
I0109 19:39:48.989356  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3732 > 20) by scale factor 0.855681
I0109 19:39:55.312115  4932 solver.cpp:240] Iteration 7720, loss = 0.114729
I0109 19:39:55.312149  4932 solver.cpp:255]     Train net output #0: loss = 0.209692 (* 1 = 0.209692 loss)
I0109 19:39:55.312158  4932 solver.cpp:631] Iteration 7720, lr = 0.0001
I0109 19:40:05.306442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1777 > 20) by scale factor 0.991191
I0109 19:40:31.943912  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8972 > 20) by scale factor 0.957066
I0109 19:40:40.832288  4932 solver.cpp:240] Iteration 7740, loss = 0.0656216
I0109 19:40:40.832326  4932 solver.cpp:255]     Train net output #0: loss = 0.114336 (* 1 = 0.114336 loss)
I0109 19:40:40.832335  4932 solver.cpp:631] Iteration 7740, lr = 0.0001
I0109 19:41:10.025020  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6877 > 20) by scale factor 0.922181
I0109 19:41:26.321084  4932 solver.cpp:240] Iteration 7760, loss = 0.0731473
I0109 19:41:26.321130  4932 solver.cpp:255]     Train net output #0: loss = 0.0619031 (* 1 = 0.0619031 loss)
I0109 19:41:26.321141  4932 solver.cpp:631] Iteration 7760, lr = 0.0001
I0109 19:42:11.301970  4932 solver.cpp:240] Iteration 7780, loss = 0.0878699
I0109 19:42:11.302069  4932 solver.cpp:255]     Train net output #0: loss = 0.432846 (* 1 = 0.432846 loss)
I0109 19:42:11.302084  4932 solver.cpp:631] Iteration 7780, lr = 0.0001
I0109 19:42:11.642544  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.4394 > 20) by scale factor 0.616534
I0109 19:42:24.957442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6929 > 20) by scale factor 0.966517
I0109 19:42:29.399572  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5964 > 20) by scale factor 0.885098
I0109 19:42:51.601269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4523 > 20) by scale factor 0.890777
I0109 19:42:55.700637  4932 solver.cpp:240] Iteration 7800, loss = 0.0895827
I0109 19:42:55.700670  4932 solver.cpp:255]     Train net output #0: loss = 0.218718 (* 1 = 0.218718 loss)
I0109 19:42:55.700677  4932 solver.cpp:631] Iteration 7800, lr = 0.0001
I0109 19:43:41.271303  4932 solver.cpp:240] Iteration 7820, loss = 0.0525767
I0109 19:43:41.271404  4932 solver.cpp:255]     Train net output #0: loss = 0.013664 (* 1 = 0.013664 loss)
I0109 19:43:41.271415  4932 solver.cpp:631] Iteration 7820, lr = 0.0001
I0109 19:43:54.925176  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6333 > 20) by scale factor 0.811909
I0109 19:44:26.412740  4932 solver.cpp:240] Iteration 7840, loss = 0.0723592
I0109 19:44:26.412830  4932 solver.cpp:255]     Train net output #0: loss = 0.0385833 (* 1 = 0.0385833 loss)
I0109 19:44:26.412842  4932 solver.cpp:631] Iteration 7840, lr = 0.0001
I0109 19:44:49.371290  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9731 > 20) by scale factor 0.953601
I0109 19:44:51.592447  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7357 > 20) by scale factor 0.777131
I0109 19:45:11.230638  4932 solver.cpp:240] Iteration 7860, loss = 0.0825673
I0109 19:45:11.230733  4932 solver.cpp:255]     Train net output #0: loss = 0.129274 (* 1 = 0.129274 loss)
I0109 19:45:11.230746  4932 solver.cpp:631] Iteration 7860, lr = 0.0001
I0109 19:45:38.243391  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1432 > 20) by scale factor 0.686267
I0109 19:45:47.120533  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 39.8503 > 20) by scale factor 0.501878
I0109 19:45:55.659446  4932 solver.cpp:240] Iteration 7880, loss = 0.134518
I0109 19:45:55.659482  4932 solver.cpp:255]     Train net output #0: loss = 0.255815 (* 1 = 0.255815 loss)
I0109 19:45:55.659492  4932 solver.cpp:631] Iteration 7880, lr = 0.0001
I0109 19:45:55.998785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4436 > 20) by scale factor 0.93268
I0109 19:46:02.657423  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0175 > 20) by scale factor 0.832725
I0109 19:46:04.881484  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4797 > 20) by scale factor 0.889692
I0109 19:46:32.191751  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3616 > 20) by scale factor 0.637722
I0109 19:46:34.412549  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0303 > 20) by scale factor 0.665995
I0109 19:46:38.857328  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6436 > 20) by scale factor 0.75065
I0109 19:46:40.739958  4932 solver.cpp:240] Iteration 7900, loss = 0.145303
I0109 19:46:40.740002  4932 solver.cpp:255]     Train net output #0: loss = 0.396144 (* 1 = 0.396144 loss)
I0109 19:46:40.740013  4932 solver.cpp:631] Iteration 7900, lr = 0.0001
I0109 19:47:26.116672  4932 solver.cpp:240] Iteration 7920, loss = 0.0649499
I0109 19:47:26.116768  4932 solver.cpp:255]     Train net output #0: loss = 0.0507244 (* 1 = 0.0507244 loss)
I0109 19:47:26.116780  4932 solver.cpp:631] Iteration 7920, lr = 0.0001
I0109 19:47:40.458348  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1039 > 20) by scale factor 0.947693
I0109 19:48:11.195963  4932 solver.cpp:240] Iteration 7940, loss = 0.0826964
I0109 19:48:11.196050  4932 solver.cpp:255]     Train net output #0: loss = 0.0178318 (* 1 = 0.0178318 loss)
I0109 19:48:11.196063  4932 solver.cpp:631] Iteration 7940, lr = 0.0001
I0109 19:48:17.169054  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.462 > 20) by scale factor 0.563984
I0109 19:48:28.265255  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5538 > 20) by scale factor 0.886769
I0109 19:48:39.365751  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.7252 > 20) by scale factor 0.559828
I0109 19:48:41.589336  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4063 > 20) by scale factor 0.787205
I0109 19:48:57.676653  4932 solver.cpp:240] Iteration 7960, loss = 0.13298
I0109 19:48:57.676695  4932 solver.cpp:255]     Train net output #0: loss = 0.0662841 (* 1 = 0.0662841 loss)
I0109 19:48:57.676704  4932 solver.cpp:631] Iteration 7960, lr = 0.0001
I0109 19:49:24.647315  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3529 > 20) by scale factor 0.821257
I0109 19:49:42.832319  4932 solver.cpp:240] Iteration 7980, loss = 0.108613
I0109 19:49:42.832360  4932 solver.cpp:255]     Train net output #0: loss = 0.0170127 (* 1 = 0.0170127 loss)
I0109 19:49:42.832370  4932 solver.cpp:631] Iteration 7980, lr = 0.0001
I0109 19:49:58.709400  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0662 > 20) by scale factor 0.797887
I0109 19:50:00.930868  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9505 > 20) by scale factor 0.690835
I0109 19:50:05.921658  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7248 > 20) by scale factor 0.696263
I0109 19:50:21.455873  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0895 > 20) by scale factor 0.797146
I0109 19:50:25.899266  4932 solver.cpp:424] Iteration 8000, Testing net (#0)
I0109 19:51:19.744076  4932 solver.cpp:481]     Test net output #0: accuracy = 0.810526
I0109 19:51:19.744189  4932 solver.cpp:481]     Test net output #1: loss = 0.890854 (* 1 = 0.890854 loss)
I0109 19:51:21.610853  4932 solver.cpp:240] Iteration 8000, loss = 0.074267
I0109 19:51:21.610891  4932 solver.cpp:255]     Train net output #0: loss = 0.0049541 (* 1 = 0.0049541 loss)
I0109 19:51:21.610900  4932 solver.cpp:631] Iteration 8000, lr = 0.0001
I0109 19:51:28.609397  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6765 > 20) by scale factor 0.967282
I0109 19:51:35.267923  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9649 > 20) by scale factor 0.801125
I0109 19:51:59.675232  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9562 > 20) by scale factor 0.741945
I0109 19:52:06.321987  4932 solver.cpp:240] Iteration 8020, loss = 0.0897599
I0109 19:52:06.322023  4932 solver.cpp:255]     Train net output #0: loss = 0.024404 (* 1 = 0.024404 loss)
I0109 19:52:06.322034  4932 solver.cpp:631] Iteration 8020, lr = 0.0001
I0109 19:52:08.879958  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7046 > 20) by scale factor 0.921464
I0109 19:52:31.075423  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3924 > 20) by scale factor 0.787638
I0109 19:52:38.463177  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5527 > 20) by scale factor 0.814576
I0109 19:52:51.442819  4932 solver.cpp:240] Iteration 8040, loss = 0.0907751
I0109 19:52:51.442857  4932 solver.cpp:255]     Train net output #0: loss = 0.337706 (* 1 = 0.337706 loss)
I0109 19:52:51.442867  4932 solver.cpp:631] Iteration 8040, lr = 0.0001
I0109 19:53:36.668329  4932 solver.cpp:240] Iteration 8060, loss = 0.0989462
I0109 19:53:36.668422  4932 solver.cpp:255]     Train net output #0: loss = 0.0303779 (* 1 = 0.0303779 loss)
I0109 19:53:36.668436  4932 solver.cpp:631] Iteration 8060, lr = 0.0001
I0109 19:53:45.893132  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.798 > 20) by scale factor 0.917514
I0109 19:53:51.213636  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8672 > 20) by scale factor 0.874615
I0109 19:54:21.934648  4932 solver.cpp:240] Iteration 8080, loss = 0.0693191
I0109 19:54:21.934715  4932 solver.cpp:255]     Train net output #0: loss = 0.0264935 (* 1 = 0.0264935 loss)
I0109 19:54:21.934725  4932 solver.cpp:631] Iteration 8080, lr = 0.0001
I0109 19:54:31.629070  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5424 > 20) by scale factor 0.973596
I0109 19:54:49.386345  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7134 > 20) by scale factor 0.809276
I0109 19:55:00.483842  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 38.2297 > 20) by scale factor 0.523153
I0109 19:55:05.553208  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4726 > 20) by scale factor 0.931418
I0109 19:55:07.434662  4932 solver.cpp:240] Iteration 8100, loss = 0.0942702
I0109 19:55:07.434701  4932 solver.cpp:255]     Train net output #0: loss = 0.115961 (* 1 = 0.115961 loss)
I0109 19:55:07.434711  4932 solver.cpp:631] Iteration 8100, lr = 0.0001
I0109 19:55:45.507648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4419 > 20) by scale factor 0.786104
I0109 19:55:51.830329  4932 solver.cpp:240] Iteration 8120, loss = 0.065877
I0109 19:55:51.830368  4932 solver.cpp:255]     Train net output #0: loss = 0.211203 (* 1 = 0.211203 loss)
I0109 19:55:51.830379  4932 solver.cpp:631] Iteration 8120, lr = 0.0001
I0109 19:56:21.893869  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3238 > 20) by scale factor 0.731962
I0109 19:56:37.087407  4932 solver.cpp:240] Iteration 8140, loss = 0.0940382
I0109 19:56:37.087453  4932 solver.cpp:255]     Train net output #0: loss = 0.140889 (* 1 = 0.140889 loss)
I0109 19:56:37.087465  4932 solver.cpp:631] Iteration 8140, lr = 0.0001
I0109 19:57:15.243913  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0736 > 20) by scale factor 0.797653
I0109 19:57:21.562610  4932 solver.cpp:240] Iteration 8160, loss = 0.0573248
I0109 19:57:21.562645  4932 solver.cpp:255]     Train net output #0: loss = 0.198699 (* 1 = 0.198699 loss)
I0109 19:57:21.562654  4932 solver.cpp:631] Iteration 8160, lr = 0.0001
I0109 19:57:27.238410  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2565 > 20) by scale factor 0.94089
I0109 19:57:29.459799  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6068 > 20) by scale factor 0.970555
I0109 19:57:36.122752  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9568 > 20) by scale factor 0.770512
I0109 19:58:07.617203  4932 solver.cpp:240] Iteration 8180, loss = 0.127033
I0109 19:58:07.617298  4932 solver.cpp:255]     Train net output #0: loss = 0.198867 (* 1 = 0.198867 loss)
I0109 19:58:07.617311  4932 solver.cpp:631] Iteration 8180, lr = 0.0001
I0109 19:58:23.491271  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.546 > 20) by scale factor 0.973427
I0109 19:58:32.369453  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7313 > 20) by scale factor 0.748186
I0109 19:58:52.999213  4932 solver.cpp:240] Iteration 8200, loss = 0.11221
I0109 19:58:52.999311  4932 solver.cpp:255]     Train net output #0: loss = 0.193746 (* 1 = 0.193746 loss)
I0109 19:58:52.999323  4932 solver.cpp:631] Iteration 8200, lr = 0.0001
I0109 19:58:59.996964  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2615 > 20) by scale factor 0.859791
I0109 19:59:11.093204  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5524 > 20) by scale factor 0.676765
I0109 19:59:38.736868  4932 solver.cpp:240] Iteration 8220, loss = 0.109059
I0109 19:59:38.736953  4932 solver.cpp:255]     Train net output #0: loss = 0.0479933 (* 1 = 0.0479933 loss)
I0109 19:59:38.736965  4932 solver.cpp:631] Iteration 8220, lr = 0.0001
I0109 19:59:55.193172  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6242 > 20) by scale factor 0.751196
I0109 20:00:24.315330  4932 solver.cpp:240] Iteration 8240, loss = 0.0733954
I0109 20:00:24.315423  4932 solver.cpp:255]     Train net output #0: loss = 0.128773 (* 1 = 0.128773 loss)
I0109 20:00:24.315435  4932 solver.cpp:631] Iteration 8240, lr = 0.0001
I0109 20:00:37.969318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1068 > 20) by scale factor 0.947562
I0109 20:01:09.685175  4932 solver.cpp:240] Iteration 8260, loss = 0.0843365
I0109 20:01:09.685283  4932 solver.cpp:255]     Train net output #0: loss = 0.0329673 (* 1 = 0.0329673 loss)
I0109 20:01:09.685298  4932 solver.cpp:631] Iteration 8260, lr = 0.0001
I0109 20:01:25.561234  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0731 > 20) by scale factor 0.797668
I0109 20:01:35.034631  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.632 > 20) by scale factor 0.723799
I0109 20:01:48.349047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3523 > 20) by scale factor 0.856445
I0109 20:01:52.788205  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3658 > 20) by scale factor 0.894221
I0109 20:01:54.668893  4932 solver.cpp:240] Iteration 8280, loss = 0.128382
I0109 20:01:54.668926  4932 solver.cpp:255]     Train net output #0: loss = 0.0355513 (* 1 = 0.0355513 loss)
I0109 20:01:54.668933  4932 solver.cpp:631] Iteration 8280, lr = 0.0001
I0109 20:02:18.047828  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9172 > 20) by scale factor 0.743021
I0109 20:02:20.267559  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4433 > 20) by scale factor 0.818219
I0109 20:02:39.907596  4932 solver.cpp:240] Iteration 8300, loss = 0.074847
I0109 20:02:39.907649  4932 solver.cpp:255]     Train net output #0: loss = 0.0141992 (* 1 = 0.0141992 loss)
I0109 20:02:39.907668  4932 solver.cpp:631] Iteration 8300, lr = 0.0001
I0109 20:03:05.726825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9168 > 20) by scale factor 0.872722
I0109 20:03:25.998126  4932 solver.cpp:240] Iteration 8320, loss = 0.0691828
I0109 20:03:25.998167  4932 solver.cpp:255]     Train net output #0: loss = 0.177624 (* 1 = 0.177624 loss)
I0109 20:03:25.998177  4932 solver.cpp:631] Iteration 8320, lr = 0.0001
I0109 20:03:37.432322  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8929 > 20) by scale factor 0.873634
I0109 20:04:10.597110  4932 solver.cpp:240] Iteration 8340, loss = 0.0655163
I0109 20:04:10.597199  4932 solver.cpp:255]     Train net output #0: loss = 0.0164597 (* 1 = 0.0164597 loss)
I0109 20:04:10.597213  4932 solver.cpp:631] Iteration 8340, lr = 0.0001
I0109 20:04:31.629909  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5369 > 20) by scale factor 0.849728
I0109 20:04:51.601830  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8757 > 20) by scale factor 0.914254
I0109 20:04:55.702410  4932 solver.cpp:240] Iteration 8360, loss = 0.083679
I0109 20:04:55.702446  4932 solver.cpp:255]     Train net output #0: loss = 0.0411875 (* 1 = 0.0411875 loss)
I0109 20:04:55.702458  4932 solver.cpp:631] Iteration 8360, lr = 0.0001
I0109 20:05:07.140717  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2523 > 20) by scale factor 0.761838
I0109 20:05:29.341157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 41.9804 > 20) by scale factor 0.476413
I0109 20:05:38.840718  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.4782 > 20) by scale factor 0.615797
I0109 20:05:40.722496  4932 solver.cpp:240] Iteration 8380, loss = 0.106576
I0109 20:05:40.722534  4932 solver.cpp:255]     Train net output #0: loss = 0.0754812 (* 1 = 0.0754812 loss)
I0109 20:05:40.722543  4932 solver.cpp:631] Iteration 8380, lr = 0.0001
I0109 20:06:25.716212  4932 solver.cpp:240] Iteration 8400, loss = 0.0552594
I0109 20:06:25.716285  4932 solver.cpp:255]     Train net output #0: loss = 0.0122338 (* 1 = 0.0122338 loss)
I0109 20:06:25.716295  4932 solver.cpp:631] Iteration 8400, lr = 0.0001
I0109 20:06:41.588431  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4229 > 20) by scale factor 0.933581
I0109 20:07:00.219091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7008 > 20) by scale factor 0.881025
I0109 20:07:10.978901  4932 solver.cpp:240] Iteration 8420, loss = 0.0588802
I0109 20:07:10.978947  4932 solver.cpp:255]     Train net output #0: loss = 0.0126764 (* 1 = 0.0126764 loss)
I0109 20:07:10.979068  4932 solver.cpp:631] Iteration 8420, lr = 0.0001
I0109 20:07:34.350253  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5448 > 20) by scale factor 0.782938
I0109 20:07:41.009336  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9574 > 20) by scale factor 0.910856
I0109 20:07:56.210950  4932 solver.cpp:240] Iteration 8440, loss = 0.105042
I0109 20:07:56.210985  4932 solver.cpp:255]     Train net output #0: loss = 0.221381 (* 1 = 0.221381 loss)
I0109 20:07:56.210994  4932 solver.cpp:631] Iteration 8440, lr = 0.0001
I0109 20:07:56.550386  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7364 > 20) by scale factor 0.879646
I0109 20:08:41.788980  4932 solver.cpp:240] Iteration 8460, loss = 0.0664174
I0109 20:08:41.789067  4932 solver.cpp:255]     Train net output #0: loss = 0.0640805 (* 1 = 0.0640805 loss)
I0109 20:08:41.789079  4932 solver.cpp:631] Iteration 8460, lr = 0.0001
I0109 20:08:55.442934  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4488 > 20) by scale factor 0.785891
I0109 20:09:04.326557  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2353 > 20) by scale factor 0.762332
I0109 20:09:18.788048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.503 > 20) by scale factor 0.850954
I0109 20:09:27.331401  4932 solver.cpp:240] Iteration 8480, loss = 0.0701219
I0109 20:09:27.331441  4932 solver.cpp:255]     Train net output #0: loss = 0.0444526 (* 1 = 0.0444526 loss)
I0109 20:09:27.331451  4932 solver.cpp:631] Iteration 8480, lr = 0.0001
I0109 20:09:48.310550  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8994 > 20) by scale factor 0.956967
I0109 20:10:12.396311  4932 solver.cpp:240] Iteration 8500, loss = 0.0690361
I0109 20:10:12.396409  4932 solver.cpp:255]     Train net output #0: loss = 0.00192024 (* 1 = 0.00192024 loss)
I0109 20:10:12.396422  4932 solver.cpp:631] Iteration 8500, lr = 0.0001
I0109 20:10:24.412997  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5297 > 20) by scale factor 0.783402
I0109 20:10:57.366309  4932 solver.cpp:240] Iteration 8520, loss = 0.0891935
I0109 20:10:57.366394  4932 solver.cpp:255]     Train net output #0: loss = 0.10029 (* 1 = 0.10029 loss)
I0109 20:10:57.366408  4932 solver.cpp:631] Iteration 8520, lr = 0.0001
I0109 20:11:15.461761  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1547 > 20) by scale factor 0.79508
I0109 20:11:24.343111  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6889 > 20) by scale factor 0.966701
I0109 20:11:41.772724  4932 solver.cpp:240] Iteration 8540, loss = 0.108564
I0109 20:11:41.772826  4932 solver.cpp:255]     Train net output #0: loss = 0.0816437 (* 1 = 0.0816437 loss)
I0109 20:11:41.772841  4932 solver.cpp:631] Iteration 8540, lr = 0.0001
I0109 20:11:53.209514  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.146 > 20) by scale factor 0.828296
I0109 20:12:18.242249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3616 > 20) by scale factor 0.982242
I0109 20:12:26.780880  4932 solver.cpp:240] Iteration 8560, loss = 0.0645646
I0109 20:12:26.780932  4932 solver.cpp:255]     Train net output #0: loss = 0.0624768 (* 1 = 0.0624768 loss)
I0109 20:12:26.780951  4932 solver.cpp:631] Iteration 8560, lr = 0.0001
I0109 20:12:42.658406  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.554 > 20) by scale factor 0.849111
I0109 20:12:56.354825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.569 > 20) by scale factor 0.725452
I0109 20:13:11.560806  4932 solver.cpp:240] Iteration 8580, loss = 0.106679
I0109 20:13:11.560848  4932 solver.cpp:255]     Train net output #0: loss = 0.00884202 (* 1 = 0.00884202 loss)
I0109 20:13:11.560863  4932 solver.cpp:631] Iteration 8580, lr = 0.0001
I0109 20:13:18.554710  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3776 > 20) by scale factor 0.704782
I0109 20:13:41.840641  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3249 > 20) by scale factor 0.937872
I0109 20:13:57.030722  4932 solver.cpp:240] Iteration 8600, loss = 0.0789647
I0109 20:13:57.030762  4932 solver.cpp:255]     Train net output #0: loss = 0.0457951 (* 1 = 0.0457951 loss)
I0109 20:13:57.030772  4932 solver.cpp:631] Iteration 8600, lr = 0.0001
I0109 20:14:40.554093  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7112 > 20) by scale factor 0.965662
I0109 20:14:42.437031  4932 solver.cpp:240] Iteration 8620, loss = 0.0746261
I0109 20:14:42.437069  4932 solver.cpp:255]     Train net output #0: loss = 0.146967 (* 1 = 0.146967 loss)
I0109 20:14:42.437078  4932 solver.cpp:631] Iteration 8620, lr = 0.0001
I0109 20:14:42.776638  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7484 > 20) by scale factor 0.720763
I0109 20:15:03.703308  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5176 > 20) by scale factor 0.974774
I0109 20:15:27.776980  4932 solver.cpp:240] Iteration 8640, loss = 0.107413
I0109 20:15:27.777092  4932 solver.cpp:255]     Train net output #0: loss = 0.0932039 (* 1 = 0.0932039 loss)
I0109 20:15:27.777108  4932 solver.cpp:631] Iteration 8640, lr = 0.0001
I0109 20:15:34.774600  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3092 > 20) by scale factor 0.858031
I0109 20:16:12.623102  4932 solver.cpp:240] Iteration 8660, loss = 0.100367
I0109 20:16:12.623196  4932 solver.cpp:255]     Train net output #0: loss = 0.0325966 (* 1 = 0.0325966 loss)
I0109 20:16:12.623208  4932 solver.cpp:631] Iteration 8660, lr = 0.0001
I0109 20:16:35.162729  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8582 > 20) by scale factor 0.874958
I0109 20:16:57.544926  4932 solver.cpp:240] Iteration 8680, loss = 0.0870106
I0109 20:16:57.545024  4932 solver.cpp:255]     Train net output #0: loss = 0.00508464 (* 1 = 0.00508464 loss)
I0109 20:16:57.545038  4932 solver.cpp:631] Iteration 8680, lr = 0.0001
I0109 20:17:02.319669  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1316 > 20) by scale factor 0.946449
I0109 20:17:20.080649  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6407 > 20) by scale factor 0.780011
I0109 20:17:22.301573  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0479 > 20) by scale factor 0.950214
I0109 20:17:34.096352  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6016 > 20) by scale factor 0.847399
I0109 20:17:42.642933  4932 solver.cpp:240] Iteration 8700, loss = 0.12799
I0109 20:17:42.642979  4932 solver.cpp:255]     Train net output #0: loss = 0.0278895 (* 1 = 0.0278895 loss)
I0109 20:17:42.642990  4932 solver.cpp:631] Iteration 8700, lr = 0.0001
I0109 20:18:14.751518  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5458 > 20) by scale factor 0.849408
I0109 20:18:27.728487  4932 solver.cpp:240] Iteration 8720, loss = 0.082536
I0109 20:18:27.728525  4932 solver.cpp:255]     Train net output #0: loss = 0.208933 (* 1 = 0.208933 loss)
I0109 20:18:27.728533  4932 solver.cpp:631] Iteration 8720, lr = 0.0001
I0109 20:18:46.577841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0221 > 20) by scale factor 0.768576
I0109 20:19:02.119894  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0369 > 20) by scale factor 0.907569
I0109 20:19:12.877545  4932 solver.cpp:240] Iteration 8740, loss = 0.091441
I0109 20:19:12.877589  4932 solver.cpp:255]     Train net output #0: loss = 0.0802708 (* 1 = 0.0802708 loss)
I0109 20:19:12.877710  4932 solver.cpp:631] Iteration 8740, lr = 0.0001
I0109 20:19:27.385697  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.72 > 20) by scale factor 0.96525
I0109 20:19:58.117785  4932 solver.cpp:240] Iteration 8760, loss = 0.080415
I0109 20:19:58.117875  4932 solver.cpp:255]     Train net output #0: loss = 0.00599536 (* 1 = 0.00599536 loss)
I0109 20:19:58.117887  4932 solver.cpp:631] Iteration 8760, lr = 0.0001
I0109 20:20:13.992478  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.392 > 20) by scale factor 0.934931
I0109 20:20:34.469491  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9262 > 20) by scale factor 0.955741
I0109 20:20:43.007618  4932 solver.cpp:240] Iteration 8780, loss = 0.0736076
I0109 20:20:43.007654  4932 solver.cpp:255]     Train net output #0: loss = 0.0523502 (* 1 = 0.0523502 loss)
I0109 20:20:43.007663  4932 solver.cpp:631] Iteration 8780, lr = 0.0001
I0109 20:20:50.000092  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6875 > 20) by scale factor 0.966766
I0109 20:21:08.484257  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0607 > 20) by scale factor 0.76744
I0109 20:21:28.114588  4932 solver.cpp:240] Iteration 8800, loss = 0.0705396
I0109 20:21:28.114621  4932 solver.cpp:255]     Train net output #0: loss = 0.020459 (* 1 = 0.020459 loss)
I0109 20:21:28.114630  4932 solver.cpp:631] Iteration 8800, lr = 0.0001
I0109 20:21:49.133601  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8013 > 20) by scale factor 0.806408
I0109 20:22:02.454143  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7484 > 20) by scale factor 0.842162
I0109 20:22:13.206267  4932 solver.cpp:240] Iteration 8820, loss = 0.0759665
I0109 20:22:13.206310  4932 solver.cpp:255]     Train net output #0: loss = 0.0639082 (* 1 = 0.0639082 loss)
I0109 20:22:13.206321  4932 solver.cpp:631] Iteration 8820, lr = 0.0001
I0109 20:22:20.958467  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5881 > 20) by scale factor 0.971433
I0109 20:22:43.156358  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3521 > 20) by scale factor 0.856452
I0109 20:22:58.995085  4932 solver.cpp:240] Iteration 8840, loss = 0.0712028
I0109 20:22:58.995204  4932 solver.cpp:255]     Train net output #0: loss = 0.0258127 (* 1 = 0.0258127 loss)
I0109 20:22:58.995223  4932 solver.cpp:631] Iteration 8840, lr = 0.0001
I0109 20:23:43.380201  4932 solver.cpp:240] Iteration 8860, loss = 0.0628228
I0109 20:23:43.380295  4932 solver.cpp:255]     Train net output #0: loss = 0.0243205 (* 1 = 0.0243205 loss)
I0109 20:23:43.380307  4932 solver.cpp:631] Iteration 8860, lr = 0.0001
I0109 20:23:57.036931  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8495 > 20) by scale factor 0.838593
I0109 20:24:14.917979  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6776 > 20) by scale factor 0.92261
I0109 20:24:26.013787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7507 > 20) by scale factor 0.808057
I0109 20:24:27.895349  4932 solver.cpp:240] Iteration 8880, loss = 0.0926209
I0109 20:24:27.895386  4932 solver.cpp:255]     Train net output #0: loss = 0.0369124 (* 1 = 0.0369124 loss)
I0109 20:24:27.895396  4932 solver.cpp:631] Iteration 8880, lr = 0.0001
I0109 20:24:43.767273  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8357 > 20) by scale factor 0.774122
I0109 20:24:48.208482  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2943 > 20) by scale factor 0.985501
I0109 20:25:07.095816  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4247 > 20) by scale factor 0.933501
I0109 20:25:13.420500  4932 solver.cpp:240] Iteration 8900, loss = 0.132429
I0109 20:25:13.420544  4932 solver.cpp:255]     Train net output #0: loss = 0.0528363 (* 1 = 0.0528363 loss)
I0109 20:25:13.420555  4932 solver.cpp:631] Iteration 8900, lr = 0.0001
I0109 20:25:39.070169  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7381 > 20) by scale factor 0.879582
I0109 20:25:58.701519  4932 solver.cpp:240] Iteration 8920, loss = 0.0568526
I0109 20:25:58.701553  4932 solver.cpp:255]     Train net output #0: loss = 0.0295719 (* 1 = 0.0295719 loss)
I0109 20:25:58.701562  4932 solver.cpp:631] Iteration 8920, lr = 0.0001
I0109 20:26:05.702708  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6911 > 20) by scale factor 0.881405
I0109 20:26:23.452633  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7185 > 20) by scale factor 0.72154
I0109 20:26:43.481159  4932 solver.cpp:240] Iteration 8940, loss = 0.0763979
I0109 20:26:43.481197  4932 solver.cpp:255]     Train net output #0: loss = 0.0355986 (* 1 = 0.0355986 loss)
I0109 20:26:43.481207  4932 solver.cpp:631] Iteration 8940, lr = 0.0001
I0109 20:27:14.981393  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3444 > 20) by scale factor 0.937015
I0109 20:27:17.201408  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5774 > 20) by scale factor 0.699854
I0109 20:27:26.087210  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2498 > 20) by scale factor 0.792084
I0109 20:27:27.969074  4932 solver.cpp:240] Iteration 8960, loss = 0.106986
I0109 20:27:27.969106  4932 solver.cpp:255]     Train net output #0: loss = 0.0183514 (* 1 = 0.0183514 loss)
I0109 20:27:28.210108  4932 solver.cpp:631] Iteration 8960, lr = 0.0001
I0109 20:27:44.797132  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2949 > 20) by scale factor 0.790675
I0109 20:27:53.671604  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2604 > 20) by scale factor 0.791753
I0109 20:28:14.179347  4932 solver.cpp:240] Iteration 8980, loss = 0.0950893
I0109 20:28:14.179385  4932 solver.cpp:255]     Train net output #0: loss = 0.0501086 (* 1 = 0.0501086 loss)
I0109 20:28:14.179394  4932 solver.cpp:631] Iteration 8980, lr = 0.0001
I0109 20:28:43.367118  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2358 > 20) by scale factor 0.825227
I0109 20:28:56.693075  4932 solver.cpp:424] Iteration 9000, Testing net (#0)
I0109 20:29:49.676728  4932 solver.cpp:481]     Test net output #0: accuracy = 0.810526
I0109 20:29:49.676816  4932 solver.cpp:481]     Test net output #1: loss = 1.00716 (* 1 = 1.00716 loss)
I0109 20:29:51.543423  4932 solver.cpp:240] Iteration 9000, loss = 0.0796736
I0109 20:29:51.543465  4932 solver.cpp:255]     Train net output #0: loss = 0.0244834 (* 1 = 0.0244834 loss)
I0109 20:29:51.543476  4932 solver.cpp:631] Iteration 9000, lr = 0.0001
I0109 20:29:58.539911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2475 > 20) by scale factor 0.898977
I0109 20:30:00.761030  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.2409 > 20) by scale factor 0.683975
I0109 20:30:07.427198  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1234 > 20) by scale factor 0.946818
I0109 20:30:09.649950  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4422 > 20) by scale factor 0.93274
I0109 20:30:36.698149  4932 solver.cpp:240] Iteration 9020, loss = 0.098701
I0109 20:30:36.698252  4932 solver.cpp:255]     Train net output #0: loss = 0.0979878 (* 1 = 0.0979878 loss)
I0109 20:30:36.698266  4932 solver.cpp:631] Iteration 9020, lr = 0.0001
I0109 20:30:39.261854  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7092 > 20) by scale factor 0.965753
I0109 20:30:43.705780  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6486 > 20) by scale factor 0.923849
I0109 20:31:21.865638  4932 solver.cpp:240] Iteration 9040, loss = 0.110825
I0109 20:31:21.865736  4932 solver.cpp:255]     Train net output #0: loss = 0.092179 (* 1 = 0.092179 loss)
I0109 20:31:21.865747  4932 solver.cpp:631] Iteration 9040, lr = 0.0001
I0109 20:31:51.054919  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2999 > 20) by scale factor 0.985227
I0109 20:32:07.345038  4932 solver.cpp:240] Iteration 9060, loss = 0.100848
I0109 20:32:07.345167  4932 solver.cpp:255]     Train net output #0: loss = 0.119193 (* 1 = 0.119193 loss)
I0109 20:32:07.345183  4932 solver.cpp:631] Iteration 9060, lr = 0.0001
I0109 20:32:34.313390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3604 > 20) by scale factor 0.85615
I0109 20:32:43.792508  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4718 > 20) by scale factor 0.976953
I0109 20:32:50.452160  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3323 > 20) by scale factor 0.937544
I0109 20:32:52.334699  4932 solver.cpp:240] Iteration 9080, loss = 0.0961196
I0109 20:32:52.334745  4932 solver.cpp:255]     Train net output #0: loss = 0.0134742 (* 1 = 0.0134742 loss)
I0109 20:32:52.334758  4932 solver.cpp:631] Iteration 9080, lr = 0.0001
I0109 20:32:59.333603  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.428 > 20) by scale factor 0.979047
I0109 20:33:22.499568  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0424 > 20) by scale factor 0.950462
I0109 20:33:29.166200  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9537 > 20) by scale factor 0.801484
I0109 20:33:37.703591  4932 solver.cpp:240] Iteration 9100, loss = 0.0849024
I0109 20:33:37.703622  4932 solver.cpp:255]     Train net output #0: loss = 0.0539422 (* 1 = 0.0539422 loss)
I0109 20:33:37.703631  4932 solver.cpp:631] Iteration 9100, lr = 0.0001
I0109 20:33:56.427340  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2486 > 20) by scale factor 0.898935
I0109 20:34:00.872186  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.344 > 20) by scale factor 0.821558
I0109 20:34:11.970760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8691 > 20) by scale factor 0.914534
I0109 20:34:22.729651  4932 solver.cpp:240] Iteration 9120, loss = 0.112056
I0109 20:34:22.729689  4932 solver.cpp:255]     Train net output #0: loss = 0.0462047 (* 1 = 0.0462047 loss)
I0109 20:34:22.729698  4932 solver.cpp:631] Iteration 9120, lr = 0.0001
I0109 20:34:48.242507  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.582 > 20) by scale factor 0.926699
I0109 20:35:08.805603  4932 solver.cpp:240] Iteration 9140, loss = 0.0467911
I0109 20:35:08.805647  4932 solver.cpp:255]     Train net output #0: loss = 0.012093 (* 1 = 0.012093 loss)
I0109 20:35:08.805660  4932 solver.cpp:631] Iteration 9140, lr = 0.0001
I0109 20:35:11.365813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5979 > 20) by scale factor 0.813078
I0109 20:35:31.337538  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5607 > 20) by scale factor 0.972728
I0109 20:35:53.581555  4932 solver.cpp:240] Iteration 9160, loss = 0.0794289
I0109 20:35:53.581593  4932 solver.cpp:255]     Train net output #0: loss = 0.255836 (* 1 = 0.255836 loss)
I0109 20:35:53.581604  4932 solver.cpp:631] Iteration 9160, lr = 0.0001
I0109 20:35:53.922147  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.688 > 20) by scale factor 0.722335
I0109 20:36:00.581542  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7351 > 20) by scale factor 0.808569
I0109 20:36:18.981614  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.368 > 20) by scale factor 0.894133
I0109 20:36:23.418956  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7235 > 20) by scale factor 0.880148
I0109 20:36:38.615123  4932 solver.cpp:240] Iteration 9180, loss = 0.102723
I0109 20:36:38.615175  4932 solver.cpp:255]     Train net output #0: loss = 0.0247079 (* 1 = 0.0247079 loss)
I0109 20:36:38.615186  4932 solver.cpp:631] Iteration 9180, lr = 0.0001
I0109 20:36:47.837535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3526 > 20) by scale factor 0.982677
I0109 20:36:57.118566  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4063 > 20) by scale factor 0.892608
I0109 20:37:23.420928  4932 solver.cpp:240] Iteration 9200, loss = 0.0813502
I0109 20:37:23.420967  4932 solver.cpp:255]     Train net output #0: loss = 0.127425 (* 1 = 0.127425 loss)
I0109 20:37:23.420976  4932 solver.cpp:631] Iteration 9200, lr = 0.0001
I0109 20:37:58.151832  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3351 > 20) by scale factor 0.759443
I0109 20:38:08.903986  4932 solver.cpp:240] Iteration 9220, loss = 0.0779522
I0109 20:38:08.904024  4932 solver.cpp:255]     Train net output #0: loss = 0.00119137 (* 1 = 0.00119137 loss)
I0109 20:38:08.904032  4932 solver.cpp:631] Iteration 9220, lr = 0.0001
I0109 20:38:27.000170  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0524 > 20) by scale factor 0.906932
I0109 20:38:36.847944  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6293 > 20) by scale factor 0.698586
I0109 20:38:39.070211  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6873 > 20) by scale factor 0.966776
I0109 20:38:47.951813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3361 > 20) by scale factor 0.705814
I0109 20:38:54.274852  4932 solver.cpp:240] Iteration 9240, loss = 0.108276
I0109 20:38:54.274893  4932 solver.cpp:255]     Train net output #0: loss = 0.060748 (* 1 = 0.060748 loss)
I0109 20:38:54.274902  4932 solver.cpp:631] Iteration 9240, lr = 0.0001
I0109 20:39:19.853468  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6676 > 20) by scale factor 0.9677
I0109 20:39:28.733963  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7127 > 20) by scale factor 0.96559
I0109 20:39:39.494308  4932 solver.cpp:240] Iteration 9260, loss = 0.0590886
I0109 20:39:39.494341  4932 solver.cpp:255]     Train net output #0: loss = 0.00812895 (* 1 = 0.00812895 loss)
I0109 20:39:39.494350  4932 solver.cpp:631] Iteration 9260, lr = 0.0001
I0109 20:39:49.257284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9987 > 20) by scale factor 0.95244
I0109 20:40:13.672595  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9577 > 20) by scale factor 0.910842
I0109 20:40:24.907786  4932 solver.cpp:240] Iteration 9280, loss = 0.116384
I0109 20:40:24.907825  4932 solver.cpp:255]     Train net output #0: loss = 0.135057 (* 1 = 0.135057 loss)
I0109 20:40:24.927567  4932 solver.cpp:631] Iteration 9280, lr = 0.0001
I0109 20:41:09.299695  4932 solver.cpp:240] Iteration 9300, loss = 0.0618723
I0109 20:41:09.299787  4932 solver.cpp:255]     Train net output #0: loss = 0.029257 (* 1 = 0.029257 loss)
I0109 20:41:09.319254  4932 solver.cpp:631] Iteration 9300, lr = 0.0001
I0109 20:41:55.007732  4932 solver.cpp:240] Iteration 9320, loss = 0.0759077
I0109 20:41:55.007825  4932 solver.cpp:255]     Train net output #0: loss = 0.115018 (* 1 = 0.115018 loss)
I0109 20:41:55.007839  4932 solver.cpp:631] Iteration 9320, lr = 0.0001
I0109 20:42:08.662863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6502 > 20) by scale factor 0.811352
I0109 20:42:37.523427  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0983 > 20) by scale factor 0.905049
I0109 20:42:39.405068  4932 solver.cpp:240] Iteration 9340, loss = 0.079423
I0109 20:42:39.405107  4932 solver.cpp:255]     Train net output #0: loss = 0.0958938 (* 1 = 0.0958938 loss)
I0109 20:42:39.405117  4932 solver.cpp:631] Iteration 9340, lr = 0.0001
I0109 20:42:48.622850  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0603 > 20) by scale factor 0.996995
I0109 20:42:50.843608  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.686 > 20) by scale factor 0.844379
I0109 20:43:24.478940  4932 solver.cpp:240] Iteration 9360, loss = 0.0896775
I0109 20:43:24.479055  4932 solver.cpp:255]     Train net output #0: loss = 0.122348 (* 1 = 0.122348 loss)
I0109 20:43:24.479074  4932 solver.cpp:631] Iteration 9360, lr = 0.0001
I0109 20:43:56.232419  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.248 > 20) by scale factor 0.987753
I0109 20:44:02.903201  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9689 > 20) by scale factor 0.645809
I0109 20:44:05.127030  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9225 > 20) by scale factor 0.912305
I0109 20:44:09.229396  4932 solver.cpp:240] Iteration 9380, loss = 0.130359
I0109 20:44:09.229434  4932 solver.cpp:255]     Train net output #0: loss = 0.00464483 (* 1 = 0.00464483 loss)
I0109 20:44:09.229444  4932 solver.cpp:631] Iteration 9380, lr = 0.0001
I0109 20:44:14.004298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9171 > 20) by scale factor 0.912531
I0109 20:44:54.305781  4932 solver.cpp:240] Iteration 9400, loss = 0.0705492
I0109 20:44:54.305876  4932 solver.cpp:255]     Train net output #0: loss = 0.00908076 (* 1 = 0.00908076 loss)
I0109 20:44:54.305889  4932 solver.cpp:631] Iteration 9400, lr = 0.0001
I0109 20:45:38.848590  4932 solver.cpp:240] Iteration 9420, loss = 0.0923115
I0109 20:45:38.848685  4932 solver.cpp:255]     Train net output #0: loss = 0.0823732 (* 1 = 0.0823732 loss)
I0109 20:45:38.848697  4932 solver.cpp:631] Iteration 9420, lr = 0.0001
I0109 20:45:43.626200  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3682 > 20) by scale factor 0.855865
I0109 20:46:08.046121  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7986 > 20) by scale factor 0.806498
I0109 20:46:19.140743  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1245 > 20) by scale factor 0.737341
I0109 20:46:23.243261  4932 solver.cpp:240] Iteration 9440, loss = 0.0961936
I0109 20:46:23.243296  4932 solver.cpp:255]     Train net output #0: loss = 0.0902046 (* 1 = 0.0902046 loss)
I0109 20:46:23.243305  4932 solver.cpp:631] Iteration 9440, lr = 0.0001
I0109 20:46:30.239933  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.142 > 20) by scale factor 0.864228
I0109 20:46:59.862387  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5765 > 20) by scale factor 0.97198
I0109 20:47:08.407392  4932 solver.cpp:240] Iteration 9460, loss = 0.107947
I0109 20:47:08.407431  4932 solver.cpp:255]     Train net output #0: loss = 0.00542678 (* 1 = 0.00542678 loss)
I0109 20:47:08.407440  4932 solver.cpp:631] Iteration 9460, lr = 0.0001
I0109 20:47:15.402050  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6894 > 20) by scale factor 0.96668
I0109 20:47:42.280623  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3675 > 20) by scale factor 0.981956
I0109 20:47:53.035845  4932 solver.cpp:240] Iteration 9480, loss = 0.0829486
I0109 20:47:53.035876  4932 solver.cpp:255]     Train net output #0: loss = 0.0100563 (* 1 = 0.0100563 loss)
I0109 20:47:53.035883  4932 solver.cpp:631] Iteration 9480, lr = 0.0001
I0109 20:48:11.832358  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1276 > 20) by scale factor 0.99366
I0109 20:48:29.598054  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4699 > 20) by scale factor 0.931536
I0109 20:48:38.928475  4932 solver.cpp:240] Iteration 9500, loss = 0.0905277
I0109 20:48:38.928509  4932 solver.cpp:255]     Train net output #0: loss = 0.0129687 (* 1 = 0.0129687 loss)
I0109 20:48:38.928517  4932 solver.cpp:631] Iteration 9500, lr = 0.0001
I0109 20:48:45.925945  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9698 > 20) by scale factor 0.910339
I0109 20:48:48.148005  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1929 > 20) by scale factor 0.82669
I0109 20:49:24.003726  4932 solver.cpp:240] Iteration 9520, loss = 0.0692382
I0109 20:49:24.003849  4932 solver.cpp:255]     Train net output #0: loss = 0.165811 (* 1 = 0.165811 loss)
I0109 20:49:24.003865  4932 solver.cpp:631] Iteration 9520, lr = 0.0001
I0109 20:50:00.334141  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6002 > 20) by scale factor 0.781243
I0109 20:50:02.560071  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3741 > 20) by scale factor 0.935711
I0109 20:50:09.359848  4932 solver.cpp:240] Iteration 9540, loss = 0.0643992
I0109 20:50:09.359889  4932 solver.cpp:255]     Train net output #0: loss = 0.0455808 (* 1 = 0.0455808 loss)
I0109 20:50:09.359899  4932 solver.cpp:631] Iteration 9540, lr = 0.0001
I0109 20:50:54.414778  4932 solver.cpp:240] Iteration 9560, loss = 0.0727965
I0109 20:50:54.414858  4932 solver.cpp:255]     Train net output #0: loss = 0.168586 (* 1 = 0.168586 loss)
I0109 20:50:54.414868  4932 solver.cpp:631] Iteration 9560, lr = 0.0001
I0109 20:51:39.340381  4932 solver.cpp:240] Iteration 9580, loss = 0.03987
I0109 20:51:39.340476  4932 solver.cpp:255]     Train net output #0: loss = 0.0687535 (* 1 = 0.0687535 loss)
I0109 20:51:39.340487  4932 solver.cpp:631] Iteration 9580, lr = 0.0001
I0109 20:51:59.894901  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.5276 > 20) by scale factor 0.562943
I0109 20:52:23.964515  4932 solver.cpp:240] Iteration 9600, loss = 0.0916807
I0109 20:52:23.964591  4932 solver.cpp:255]     Train net output #0: loss = 0.0831587 (* 1 = 0.0831587 loss)
I0109 20:52:23.964601  4932 solver.cpp:631] Iteration 9600, lr = 0.0001
I0109 20:52:30.965374  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1674 > 20) by scale factor 0.991701
I0109 20:53:06.490006  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.5434 > 20) by scale factor 0.634046
I0109 20:53:08.373906  4932 solver.cpp:240] Iteration 9620, loss = 0.0737182
I0109 20:53:08.373950  4932 solver.cpp:255]     Train net output #0: loss = 0.190979 (* 1 = 0.190979 loss)
I0109 20:53:08.373961  4932 solver.cpp:631] Iteration 9620, lr = 0.0001
I0109 20:53:53.085685  4932 solver.cpp:240] Iteration 9640, loss = 0.0539465
I0109 20:53:53.085788  4932 solver.cpp:255]     Train net output #0: loss = 0.172654 (* 1 = 0.172654 loss)
I0109 20:53:53.085803  4932 solver.cpp:631] Iteration 9640, lr = 0.0001
I0109 20:53:53.426332  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7139 > 20) by scale factor 0.965535
I0109 20:54:37.494770  4932 solver.cpp:240] Iteration 9660, loss = 0.0465282
I0109 20:54:37.494858  4932 solver.cpp:255]     Train net output #0: loss = 0.0160809 (* 1 = 0.0160809 loss)
I0109 20:54:37.494871  4932 solver.cpp:631] Iteration 9660, lr = 0.0001
I0109 20:54:48.936054  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4168 > 20) by scale factor 0.657532
I0109 20:55:08.919737  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1021 > 20) by scale factor 0.796746
I0109 20:55:11.144067  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8795 > 20) by scale factor 0.837539
I0109 20:55:21.904920  4932 solver.cpp:240] Iteration 9680, loss = 0.10551
I0109 20:55:21.904963  4932 solver.cpp:255]     Train net output #0: loss = 0.0651742 (* 1 = 0.0651742 loss)
I0109 20:55:21.904974  4932 solver.cpp:631] Iteration 9680, lr = 0.0001
I0109 20:55:35.565821  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5772 > 20) by scale factor 0.676197
I0109 20:56:06.892673  4932 solver.cpp:240] Iteration 9700, loss = 0.0898066
I0109 20:56:06.892783  4932 solver.cpp:255]     Train net output #0: loss = 0.00968784 (* 1 = 0.00968784 loss)
I0109 20:56:06.892798  4932 solver.cpp:631] Iteration 9700, lr = 0.0001
I0109 20:56:11.676380  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4914 > 20) by scale factor 0.88923
I0109 20:56:32.165776  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.5584 > 20) by scale factor 0.61428
I0109 20:56:51.962069  4932 solver.cpp:240] Iteration 9720, loss = 0.0940263
I0109 20:56:51.962205  4932 solver.cpp:255]     Train net output #0: loss = 0.170899 (* 1 = 0.170899 loss)
I0109 20:56:51.962220  4932 solver.cpp:631] Iteration 9720, lr = 0.0001
I0109 20:57:07.844962  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3338 > 20) by scale factor 0.821902
I0109 20:57:10.068338  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7156 > 20) by scale factor 0.696484
I0109 20:57:14.983731  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.8495 > 20) by scale factor 0.670027
I0109 20:57:23.862160  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4553 > 20) by scale factor 0.852685
I0109 20:57:36.835996  4932 solver.cpp:240] Iteration 9740, loss = 0.128425
I0109 20:57:36.836041  4932 solver.cpp:255]     Train net output #0: loss = 0.443706 (* 1 = 0.443706 loss)
I0109 20:57:36.836053  4932 solver.cpp:631] Iteration 9740, lr = 0.0001
I0109 20:57:37.176396  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6631 > 20) by scale factor 0.88249
I0109 20:57:43.835031  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1498 > 20) by scale factor 0.945636
I0109 20:57:52.713135  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3682 > 20) by scale factor 0.93597
I0109 20:58:21.223392  4932 solver.cpp:240] Iteration 9760, loss = 0.0775432
I0109 20:58:21.223496  4932 solver.cpp:255]     Train net output #0: loss = 0.0112672 (* 1 = 0.0112672 loss)
I0109 20:58:21.223510  4932 solver.cpp:631] Iteration 9760, lr = 0.0001
I0109 20:59:02.594604  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0184 > 20) by scale factor 0.951547
I0109 20:59:06.696868  4932 solver.cpp:240] Iteration 9780, loss = 0.0831908
I0109 20:59:06.696909  4932 solver.cpp:255]     Train net output #0: loss = 0.073298 (* 1 = 0.073298 loss)
I0109 20:59:06.696918  4932 solver.cpp:631] Iteration 9780, lr = 0.0001
I0109 20:59:31.442904  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2721 > 20) by scale factor 0.940199
I0109 20:59:51.600209  4932 solver.cpp:240] Iteration 9800, loss = 0.075036
I0109 20:59:51.600304  4932 solver.cpp:255]     Train net output #0: loss = 0.10744 (* 1 = 0.10744 loss)
I0109 20:59:51.600317  4932 solver.cpp:631] Iteration 9800, lr = 0.0001
I0109 21:00:36.450321  4932 solver.cpp:240] Iteration 9820, loss = 0.052345
I0109 21:00:36.450419  4932 solver.cpp:255]     Train net output #0: loss = 0.0195186 (* 1 = 0.0195186 loss)
I0109 21:00:36.450435  4932 solver.cpp:631] Iteration 9820, lr = 0.0001
I0109 21:01:21.283198  4932 solver.cpp:240] Iteration 9840, loss = 0.0409142
I0109 21:01:21.283296  4932 solver.cpp:255]     Train net output #0: loss = 0.0391558 (* 1 = 0.0391558 loss)
I0109 21:01:21.283308  4932 solver.cpp:631] Iteration 9840, lr = 0.0001
I0109 21:01:33.200698  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8907 > 20) by scale factor 0.913632
I0109 21:01:57.623821  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0186 > 20) by scale factor 0.95154
I0109 21:02:06.870261  4932 solver.cpp:240] Iteration 9860, loss = 0.114924
I0109 21:02:06.870309  4932 solver.cpp:255]     Train net output #0: loss = 0.00631507 (* 1 = 0.00631507 loss)
I0109 21:02:06.870321  4932 solver.cpp:631] Iteration 9860, lr = 0.0001
I0109 21:02:18.305658  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8268 > 20) by scale factor 0.805582
I0109 21:02:29.400972  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4056 > 20) by scale factor 0.980125
I0109 21:02:51.897789  4932 solver.cpp:240] Iteration 9880, loss = 0.0864852
I0109 21:02:51.897835  4932 solver.cpp:255]     Train net output #0: loss = 0.00699043 (* 1 = 0.00699043 loss)
I0109 21:02:51.897846  4932 solver.cpp:631] Iteration 9880, lr = 0.0001
I0109 21:03:09.993705  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8807 > 20) by scale factor 0.957823
I0109 21:03:18.874181  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1088 > 20) by scale factor 0.829572
I0109 21:03:23.320622  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3745 > 20) by scale factor 0.855633
I0109 21:03:36.297694  4932 solver.cpp:240] Iteration 9900, loss = 0.108831
I0109 21:03:36.297744  4932 solver.cpp:255]     Train net output #0: loss = 0.102053 (* 1 = 0.102053 loss)
I0109 21:03:36.297755  4932 solver.cpp:631] Iteration 9900, lr = 0.0001
I0109 21:03:36.638813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4973 > 20) by scale factor 0.975739
I0109 21:03:47.740290  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2008 > 20) by scale factor 0.7092
I0109 21:04:03.541481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6912 > 20) by scale factor 0.844195
I0109 21:04:05.761905  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5528 > 20) by scale factor 0.973104
I0109 21:04:20.963176  4932 solver.cpp:240] Iteration 9920, loss = 0.0708732
I0109 21:04:20.963273  4932 solver.cpp:255]     Train net output #0: loss = 0.126121 (* 1 = 0.126121 loss)
I0109 21:04:20.963285  4932 solver.cpp:631] Iteration 9920, lr = 0.0001
I0109 21:04:23.520292  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5735 > 20) by scale factor 0.782059
I0109 21:04:55.101454  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7508 > 20) by scale factor 0.842076
I0109 21:05:01.765663  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3314 > 20) by scale factor 0.821984
I0109 21:05:05.868660  4932 solver.cpp:240] Iteration 9940, loss = 0.105076
I0109 21:05:05.868698  4932 solver.cpp:255]     Train net output #0: loss = 0.176762 (* 1 = 0.176762 loss)
I0109 21:05:05.868707  4932 solver.cpp:631] Iteration 9940, lr = 0.0001
I0109 21:05:26.811996  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4969 > 20) by scale factor 0.975756
I0109 21:05:33.474741  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.833 > 20) by scale factor 0.960013
I0109 21:05:37.916326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6625 > 20) by scale factor 0.923253
I0109 21:05:51.539417  4932 solver.cpp:240] Iteration 9960, loss = 0.0956573
I0109 21:05:51.539458  4932 solver.cpp:255]     Train net output #0: loss = 0.104917 (* 1 = 0.104917 loss)
I0109 21:05:51.539466  4932 solver.cpp:631] Iteration 9960, lr = 0.0001
I0109 21:06:05.198416  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2123 > 20) by scale factor 0.942849
I0109 21:06:36.221441  4932 solver.cpp:240] Iteration 9980, loss = 0.0782343
I0109 21:06:36.221534  4932 solver.cpp:255]     Train net output #0: loss = 0.0390092 (* 1 = 0.0390092 loss)
I0109 21:06:36.221546  4932 solver.cpp:631] Iteration 9980, lr = 0.0001
I0109 21:06:45.436036  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3184 > 20) by scale factor 0.938157
I0109 21:07:03.479507  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4111 > 20) by scale factor 0.934096
I0109 21:07:05.703130  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5632 > 20) by scale factor 0.676517
I0109 21:07:19.021814  4932 solver.cpp:424] Iteration 10000, Testing net (#0)
I0109 21:08:12.230378  4932 solver.cpp:481]     Test net output #0: accuracy = 0.829474
I0109 21:08:12.230480  4932 solver.cpp:481]     Test net output #1: loss = 0.783755 (* 1 = 0.783755 loss)
I0109 21:08:14.097152  4932 solver.cpp:240] Iteration 10000, loss = 0.0669337
I0109 21:08:14.097192  4932 solver.cpp:255]     Train net output #0: loss = 0.0425478 (* 1 = 0.0425478 loss)
I0109 21:08:14.097199  4932 solver.cpp:565] MultiStep Status: Iteration 10000, step = 1
I0109 21:08:14.097204  4932 solver.cpp:631] Iteration 10000, lr = 1e-05
I0109 21:08:16.654393  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.2531 > 20) by scale factor 0.661088
I0109 21:08:18.875017  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1694 > 20) by scale factor 0.736123
I0109 21:08:43.291704  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1172 > 20) by scale factor 0.711309
I0109 21:08:58.483052  4932 solver.cpp:240] Iteration 10020, loss = 0.100943
I0109 21:08:58.483084  4932 solver.cpp:255]     Train net output #0: loss = 0.02979 (* 1 = 0.02979 loss)
I0109 21:08:58.483093  4932 solver.cpp:631] Iteration 10020, lr = 1e-05
I0109 21:09:43.012301  4932 solver.cpp:240] Iteration 10040, loss = 0.0807674
I0109 21:09:43.012387  4932 solver.cpp:255]     Train net output #0: loss = 0.097359 (* 1 = 0.097359 loss)
I0109 21:09:43.012399  4932 solver.cpp:631] Iteration 10040, lr = 1e-05
I0109 21:09:47.794500  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4924 > 20) by scale factor 0.975974
I0109 21:10:27.949407  4932 solver.cpp:240] Iteration 10060, loss = 0.098232
I0109 21:10:27.949518  4932 solver.cpp:255]     Train net output #0: loss = 0.124981 (* 1 = 0.124981 loss)
I0109 21:10:27.949533  4932 solver.cpp:631] Iteration 10060, lr = 1e-05
I0109 21:11:13.004158  4932 solver.cpp:240] Iteration 10080, loss = 0.0630113
I0109 21:11:13.004258  4932 solver.cpp:255]     Train net output #0: loss = 0.0427352 (* 1 = 0.0427352 loss)
I0109 21:11:13.004273  4932 solver.cpp:631] Iteration 10080, lr = 1e-05
I0109 21:11:59.005826  4932 solver.cpp:240] Iteration 10100, loss = 0.0492846
I0109 21:11:59.005915  4932 solver.cpp:255]     Train net output #0: loss = 0.216416 (* 1 = 0.216416 loss)
I0109 21:11:59.005926  4932 solver.cpp:631] Iteration 10100, lr = 1e-05
I0109 21:12:03.780594  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2696 > 20) by scale factor 0.791465
I0109 21:12:43.722719  4932 solver.cpp:240] Iteration 10120, loss = 0.0870941
I0109 21:12:43.722812  4932 solver.cpp:255]     Train net output #0: loss = 0.116 (* 1 = 0.116 loss)
I0109 21:12:43.722826  4932 solver.cpp:631] Iteration 10120, lr = 1e-05
I0109 21:13:01.813563  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3094 > 20) by scale factor 0.790222
I0109 21:13:04.035145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7914 > 20) by scale factor 0.806733
I0109 21:13:28.755533  4932 solver.cpp:240] Iteration 10140, loss = 0.103487
I0109 21:13:28.755652  4932 solver.cpp:255]     Train net output #0: loss = 0.0302372 (* 1 = 0.0302372 loss)
I0109 21:13:28.755671  4932 solver.cpp:631] Iteration 10140, lr = 1e-05
I0109 21:14:13.533943  4932 solver.cpp:240] Iteration 10160, loss = 0.0826904
I0109 21:14:13.534057  4932 solver.cpp:255]     Train net output #0: loss = 0.141481 (* 1 = 0.141481 loss)
I0109 21:14:13.534075  4932 solver.cpp:631] Iteration 10160, lr = 1e-05
I0109 21:14:32.616922  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3036 > 20) by scale factor 0.858235
I0109 21:14:43.717247  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3161 > 20) by scale factor 0.896215
I0109 21:14:59.604794  4932 solver.cpp:240] Iteration 10180, loss = 0.0959827
I0109 21:14:59.604835  4932 solver.cpp:255]     Train net output #0: loss = 0.0369527 (* 1 = 0.0369527 loss)
I0109 21:14:59.604845  4932 solver.cpp:631] Iteration 10180, lr = 1e-05
I0109 21:15:44.638082  4932 solver.cpp:240] Iteration 10200, loss = 0.0684108
I0109 21:15:44.638175  4932 solver.cpp:255]     Train net output #0: loss = 0.167601 (* 1 = 0.167601 loss)
I0109 21:15:44.638185  4932 solver.cpp:631] Iteration 10200, lr = 1e-05
I0109 21:16:18.877286  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9487 > 20) by scale factor 0.801645
I0109 21:16:25.538733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0407 > 20) by scale factor 0.831924
I0109 21:16:29.640256  4932 solver.cpp:240] Iteration 10220, loss = 0.0923094
I0109 21:16:29.640300  4932 solver.cpp:255]     Train net output #0: loss = 0.113412 (* 1 = 0.113412 loss)
I0109 21:16:29.640310  4932 solver.cpp:631] Iteration 10220, lr = 1e-05
I0109 21:16:36.632737  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3102 > 20) by scale factor 0.93852
I0109 21:16:48.240671  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9103 > 20) by scale factor 0.74321
I0109 21:16:52.685485  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0037 > 20) by scale factor 0.769121
I0109 21:17:14.541324  4932 solver.cpp:240] Iteration 10240, loss = 0.0616323
I0109 21:17:14.541359  4932 solver.cpp:255]     Train net output #0: loss = 0.00465013 (* 1 = 0.00465013 loss)
I0109 21:17:14.541368  4932 solver.cpp:631] Iteration 10240, lr = 1e-05
I0109 21:17:30.852217  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5886 > 20) by scale factor 0.724936
I0109 21:17:59.845664  4932 solver.cpp:240] Iteration 10260, loss = 0.0698367
I0109 21:17:59.845703  4932 solver.cpp:255]     Train net output #0: loss = 0.00475666 (* 1 = 0.00475666 loss)
I0109 21:17:59.845712  4932 solver.cpp:631] Iteration 10260, lr = 1e-05
I0109 21:18:44.231107  4932 solver.cpp:240] Iteration 10280, loss = 0.0701061
I0109 21:18:44.231202  4932 solver.cpp:255]     Train net output #0: loss = 0.0526123 (* 1 = 0.0526123 loss)
I0109 21:18:44.231214  4932 solver.cpp:631] Iteration 10280, lr = 1e-05
I0109 21:19:13.900413  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5024 > 20) by scale factor 0.975495
I0109 21:19:29.719190  4932 solver.cpp:240] Iteration 10300, loss = 0.0894957
I0109 21:19:29.719303  4932 solver.cpp:255]     Train net output #0: loss = 0.0954027 (* 1 = 0.0954027 loss)
I0109 21:19:29.719319  4932 solver.cpp:631] Iteration 10300, lr = 1e-05
I0109 21:19:47.813551  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3516 > 20) by scale factor 0.856473
I0109 21:20:10.372673  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9044 > 20) by scale factor 0.956736
I0109 21:20:14.473634  4932 solver.cpp:240] Iteration 10320, loss = 0.0798153
I0109 21:20:14.473665  4932 solver.cpp:255]     Train net output #0: loss = 0.0196525 (* 1 = 0.0196525 loss)
I0109 21:20:14.473675  4932 solver.cpp:631] Iteration 10320, lr = 1e-05
I0109 21:20:21.470819  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1023 > 20) by scale factor 0.766216
I0109 21:20:28.130285  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.602 > 20) by scale factor 0.847387
I0109 21:20:59.270520  4932 solver.cpp:240] Iteration 10340, loss = 0.0720054
I0109 21:20:59.270614  4932 solver.cpp:255]     Train net output #0: loss = 0.0495032 (* 1 = 0.0495032 loss)
I0109 21:20:59.270625  4932 solver.cpp:631] Iteration 10340, lr = 1e-05
I0109 21:21:43.647086  4932 solver.cpp:240] Iteration 10360, loss = 0.0841688
I0109 21:21:43.647199  4932 solver.cpp:255]     Train net output #0: loss = 0.0190456 (* 1 = 0.0190456 loss)
I0109 21:21:43.647215  4932 solver.cpp:631] Iteration 10360, lr = 1e-05
I0109 21:21:46.207911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6075 > 20) by scale factor 0.970522
I0109 21:22:26.650411  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3505 > 20) by scale factor 0.894836
I0109 21:22:28.531769  4932 solver.cpp:240] Iteration 10380, loss = 0.0815615
I0109 21:22:28.531810  4932 solver.cpp:255]     Train net output #0: loss = 0.0361443 (* 1 = 0.0361443 loss)
I0109 21:22:28.531818  4932 solver.cpp:631] Iteration 10380, lr = 1e-05
I0109 21:22:55.676439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5304 > 20) by scale factor 0.783381
I0109 21:23:02.338335  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2129 > 20) by scale factor 0.900376
I0109 21:23:08.999466  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.818 > 20) by scale factor 0.876501
I0109 21:23:13.103391  4932 solver.cpp:240] Iteration 10400, loss = 0.103516
I0109 21:23:13.103435  4932 solver.cpp:255]     Train net output #0: loss = 0.0423437 (* 1 = 0.0423437 loss)
I0109 21:23:13.103444  4932 solver.cpp:631] Iteration 10400, lr = 1e-05
I0109 21:23:17.882261  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4595 > 20) by scale factor 0.977543
I0109 21:23:58.056030  4932 solver.cpp:240] Iteration 10420, loss = 0.0769664
I0109 21:23:58.056114  4932 solver.cpp:255]     Train net output #0: loss = 0.00779001 (* 1 = 0.00779001 loss)
I0109 21:23:58.056128  4932 solver.cpp:631] Iteration 10420, lr = 1e-05
I0109 21:24:03.317446  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6185 > 20) by scale factor 0.884232
I0109 21:24:43.074731  4932 solver.cpp:240] Iteration 10440, loss = 0.0821261
I0109 21:24:43.074825  4932 solver.cpp:255]     Train net output #0: loss = 0.128988 (* 1 = 0.128988 loss)
I0109 21:24:43.074837  4932 solver.cpp:631] Iteration 10440, lr = 1e-05
I0109 21:25:08.043160  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5521 > 20) by scale factor 0.67677
I0109 21:25:27.676275  4932 solver.cpp:240] Iteration 10460, loss = 0.0467754
I0109 21:25:27.676373  4932 solver.cpp:255]     Train net output #0: loss = 0.0004803 (* 1 = 0.0004803 loss)
I0109 21:25:27.676386  4932 solver.cpp:631] Iteration 10460, lr = 1e-05
I0109 21:26:01.580703  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0037 > 20) by scale factor 0.908937
I0109 21:26:08.238342  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8053 > 20) by scale factor 0.961292
I0109 21:26:12.342490  4932 solver.cpp:240] Iteration 10480, loss = 0.0637022
I0109 21:26:12.342535  4932 solver.cpp:255]     Train net output #0: loss = 0.0417048 (* 1 = 0.0417048 loss)
I0109 21:26:12.342546  4932 solver.cpp:631] Iteration 10480, lr = 1e-05
I0109 21:26:14.903348  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2819 > 20) by scale factor 0.986101
I0109 21:26:42.092582  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6149 > 20) by scale factor 0.812517
I0109 21:26:46.534869  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0373 > 20) by scale factor 0.998138
I0109 21:26:57.289252  4932 solver.cpp:240] Iteration 10500, loss = 0.0848518
I0109 21:26:57.289288  4932 solver.cpp:255]     Train net output #0: loss = 0.0035192 (* 1 = 0.0035192 loss)
I0109 21:26:57.289295  4932 solver.cpp:631] Iteration 10500, lr = 1e-05
I0109 21:27:22.409011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8698 > 20) by scale factor 0.804189
I0109 21:27:42.147976  4932 solver.cpp:240] Iteration 10520, loss = 0.047076
I0109 21:27:42.148017  4932 solver.cpp:255]     Train net output #0: loss = 0.00179735 (* 1 = 0.00179735 loss)
I0109 21:27:42.148027  4932 solver.cpp:631] Iteration 10520, lr = 1e-05
I0109 21:28:00.244635  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4241 > 20) by scale factor 0.891898
I0109 21:28:09.121206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8098 > 20) by scale factor 0.774898
I0109 21:28:27.080376  4932 solver.cpp:240] Iteration 10540, loss = 0.06127
I0109 21:28:27.080413  4932 solver.cpp:255]     Train net output #0: loss = 0.00142401 (* 1 = 0.00142401 loss)
I0109 21:28:27.080422  4932 solver.cpp:631] Iteration 10540, lr = 1e-05
I0109 21:28:40.729216  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8805 > 20) by scale factor 0.772782
I0109 21:28:42.949686  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.271 > 20) by scale factor 0.824029
I0109 21:29:11.957211  4932 solver.cpp:240] Iteration 10560, loss = 0.11659
I0109 21:29:11.957309  4932 solver.cpp:255]     Train net output #0: loss = 0.255682 (* 1 = 0.255682 loss)
I0109 21:29:11.957322  4932 solver.cpp:631] Iteration 10560, lr = 1e-05
I0109 21:29:14.514607  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8594 > 20) by scale factor 0.874915
I0109 21:29:56.373764  4932 solver.cpp:240] Iteration 10580, loss = 0.0807781
I0109 21:29:56.373872  4932 solver.cpp:255]     Train net output #0: loss = 0.00924189 (* 1 = 0.00924189 loss)
I0109 21:29:56.373886  4932 solver.cpp:631] Iteration 10580, lr = 1e-05
I0109 21:30:21.331312  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8542 > 20) by scale factor 0.959041
I0109 21:30:40.975257  4932 solver.cpp:240] Iteration 10600, loss = 0.0543362
I0109 21:30:40.975370  4932 solver.cpp:255]     Train net output #0: loss = 0.0648057 (* 1 = 0.0648057 loss)
I0109 21:30:40.975385  4932 solver.cpp:631] Iteration 10600, lr = 1e-05
I0109 21:30:55.062412  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.124 > 20) by scale factor 0.993839
I0109 21:31:25.794075  4932 solver.cpp:240] Iteration 10620, loss = 0.0640528
I0109 21:31:25.794169  4932 solver.cpp:255]     Train net output #0: loss = 0.0868241 (* 1 = 0.0868241 loss)
I0109 21:31:25.794183  4932 solver.cpp:631] Iteration 10620, lr = 1e-05
I0109 21:31:35.606552  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0801 > 20) by scale factor 0.866547
I0109 21:32:11.191962  4932 solver.cpp:240] Iteration 10640, loss = 0.0837134
I0109 21:32:11.192045  4932 solver.cpp:255]     Train net output #0: loss = 0.0183159 (* 1 = 0.0183159 loss)
I0109 21:32:11.192056  4932 solver.cpp:631] Iteration 10640, lr = 1e-05
I0109 21:32:27.070567  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5492 > 20) by scale factor 0.886949
I0109 21:32:55.818173  4932 solver.cpp:240] Iteration 10660, loss = 0.0801152
I0109 21:32:55.818274  4932 solver.cpp:255]     Train net output #0: loss = 0.00436007 (* 1 = 0.00436007 loss)
I0109 21:32:55.818285  4932 solver.cpp:631] Iteration 10660, lr = 1e-05
I0109 21:33:13.916678  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2169 > 20) by scale factor 0.989271
I0109 21:33:22.795536  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8044 > 20) by scale factor 0.961336
I0109 21:33:40.211241  4932 solver.cpp:240] Iteration 10680, loss = 0.0367544
I0109 21:33:40.211314  4932 solver.cpp:255]     Train net output #0: loss = 0.0171155 (* 1 = 0.0171155 loss)
I0109 21:33:40.211326  4932 solver.cpp:631] Iteration 10680, lr = 1e-05
I0109 21:33:56.237383  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2036 > 20) by scale factor 0.900754
I0109 21:34:25.404521  4932 solver.cpp:240] Iteration 10700, loss = 0.0745546
I0109 21:34:25.404635  4932 solver.cpp:255]     Train net output #0: loss = 0.0534584 (* 1 = 0.0534584 loss)
I0109 21:34:25.404651  4932 solver.cpp:631] Iteration 10700, lr = 1e-05
I0109 21:34:30.183410  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6916 > 20) by scale factor 0.966578
I0109 21:34:36.839385  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0331 > 20) by scale factor 0.798942
I0109 21:35:03.467458  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9427 > 20) by scale factor 0.77093
I0109 21:35:09.789702  4932 solver.cpp:240] Iteration 10720, loss = 0.102132
I0109 21:35:09.789752  4932 solver.cpp:255]     Train net output #0: loss = 0.16346 (* 1 = 0.16346 loss)
I0109 21:35:09.789765  4932 solver.cpp:631] Iteration 10720, lr = 1e-05
I0109 21:35:15.125411  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6099 > 20) by scale factor 0.884569
I0109 21:35:17.345880  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4825 > 20) by scale factor 0.976443
I0109 21:35:39.537174  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.2007 > 20) by scale factor 0.602398
I0109 21:35:55.105435  4932 solver.cpp:240] Iteration 10740, loss = 0.113006
I0109 21:35:55.105476  4932 solver.cpp:255]     Train net output #0: loss = 0.317199 (* 1 = 0.317199 loss)
I0109 21:35:55.105494  4932 solver.cpp:631] Iteration 10740, lr = 1e-05
I0109 21:36:39.582888  4932 solver.cpp:240] Iteration 10760, loss = 0.0569167
I0109 21:36:39.583006  4932 solver.cpp:255]     Train net output #0: loss = 0.0551464 (* 1 = 0.0551464 loss)
I0109 21:36:39.583019  4932 solver.cpp:631] Iteration 10760, lr = 1e-05
I0109 21:37:24.495157  4932 solver.cpp:240] Iteration 10780, loss = 0.0882459
I0109 21:37:24.495251  4932 solver.cpp:255]     Train net output #0: loss = 0.0325481 (* 1 = 0.0325481 loss)
I0109 21:37:24.495262  4932 solver.cpp:631] Iteration 10780, lr = 1e-05
I0109 21:37:43.011142  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1078 > 20) by scale factor 0.829608
I0109 21:38:07.424142  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4797 > 20) by scale factor 0.8518
I0109 21:38:09.306090  4932 solver.cpp:240] Iteration 10800, loss = 0.0870576
I0109 21:38:09.306129  4932 solver.cpp:255]     Train net output #0: loss = 0.0719094 (* 1 = 0.0719094 loss)
I0109 21:38:09.306138  4932 solver.cpp:631] Iteration 10800, lr = 1e-05
I0109 21:38:11.863318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.833 > 20) by scale factor 0.916046
I0109 21:38:45.158186  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4236 > 20) by scale factor 0.891917
I0109 21:38:53.698012  4932 solver.cpp:240] Iteration 10820, loss = 0.061205
I0109 21:38:53.698058  4932 solver.cpp:255]     Train net output #0: loss = 0.0728854 (* 1 = 0.0728854 loss)
I0109 21:38:53.698071  4932 solver.cpp:631] Iteration 10820, lr = 1e-05
I0109 21:39:38.250185  4932 solver.cpp:240] Iteration 10840, loss = 0.0382537
I0109 21:39:38.250288  4932 solver.cpp:255]     Train net output #0: loss = 0.0626913 (* 1 = 0.0626913 loss)
I0109 21:39:38.250303  4932 solver.cpp:631] Iteration 10840, lr = 1e-05
I0109 21:40:23.058990  4932 solver.cpp:240] Iteration 10860, loss = 0.0417374
I0109 21:40:23.059084  4932 solver.cpp:255]     Train net output #0: loss = 0.0347354 (* 1 = 0.0347354 loss)
I0109 21:40:23.059095  4932 solver.cpp:631] Iteration 10860, lr = 1e-05
I0109 21:40:34.492207  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7397 > 20) by scale factor 0.964335
I0109 21:40:47.816911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2173 > 20) by scale factor 0.825857
I0109 21:41:01.279546  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0091 > 20) by scale factor 0.768961
I0109 21:41:07.597983  4932 solver.cpp:240] Iteration 10880, loss = 0.0805312
I0109 21:41:07.598023  4932 solver.cpp:255]     Train net output #0: loss = 0.174437 (* 1 = 0.174437 loss)
I0109 21:41:07.598032  4932 solver.cpp:631] Iteration 10880, lr = 1e-05
I0109 21:41:23.471485  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9574 > 20) by scale factor 0.834816
I0109 21:41:52.194891  4932 solver.cpp:240] Iteration 10900, loss = 0.0653509
I0109 21:41:52.194988  4932 solver.cpp:255]     Train net output #0: loss = 0.0200648 (* 1 = 0.0200648 loss)
I0109 21:41:52.195000  4932 solver.cpp:631] Iteration 10900, lr = 1e-05
I0109 21:42:01.413756  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9222 > 20) by scale factor 0.912316
I0109 21:42:21.385561  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6007 > 20) by scale factor 0.970842
I0109 21:42:36.581290  4932 solver.cpp:240] Iteration 10920, loss = 0.0602011
I0109 21:42:36.581389  4932 solver.cpp:255]     Train net output #0: loss = 0.180144 (* 1 = 0.180144 loss)
I0109 21:42:36.581403  4932 solver.cpp:631] Iteration 10920, lr = 1e-05
I0109 21:42:36.922368  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0292 > 20) by scale factor 0.998541
I0109 21:43:21.778115  4932 solver.cpp:240] Iteration 10940, loss = 0.0588344
I0109 21:43:21.778223  4932 solver.cpp:255]     Train net output #0: loss = 0.0594971 (* 1 = 0.0594971 loss)
I0109 21:43:21.778234  4932 solver.cpp:631] Iteration 10940, lr = 1e-05
I0109 21:43:35.429440  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.2986 > 20) by scale factor 0.660096
I0109 21:43:44.307263  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0274 > 20) by scale factor 0.666059
I0109 21:43:55.400439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9277 > 20) by scale factor 0.83585
I0109 21:44:00.286448  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6694 > 20) by scale factor 0.92296
I0109 21:44:06.610013  4932 solver.cpp:240] Iteration 10960, loss = 0.097463
I0109 21:44:06.610059  4932 solver.cpp:255]     Train net output #0: loss = 0.0400443 (* 1 = 0.0400443 loss)
I0109 21:44:06.610070  4932 solver.cpp:631] Iteration 10960, lr = 1e-05
I0109 21:44:50.994171  4932 solver.cpp:240] Iteration 10980, loss = 0.117696
I0109 21:44:50.994262  4932 solver.cpp:255]     Train net output #0: loss = 0.3658 (* 1 = 0.3658 loss)
I0109 21:44:50.994274  4932 solver.cpp:631] Iteration 10980, lr = 1e-05
I0109 21:45:15.739923  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6799 > 20) by scale factor 0.922514
I0109 21:45:33.504897  4932 solver.cpp:424] Iteration 11000, Testing net (#0)
I0109 21:46:26.036691  4932 solver.cpp:481]     Test net output #0: accuracy = 0.845263
I0109 21:46:26.036789  4932 solver.cpp:481]     Test net output #1: loss = 0.77816 (* 1 = 0.77816 loss)
I0109 21:46:27.904472  4932 solver.cpp:240] Iteration 11000, loss = 0.070723
I0109 21:46:27.904516  4932 solver.cpp:255]     Train net output #0: loss = 0.0238325 (* 1 = 0.0238325 loss)
I0109 21:46:27.904528  4932 solver.cpp:631] Iteration 11000, lr = 1e-05
I0109 21:46:41.558317  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6346 > 20) by scale factor 0.969247
I0109 21:47:12.285658  4932 solver.cpp:240] Iteration 11020, loss = 0.0460523
I0109 21:47:12.285742  4932 solver.cpp:255]     Train net output #0: loss = 0.0419727 (* 1 = 0.0419727 loss)
I0109 21:47:12.285751  4932 solver.cpp:631] Iteration 11020, lr = 1e-05
I0109 21:47:23.718791  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.3593 > 20) by scale factor 0.658778
I0109 21:47:57.047806  4932 solver.cpp:240] Iteration 11040, loss = 0.067751
I0109 21:47:57.047895  4932 solver.cpp:255]     Train net output #0: loss = 0.000407243 (* 1 = 0.000407243 loss)
I0109 21:47:57.047909  4932 solver.cpp:631] Iteration 11040, lr = 1e-05
I0109 21:48:12.922876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7629 > 20) by scale factor 0.878622
I0109 21:48:26.358562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1926 > 20) by scale factor 0.990463
I0109 21:48:30.800145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3319 > 20) by scale factor 0.759534
I0109 21:48:41.555979  4932 solver.cpp:240] Iteration 11060, loss = 0.100071
I0109 21:48:41.556030  4932 solver.cpp:255]     Train net output #0: loss = 0.0515903 (* 1 = 0.0515903 loss)
I0109 21:48:41.556048  4932 solver.cpp:631] Iteration 11060, lr = 1e-05
I0109 21:48:50.779000  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1962 > 20) by scale factor 0.943566
I0109 21:49:26.166424  4932 solver.cpp:240] Iteration 11080, loss = 0.102494
I0109 21:49:26.166518  4932 solver.cpp:255]     Train net output #0: loss = 0.0754259 (* 1 = 0.0754259 loss)
I0109 21:49:26.166530  4932 solver.cpp:631] Iteration 11080, lr = 1e-05
I0109 21:49:53.556932  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5167 > 20) by scale factor 0.974817
I0109 21:50:11.216738  4932 solver.cpp:240] Iteration 11100, loss = 0.086204
I0109 21:50:11.216819  4932 solver.cpp:255]     Train net output #0: loss = 0.187737 (* 1 = 0.187737 loss)
I0109 21:50:11.216830  4932 solver.cpp:631] Iteration 11100, lr = 1e-05
I0109 21:50:18.213697  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4996 > 20) by scale factor 0.784325
I0109 21:50:55.746892  4932 solver.cpp:240] Iteration 11120, loss = 0.0858777
I0109 21:50:55.747004  4932 solver.cpp:255]     Train net output #0: loss = 0.160848 (* 1 = 0.160848 loss)
I0109 21:50:55.747018  4932 solver.cpp:631] Iteration 11120, lr = 1e-05
I0109 21:51:29.626199  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0953 > 20) by scale factor 0.995259
I0109 21:51:38.506007  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.232 > 20) by scale factor 0.941972
I0109 21:51:40.388898  4932 solver.cpp:240] Iteration 11140, loss = 0.0899967
I0109 21:51:40.388945  4932 solver.cpp:255]     Train net output #0: loss = 0.00266087 (* 1 = 0.00266087 loss)
I0109 21:51:40.388957  4932 solver.cpp:631] Iteration 11140, lr = 1e-05
I0109 21:52:24.985502  4932 solver.cpp:240] Iteration 11160, loss = 0.0643104
I0109 21:52:24.985590  4932 solver.cpp:255]     Train net output #0: loss = 0.254612 (* 1 = 0.254612 loss)
I0109 21:52:24.985601  4932 solver.cpp:631] Iteration 11160, lr = 1e-05
I0109 21:53:09.370107  4932 solver.cpp:240] Iteration 11180, loss = 0.0470491
I0109 21:53:09.370201  4932 solver.cpp:255]     Train net output #0: loss = 0.0758984 (* 1 = 0.0758984 loss)
I0109 21:53:09.370213  4932 solver.cpp:631] Iteration 11180, lr = 1e-05
I0109 21:53:20.807559  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9702 > 20) by scale factor 0.870693
I0109 21:53:53.839061  4932 solver.cpp:240] Iteration 11200, loss = 0.0752266
I0109 21:53:53.839150  4932 solver.cpp:255]     Train net output #0: loss = 0.00871254 (* 1 = 0.00871254 loss)
I0109 21:53:53.839161  4932 solver.cpp:631] Iteration 11200, lr = 1e-05
I0109 21:54:09.711220  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8518 > 20) by scale factor 0.804769
I0109 21:54:27.556145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9357 > 20) by scale factor 0.802064
I0109 21:54:29.779093  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5065 > 20) by scale factor 0.754533
I0109 21:54:38.319669  4932 solver.cpp:240] Iteration 11220, loss = 0.087394
I0109 21:54:38.319706  4932 solver.cpp:255]     Train net output #0: loss = 0.0263683 (* 1 = 0.0263683 loss)
I0109 21:54:38.319715  4932 solver.cpp:631] Iteration 11220, lr = 1e-05
I0109 21:54:58.979859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9361 > 20) by scale factor 0.955289
I0109 21:55:23.049111  4932 solver.cpp:240] Iteration 11240, loss = 0.0667378
I0109 21:55:23.049155  4932 solver.cpp:255]     Train net output #0: loss = 0.0113218 (* 1 = 0.0113218 loss)
I0109 21:55:23.049166  4932 solver.cpp:631] Iteration 11240, lr = 1e-05
I0109 21:56:07.850411  4932 solver.cpp:240] Iteration 11260, loss = 0.0556414
I0109 21:56:07.850495  4932 solver.cpp:255]     Train net output #0: loss = 0.107384 (* 1 = 0.107384 loss)
I0109 21:56:07.850505  4932 solver.cpp:631] Iteration 11260, lr = 1e-05
I0109 21:56:17.066978  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2874 > 20) by scale factor 0.823473
I0109 21:56:44.053202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.361 > 20) by scale factor 0.820984
I0109 21:56:50.716011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0748 > 20) by scale factor 0.949001
I0109 21:56:52.597844  4932 solver.cpp:240] Iteration 11280, loss = 0.0741622
I0109 21:56:52.597882  4932 solver.cpp:255]     Train net output #0: loss = 0.127529 (* 1 = 0.127529 loss)
I0109 21:56:52.597892  4932 solver.cpp:631] Iteration 11280, lr = 1e-05
I0109 21:57:10.688721  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0499 > 20) by scale factor 0.950123
I0109 21:57:33.171452  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8078 > 20) by scale factor 0.876892
I0109 21:57:37.274345  4932 solver.cpp:240] Iteration 11300, loss = 0.0802545
I0109 21:57:37.274379  4932 solver.cpp:255]     Train net output #0: loss = 0.00864412 (* 1 = 0.00864412 loss)
I0109 21:57:37.274394  4932 solver.cpp:631] Iteration 11300, lr = 1e-05
I0109 21:57:44.266340  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2379 > 20) by scale factor 0.941711
I0109 21:58:22.047560  4932 solver.cpp:240] Iteration 11320, loss = 0.061084
I0109 21:58:22.047643  4932 solver.cpp:255]     Train net output #0: loss = 0.133966 (* 1 = 0.133966 loss)
I0109 21:58:22.047653  4932 solver.cpp:631] Iteration 11320, lr = 1e-05
I0109 21:58:33.527361  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4397 > 20) by scale factor 0.891279
I0109 21:58:37.966212  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5857 > 20) by scale factor 0.92654
I0109 21:59:06.805485  4932 solver.cpp:240] Iteration 11340, loss = 0.0851904
I0109 21:59:06.805579  4932 solver.cpp:255]     Train net output #0: loss = 0.200974 (* 1 = 0.200974 loss)
I0109 21:59:06.805591  4932 solver.cpp:631] Iteration 11340, lr = 1e-05
I0109 21:59:07.145037  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0209 > 20) by scale factor 0.768612
I0109 21:59:42.650821  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3616 > 20) by scale factor 0.856105
I0109 21:59:51.192486  4932 solver.cpp:240] Iteration 11360, loss = 0.0986564
I0109 21:59:51.192528  4932 solver.cpp:255]     Train net output #0: loss = 0.0752777 (* 1 = 0.0752777 loss)
I0109 21:59:51.192538  4932 solver.cpp:631] Iteration 11360, lr = 1e-05
I0109 22:00:04.842701  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2765 > 20) by scale factor 0.859235
I0109 22:00:07.063566  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5503 > 20) by scale factor 0.886906
I0109 22:00:13.720844  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.924 > 20) by scale factor 0.955841
I0109 22:00:35.570549  4932 solver.cpp:240] Iteration 11380, loss = 0.0779394
I0109 22:00:35.570588  4932 solver.cpp:255]     Train net output #0: loss = 0.0244896 (* 1 = 0.0244896 loss)
I0109 22:00:35.570596  4932 solver.cpp:631] Iteration 11380, lr = 1e-05
I0109 22:01:09.273449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8859 > 20) by scale factor 0.91383
I0109 22:01:20.039633  4932 solver.cpp:240] Iteration 11400, loss = 0.0767768
I0109 22:01:20.039677  4932 solver.cpp:255]     Train net output #0: loss = 0.0842815 (* 1 = 0.0842815 loss)
I0109 22:01:20.039688  4932 solver.cpp:631] Iteration 11400, lr = 1e-05
I0109 22:02:04.730355  4932 solver.cpp:240] Iteration 11420, loss = 0.0472457
I0109 22:02:04.730438  4932 solver.cpp:255]     Train net output #0: loss = 0.0384506 (* 1 = 0.0384506 loss)
I0109 22:02:04.730448  4932 solver.cpp:631] Iteration 11420, lr = 1e-05
I0109 22:02:43.000448  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6037 > 20) by scale factor 0.884811
I0109 22:02:45.222522  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7694 > 20) by scale factor 0.91872
I0109 22:02:49.323779  4932 solver.cpp:240] Iteration 11440, loss = 0.0873089
I0109 22:02:49.323819  4932 solver.cpp:255]     Train net output #0: loss = 0.000124085 (* 1 = 0.000124085 loss)
I0109 22:02:49.323828  4932 solver.cpp:631] Iteration 11440, lr = 1e-05
I0109 22:03:00.754714  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5301 > 20) by scale factor 0.974177
I0109 22:03:18.730011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0971 > 20) by scale factor 0.905097
I0109 22:03:33.928851  4932 solver.cpp:240] Iteration 11460, loss = 0.0733331
I0109 22:03:33.928884  4932 solver.cpp:255]     Train net output #0: loss = 0.00927582 (* 1 = 0.00927582 loss)
I0109 22:03:33.928892  4932 solver.cpp:631] Iteration 11460, lr = 1e-05
I0109 22:03:47.584956  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1354 > 20) by scale factor 0.946279
I0109 22:04:18.877447  4932 solver.cpp:240] Iteration 11480, loss = 0.0714062
I0109 22:04:18.877566  4932 solver.cpp:255]     Train net output #0: loss = 0.347991 (* 1 = 0.347991 loss)
I0109 22:04:18.877578  4932 solver.cpp:631] Iteration 11480, lr = 1e-05
I0109 22:05:03.256119  4932 solver.cpp:240] Iteration 11500, loss = 0.0542812
I0109 22:05:03.256206  4932 solver.cpp:255]     Train net output #0: loss = 0.0120456 (* 1 = 0.0120456 loss)
I0109 22:05:03.256218  4932 solver.cpp:631] Iteration 11500, lr = 1e-05
I0109 22:05:05.815121  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.755 > 20) by scale factor 0.878928
I0109 22:05:12.471557  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0896 > 20) by scale factor 0.797142
I0109 22:05:21.350584  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.7588 > 20) by scale factor 0.650221
I0109 22:05:47.642012  4932 solver.cpp:240] Iteration 11520, loss = 0.0618807
I0109 22:05:47.642104  4932 solver.cpp:255]     Train net output #0: loss = 0.00450822 (* 1 = 0.00450822 loss)
I0109 22:05:47.642115  4932 solver.cpp:631] Iteration 11520, lr = 1e-05
I0109 22:05:59.080812  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2621 > 20) by scale factor 0.987066
I0109 22:06:10.177743  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4753 > 20) by scale factor 0.75542
I0109 22:06:23.559644  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2043 > 20) by scale factor 0.943204
I0109 22:06:32.100383  4932 solver.cpp:240] Iteration 11540, loss = 0.0862216
I0109 22:06:32.100424  4932 solver.cpp:255]     Train net output #0: loss = 0.0314732 (* 1 = 0.0314732 loss)
I0109 22:06:32.100431  4932 solver.cpp:631] Iteration 11540, lr = 1e-05
I0109 22:06:41.314785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3226 > 20) by scale factor 0.82228
I0109 22:06:50.192173  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0782 > 20) by scale factor 0.866618
I0109 22:07:16.806037  4932 solver.cpp:240] Iteration 11560, loss = 0.0648919
I0109 22:07:16.806149  4932 solver.cpp:255]     Train net output #0: loss = 0.0358965 (* 1 = 0.0358965 loss)
I0109 22:07:16.806164  4932 solver.cpp:631] Iteration 11560, lr = 1e-05
I0109 22:08:01.356634  4932 solver.cpp:240] Iteration 11580, loss = 0.0644648
I0109 22:08:01.356724  4932 solver.cpp:255]     Train net output #0: loss = 0.219833 (* 1 = 0.219833 loss)
I0109 22:08:01.356735  4932 solver.cpp:631] Iteration 11580, lr = 1e-05
I0109 22:08:01.696184  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5118 > 20) by scale factor 0.888422
I0109 22:08:39.458822  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6302 > 20) by scale factor 0.846376
I0109 22:08:45.779094  4932 solver.cpp:240] Iteration 11600, loss = 0.0675983
I0109 22:08:45.779139  4932 solver.cpp:255]     Train net output #0: loss = 0.06347 (* 1 = 0.06347 loss)
I0109 22:08:45.779150  4932 solver.cpp:631] Iteration 11600, lr = 1e-05
I0109 22:09:19.944747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1699 > 20) by scale factor 0.991578
I0109 22:09:30.699240  4932 solver.cpp:240] Iteration 11620, loss = 0.0715811
I0109 22:09:30.699285  4932 solver.cpp:255]     Train net output #0: loss = 0.0753237 (* 1 = 0.0753237 loss)
I0109 22:09:30.699295  4932 solver.cpp:631] Iteration 11620, lr = 1e-05
I0109 22:09:35.477311  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3356 > 20) by scale factor 0.895433
I0109 22:09:44.352890  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6146 > 20) by scale factor 0.751467
I0109 22:10:02.511412  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7303 > 20) by scale factor 0.920372
I0109 22:10:15.488250  4932 solver.cpp:240] Iteration 11640, loss = 0.101645
I0109 22:10:15.488297  4932 solver.cpp:255]     Train net output #0: loss = 0.120024 (* 1 = 0.120024 loss)
I0109 22:10:15.488319  4932 solver.cpp:631] Iteration 11640, lr = 1e-05
I0109 22:10:26.974648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8144 > 20) by scale factor 0.876639
I0109 22:10:59.914901  4932 solver.cpp:240] Iteration 11660, loss = 0.0791235
I0109 22:10:59.914988  4932 solver.cpp:255]     Train net output #0: loss = 0.250892 (* 1 = 0.250892 loss)
I0109 22:10:59.914999  4932 solver.cpp:631] Iteration 11660, lr = 1e-05
I0109 22:11:15.973711  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6317 > 20) by scale factor 0.969382
I0109 22:11:38.728627  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0137 > 20) by scale factor 0.908526
I0109 22:11:45.046478  4932 solver.cpp:240] Iteration 11680, loss = 0.0755857
I0109 22:11:45.046517  4932 solver.cpp:255]     Train net output #0: loss = 0.0617892 (* 1 = 0.0617892 loss)
I0109 22:11:45.046525  4932 solver.cpp:631] Iteration 11680, lr = 1e-05
I0109 22:11:54.259248  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.45 > 20) by scale factor 0.977997
I0109 22:12:17.051173  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.545 > 20) by scale factor 0.814831
I0109 22:12:19.274137  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8257 > 20) by scale factor 0.839428
I0109 22:12:30.034945  4932 solver.cpp:240] Iteration 11700, loss = 0.116365
I0109 22:12:30.034978  4932 solver.cpp:255]     Train net output #0: loss = 0.0112815 (* 1 = 0.0112815 loss)
I0109 22:12:30.034986  4932 solver.cpp:631] Iteration 11700, lr = 1e-05
I0109 22:12:39.257352  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.941 > 20) by scale factor 0.955064
I0109 22:12:57.229645  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.311 > 20) by scale factor 0.98469
I0109 22:13:14.641202  4932 solver.cpp:240] Iteration 11720, loss = 0.0647704
I0109 22:13:14.641239  4932 solver.cpp:255]     Train net output #0: loss = 0.0294647 (* 1 = 0.0294647 loss)
I0109 22:13:14.641248  4932 solver.cpp:631] Iteration 11720, lr = 1e-05
I0109 22:13:26.615150  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2827 > 20) by scale factor 0.823633
I0109 22:13:51.029697  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9374 > 20) by scale factor 0.871938
I0109 22:13:59.575862  4932 solver.cpp:240] Iteration 11740, loss = 0.0515
I0109 22:13:59.575904  4932 solver.cpp:255]     Train net output #0: loss = 0.070326 (* 1 = 0.070326 loss)
I0109 22:13:59.575916  4932 solver.cpp:631] Iteration 11740, lr = 1e-05
I0109 22:14:06.825680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3442 > 20) by scale factor 0.821551
I0109 22:14:42.629813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.286 > 20) by scale factor 0.939583
I0109 22:14:44.511093  4932 solver.cpp:240] Iteration 11760, loss = 0.0603734
I0109 22:14:44.511133  4932 solver.cpp:255]     Train net output #0: loss = 0.00170922 (* 1 = 0.00170922 loss)
I0109 22:14:44.511142  4932 solver.cpp:631] Iteration 11760, lr = 1e-05
I0109 22:15:29.029453  4932 solver.cpp:240] Iteration 11780, loss = 0.0828744
I0109 22:15:29.029564  4932 solver.cpp:255]     Train net output #0: loss = 0.00714191 (* 1 = 0.00714191 loss)
I0109 22:15:29.029579  4932 solver.cpp:631] Iteration 11780, lr = 1e-05
I0109 22:16:03.224355  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5159 > 20) by scale factor 0.929544
I0109 22:16:13.978453  4932 solver.cpp:240] Iteration 11800, loss = 0.0917672
I0109 22:16:13.978490  4932 solver.cpp:255]     Train net output #0: loss = 0.0403821 (* 1 = 0.0403821 loss)
I0109 22:16:13.978499  4932 solver.cpp:631] Iteration 11800, lr = 1e-05
I0109 22:16:30.113178  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9492 > 20) by scale factor 0.95469
I0109 22:16:54.519749  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1637 > 20) by scale factor 0.945014
I0109 22:16:58.724326  4932 solver.cpp:240] Iteration 11820, loss = 0.0628511
I0109 22:16:58.724362  4932 solver.cpp:255]     Train net output #0: loss = 0.0658419 (* 1 = 0.0658419 loss)
I0109 22:16:58.724371  4932 solver.cpp:631] Iteration 11820, lr = 1e-05
I0109 22:17:43.109575  4932 solver.cpp:240] Iteration 11840, loss = 0.0524967
I0109 22:17:43.109661  4932 solver.cpp:255]     Train net output #0: loss = 0.038736 (* 1 = 0.038736 loss)
I0109 22:17:43.109674  4932 solver.cpp:631] Iteration 11840, lr = 1e-05
I0109 22:17:56.761817  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0193 > 20) by scale factor 0.799382
I0109 22:18:27.492550  4932 solver.cpp:240] Iteration 11860, loss = 0.0681035
I0109 22:18:27.492640  4932 solver.cpp:255]     Train net output #0: loss = 0.0166461 (* 1 = 0.0166461 loss)
I0109 22:18:27.492651  4932 solver.cpp:631] Iteration 11860, lr = 1e-05
I0109 22:18:38.924835  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9475 > 20) by scale factor 0.954768
I0109 22:19:12.181947  4932 solver.cpp:240] Iteration 11880, loss = 0.068327
I0109 22:19:12.182029  4932 solver.cpp:255]     Train net output #0: loss = 0.000729689 (* 1 = 0.000729689 loss)
I0109 22:19:12.182040  4932 solver.cpp:631] Iteration 11880, lr = 1e-05
I0109 22:19:41.368918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1442 > 20) by scale factor 0.903169
I0109 22:19:54.900355  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6182 > 20) by scale factor 0.698855
I0109 22:19:56.782392  4932 solver.cpp:240] Iteration 11900, loss = 0.0695294
I0109 22:19:56.782429  4932 solver.cpp:255]     Train net output #0: loss = 0.0115934 (* 1 = 0.0115934 loss)
I0109 22:19:56.782438  4932 solver.cpp:631] Iteration 11900, lr = 1e-05
I0109 22:20:41.398924  4932 solver.cpp:240] Iteration 11920, loss = 0.0533511
I0109 22:20:41.399022  4932 solver.cpp:255]     Train net output #0: loss = 0.121909 (* 1 = 0.121909 loss)
I0109 22:20:41.399035  4932 solver.cpp:631] Iteration 11920, lr = 1e-05
I0109 22:20:55.053169  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3143 > 20) by scale factor 0.706356
I0109 22:20:57.495127  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1236 > 20) by scale factor 0.76559
I0109 22:21:21.898947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6795 > 20) by scale factor 0.722558
I0109 22:21:25.998811  4932 solver.cpp:240] Iteration 11940, loss = 0.111782
I0109 22:21:25.998857  4932 solver.cpp:255]     Train net output #0: loss = 0.000659232 (* 1 = 0.000659232 loss)
I0109 22:21:25.998867  4932 solver.cpp:631] Iteration 11940, lr = 1e-05
I0109 22:21:28.558804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.163 > 20) by scale factor 0.621833
I0109 22:21:41.890923  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.152 > 20) by scale factor 0.945538
I0109 22:22:10.401562  4932 solver.cpp:240] Iteration 11960, loss = 0.0801765
I0109 22:22:10.401651  4932 solver.cpp:255]     Train net output #0: loss = 0.0071361 (* 1 = 0.0071361 loss)
I0109 22:22:10.401662  4932 solver.cpp:631] Iteration 11960, lr = 1e-05
I0109 22:22:54.779093  4932 solver.cpp:240] Iteration 11980, loss = 0.0669203
I0109 22:22:54.779181  4932 solver.cpp:255]     Train net output #0: loss = 0.0509175 (* 1 = 0.0509175 loss)
I0109 22:22:54.779193  4932 solver.cpp:631] Iteration 11980, lr = 1e-05
I0109 22:23:06.215175  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9903 > 20) by scale factor 0.83367
I0109 22:23:10.654742  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5758 > 20) by scale factor 0.78199
I0109 22:23:37.292094  4932 solver.cpp:424] Iteration 12000, Testing net (#0)
I0109 22:24:26.229792  4932 solver.cpp:481]     Test net output #0: accuracy = 0.812632
I0109 22:24:26.229897  4932 solver.cpp:481]     Test net output #1: loss = 0.894667 (* 1 = 0.894667 loss)
I0109 22:24:28.095829  4932 solver.cpp:240] Iteration 12000, loss = 0.100996
I0109 22:24:28.095867  4932 solver.cpp:255]     Train net output #0: loss = 0.0272753 (* 1 = 0.0272753 loss)
I0109 22:24:28.095876  4932 solver.cpp:631] Iteration 12000, lr = 1e-05
I0109 22:24:37.311856  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7686 > 20) by scale factor 0.747143
I0109 22:25:12.480563  4932 solver.cpp:240] Iteration 12020, loss = 0.0435799
I0109 22:25:12.480653  4932 solver.cpp:255]     Train net output #0: loss = 0.0732691 (* 1 = 0.0732691 loss)
I0109 22:25:12.480665  4932 solver.cpp:631] Iteration 12020, lr = 1e-05
I0109 22:25:28.363468  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3396 > 20) by scale factor 0.856912
I0109 22:25:30.585243  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2022 > 20) by scale factor 0.989992
I0109 22:25:46.117053  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6238 > 20) by scale factor 0.969755
I0109 22:25:56.881124  4932 solver.cpp:240] Iteration 12040, loss = 0.11035
I0109 22:25:56.881168  4932 solver.cpp:255]     Train net output #0: loss = 0.0490366 (* 1 = 0.0490366 loss)
I0109 22:25:56.881180  4932 solver.cpp:631] Iteration 12040, lr = 1e-05
I0109 22:26:03.880581  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.743 > 20) by scale factor 0.964179
I0109 22:26:21.735047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9385 > 20) by scale factor 0.871896
I0109 22:26:41.365283  4932 solver.cpp:240] Iteration 12060, loss = 0.0827722
I0109 22:26:41.365322  4932 solver.cpp:255]     Train net output #0: loss = 0.127809 (* 1 = 0.127809 loss)
I0109 22:26:41.365331  4932 solver.cpp:631] Iteration 12060, lr = 1e-05
I0109 22:26:41.704274  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7656 > 20) by scale factor 0.963133
I0109 22:26:52.805048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5455 > 20) by scale factor 0.753425
I0109 22:27:06.230093  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.6641 > 20) by scale factor 0.594105
I0109 22:27:15.106134  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6164 > 20) by scale factor 0.780751
I0109 22:27:25.865669  4932 solver.cpp:240] Iteration 12080, loss = 0.1034
I0109 22:27:25.865766  4932 solver.cpp:255]     Train net output #0: loss = 0.0037814 (* 1 = 0.0037814 loss)
I0109 22:27:25.865777  4932 solver.cpp:631] Iteration 12080, lr = 1e-05
I0109 22:27:44.023320  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8815 > 20) by scale factor 0.80381
I0109 22:28:10.643416  4932 solver.cpp:240] Iteration 12100, loss = 0.0763247
I0109 22:28:10.643503  4932 solver.cpp:255]     Train net output #0: loss = 0.113298 (* 1 = 0.113298 loss)
I0109 22:28:10.643517  4932 solver.cpp:631] Iteration 12100, lr = 1e-05
I0109 22:28:46.493644  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9955 > 20) by scale factor 0.689763
I0109 22:28:53.147677  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3439 > 20) by scale factor 0.759188
I0109 22:28:55.028730  4932 solver.cpp:240] Iteration 12120, loss = 0.082703
I0109 22:28:55.028769  4932 solver.cpp:255]     Train net output #0: loss = 0.0315555 (* 1 = 0.0315555 loss)
I0109 22:28:55.028777  4932 solver.cpp:631] Iteration 12120, lr = 1e-05
I0109 22:29:26.698643  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1821 > 20) by scale factor 0.901627
I0109 22:29:37.801264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8516 > 20) by scale factor 0.804778
I0109 22:29:39.684795  4932 solver.cpp:240] Iteration 12140, loss = 0.043892
I0109 22:29:39.684835  4932 solver.cpp:255]     Train net output #0: loss = 0.0373066 (* 1 = 0.0373066 loss)
I0109 22:29:39.684844  4932 solver.cpp:631] Iteration 12140, lr = 1e-05
I0109 22:30:02.415711  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2207 > 20) by scale factor 0.861302
I0109 22:30:24.566954  4932 solver.cpp:240] Iteration 12160, loss = 0.0475936
I0109 22:30:24.566999  4932 solver.cpp:255]     Train net output #0: loss = 0.0137981 (* 1 = 0.0137981 loss)
I0109 22:30:24.567010  4932 solver.cpp:631] Iteration 12160, lr = 1e-05
I0109 22:30:33.782201  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8559 > 20) by scale factor 0.95896
I0109 22:31:02.991040  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6378 > 20) by scale factor 0.969097
I0109 22:31:09.308655  4932 solver.cpp:240] Iteration 12180, loss = 0.108604
I0109 22:31:09.308738  4932 solver.cpp:255]     Train net output #0: loss = 0.059425 (* 1 = 0.059425 loss)
I0109 22:31:09.308750  4932 solver.cpp:631] Iteration 12180, lr = 1e-05
I0109 22:31:54.166872  4932 solver.cpp:240] Iteration 12200, loss = 0.0695232
I0109 22:31:54.166972  4932 solver.cpp:255]     Train net output #0: loss = 0.077859 (* 1 = 0.077859 loss)
I0109 22:31:54.166986  4932 solver.cpp:631] Iteration 12200, lr = 1e-05
I0109 22:32:25.683043  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0364 > 20) by scale factor 0.768156
I0109 22:32:38.663482  4932 solver.cpp:240] Iteration 12220, loss = 0.0947141
I0109 22:32:38.663519  4932 solver.cpp:255]     Train net output #0: loss = 0.183659 (* 1 = 0.183659 loss)
I0109 22:32:38.663527  4932 solver.cpp:631] Iteration 12220, lr = 1e-05
I0109 22:32:43.437075  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7596 > 20) by scale factor 0.919136
I0109 22:33:06.112985  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3184 > 20) by scale factor 0.938155
I0109 22:33:23.898542  4932 solver.cpp:240] Iteration 12240, loss = 0.0599938
I0109 22:33:23.898583  4932 solver.cpp:255]     Train net output #0: loss = 0.00115992 (* 1 = 0.00115992 loss)
I0109 22:33:23.898592  4932 solver.cpp:631] Iteration 12240, lr = 1e-05
I0109 22:34:02.147408  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4195 > 20) by scale factor 0.786797
I0109 22:34:08.464500  4932 solver.cpp:240] Iteration 12260, loss = 0.0903975
I0109 22:34:08.464539  4932 solver.cpp:255]     Train net output #0: loss = 0.0872705 (* 1 = 0.0872705 loss)
I0109 22:34:08.464546  4932 solver.cpp:631] Iteration 12260, lr = 1e-05
I0109 22:34:11.023602  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8124 > 20) by scale factor 0.916911
I0109 22:34:19.903283  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0966 > 20) by scale factor 0.829993
I0109 22:34:28.784643  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4536 > 20) by scale factor 0.932244
I0109 22:34:33.224779  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.56 > 20) by scale factor 0.927646
I0109 22:34:39.975116  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3428 > 20) by scale factor 0.98315
I0109 22:34:52.952700  4932 solver.cpp:240] Iteration 12280, loss = 0.0902999
I0109 22:34:52.952739  4932 solver.cpp:255]     Train net output #0: loss = 0.0537352 (* 1 = 0.0537352 loss)
I0109 22:34:52.952746  4932 solver.cpp:631] Iteration 12280, lr = 1e-05
I0109 22:34:55.510165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8623 > 20) by scale factor 0.958668
I0109 22:35:37.449126  4932 solver.cpp:240] Iteration 12300, loss = 0.0457707
I0109 22:35:37.449208  4932 solver.cpp:255]     Train net output #0: loss = 0.00619187 (* 1 = 0.00619187 loss)
I0109 22:35:37.449223  4932 solver.cpp:631] Iteration 12300, lr = 1e-05
I0109 22:35:44.449839  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2456 > 20) by scale factor 0.824893
I0109 22:36:02.391206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1647 > 20) by scale factor 0.794764
I0109 22:36:17.925324  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8648 > 20) by scale factor 0.744468
I0109 22:36:22.025612  4932 solver.cpp:240] Iteration 12320, loss = 0.0901118
I0109 22:36:22.025650  4932 solver.cpp:255]     Train net output #0: loss = 0.0723701 (* 1 = 0.0723701 loss)
I0109 22:36:22.025658  4932 solver.cpp:631] Iteration 12320, lr = 1e-05
I0109 22:36:24.583665  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9072 > 20) by scale factor 0.716662
I0109 22:36:44.555572  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2942 > 20) by scale factor 0.985502
I0109 22:36:46.777976  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5481 > 20) by scale factor 0.849326
I0109 22:37:00.094363  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2343 > 20) by scale factor 0.860796
I0109 22:37:06.409919  4932 solver.cpp:240] Iteration 12340, loss = 0.110117
I0109 22:37:06.409963  4932 solver.cpp:255]     Train net output #0: loss = 0.0351489 (* 1 = 0.0351489 loss)
I0109 22:37:06.409976  4932 solver.cpp:631] Iteration 12340, lr = 1e-05
I0109 22:37:22.282667  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9939 > 20) by scale factor 0.869795
I0109 22:37:35.607730  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9205 > 20) by scale factor 0.912388
I0109 22:37:40.051327  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5227 > 20) by scale factor 0.974532
I0109 22:37:51.209589  4932 solver.cpp:240] Iteration 12360, loss = 0.0870219
I0109 22:37:51.209630  4932 solver.cpp:255]     Train net output #0: loss = 0.00508499 (* 1 = 0.00508499 loss)
I0109 22:37:51.209638  4932 solver.cpp:631] Iteration 12360, lr = 1e-05
I0109 22:37:58.213225  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5251 > 20) by scale factor 0.929148
I0109 22:38:18.188032  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.641 > 20) by scale factor 0.924172
I0109 22:38:35.644861  4932 solver.cpp:240] Iteration 12380, loss = 0.0826422
I0109 22:38:35.644903  4932 solver.cpp:255]     Train net output #0: loss = 0.136148 (* 1 = 0.136148 loss)
I0109 22:38:35.644912  4932 solver.cpp:631] Iteration 12380, lr = 1e-05
I0109 22:38:35.984104  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6189 > 20) by scale factor 0.884216
I0109 22:39:00.443881  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9081 > 20) by scale factor 0.873052
I0109 22:39:04.887619  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2293 > 20) by scale factor 0.762506
I0109 22:39:20.080188  4932 solver.cpp:240] Iteration 12400, loss = 0.0591953
I0109 22:39:20.080222  4932 solver.cpp:255]     Train net output #0: loss = 0.00607673 (* 1 = 0.00607673 loss)
I0109 22:39:20.080231  4932 solver.cpp:631] Iteration 12400, lr = 1e-05
I0109 22:40:04.462226  4932 solver.cpp:240] Iteration 12420, loss = 0.0881767
I0109 22:40:04.462328  4932 solver.cpp:255]     Train net output #0: loss = 0.0138454 (* 1 = 0.0138454 loss)
I0109 22:40:04.462342  4932 solver.cpp:631] Iteration 12420, lr = 1e-05
I0109 22:40:11.970171  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5092 > 20) by scale factor 0.929836
I0109 22:40:45.648880  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4185 > 20) by scale factor 0.786829
I0109 22:40:49.751049  4932 solver.cpp:240] Iteration 12440, loss = 0.0812303
I0109 22:40:49.751090  4932 solver.cpp:255]     Train net output #0: loss = 0.000333967 (* 1 = 0.000333967 loss)
I0109 22:40:49.751098  4932 solver.cpp:631] Iteration 12440, lr = 1e-05
I0109 22:41:21.474337  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6803 > 20) by scale factor 0.967103
I0109 22:41:34.448148  4932 solver.cpp:240] Iteration 12460, loss = 0.049431
I0109 22:41:34.448180  4932 solver.cpp:255]     Train net output #0: loss = 0.0254087 (* 1 = 0.0254087 loss)
I0109 22:41:34.448194  4932 solver.cpp:631] Iteration 12460, lr = 1e-05
I0109 22:41:52.545264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.9743 > 20) by scale factor 0.625501
I0109 22:42:19.409859  4932 solver.cpp:240] Iteration 12480, loss = 0.0975956
I0109 22:42:19.409899  4932 solver.cpp:255]     Train net output #0: loss = 0.0171252 (* 1 = 0.0171252 loss)
I0109 22:42:19.409907  4932 solver.cpp:631] Iteration 12480, lr = 1e-05
I0109 22:42:30.996069  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0286 > 20) by scale factor 0.768387
I0109 22:42:44.309383  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4521 > 20) by scale factor 0.728543
I0109 22:42:57.618294  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5894 > 20) by scale factor 0.724917
I0109 22:43:03.938674  4932 solver.cpp:240] Iteration 12500, loss = 0.107984
I0109 22:43:03.938760  4932 solver.cpp:255]     Train net output #0: loss = 0.0114071 (* 1 = 0.0114071 loss)
I0109 22:43:03.938772  4932 solver.cpp:631] Iteration 12500, lr = 1e-05
I0109 22:43:11.126296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5861 > 20) by scale factor 0.675994
I0109 22:43:22.229965  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6089 > 20) by scale factor 0.812714
I0109 22:43:48.516939  4932 solver.cpp:240] Iteration 12520, loss = 0.1101
I0109 22:43:48.517032  4932 solver.cpp:255]     Train net output #0: loss = 0.0617123 (* 1 = 0.0617123 loss)
I0109 22:43:48.517045  4932 solver.cpp:631] Iteration 12520, lr = 1e-05
I0109 22:44:08.825136  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.093 > 20) by scale factor 0.995369
I0109 22:44:32.901387  4932 solver.cpp:240] Iteration 12540, loss = 0.0450149
I0109 22:44:32.901480  4932 solver.cpp:255]     Train net output #0: loss = 0.0238227 (* 1 = 0.0238227 loss)
I0109 22:44:32.901492  4932 solver.cpp:631] Iteration 12540, lr = 1e-05
I0109 22:44:37.678546  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5926 > 20) by scale factor 0.813254
I0109 22:44:44.337035  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0947 > 20) by scale factor 0.995285
I0109 22:44:50.993405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7163 > 20) by scale factor 0.920968
I0109 22:45:17.275619  4932 solver.cpp:240] Iteration 12560, loss = 0.0943675
I0109 22:45:17.275713  4932 solver.cpp:255]     Train net output #0: loss = 0.243433 (* 1 = 0.243433 loss)
I0109 22:45:17.275727  4932 solver.cpp:631] Iteration 12560, lr = 1e-05
I0109 22:45:17.616360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2703 > 20) by scale factor 0.824051
I0109 22:45:33.159523  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9328 > 20) by scale factor 0.716004
I0109 22:45:57.570155  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0139 > 20) by scale factor 0.999305
I0109 22:46:01.670325  4932 solver.cpp:240] Iteration 12580, loss = 0.0929107
I0109 22:46:01.670363  4932 solver.cpp:255]     Train net output #0: loss = 0.225944 (* 1 = 0.225944 loss)
I0109 22:46:01.670372  4932 solver.cpp:631] Iteration 12580, lr = 1e-05
I0109 22:46:44.513200  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.597 > 20) by scale factor 0.926054
I0109 22:46:46.395201  4932 solver.cpp:240] Iteration 12600, loss = 0.0343512
I0109 22:46:46.395234  4932 solver.cpp:255]     Train net output #0: loss = 0.0322773 (* 1 = 0.0322773 loss)
I0109 22:46:46.395243  4932 solver.cpp:631] Iteration 12600, lr = 1e-05
I0109 22:47:30.994487  4932 solver.cpp:240] Iteration 12620, loss = 0.0798181
I0109 22:47:30.994582  4932 solver.cpp:255]     Train net output #0: loss = 0.00474085 (* 1 = 0.00474085 loss)
I0109 22:47:30.994595  4932 solver.cpp:631] Iteration 12620, lr = 1e-05
I0109 22:47:33.552426  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2834 > 20) by scale factor 0.9397
I0109 22:47:35.772562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4818 > 20) by scale factor 0.816934
I0109 22:48:15.374223  4932 solver.cpp:240] Iteration 12640, loss = 0.0579097
I0109 22:48:15.374331  4932 solver.cpp:255]     Train net output #0: loss = 0.0171869 (* 1 = 0.0171869 loss)
I0109 22:48:15.374346  4932 solver.cpp:631] Iteration 12640, lr = 1e-05
I0109 22:48:49.113713  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.098 > 20) by scale factor 0.569833
I0109 22:48:55.773331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9022 > 20) by scale factor 0.836742
I0109 22:48:59.873212  4932 solver.cpp:240] Iteration 12660, loss = 0.0885338
I0109 22:48:59.873250  4932 solver.cpp:255]     Train net output #0: loss = 0.0979103 (* 1 = 0.0979103 loss)
I0109 22:48:59.873258  4932 solver.cpp:631] Iteration 12660, lr = 1e-05
I0109 22:49:35.726444  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7755 > 20) by scale factor 0.962673
I0109 22:49:37.949985  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8488 > 20) by scale factor 0.77373
I0109 22:49:44.432248  4932 solver.cpp:240] Iteration 12680, loss = 0.069642
I0109 22:49:44.432286  4932 solver.cpp:255]     Train net output #0: loss = 0.0821529 (* 1 = 0.0821529 loss)
I0109 22:49:44.432296  4932 solver.cpp:631] Iteration 12680, lr = 1e-05
I0109 22:50:02.522949  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9505 > 20) by scale factor 0.911141
I0109 22:50:28.846483  4932 solver.cpp:240] Iteration 12700, loss = 0.0716594
I0109 22:50:28.846577  4932 solver.cpp:255]     Train net output #0: loss = 0.0331711 (* 1 = 0.0331711 loss)
I0109 22:50:28.846590  4932 solver.cpp:631] Iteration 12700, lr = 1e-05
I0109 22:50:38.066622  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8918 > 20) by scale factor 0.913584
I0109 22:50:42.508640  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9385 > 20) by scale factor 0.835473
I0109 22:50:55.988247  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7685 > 20) by scale factor 0.747148
I0109 22:51:02.650933  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6734 > 20) by scale factor 0.810589
I0109 22:51:13.407218  4932 solver.cpp:240] Iteration 12720, loss = 0.106813
I0109 22:51:13.407260  4932 solver.cpp:255]     Train net output #0: loss = 0.0096775 (* 1 = 0.0096775 loss)
I0109 22:51:13.407271  4932 solver.cpp:631] Iteration 12720, lr = 1e-05
I0109 22:51:38.629191  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3731 > 20) by scale factor 0.680895
I0109 22:51:58.269796  4932 solver.cpp:240] Iteration 12740, loss = 0.125319
I0109 22:51:58.269848  4932 solver.cpp:255]     Train net output #0: loss = 0.388001 (* 1 = 0.388001 loss)
I0109 22:51:58.269861  4932 solver.cpp:631] Iteration 12740, lr = 1e-05
I0109 22:51:58.610215  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8698 > 20) by scale factor 0.914502
I0109 22:52:23.213253  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4975 > 20) by scale factor 0.975728
I0109 22:52:43.162835  4932 solver.cpp:240] Iteration 12760, loss = 0.0875441
I0109 22:52:43.162874  4932 solver.cpp:255]     Train net output #0: loss = 0.0684551 (* 1 = 0.0684551 loss)
I0109 22:52:43.163010  4932 solver.cpp:631] Iteration 12760, lr = 1e-05
I0109 22:53:27.853813  4932 solver.cpp:240] Iteration 12780, loss = 0.026509
I0109 22:53:27.853924  4932 solver.cpp:255]     Train net output #0: loss = 0.0288501 (* 1 = 0.0288501 loss)
I0109 22:53:27.853940  4932 solver.cpp:631] Iteration 12780, lr = 1e-05
I0109 22:53:30.416759  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8389 > 20) by scale factor 0.875697
I0109 22:54:12.244369  4932 solver.cpp:240] Iteration 12800, loss = 0.0671298
I0109 22:54:12.244477  4932 solver.cpp:255]     Train net output #0: loss = 0.0732281 (* 1 = 0.0732281 loss)
I0109 22:54:12.244488  4932 solver.cpp:631] Iteration 12800, lr = 1e-05
I0109 22:54:17.020341  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1051 > 20) by scale factor 0.865609
I0109 22:54:41.735599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3062 > 20) by scale factor 0.984922
I0109 22:54:56.933464  4932 solver.cpp:240] Iteration 12820, loss = 0.0712549
I0109 22:54:56.933562  4932 solver.cpp:255]     Train net output #0: loss = 0.00138354 (* 1 = 0.00138354 loss)
I0109 22:54:56.933573  4932 solver.cpp:631] Iteration 12820, lr = 1e-05
I0109 22:55:21.677397  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1329 > 20) by scale factor 0.993398
I0109 22:55:41.568857  4932 solver.cpp:240] Iteration 12840, loss = 0.0500513
I0109 22:55:41.568934  4932 solver.cpp:255]     Train net output #0: loss = 0.00915812 (* 1 = 0.00915812 loss)
I0109 22:55:41.568944  4932 solver.cpp:631] Iteration 12840, lr = 1e-05
I0109 22:56:04.110625  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6815 > 20) by scale factor 0.922445
I0109 22:56:15.451354  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0251 > 20) by scale factor 0.998747
I0109 22:56:19.892446  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1146 > 20) by scale factor 0.829373
I0109 22:56:26.209424  4932 solver.cpp:240] Iteration 12860, loss = 0.104391
I0109 22:56:26.209455  4932 solver.cpp:255]     Train net output #0: loss = 0.0467483 (* 1 = 0.0467483 loss)
I0109 22:56:26.209463  4932 solver.cpp:631] Iteration 12860, lr = 1e-05
I0109 22:56:28.767976  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.585 > 20) by scale factor 0.725031
I0109 22:57:10.597965  4932 solver.cpp:240] Iteration 12880, loss = 0.0681815
I0109 22:57:10.598048  4932 solver.cpp:255]     Train net output #0: loss = 0.0124613 (* 1 = 0.0124613 loss)
I0109 22:57:10.598059  4932 solver.cpp:631] Iteration 12880, lr = 1e-05
I0109 22:57:55.009454  4932 solver.cpp:240] Iteration 12900, loss = 0.0547034
I0109 22:57:55.009531  4932 solver.cpp:255]     Train net output #0: loss = 0.0560295 (* 1 = 0.0560295 loss)
I0109 22:57:55.009541  4932 solver.cpp:631] Iteration 12900, lr = 1e-05
I0109 22:58:39.675647  4932 solver.cpp:240] Iteration 12920, loss = 0.0561117
I0109 22:58:39.675735  4932 solver.cpp:255]     Train net output #0: loss = 0.0745669 (* 1 = 0.0745669 loss)
I0109 22:58:39.675746  4932 solver.cpp:631] Iteration 12920, lr = 1e-05
I0109 22:58:53.327802  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2625 > 20) by scale factor 0.940621
I0109 22:59:11.460022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8644 > 20) by scale factor 0.958569
I0109 22:59:24.437439  4932 solver.cpp:240] Iteration 12940, loss = 0.0687348
I0109 22:59:24.437481  4932 solver.cpp:255]     Train net output #0: loss = 0.0150057 (* 1 = 0.0150057 loss)
I0109 22:59:24.437490  4932 solver.cpp:631] Iteration 12940, lr = 1e-05
I0109 22:59:35.874716  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1025 > 20) by scale factor 0.904873
I0109 22:59:47.357754  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6828 > 20) by scale factor 0.966988
I0109 23:00:09.212402  4932 solver.cpp:240] Iteration 12960, loss = 0.0871216
I0109 23:00:09.212437  4932 solver.cpp:255]     Train net output #0: loss = 0.00957745 (* 1 = 0.00957745 loss)
I0109 23:00:09.212446  4932 solver.cpp:631] Iteration 12960, lr = 1e-05
I0109 23:00:18.471563  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2712 > 20) by scale factor 0.898022
I0109 23:00:47.323568  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5617 > 20) by scale factor 0.814275
I0109 23:00:53.728454  4932 solver.cpp:240] Iteration 12980, loss = 0.089546
I0109 23:00:53.728581  4932 solver.cpp:255]     Train net output #0: loss = 0.0556012 (* 1 = 0.0556012 loss)
I0109 23:00:53.728601  4932 solver.cpp:631] Iteration 12980, lr = 1e-05
I0109 23:01:36.241703  4932 solver.cpp:424] Iteration 13000, Testing net (#0)
I0109 23:02:27.130211  4932 solver.cpp:481]     Test net output #0: accuracy = 0.817895
I0109 23:02:27.130302  4932 solver.cpp:481]     Test net output #1: loss = 0.946007 (* 1 = 0.946007 loss)
I0109 23:02:28.997800  4932 solver.cpp:240] Iteration 13000, loss = 0.0527411
I0109 23:02:28.997848  4932 solver.cpp:255]     Train net output #0: loss = 0.0507259 (* 1 = 0.0507259 loss)
I0109 23:02:28.998090  4932 solver.cpp:631] Iteration 13000, lr = 1e-05
I0109 23:03:00.396203  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4421 > 20) by scale factor 0.818261
I0109 23:03:07.055181  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8414 > 20) by scale factor 0.875602
I0109 23:03:11.899813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7131 > 20) by scale factor 0.921103
I0109 23:03:13.780905  4932 solver.cpp:240] Iteration 13020, loss = 0.0564326
I0109 23:03:13.780943  4932 solver.cpp:255]     Train net output #0: loss = 0.0244502 (* 1 = 0.0244502 loss)
I0109 23:03:13.780952  4932 solver.cpp:631] Iteration 13020, lr = 1e-05
I0109 23:03:25.215632  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6929 > 20) by scale factor 0.92196
I0109 23:03:34.093448  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9105 > 20) by scale factor 0.64703
I0109 23:03:49.704241  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0461 > 20) by scale factor 0.907188
I0109 23:03:58.243417  4932 solver.cpp:240] Iteration 13040, loss = 0.122307
I0109 23:03:58.243456  4932 solver.cpp:255]     Train net output #0: loss = 0.138278 (* 1 = 0.138278 loss)
I0109 23:03:58.243465  4932 solver.cpp:631] Iteration 13040, lr = 1e-05
I0109 23:04:14.118826  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3379 > 20) by scale factor 0.856976
I0109 23:04:16.339620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 41.3294 > 20) by scale factor 0.483916
I0109 23:04:20.781671  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5994 > 20) by scale factor 0.925953
I0109 23:04:42.881851  4932 solver.cpp:240] Iteration 13060, loss = 0.114552
I0109 23:04:42.881887  4932 solver.cpp:255]     Train net output #0: loss = 0.0664055 (* 1 = 0.0664055 loss)
I0109 23:04:42.881896  4932 solver.cpp:631] Iteration 13060, lr = 1e-05
I0109 23:05:01.271987  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9916 > 20) by scale factor 0.833624
I0109 23:05:14.594645  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1598 > 20) by scale factor 0.992074
I0109 23:05:27.569635  4932 solver.cpp:240] Iteration 13080, loss = 0.0699286
I0109 23:05:27.569686  4932 solver.cpp:255]     Train net output #0: loss = 0.00524848 (* 1 = 0.00524848 loss)
I0109 23:05:27.569818  4932 solver.cpp:631] Iteration 13080, lr = 1e-05
I0109 23:06:05.944344  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3276 > 20) by scale factor 0.983883
I0109 23:06:12.265378  4932 solver.cpp:240] Iteration 13100, loss = 0.0917469
I0109 23:06:12.265416  4932 solver.cpp:255]     Train net output #0: loss = 0.0656471 (* 1 = 0.0656471 loss)
I0109 23:06:12.265425  4932 solver.cpp:631] Iteration 13100, lr = 1e-05
I0109 23:06:28.144784  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4183 > 20) by scale factor 0.786835
I0109 23:06:34.802677  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1756 > 20) by scale factor 0.862977
I0109 23:06:46.189631  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7245 > 20) by scale factor 0.808914
I0109 23:06:56.950608  4932 solver.cpp:240] Iteration 13120, loss = 0.100708
I0109 23:06:56.950649  4932 solver.cpp:255]     Train net output #0: loss = 0.00655841 (* 1 = 0.00655841 loss)
I0109 23:06:56.950664  4932 solver.cpp:631] Iteration 13120, lr = 1e-05
I0109 23:07:01.727915  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4524 > 20) by scale factor 0.728533
I0109 23:07:41.491984  4932 solver.cpp:240] Iteration 13140, loss = 0.102542
I0109 23:07:41.492060  4932 solver.cpp:255]     Train net output #0: loss = 0.076385 (* 1 = 0.076385 loss)
I0109 23:07:41.492071  4932 solver.cpp:631] Iteration 13140, lr = 1e-05
I0109 23:08:04.031177  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4074 > 20) by scale factor 0.934258
I0109 23:08:25.892020  4932 solver.cpp:240] Iteration 13160, loss = 0.0692849
I0109 23:08:25.892103  4932 solver.cpp:255]     Train net output #0: loss = 0.0478535 (* 1 = 0.0478535 loss)
I0109 23:08:25.892119  4932 solver.cpp:631] Iteration 13160, lr = 1e-05
I0109 23:08:30.667755  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0941 > 20) by scale factor 0.948131
I0109 23:08:52.856637  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1922 > 20) by scale factor 0.685114
I0109 23:08:59.520648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1483 > 20) by scale factor 0.764868
I0109 23:09:01.744417  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6835 > 20) by scale factor 0.84447
I0109 23:09:10.596690  4932 solver.cpp:240] Iteration 13180, loss = 0.11378
I0109 23:09:10.596735  4932 solver.cpp:255]     Train net output #0: loss = 0.00214032 (* 1 = 0.00214032 loss)
I0109 23:09:10.596746  4932 solver.cpp:631] Iteration 13180, lr = 1e-05
I0109 23:09:35.347769  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8776 > 20) by scale factor 0.957966
I0109 23:09:55.350968  4932 solver.cpp:240] Iteration 13200, loss = 0.105561
I0109 23:09:55.351007  4932 solver.cpp:255]     Train net output #0: loss = 0.380397 (* 1 = 0.380397 loss)
I0109 23:09:55.351017  4932 solver.cpp:631] Iteration 13200, lr = 1e-05
I0109 23:09:55.690440  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5995 > 20) by scale factor 0.675687
I0109 23:10:00.128955  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3334 > 20) by scale factor 0.983603
I0109 23:10:27.058954  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5694 > 20) by scale factor 0.725441
I0109 23:10:40.041596  4932 solver.cpp:240] Iteration 13220, loss = 0.06891
I0109 23:10:40.041635  4932 solver.cpp:255]     Train net output #0: loss = 0.00712536 (* 1 = 0.00712536 loss)
I0109 23:10:40.041642  4932 solver.cpp:631] Iteration 13220, lr = 1e-05
I0109 23:11:24.428163  4932 solver.cpp:240] Iteration 13240, loss = 0.0503123
I0109 23:11:24.428261  4932 solver.cpp:255]     Train net output #0: loss = 0.091681 (* 1 = 0.091681 loss)
I0109 23:11:24.428273  4932 solver.cpp:631] Iteration 13240, lr = 1e-05
I0109 23:12:08.841068  4932 solver.cpp:240] Iteration 13260, loss = 0.0768009
I0109 23:12:08.841172  4932 solver.cpp:255]     Train net output #0: loss = 0.154384 (* 1 = 0.154384 loss)
I0109 23:12:08.841188  4932 solver.cpp:631] Iteration 13260, lr = 1e-05
I0109 23:12:29.153545  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2283 > 20) by scale factor 0.988712
I0109 23:12:40.254384  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4781 > 20) by scale factor 0.931179
I0109 23:12:53.236501  4932 solver.cpp:240] Iteration 13280, loss = 0.0576534
I0109 23:12:53.236539  4932 solver.cpp:255]     Train net output #0: loss = 0.0866486 (* 1 = 0.0866486 loss)
I0109 23:12:53.236548  4932 solver.cpp:631] Iteration 13280, lr = 1e-05
I0109 23:12:55.793501  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3405 > 20) by scale factor 0.937184
I0109 23:13:37.633478  4932 solver.cpp:240] Iteration 13300, loss = 0.0727551
I0109 23:13:37.633590  4932 solver.cpp:255]     Train net output #0: loss = 0.015847 (* 1 = 0.015847 loss)
I0109 23:13:37.633608  4932 solver.cpp:631] Iteration 13300, lr = 1e-05
I0109 23:14:00.167536  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5367 > 20) by scale factor 0.973866
I0109 23:14:22.015264  4932 solver.cpp:240] Iteration 13320, loss = 0.0422061
I0109 23:14:22.015360  4932 solver.cpp:255]     Train net output #0: loss = 0.0266781 (* 1 = 0.0266781 loss)
I0109 23:14:22.015372  4932 solver.cpp:631] Iteration 13320, lr = 1e-05
I0109 23:15:06.398373  4932 solver.cpp:240] Iteration 13340, loss = 0.0476349
I0109 23:15:06.398469  4932 solver.cpp:255]     Train net output #0: loss = 0.0837624 (* 1 = 0.0837624 loss)
I0109 23:15:06.398481  4932 solver.cpp:631] Iteration 13340, lr = 1e-05
I0109 23:15:44.474336  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.032 > 20) by scale factor 0.71347
I0109 23:15:46.845835  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3821 > 20) by scale factor 0.855355
I0109 23:15:50.950497  4932 solver.cpp:240] Iteration 13360, loss = 0.0770873
I0109 23:15:50.950541  4932 solver.cpp:255]     Train net output #0: loss = 0.0363687 (* 1 = 0.0363687 loss)
I0109 23:15:50.950552  4932 solver.cpp:631] Iteration 13360, lr = 1e-05
I0109 23:16:35.612030  4932 solver.cpp:240] Iteration 13380, loss = 0.0666775
I0109 23:16:35.612125  4932 solver.cpp:255]     Train net output #0: loss = 0.15945 (* 1 = 0.15945 loss)
I0109 23:16:35.612136  4932 solver.cpp:631] Iteration 13380, lr = 1e-05
I0109 23:17:19.998478  4932 solver.cpp:240] Iteration 13400, loss = 0.088064
I0109 23:17:19.998565  4932 solver.cpp:255]     Train net output #0: loss = 0.0285412 (* 1 = 0.0285412 loss)
I0109 23:17:19.998576  4932 solver.cpp:631] Iteration 13400, lr = 1e-05
I0109 23:18:04.429848  4932 solver.cpp:240] Iteration 13420, loss = 0.061326
I0109 23:18:04.429939  4932 solver.cpp:255]     Train net output #0: loss = 0.101533 (* 1 = 0.101533 loss)
I0109 23:18:04.429950  4932 solver.cpp:631] Iteration 13420, lr = 1e-05
I0109 23:18:04.769307  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6347 > 20) by scale factor 0.969243
I0109 23:18:06.990182  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5047 > 20) by scale factor 0.816169
I0109 23:18:49.328747  4932 solver.cpp:240] Iteration 13440, loss = 0.0584873
I0109 23:18:49.328865  4932 solver.cpp:255]     Train net output #0: loss = 0.0402249 (* 1 = 0.0402249 loss)
I0109 23:18:49.328881  4932 solver.cpp:631] Iteration 13440, lr = 1e-05
I0109 23:19:05.199940  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8834 > 20) by scale factor 0.913935
I0109 23:19:21.059036  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4888 > 20) by scale factor 0.889331
I0109 23:19:34.035529  4932 solver.cpp:240] Iteration 13460, loss = 0.0813729
I0109 23:19:34.035568  4932 solver.cpp:255]     Train net output #0: loss = 0.0446603 (* 1 = 0.0446603 loss)
I0109 23:19:34.035578  4932 solver.cpp:631] Iteration 13460, lr = 1e-05
I0109 23:20:18.806010  4932 solver.cpp:240] Iteration 13480, loss = 0.064787
I0109 23:20:18.806109  4932 solver.cpp:255]     Train net output #0: loss = 0.0142485 (* 1 = 0.0142485 loss)
I0109 23:20:18.806123  4932 solver.cpp:631] Iteration 13480, lr = 1e-05
I0109 23:21:03.201702  4932 solver.cpp:240] Iteration 13500, loss = 0.0326885
I0109 23:21:03.201794  4932 solver.cpp:255]     Train net output #0: loss = 0.0477177 (* 1 = 0.0477177 loss)
I0109 23:21:03.201807  4932 solver.cpp:631] Iteration 13500, lr = 1e-05
I0109 23:21:43.524801  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3252 > 20) by scale factor 0.937858
I0109 23:21:47.628866  4932 solver.cpp:240] Iteration 13520, loss = 0.0608381
I0109 23:21:47.628912  4932 solver.cpp:255]     Train net output #0: loss = 0.0161631 (* 1 = 0.0161631 loss)
I0109 23:21:47.628923  4932 solver.cpp:631] Iteration 13520, lr = 1e-05
I0109 23:22:32.190791  4932 solver.cpp:240] Iteration 13540, loss = 0.0775259
I0109 23:22:32.190897  4932 solver.cpp:255]     Train net output #0: loss = 0.000673324 (* 1 = 0.000673324 loss)
I0109 23:22:32.190909  4932 solver.cpp:631] Iteration 13540, lr = 1e-05
I0109 23:23:03.809144  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4441 > 20) by scale factor 0.97828
I0109 23:23:06.030643  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3455 > 20) by scale factor 0.983017
I0109 23:23:16.788120  4932 solver.cpp:240] Iteration 13560, loss = 0.0498317
I0109 23:23:16.788152  4932 solver.cpp:255]     Train net output #0: loss = 0.00937719 (* 1 = 0.00937719 loss)
I0109 23:23:16.788161  4932 solver.cpp:631] Iteration 13560, lr = 1e-05
I0109 23:23:28.223217  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9618 > 20) by scale factor 0.834662
I0109 23:23:34.889014  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.541 > 20) by scale factor 0.973662
I0109 23:24:01.187176  4932 solver.cpp:240] Iteration 13580, loss = 0.0743518
I0109 23:24:01.187214  4932 solver.cpp:255]     Train net output #0: loss = 0.00651098 (* 1 = 0.00651098 loss)
I0109 23:24:01.187223  4932 solver.cpp:631] Iteration 13580, lr = 1e-05
I0109 23:24:21.502948  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.02 > 20) by scale factor 0.832638
I0109 23:24:45.582450  4932 solver.cpp:240] Iteration 13600, loss = 0.0746734
I0109 23:24:45.582496  4932 solver.cpp:255]     Train net output #0: loss = 0.00461255 (* 1 = 0.00461255 loss)
I0109 23:24:45.582507  4932 solver.cpp:631] Iteration 13600, lr = 1e-05
I0109 23:25:30.151315  4932 solver.cpp:240] Iteration 13620, loss = 0.0493712
I0109 23:25:30.151407  4932 solver.cpp:255]     Train net output #0: loss = 0.0132814 (* 1 = 0.0132814 loss)
I0109 23:25:30.151418  4932 solver.cpp:631] Iteration 13620, lr = 1e-05
I0109 23:26:14.533689  4932 solver.cpp:240] Iteration 13640, loss = 0.0456824
I0109 23:26:14.533787  4932 solver.cpp:255]     Train net output #0: loss = 0.0532621 (* 1 = 0.0532621 loss)
I0109 23:26:14.533799  4932 solver.cpp:631] Iteration 13640, lr = 1e-05
I0109 23:26:28.199219  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9082 > 20) by scale factor 0.647078
I0109 23:26:58.939057  4932 solver.cpp:240] Iteration 13660, loss = 0.0795838
I0109 23:26:58.939149  4932 solver.cpp:255]     Train net output #0: loss = 0.0120899 (* 1 = 0.0120899 loss)
I0109 23:26:58.939162  4932 solver.cpp:631] Iteration 13660, lr = 1e-05
I0109 23:27:05.937355  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6378 > 20) by scale factor 0.750812
I0109 23:27:43.341421  4932 solver.cpp:240] Iteration 13680, loss = 0.0630178
I0109 23:27:43.341486  4932 solver.cpp:255]     Train net output #0: loss = 0.0521618 (* 1 = 0.0521618 loss)
I0109 23:27:43.341498  4932 solver.cpp:631] Iteration 13680, lr = 1e-05
I0109 23:28:27.861884  4932 solver.cpp:240] Iteration 13700, loss = 0.0625536
I0109 23:28:27.861973  4932 solver.cpp:255]     Train net output #0: loss = 0.00355127 (* 1 = 0.00355127 loss)
I0109 23:28:27.861984  4932 solver.cpp:631] Iteration 13700, lr = 1e-05
I0109 23:29:10.672833  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.26 > 20) by scale factor 0.683526
I0109 23:29:12.554041  4932 solver.cpp:240] Iteration 13720, loss = 0.0634832
I0109 23:29:12.554081  4932 solver.cpp:255]     Train net output #0: loss = 0.267405 (* 1 = 0.267405 loss)
I0109 23:29:12.554091  4932 solver.cpp:631] Iteration 13720, lr = 1e-05
I0109 23:29:28.436589  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5436 > 20) by scale factor 0.782976
I0109 23:29:55.079030  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8648 > 20) by scale factor 0.958552
I0109 23:29:57.004184  4932 solver.cpp:240] Iteration 13740, loss = 0.0759705
I0109 23:29:57.004223  4932 solver.cpp:255]     Train net output #0: loss = 0.0375925 (* 1 = 0.0375925 loss)
I0109 23:29:57.004233  4932 solver.cpp:631] Iteration 13740, lr = 1e-05
I0109 23:29:59.561532  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3829 > 20) by scale factor 0.637289
I0109 23:30:04.005753  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0841 > 20) by scale factor 0.766751
I0109 23:30:37.530908  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4384 > 20) by scale factor 0.932905
I0109 23:30:41.632273  4932 solver.cpp:240] Iteration 13760, loss = 0.0588205
I0109 23:30:41.632316  4932 solver.cpp:255]     Train net output #0: loss = 0.0453934 (* 1 = 0.0453934 loss)
I0109 23:30:41.632328  4932 solver.cpp:631] Iteration 13760, lr = 1e-05
I0109 23:31:01.950420  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6538 > 20) by scale factor 0.923626
I0109 23:31:26.029712  4932 solver.cpp:240] Iteration 13780, loss = 0.0413273
I0109 23:31:26.029795  4932 solver.cpp:255]     Train net output #0: loss = 0.00387015 (* 1 = 0.00387015 loss)
I0109 23:31:26.029808  4932 solver.cpp:631] Iteration 13780, lr = 1e-05
I0109 23:31:57.662469  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7889 > 20) by scale factor 0.877619
I0109 23:32:10.642446  4932 solver.cpp:240] Iteration 13800, loss = 0.0592323
I0109 23:32:10.642485  4932 solver.cpp:255]     Train net output #0: loss = 0.0288677 (* 1 = 0.0288677 loss)
I0109 23:32:10.642494  4932 solver.cpp:631] Iteration 13800, lr = 1e-05
I0109 23:32:35.631907  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0872 > 20) by scale factor 0.738357
I0109 23:32:55.700047  4932 solver.cpp:240] Iteration 13820, loss = 0.0945133
I0109 23:32:55.700083  4932 solver.cpp:255]     Train net output #0: loss = 0.0116977 (* 1 = 0.0116977 loss)
I0109 23:32:55.700091  4932 solver.cpp:631] Iteration 13820, lr = 1e-05
I0109 23:33:04.917582  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2952 > 20) by scale factor 0.823208
I0109 23:33:33.779394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6566 > 20) by scale factor 0.923504
I0109 23:33:40.104949  4932 solver.cpp:240] Iteration 13840, loss = 0.0754657
I0109 23:33:40.104993  4932 solver.cpp:255]     Train net output #0: loss = 0.153862 (* 1 = 0.153862 loss)
I0109 23:33:40.105003  4932 solver.cpp:631] Iteration 13840, lr = 1e-05
I0109 23:33:49.325609  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2425 > 20) by scale factor 0.899179
I0109 23:33:55.992383  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.407 > 20) by scale factor 0.854447
I0109 23:34:24.507834  4932 solver.cpp:240] Iteration 13860, loss = 0.086702
I0109 23:34:24.507935  4932 solver.cpp:255]     Train net output #0: loss = 0.00593567 (* 1 = 0.00593567 loss)
I0109 23:34:24.507948  4932 solver.cpp:631] Iteration 13860, lr = 1e-05
I0109 23:35:04.804764  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9609 > 20) by scale factor 0.954159
I0109 23:35:08.907411  4932 solver.cpp:240] Iteration 13880, loss = 0.0534179
I0109 23:35:08.907454  4932 solver.cpp:255]     Train net output #0: loss = 0.0641896 (* 1 = 0.0641896 loss)
I0109 23:35:08.907469  4932 solver.cpp:631] Iteration 13880, lr = 1e-05
I0109 23:35:53.432899  4932 solver.cpp:240] Iteration 13900, loss = 0.0640992
I0109 23:35:53.433006  4932 solver.cpp:255]     Train net output #0: loss = 0.0244064 (* 1 = 0.0244064 loss)
I0109 23:35:53.433020  4932 solver.cpp:631] Iteration 13900, lr = 1e-05
I0109 23:36:31.776738  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7565 > 20) by scale factor 0.963554
I0109 23:36:38.095959  4932 solver.cpp:240] Iteration 13920, loss = 0.0513251
I0109 23:36:38.095999  4932 solver.cpp:255]     Train net output #0: loss = 0.0236 (* 1 = 0.0236 loss)
I0109 23:36:38.096007  4932 solver.cpp:631] Iteration 13920, lr = 1e-05
I0109 23:36:42.874145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2796 > 20) by scale factor 0.859122
I0109 23:37:13.954787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3751 > 20) by scale factor 0.981588
I0109 23:37:22.492739  4932 solver.cpp:240] Iteration 13940, loss = 0.0668303
I0109 23:37:22.492780  4932 solver.cpp:255]     Train net output #0: loss = 0.00928951 (* 1 = 0.00928951 loss)
I0109 23:37:22.492789  4932 solver.cpp:631] Iteration 13940, lr = 1e-05
I0109 23:37:42.806435  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9906 > 20) by scale factor 0.909478
I0109 23:37:58.339042  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3792 > 20) by scale factor 0.935488
I0109 23:38:06.880189  4932 solver.cpp:240] Iteration 13960, loss = 0.0602233
I0109 23:38:06.880231  4932 solver.cpp:255]     Train net output #0: loss = 0.0792157 (* 1 = 0.0792157 loss)
I0109 23:38:06.880244  4932 solver.cpp:631] Iteration 13960, lr = 1e-05
I0109 23:38:13.882472  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4648 > 20) by scale factor 0.977288
I0109 23:38:36.088981  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.1552 > 20) by scale factor 0.641947
I0109 23:38:51.296582  4932 solver.cpp:240] Iteration 13980, loss = 0.053095
I0109 23:38:51.296628  4932 solver.cpp:255]     Train net output #0: loss = 0.027039 (* 1 = 0.027039 loss)
I0109 23:38:51.296640  4932 solver.cpp:631] Iteration 13980, lr = 1e-05
I0109 23:39:09.402402  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4095 > 20) by scale factor 0.892479
I0109 23:39:16.065635  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9834 > 20) by scale factor 0.741195
I0109 23:39:29.391685  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4714 > 20) by scale factor 0.728029
I0109 23:39:33.844957  4932 solver.cpp:424] Iteration 14000, Testing net (#0)
I0109 23:40:21.775902  4932 solver.cpp:481]     Test net output #0: accuracy = 0.84
I0109 23:40:21.775996  4932 solver.cpp:481]     Test net output #1: loss = 0.735082 (* 1 = 0.735082 loss)
I0109 23:40:23.642380  4932 solver.cpp:240] Iteration 14000, loss = 0.0803417
I0109 23:40:23.642417  4932 solver.cpp:255]     Train net output #0: loss = 0.0595417 (* 1 = 0.0595417 loss)
I0109 23:40:23.642426  4932 solver.cpp:631] Iteration 14000, lr = 1e-05
I0109 23:40:32.860764  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8888 > 20) by scale factor 0.803575
I0109 23:40:52.834326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.384 > 20) by scale factor 0.981162
I0109 23:41:08.133649  4932 solver.cpp:240] Iteration 14020, loss = 0.0701935
I0109 23:41:08.133688  4932 solver.cpp:255]     Train net output #0: loss = 0.00272646 (* 1 = 0.00272646 loss)
I0109 23:41:08.133697  4932 solver.cpp:631] Iteration 14020, lr = 1e-05
I0109 23:41:46.188585  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7764 > 20) by scale factor 0.775902
I0109 23:41:52.511297  4932 solver.cpp:240] Iteration 14040, loss = 0.0648154
I0109 23:41:52.511339  4932 solver.cpp:255]     Train net output #0: loss = 0.0399471 (* 1 = 0.0399471 loss)
I0109 23:41:52.511349  4932 solver.cpp:631] Iteration 14040, lr = 1e-05
I0109 23:42:06.162056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5662 > 20) by scale factor 0.752837
I0109 23:42:28.354455  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0476 > 20) by scale factor 0.950227
I0109 23:42:32.798177  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9017 > 20) by scale factor 0.91317
I0109 23:42:36.901558  4932 solver.cpp:240] Iteration 14060, loss = 0.0638269
I0109 23:42:36.901602  4932 solver.cpp:255]     Train net output #0: loss = 0.122965 (* 1 = 0.122965 loss)
I0109 23:42:36.901614  4932 solver.cpp:631] Iteration 14060, lr = 1e-05
I0109 23:42:48.335983  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7019 > 20) by scale factor 0.921577
I0109 23:42:52.777568  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9461 > 20) by scale factor 0.801727
I0109 23:42:59.435716  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7859 > 20) by scale factor 0.840836
I0109 23:43:19.405505  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4125 > 20) by scale factor 0.979792
I0109 23:43:21.286651  4932 solver.cpp:240] Iteration 14080, loss = 0.0783113
I0109 23:43:21.286691  4932 solver.cpp:255]     Train net output #0: loss = 0.012349 (* 1 = 0.012349 loss)
I0109 23:43:21.286700  4932 solver.cpp:631] Iteration 14080, lr = 1e-05
I0109 23:44:05.670634  4932 solver.cpp:240] Iteration 14100, loss = 0.0612728
I0109 23:44:05.670725  4932 solver.cpp:255]     Train net output #0: loss = 0.00774503 (* 1 = 0.00774503 loss)
I0109 23:44:05.670738  4932 solver.cpp:631] Iteration 14100, lr = 1e-05
I0109 23:44:32.640233  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4559 > 20) by scale factor 0.890633
I0109 23:44:39.303498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7788 > 20) by scale factor 0.841086
I0109 23:44:45.965139  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.835 > 20) by scale factor 0.693602
I0109 23:44:50.063758  4932 solver.cpp:240] Iteration 14120, loss = 0.085243
I0109 23:44:50.063796  4932 solver.cpp:255]     Train net output #0: loss = 0.0320652 (* 1 = 0.0320652 loss)
I0109 23:44:50.063805  4932 solver.cpp:631] Iteration 14120, lr = 1e-05
I0109 23:45:34.639749  4932 solver.cpp:240] Iteration 14140, loss = 0.0446734
I0109 23:45:34.639837  4932 solver.cpp:255]     Train net output #0: loss = 0.0234282 (* 1 = 0.0234282 loss)
I0109 23:45:34.639850  4932 solver.cpp:631] Iteration 14140, lr = 1e-05
I0109 23:45:46.081823  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.857 > 20) by scale factor 0.717953
I0109 23:46:10.583252  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0343 > 20) by scale factor 0.768216
I0109 23:46:19.122498  4932 solver.cpp:240] Iteration 14160, loss = 0.061196
I0109 23:46:19.122531  4932 solver.cpp:255]     Train net output #0: loss = 0.0246721 (* 1 = 0.0246721 loss)
I0109 23:46:19.122541  4932 solver.cpp:631] Iteration 14160, lr = 1e-05
I0109 23:46:26.117055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7388 > 20) by scale factor 0.964378
I0109 23:46:48.309098  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9075 > 20) by scale factor 0.956597
I0109 23:46:52.751360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1864 > 20) by scale factor 0.862573
I0109 23:46:54.973130  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1106 > 20) by scale factor 0.947393
I0109 23:47:03.731181  4932 solver.cpp:240] Iteration 14180, loss = 0.0833805
I0109 23:47:03.731228  4932 solver.cpp:255]     Train net output #0: loss = 0.129632 (* 1 = 0.129632 loss)
I0109 23:47:03.731240  4932 solver.cpp:631] Iteration 14180, lr = 1e-05
I0109 23:47:26.280186  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0626 > 20) by scale factor 0.767385
I0109 23:47:48.386191  4932 solver.cpp:240] Iteration 14200, loss = 0.0954042
I0109 23:47:48.386239  4932 solver.cpp:255]     Train net output #0: loss = 0.00277023 (* 1 = 0.00277023 loss)
I0109 23:47:48.386250  4932 solver.cpp:631] Iteration 14200, lr = 1e-05
I0109 23:48:17.845257  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7141 > 20) by scale factor 0.92106
I0109 23:48:33.055248  4932 solver.cpp:240] Iteration 14220, loss = 0.0705063
I0109 23:48:33.055290  4932 solver.cpp:255]     Train net output #0: loss = 0.00789862 (* 1 = 0.00789862 loss)
I0109 23:48:33.055301  4932 solver.cpp:631] Iteration 14220, lr = 1e-05
I0109 23:48:40.056905  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5982 > 20) by scale factor 0.885026
I0109 23:49:13.370709  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8421 > 20) by scale factor 0.745097
I0109 23:49:17.474854  4932 solver.cpp:240] Iteration 14240, loss = 0.0654826
I0109 23:49:17.474897  4932 solver.cpp:255]     Train net output #0: loss = 0.097972 (* 1 = 0.097972 loss)
I0109 23:49:17.474907  4932 solver.cpp:631] Iteration 14240, lr = 1e-05
I0109 23:49:17.813982  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4979 > 20) by scale factor 0.930322
I0109 23:50:01.853288  4932 solver.cpp:240] Iteration 14260, loss = 0.0711508
I0109 23:50:01.853363  4932 solver.cpp:255]     Train net output #0: loss = 0.188093 (* 1 = 0.188093 loss)
I0109 23:50:01.853374  4932 solver.cpp:631] Iteration 14260, lr = 1e-05
I0109 23:50:11.067256  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8552 > 20) by scale factor 0.83839
I0109 23:50:31.039707  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0882 > 20) by scale factor 0.90546
I0109 23:50:33.260437  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9007 > 20) by scale factor 0.956904
I0109 23:50:46.238986  4932 solver.cpp:240] Iteration 14280, loss = 0.0837469
I0109 23:50:46.239029  4932 solver.cpp:255]     Train net output #0: loss = 0.160474 (* 1 = 0.160474 loss)
I0109 23:50:46.239042  4932 solver.cpp:631] Iteration 14280, lr = 1e-05
I0109 23:51:26.636018  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0485 > 20) by scale factor 0.907091
I0109 23:51:30.739127  4932 solver.cpp:240] Iteration 14300, loss = 0.0722545
I0109 23:51:30.739164  4932 solver.cpp:255]     Train net output #0: loss = 0.15132 (* 1 = 0.15132 loss)
I0109 23:51:30.739174  4932 solver.cpp:631] Iteration 14300, lr = 1e-05
I0109 23:52:15.155189  4932 solver.cpp:240] Iteration 14320, loss = 0.0596439
I0109 23:52:15.155288  4932 solver.cpp:255]     Train net output #0: loss = 0.215174 (* 1 = 0.215174 loss)
I0109 23:52:15.155304  4932 solver.cpp:631] Iteration 14320, lr = 1e-05
I0109 23:52:15.495748  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4976 > 20) by scale factor 0.754785
I0109 23:52:19.940428  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.2521 > 20) by scale factor 0.683711
I0109 23:52:51.188901  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7184 > 20) by scale factor 0.965326
I0109 23:52:59.732391  4932 solver.cpp:240] Iteration 14340, loss = 0.0879255
I0109 23:52:59.732424  4932 solver.cpp:255]     Train net output #0: loss = 0.084018 (* 1 = 0.084018 loss)
I0109 23:52:59.732432  4932 solver.cpp:631] Iteration 14340, lr = 1e-05
I0109 23:53:13.390241  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8683 > 20) by scale factor 0.837931
I0109 23:53:44.125404  4932 solver.cpp:240] Iteration 14360, loss = 0.0625745
I0109 23:53:44.125499  4932 solver.cpp:255]     Train net output #0: loss = 0.0163877 (* 1 = 0.0163877 loss)
I0109 23:53:44.125510  4932 solver.cpp:631] Iteration 14360, lr = 1e-05
I0109 23:54:19.978950  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1287 > 20) by scale factor 0.686609
I0109 23:54:28.515887  4932 solver.cpp:240] Iteration 14380, loss = 0.089105
I0109 23:54:28.515929  4932 solver.cpp:255]     Train net output #0: loss = 0.049397 (* 1 = 0.049397 loss)
I0109 23:54:28.515940  4932 solver.cpp:631] Iteration 14380, lr = 1e-05
I0109 23:54:48.828806  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0675 > 20) by scale factor 0.996635
I0109 23:55:08.805214  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2978 > 20) by scale factor 0.985327
I0109 23:55:11.026474  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.039 > 20) by scale factor 0.713292
I0109 23:55:12.908072  4932 solver.cpp:240] Iteration 14400, loss = 0.0932083
I0109 23:55:12.908115  4932 solver.cpp:255]     Train net output #0: loss = 0.127449 (* 1 = 0.127449 loss)
I0109 23:55:12.908324  4932 solver.cpp:631] Iteration 14400, lr = 1e-05
I0109 23:55:53.385859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 40.8334 > 20) by scale factor 0.489795
I0109 23:55:57.492239  4932 solver.cpp:240] Iteration 14420, loss = 0.0806073
I0109 23:55:57.492280  4932 solver.cpp:255]     Train net output #0: loss = 0.213618 (* 1 = 0.213618 loss)
I0109 23:55:57.492290  4932 solver.cpp:631] Iteration 14420, lr = 1e-05
I0109 23:56:26.701581  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9498 > 20) by scale factor 0.83508
I0109 23:56:41.903540  4932 solver.cpp:240] Iteration 14440, loss = 0.053564
I0109 23:56:41.903576  4932 solver.cpp:255]     Train net output #0: loss = 0.0281011 (* 1 = 0.0281011 loss)
I0109 23:56:41.903586  4932 solver.cpp:631] Iteration 14440, lr = 1e-05
I0109 23:56:48.896339  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6138 > 20) by scale factor 0.846964
I0109 23:57:20.663368  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9288 > 20) by scale factor 0.912043
I0109 23:57:26.980707  4932 solver.cpp:240] Iteration 14460, loss = 0.062187
I0109 23:57:26.980756  4932 solver.cpp:255]     Train net output #0: loss = 0.00419992 (* 1 = 0.00419992 loss)
I0109 23:57:26.980767  4932 solver.cpp:631] Iteration 14460, lr = 1e-05
I0109 23:58:11.352051  4932 solver.cpp:240] Iteration 14480, loss = 0.0541975
I0109 23:58:11.352145  4932 solver.cpp:255]     Train net output #0: loss = 0.135691 (* 1 = 0.135691 loss)
I0109 23:58:11.352157  4932 solver.cpp:631] Iteration 14480, lr = 1e-05
I0109 23:58:22.788022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7409 > 20) by scale factor 0.747917
I0109 23:58:36.101047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.809 > 20) by scale factor 0.876849
I0109 23:58:55.729611  4932 solver.cpp:240] Iteration 14500, loss = 0.0915952
I0109 23:58:55.729723  4932 solver.cpp:255]     Train net output #0: loss = 0.0332473 (* 1 = 0.0332473 loss)
I0109 23:58:55.729739  4932 solver.cpp:631] Iteration 14500, lr = 1e-05
I0109 23:58:58.289299  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1266 > 20) by scale factor 0.795969
I0109 23:59:02.728894  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.968 > 20) by scale factor 0.834446
I0109 23:59:29.370692  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0914 > 20) by scale factor 0.797085
I0109 23:59:33.810767  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5556 > 20) by scale factor 0.782606
I0109 23:59:40.129986  4932 solver.cpp:240] Iteration 14520, loss = 0.102884
I0109 23:59:40.130025  4932 solver.cpp:255]     Train net output #0: loss = 0.0101811 (* 1 = 0.0101811 loss)
I0109 23:59:40.130034  4932 solver.cpp:631] Iteration 14520, lr = 1e-05
I0109 23:59:51.566731  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8362 > 20) by scale factor 0.875804
I0109 23:59:56.003588  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4741 > 20) by scale factor 0.81719
I0110 00:00:24.514719  4932 solver.cpp:240] Iteration 14540, loss = 0.063914
I0110 00:00:24.514811  4932 solver.cpp:255]     Train net output #0: loss = 0.0546938 (* 1 = 0.0546938 loss)
I0110 00:00:24.514822  4932 solver.cpp:631] Iteration 14540, lr = 1e-05
I0110 00:00:29.291959  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0059 > 20) by scale factor 0.952114
I0110 00:01:08.898810  4932 solver.cpp:240] Iteration 14560, loss = 0.083471
I0110 00:01:08.898908  4932 solver.cpp:255]     Train net output #0: loss = 0.0867112 (* 1 = 0.0867112 loss)
I0110 00:01:08.898921  4932 solver.cpp:631] Iteration 14560, lr = 1e-05
I0110 00:01:31.425662  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.798 > 20) by scale factor 0.719476
I0110 00:01:53.281225  4932 solver.cpp:240] Iteration 14580, loss = 0.0567498
I0110 00:01:53.281327  4932 solver.cpp:255]     Train net output #0: loss = 0.286083 (* 1 = 0.286083 loss)
I0110 00:01:53.281343  4932 solver.cpp:631] Iteration 14580, lr = 1e-05
I0110 00:01:53.620545  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8441 > 20) by scale factor 0.838781
I0110 00:02:37.662822  4932 solver.cpp:240] Iteration 14600, loss = 0.048727
I0110 00:02:37.662889  4932 solver.cpp:255]     Train net output #0: loss = 0.0374453 (* 1 = 0.0374453 loss)
I0110 00:02:37.662899  4932 solver.cpp:631] Iteration 14600, lr = 1e-05
I0110 00:02:42.440481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4163 > 20) by scale factor 0.979609
I0110 00:02:49.102814  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5312 > 20) by scale factor 0.928886
I0110 00:03:09.081010  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4764 > 20) by scale factor 0.931253
I0110 00:03:22.055074  4932 solver.cpp:240] Iteration 14620, loss = 0.0895064
I0110 00:03:22.055115  4932 solver.cpp:255]     Train net output #0: loss = 0.011112 (* 1 = 0.011112 loss)
I0110 00:03:22.055125  4932 solver.cpp:631] Iteration 14620, lr = 1e-05
I0110 00:03:53.457193  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0885 > 20) by scale factor 0.948382
I0110 00:04:06.433018  4932 solver.cpp:240] Iteration 14640, loss = 0.0741229
I0110 00:04:06.433058  4932 solver.cpp:255]     Train net output #0: loss = 0.0285828 (* 1 = 0.0285828 loss)
I0110 00:04:06.433066  4932 solver.cpp:631] Iteration 14640, lr = 1e-05
I0110 00:04:40.054181  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7514 > 20) by scale factor 0.808036
I0110 00:04:48.938060  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6752 > 20) by scale factor 0.967344
I0110 00:04:50.820875  4932 solver.cpp:240] Iteration 14660, loss = 0.0786859
I0110 00:04:50.820915  4932 solver.cpp:255]     Train net output #0: loss = 0.108332 (* 1 = 0.108332 loss)
I0110 00:04:50.820924  4932 solver.cpp:631] Iteration 14660, lr = 1e-05
I0110 00:05:15.978852  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6437 > 20) by scale factor 0.779919
I0110 00:05:35.634646  4932 solver.cpp:240] Iteration 14680, loss = 0.0548749
I0110 00:05:35.634687  4932 solver.cpp:255]     Train net output #0: loss = 0.00709346 (* 1 = 0.00709346 loss)
I0110 00:05:35.634697  4932 solver.cpp:631] Iteration 14680, lr = 1e-05
I0110 00:05:38.192387  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3914 > 20) by scale factor 0.980806
I0110 00:05:47.069017  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1118 > 20) by scale factor 0.865359
I0110 00:06:20.030676  4932 solver.cpp:240] Iteration 14700, loss = 0.0877214
I0110 00:06:20.030769  4932 solver.cpp:255]     Train net output #0: loss = 0.0266288 (* 1 = 0.0266288 loss)
I0110 00:06:20.030782  4932 solver.cpp:631] Iteration 14700, lr = 1e-05
I0110 00:06:27.027096  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8573 > 20) by scale factor 0.958895
I0110 00:06:29.247864  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8738 > 20) by scale factor 0.914335
I0110 00:07:04.718936  4932 solver.cpp:240] Iteration 14720, loss = 0.0545362
I0110 00:07:04.719015  4932 solver.cpp:255]     Train net output #0: loss = 0.0329044 (* 1 = 0.0329044 loss)
I0110 00:07:04.719025  4932 solver.cpp:631] Iteration 14720, lr = 1e-05
I0110 00:07:31.693836  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4929 > 20) by scale factor 0.784532
I0110 00:07:49.111665  4932 solver.cpp:240] Iteration 14740, loss = 0.0429533
I0110 00:07:49.111734  4932 solver.cpp:255]     Train net output #0: loss = 0.0652511 (* 1 = 0.0652511 loss)
I0110 00:07:49.111744  4932 solver.cpp:631] Iteration 14740, lr = 1e-05
I0110 00:08:24.955287  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.049 > 20) by scale factor 0.997556
I0110 00:08:33.492358  4932 solver.cpp:240] Iteration 14760, loss = 0.0969519
I0110 00:08:33.492398  4932 solver.cpp:255]     Train net output #0: loss = 0.120636 (* 1 = 0.120636 loss)
I0110 00:08:33.492406  4932 solver.cpp:631] Iteration 14760, lr = 1e-05
I0110 00:09:17.911401  4932 solver.cpp:240] Iteration 14780, loss = 0.0330676
I0110 00:09:17.911491  4932 solver.cpp:255]     Train net output #0: loss = 0.0140243 (* 1 = 0.0140243 loss)
I0110 00:09:17.911504  4932 solver.cpp:631] Iteration 14780, lr = 1e-05
I0110 00:09:24.905858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4902 > 20) by scale factor 0.930656
I0110 00:09:31.565575  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.666 > 20) by scale factor 0.967773
I0110 00:09:49.383363  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.661 > 20) by scale factor 0.779391
I0110 00:10:02.359266  4932 solver.cpp:240] Iteration 14800, loss = 0.0893476
I0110 00:10:02.359300  4932 solver.cpp:255]     Train net output #0: loss = 0.00530081 (* 1 = 0.00530081 loss)
I0110 00:10:02.359310  4932 solver.cpp:631] Iteration 14800, lr = 1e-05
I0110 00:10:35.978665  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0695 > 20) by scale factor 0.90623
I0110 00:10:46.738334  4932 solver.cpp:240] Iteration 14820, loss = 0.0504776
I0110 00:10:46.738387  4932 solver.cpp:255]     Train net output #0: loss = 0.00536229 (* 1 = 0.00536229 loss)
I0110 00:10:46.738533  4932 solver.cpp:631] Iteration 14820, lr = 1e-05
I0110 00:11:00.399986  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2401 > 20) by scale factor 0.988137
I0110 00:11:31.165565  4932 solver.cpp:240] Iteration 14840, loss = 0.0528825
I0110 00:11:31.165653  4932 solver.cpp:255]     Train net output #0: loss = 0.04202 (* 1 = 0.04202 loss)
I0110 00:11:31.165665  4932 solver.cpp:631] Iteration 14840, lr = 1e-05
I0110 00:11:35.942430  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2656 > 20) by scale factor 0.940485
I0110 00:12:02.566416  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2919 > 20) by scale factor 0.985615
I0110 00:12:15.544400  4932 solver.cpp:240] Iteration 14860, loss = 0.0877449
I0110 00:12:15.544447  4932 solver.cpp:255]     Train net output #0: loss = 0.0342221 (* 1 = 0.0342221 loss)
I0110 00:12:15.544461  4932 solver.cpp:631] Iteration 14860, lr = 1e-05
I0110 00:12:33.644708  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5976 > 20) by scale factor 0.813086
I0110 00:12:38.088804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8163 > 20) by scale factor 0.916746
I0110 00:12:59.944357  4932 solver.cpp:240] Iteration 14880, loss = 0.0573813
I0110 00:12:59.944397  4932 solver.cpp:255]     Train net output #0: loss = 0.117095 (* 1 = 0.117095 loss)
I0110 00:12:59.944406  4932 solver.cpp:631] Iteration 14880, lr = 1e-05
I0110 00:13:18.037525  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3492 > 20) by scale factor 0.821382
I0110 00:13:26.917675  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0265 > 20) by scale factor 0.907997
I0110 00:13:44.330442  4932 solver.cpp:240] Iteration 14900, loss = 0.0782655
I0110 00:13:44.330488  4932 solver.cpp:255]     Train net output #0: loss = 0.106021 (* 1 = 0.106021 loss)
I0110 00:13:44.330499  4932 solver.cpp:631] Iteration 14900, lr = 1e-05
I0110 00:14:28.757257  4932 solver.cpp:240] Iteration 14920, loss = 0.0629904
I0110 00:14:28.757355  4932 solver.cpp:255]     Train net output #0: loss = 0.000828395 (* 1 = 0.000828395 loss)
I0110 00:14:28.757369  4932 solver.cpp:631] Iteration 14920, lr = 1e-05
I0110 00:15:13.252331  4932 solver.cpp:240] Iteration 14940, loss = 0.0472755
I0110 00:15:13.252436  4932 solver.cpp:255]     Train net output #0: loss = 0.0143222 (* 1 = 0.0143222 loss)
I0110 00:15:13.252452  4932 solver.cpp:631] Iteration 14940, lr = 1e-05
I0110 00:15:46.881897  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7819 > 20) by scale factor 0.746774
I0110 00:15:49.274834  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4264 > 20) by scale factor 0.818788
I0110 00:15:57.812885  4932 solver.cpp:240] Iteration 14960, loss = 0.0572562
I0110 00:15:57.812923  4932 solver.cpp:255]     Train net output #0: loss = 0.0997801 (* 1 = 0.0997801 loss)
I0110 00:15:57.812932  4932 solver.cpp:631] Iteration 14960, lr = 1e-05
I0110 00:16:42.194778  4932 solver.cpp:240] Iteration 14980, loss = 0.04896
I0110 00:16:42.194866  4932 solver.cpp:255]     Train net output #0: loss = 0.155417 (* 1 = 0.155417 loss)
I0110 00:16:42.194877  4932 solver.cpp:631] Iteration 14980, lr = 1e-05
I0110 00:16:51.405508  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2856 > 20) by scale factor 0.939603
I0110 00:17:18.043190  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8619 > 20) by scale factor 0.838158
I0110 00:17:24.712462  4932 solver.cpp:424] Iteration 15000, Testing net (#0)
I0110 00:18:14.424393  4932 solver.cpp:481]     Test net output #0: accuracy = 0.847368
I0110 00:18:14.424482  4932 solver.cpp:481]     Test net output #1: loss = 0.78674 (* 1 = 0.78674 loss)
I0110 00:18:16.291429  4932 solver.cpp:240] Iteration 15000, loss = 0.0795357
I0110 00:18:16.291468  4932 solver.cpp:255]     Train net output #0: loss = 0.13785 (* 1 = 0.13785 loss)
I0110 00:18:16.291477  4932 solver.cpp:631] Iteration 15000, lr = 1e-05
I0110 00:19:00.665369  4932 solver.cpp:240] Iteration 15020, loss = 0.0838906
I0110 00:19:00.665459  4932 solver.cpp:255]     Train net output #0: loss = 0.00825292 (* 1 = 0.00825292 loss)
I0110 00:19:00.665470  4932 solver.cpp:631] Iteration 15020, lr = 1e-05
I0110 00:19:09.880195  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7357 > 20) by scale factor 0.96452
I0110 00:19:45.057121  4932 solver.cpp:240] Iteration 15040, loss = 0.0632737
I0110 00:19:45.057219  4932 solver.cpp:255]     Train net output #0: loss = 0.00492414 (* 1 = 0.00492414 loss)
I0110 00:19:45.057231  4932 solver.cpp:631] Iteration 15040, lr = 1e-05
I0110 00:20:29.441488  4932 solver.cpp:240] Iteration 15060, loss = 0.0682964
I0110 00:20:29.441577  4932 solver.cpp:255]     Train net output #0: loss = 0.294966 (* 1 = 0.294966 loss)
I0110 00:20:29.441589  4932 solver.cpp:631] Iteration 15060, lr = 1e-05
I0110 00:20:29.781736  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.887 > 20) by scale factor 0.717181
I0110 00:21:07.752002  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9025 > 20) by scale factor 0.873267
I0110 00:21:14.074939  4932 solver.cpp:240] Iteration 15080, loss = 0.0651687
I0110 00:21:14.074986  4932 solver.cpp:255]     Train net output #0: loss = 0.0438451 (* 1 = 0.0438451 loss)
I0110 00:21:14.074998  4932 solver.cpp:631] Iteration 15080, lr = 1e-05
I0110 00:21:58.449141  4932 solver.cpp:240] Iteration 15100, loss = 0.0492911
I0110 00:21:58.449229  4932 solver.cpp:255]     Train net output #0: loss = 0.00758102 (* 1 = 0.00758102 loss)
I0110 00:21:58.449241  4932 solver.cpp:631] Iteration 15100, lr = 1e-05
I0110 00:22:05.449918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8145 > 20) by scale factor 0.876634
I0110 00:22:42.844416  4932 solver.cpp:240] Iteration 15120, loss = 0.0570892
I0110 00:22:42.844501  4932 solver.cpp:255]     Train net output #0: loss = 0.0181059 (* 1 = 0.0181059 loss)
I0110 00:22:42.844513  4932 solver.cpp:631] Iteration 15120, lr = 1e-05
I0110 00:23:27.227810  4932 solver.cpp:240] Iteration 15140, loss = 0.0560367
I0110 00:23:27.227898  4932 solver.cpp:255]     Train net output #0: loss = 0.00320395 (* 1 = 0.00320395 loss)
I0110 00:23:27.227911  4932 solver.cpp:631] Iteration 15140, lr = 1e-05
I0110 00:23:54.195253  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0951 > 20) by scale factor 0.796969
I0110 00:24:05.296674  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1297 > 20) by scale factor 0.864689
I0110 00:24:09.736342  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1847 > 20) by scale factor 0.944075
I0110 00:24:11.617812  4932 solver.cpp:240] Iteration 15160, loss = 0.0763652
I0110 00:24:11.617848  4932 solver.cpp:255]     Train net output #0: loss = 0.0137617 (* 1 = 0.0137617 loss)
I0110 00:24:11.617856  4932 solver.cpp:631] Iteration 15160, lr = 1e-05
I0110 00:24:25.266454  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2625 > 20) by scale factor 0.898373
I0110 00:24:40.808204  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6398 > 20) by scale factor 0.924224
I0110 00:24:56.006413  4932 solver.cpp:240] Iteration 15180, loss = 0.077964
I0110 00:24:56.006458  4932 solver.cpp:255]     Train net output #0: loss = 0.0240952 (* 1 = 0.0240952 loss)
I0110 00:24:56.006598  4932 solver.cpp:631] Iteration 15180, lr = 1e-05
I0110 00:25:00.787786  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5781 > 20) by scale factor 0.676176
I0110 00:25:40.413377  4932 solver.cpp:240] Iteration 15200, loss = 0.0648735
I0110 00:25:40.413466  4932 solver.cpp:255]     Train net output #0: loss = 0.037318 (* 1 = 0.037318 loss)
I0110 00:25:40.413477  4932 solver.cpp:631] Iteration 15200, lr = 1e-05
I0110 00:25:47.409739  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5203 > 20) by scale factor 0.929355
I0110 00:26:24.798120  4932 solver.cpp:240] Iteration 15220, loss = 0.0701722
I0110 00:26:24.798209  4932 solver.cpp:255]     Train net output #0: loss = 0.0116943 (* 1 = 0.0116943 loss)
I0110 00:26:24.798221  4932 solver.cpp:631] Iteration 15220, lr = 1e-05
I0110 00:26:40.671303  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5969 > 20) by scale factor 0.926059
I0110 00:27:09.186609  4932 solver.cpp:240] Iteration 15240, loss = 0.0624166
I0110 00:27:09.186704  4932 solver.cpp:255]     Train net output #0: loss = 0.152602 (* 1 = 0.152602 loss)
I0110 00:27:09.186717  4932 solver.cpp:631] Iteration 15240, lr = 1e-05
I0110 00:27:53.580601  4932 solver.cpp:240] Iteration 15260, loss = 0.0261167
I0110 00:27:53.580693  4932 solver.cpp:255]     Train net output #0: loss = 0.0347665 (* 1 = 0.0347665 loss)
I0110 00:27:53.580704  4932 solver.cpp:631] Iteration 15260, lr = 1e-05
I0110 00:28:07.237241  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.762 > 20) by scale factor 0.963301
I0110 00:28:13.896723  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2011 > 20) by scale factor 0.943346
I0110 00:28:37.970623  4932 solver.cpp:240] Iteration 15280, loss = 0.0637139
I0110 00:28:37.970710  4932 solver.cpp:255]     Train net output #0: loss = 0.216997 (* 1 = 0.216997 loss)
I0110 00:28:37.970723  4932 solver.cpp:631] Iteration 15280, lr = 1e-05
I0110 00:29:22.359043  4932 solver.cpp:240] Iteration 15300, loss = 0.0739763
I0110 00:29:22.359115  4932 solver.cpp:255]     Train net output #0: loss = 0.0237701 (* 1 = 0.0237701 loss)
I0110 00:29:22.359125  4932 solver.cpp:631] Iteration 15300, lr = 1e-05
I0110 00:29:47.115725  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2491 > 20) by scale factor 0.898914
I0110 00:30:06.747974  4932 solver.cpp:240] Iteration 15320, loss = 0.0411371
I0110 00:30:06.748045  4932 solver.cpp:255]     Train net output #0: loss = 0.0088397 (* 1 = 0.0088397 loss)
I0110 00:30:06.748054  4932 solver.cpp:631] Iteration 15320, lr = 1e-05
I0110 00:30:51.139101  4932 solver.cpp:240] Iteration 15340, loss = 0.0630588
I0110 00:30:51.139168  4932 solver.cpp:255]     Train net output #0: loss = 0.00654001 (* 1 = 0.00654001 loss)
I0110 00:30:51.139178  4932 solver.cpp:631] Iteration 15340, lr = 1e-05
I0110 00:31:31.422386  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.77 > 20) by scale factor 0.918694
I0110 00:31:35.521585  4932 solver.cpp:240] Iteration 15360, loss = 0.0979414
I0110 00:31:35.521616  4932 solver.cpp:255]     Train net output #0: loss = 0.0900926 (* 1 = 0.0900926 loss)
I0110 00:31:35.521631  4932 solver.cpp:631] Iteration 15360, lr = 1e-05
I0110 00:31:35.860775  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4898 > 20) by scale factor 0.930676
I0110 00:31:49.179675  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9718 > 20) by scale factor 0.834312
I0110 00:32:11.374634  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6651 > 20) by scale factor 0.845125
I0110 00:32:19.915140  4932 solver.cpp:240] Iteration 15380, loss = 0.0613331
I0110 00:32:19.915186  4932 solver.cpp:255]     Train net output #0: loss = 0.0106838 (* 1 = 0.0106838 loss)
I0110 00:32:19.915199  4932 solver.cpp:631] Iteration 15380, lr = 1e-05
I0110 00:32:35.803062  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3895 > 20) by scale factor 0.730207
I0110 00:33:02.442642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0423 > 20) by scale factor 0.798647
I0110 00:33:04.324198  4932 solver.cpp:240] Iteration 15400, loss = 0.0783087
I0110 00:33:04.324239  4932 solver.cpp:255]     Train net output #0: loss = 0.0490072 (* 1 = 0.0490072 loss)
I0110 00:33:04.324368  4932 solver.cpp:631] Iteration 15400, lr = 1e-05
I0110 00:33:26.851428  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0231 > 20) by scale factor 0.951333
I0110 00:33:48.738628  4932 solver.cpp:240] Iteration 15420, loss = 0.101692
I0110 00:33:48.738711  4932 solver.cpp:255]     Train net output #0: loss = 0.0172338 (* 1 = 0.0172338 loss)
I0110 00:33:48.738723  4932 solver.cpp:631] Iteration 15420, lr = 1e-05
I0110 00:34:33.114495  4932 solver.cpp:240] Iteration 15440, loss = 0.036064
I0110 00:34:33.114586  4932 solver.cpp:255]     Train net output #0: loss = 0.0130203 (* 1 = 0.0130203 loss)
I0110 00:34:33.114598  4932 solver.cpp:631] Iteration 15440, lr = 1e-05
I0110 00:35:17.491276  4932 solver.cpp:240] Iteration 15460, loss = 0.0423247
I0110 00:35:17.491370  4932 solver.cpp:255]     Train net output #0: loss = 0.000892275 (* 1 = 0.000892275 loss)
I0110 00:35:17.491384  4932 solver.cpp:631] Iteration 15460, lr = 1e-05
I0110 00:35:24.488713  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1842 > 20) by scale factor 0.862658
I0110 00:35:53.482094  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7254 > 20) by scale factor 0.777441
I0110 00:36:02.023169  4932 solver.cpp:240] Iteration 15480, loss = 0.0781885
I0110 00:36:02.023205  4932 solver.cpp:255]     Train net output #0: loss = 0.075328 (* 1 = 0.075328 loss)
I0110 00:36:02.023214  4932 solver.cpp:631] Iteration 15480, lr = 1e-05
I0110 00:36:28.996215  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5433 > 20) by scale factor 0.753486
I0110 00:36:46.412602  4932 solver.cpp:240] Iteration 15500, loss = 0.0848152
I0110 00:36:46.412642  4932 solver.cpp:255]     Train net output #0: loss = 0.137069 (* 1 = 0.137069 loss)
I0110 00:36:46.412652  4932 solver.cpp:631] Iteration 15500, lr = 1e-05
I0110 00:37:15.599580  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5621 > 20) by scale factor 0.814262
I0110 00:37:30.791734  4932 solver.cpp:240] Iteration 15520, loss = 0.0749216
I0110 00:37:30.791780  4932 solver.cpp:255]     Train net output #0: loss = 0.0101672 (* 1 = 0.0101672 loss)
I0110 00:37:30.791792  4932 solver.cpp:631] Iteration 15520, lr = 1e-05
I0110 00:38:15.167717  4932 solver.cpp:240] Iteration 15540, loss = 0.0350941
I0110 00:38:15.167814  4932 solver.cpp:255]     Train net output #0: loss = 0.0358352 (* 1 = 0.0358352 loss)
I0110 00:38:15.167824  4932 solver.cpp:631] Iteration 15540, lr = 1e-05
I0110 00:38:59.720407  4932 solver.cpp:240] Iteration 15560, loss = 0.0530295
I0110 00:38:59.720495  4932 solver.cpp:255]     Train net output #0: loss = 0.132273 (* 1 = 0.132273 loss)
I0110 00:38:59.720507  4932 solver.cpp:631] Iteration 15560, lr = 1e-05
I0110 00:39:44.096457  4932 solver.cpp:240] Iteration 15580, loss = 0.0414945
I0110 00:39:44.096562  4932 solver.cpp:255]     Train net output #0: loss = 0.0789463 (* 1 = 0.0789463 loss)
I0110 00:39:44.096575  4932 solver.cpp:631] Iteration 15580, lr = 1e-05
I0110 00:40:11.065016  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 43.6664 > 20) by scale factor 0.458018
I0110 00:40:28.476572  4932 solver.cpp:240] Iteration 15600, loss = 0.0854468
I0110 00:40:28.476652  4932 solver.cpp:255]     Train net output #0: loss = 0.167186 (* 1 = 0.167186 loss)
I0110 00:40:28.476663  4932 solver.cpp:631] Iteration 15600, lr = 1e-05
I0110 00:40:28.816189  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5562 > 20) by scale factor 0.972942
I0110 00:40:57.663432  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1843 > 20) by scale factor 0.826981
I0110 00:41:02.106602  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4871 > 20) by scale factor 0.889398
I0110 00:41:12.863369  4932 solver.cpp:240] Iteration 15620, loss = 0.0735927
I0110 00:41:12.863406  4932 solver.cpp:255]     Train net output #0: loss = 0.0724192 (* 1 = 0.0724192 loss)
I0110 00:41:12.863415  4932 solver.cpp:631] Iteration 15620, lr = 1e-05
I0110 00:41:17.640733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.364 > 20) by scale factor 0.894295
I0110 00:41:57.249400  4932 solver.cpp:240] Iteration 15640, loss = 0.0683308
I0110 00:41:57.249498  4932 solver.cpp:255]     Train net output #0: loss = 0.0046372 (* 1 = 0.0046372 loss)
I0110 00:41:57.249511  4932 solver.cpp:631] Iteration 15640, lr = 1e-05
I0110 00:42:13.120029  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6688 > 20) by scale factor 0.844996
I0110 00:42:37.525174  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.08 > 20) by scale factor 0.905798
I0110 00:42:41.624886  4932 solver.cpp:240] Iteration 15660, loss = 0.0762963
I0110 00:42:41.624924  4932 solver.cpp:255]     Train net output #0: loss = 0.0198833 (* 1 = 0.0198833 loss)
I0110 00:42:41.624933  4932 solver.cpp:631] Iteration 15660, lr = 1e-05
I0110 00:42:46.403599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1122 > 20) by scale factor 0.904476
I0110 00:43:26.010574  4932 solver.cpp:240] Iteration 15680, loss = 0.0721241
I0110 00:43:26.010644  4932 solver.cpp:255]     Train net output #0: loss = 0.0125281 (* 1 = 0.0125281 loss)
I0110 00:43:26.010654  4932 solver.cpp:631] Iteration 15680, lr = 1e-05
I0110 00:43:59.633478  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8175 > 20) by scale factor 0.745782
I0110 00:44:04.075523  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6489 > 20) by scale factor 0.698107
I0110 00:44:08.515199  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5069 > 20) by scale factor 0.850813
I0110 00:44:10.395684  4932 solver.cpp:240] Iteration 15700, loss = 0.0819224
I0110 00:44:10.395723  4932 solver.cpp:255]     Train net output #0: loss = 0.0572881 (* 1 = 0.0572881 loss)
I0110 00:44:10.395732  4932 solver.cpp:631] Iteration 15700, lr = 1e-05
I0110 00:44:15.172013  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6192 > 20) by scale factor 0.884205
I0110 00:44:54.773165  4932 solver.cpp:240] Iteration 15720, loss = 0.0775159
I0110 00:44:54.773233  4932 solver.cpp:255]     Train net output #0: loss = 0.281821 (* 1 = 0.281821 loss)
I0110 00:44:54.773243  4932 solver.cpp:631] Iteration 15720, lr = 1e-05
I0110 00:45:35.042147  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7764 > 20) by scale factor 0.962629
I0110 00:45:39.146423  4932 solver.cpp:240] Iteration 15740, loss = 0.0706052
I0110 00:45:39.146471  4932 solver.cpp:255]     Train net output #0: loss = 0.108979 (* 1 = 0.108979 loss)
I0110 00:45:39.146481  4932 solver.cpp:631] Iteration 15740, lr = 1e-05
I0110 00:46:08.336439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8461 > 20) by scale factor 0.773812
I0110 00:46:23.528486  4932 solver.cpp:240] Iteration 15760, loss = 0.0556073
I0110 00:46:23.528524  4932 solver.cpp:255]     Train net output #0: loss = 0.00828025 (* 1 = 0.00828025 loss)
I0110 00:46:23.528534  4932 solver.cpp:631] Iteration 15760, lr = 1e-05
I0110 00:47:07.905592  4932 solver.cpp:240] Iteration 15780, loss = 0.0490079
I0110 00:47:07.905661  4932 solver.cpp:255]     Train net output #0: loss = 0.0409012 (* 1 = 0.0409012 loss)
I0110 00:47:07.905670  4932 solver.cpp:631] Iteration 15780, lr = 1e-05
I0110 00:47:28.214645  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9584 > 20) by scale factor 0.910812
I0110 00:47:34.875826  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3431 > 20) by scale factor 0.937073
I0110 00:47:52.288519  4932 solver.cpp:240] Iteration 15800, loss = 0.0546532
I0110 00:47:52.288594  4932 solver.cpp:255]     Train net output #0: loss = 0.0561441 (* 1 = 0.0561441 loss)
I0110 00:47:52.288605  4932 solver.cpp:631] Iteration 15800, lr = 1e-05
I0110 00:47:54.846483  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.8705 > 20) by scale factor 0.542439
I0110 00:48:01.505522  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2495 > 20) by scale factor 0.941198
I0110 00:48:05.945814  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.7094 > 20) by scale factor 0.630728
I0110 00:48:36.672922  4932 solver.cpp:240] Iteration 15820, loss = 0.104243
I0110 00:48:36.672996  4932 solver.cpp:255]     Train net output #0: loss = 0.000764322 (* 1 = 0.000764322 loss)
I0110 00:48:36.673007  4932 solver.cpp:631] Iteration 15820, lr = 1e-05
I0110 00:48:48.108358  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9923 > 20) by scale factor 0.90941
I0110 00:49:21.053741  4932 solver.cpp:240] Iteration 15840, loss = 0.0878353
I0110 00:49:21.053815  4932 solver.cpp:255]     Train net output #0: loss = 0.00756909 (* 1 = 0.00756909 loss)
I0110 00:49:21.053827  4932 solver.cpp:631] Iteration 15840, lr = 1e-05
I0110 00:49:56.888226  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4455 > 20) by scale factor 0.97821
I0110 00:50:05.428395  4932 solver.cpp:240] Iteration 15860, loss = 0.0693699
I0110 00:50:05.428437  4932 solver.cpp:255]     Train net output #0: loss = 0.00784544 (* 1 = 0.00784544 loss)
I0110 00:50:05.428447  4932 solver.cpp:631] Iteration 15860, lr = 1e-05
I0110 00:50:39.050783  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4204 > 20) by scale factor 0.979413
I0110 00:50:49.807910  4932 solver.cpp:240] Iteration 15880, loss = 0.0610881
I0110 00:50:49.807950  4932 solver.cpp:255]     Train net output #0: loss = 0.122482 (* 1 = 0.122482 loss)
I0110 00:50:49.807960  4932 solver.cpp:631] Iteration 15880, lr = 1e-05
I0110 00:50:52.365614  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2762 > 20) by scale factor 0.940018
I0110 00:51:23.434782  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4463 > 20) by scale factor 0.853013
I0110 00:51:25.655004  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4022 > 20) by scale factor 0.892771
I0110 00:51:34.190614  4932 solver.cpp:240] Iteration 15900, loss = 0.0802459
I0110 00:51:34.190654  4932 solver.cpp:255]     Train net output #0: loss = 0.00079966 (* 1 = 0.00079966 loss)
I0110 00:51:34.190663  4932 solver.cpp:631] Iteration 15900, lr = 1e-05
I0110 00:51:41.184162  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7872 > 20) by scale factor 0.877686
I0110 00:52:18.561362  4932 solver.cpp:240] Iteration 15920, loss = 0.096476
I0110 00:52:18.561450  4932 solver.cpp:255]     Train net output #0: loss = 0.0922804 (* 1 = 0.0922804 loss)
I0110 00:52:18.561462  4932 solver.cpp:631] Iteration 15920, lr = 1e-05
I0110 00:53:02.945603  4932 solver.cpp:240] Iteration 15940, loss = 0.0318081
I0110 00:53:02.945706  4932 solver.cpp:255]     Train net output #0: loss = 0.00576815 (* 1 = 0.00576815 loss)
I0110 00:53:02.945718  4932 solver.cpp:631] Iteration 15940, lr = 1e-05
I0110 00:53:09.941790  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1044 > 20) by scale factor 0.711632
I0110 00:53:47.317435  4932 solver.cpp:240] Iteration 15960, loss = 0.0687526
I0110 00:53:47.317509  4932 solver.cpp:255]     Train net output #0: loss = 0.00799166 (* 1 = 0.00799166 loss)
I0110 00:53:47.317519  4932 solver.cpp:631] Iteration 15960, lr = 1e-05
I0110 00:53:49.875041  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0633 > 20) by scale factor 0.949519
I0110 00:54:16.507050  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5261 > 20) by scale factor 0.887859
I0110 00:54:25.381953  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2379 > 20) by scale factor 0.941714
I0110 00:54:31.703346  4932 solver.cpp:240] Iteration 15980, loss = 0.0797037
I0110 00:54:31.703385  4932 solver.cpp:255]     Train net output #0: loss = 0.00821536 (* 1 = 0.00821536 loss)
I0110 00:54:31.703394  4932 solver.cpp:631] Iteration 15980, lr = 1e-05
I0110 00:54:45.350049  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0875 > 20) by scale factor 0.995643
I0110 00:55:14.207839  4932 solver.cpp:424] Iteration 16000, Testing net (#0)
I0110 00:56:05.114058  4932 solver.cpp:481]     Test net output #0: accuracy = 0.813684
I0110 00:56:05.114141  4932 solver.cpp:481]     Test net output #1: loss = 0.894753 (* 1 = 0.894753 loss)
I0110 00:56:06.981480  4932 solver.cpp:240] Iteration 16000, loss = 0.0543541
I0110 00:56:06.981518  4932 solver.cpp:255]     Train net output #0: loss = 0.214529 (* 1 = 0.214529 loss)
I0110 00:56:06.981526  4932 solver.cpp:631] Iteration 16000, lr = 1e-05
I0110 00:56:51.353749  4932 solver.cpp:240] Iteration 16020, loss = 0.0576221
I0110 00:56:51.353828  4932 solver.cpp:255]     Train net output #0: loss = 0.0842954 (* 1 = 0.0842954 loss)
I0110 00:56:51.353838  4932 solver.cpp:631] Iteration 16020, lr = 1e-05
I0110 00:57:07.226634  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8134 > 20) by scale factor 0.960919
I0110 00:57:20.545924  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4887 > 20) by scale factor 0.851472
I0110 00:57:35.743594  4932 solver.cpp:240] Iteration 16040, loss = 0.0436306
I0110 00:57:35.743690  4932 solver.cpp:255]     Train net output #0: loss = 0.00907778 (* 1 = 0.00907778 loss)
I0110 00:57:35.743702  4932 solver.cpp:631] Iteration 16040, lr = 1e-05
I0110 00:57:40.520642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0277 > 20) by scale factor 0.998616
I0110 00:57:42.741941  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0404 > 20) by scale factor 0.997985
I0110 00:58:20.126631  4932 solver.cpp:240] Iteration 16060, loss = 0.0685495
I0110 00:58:20.126723  4932 solver.cpp:255]     Train net output #0: loss = 0.00403201 (* 1 = 0.00403201 loss)
I0110 00:58:20.126734  4932 solver.cpp:631] Iteration 16060, lr = 1e-05
I0110 00:59:04.506237  4932 solver.cpp:240] Iteration 16080, loss = 0.0801428
I0110 00:59:04.506315  4932 solver.cpp:255]     Train net output #0: loss = 0.0630844 (* 1 = 0.0630844 loss)
I0110 00:59:04.506326  4932 solver.cpp:631] Iteration 16080, lr = 1e-05
I0110 00:59:48.885315  4932 solver.cpp:240] Iteration 16100, loss = 0.0315669
I0110 00:59:48.885386  4932 solver.cpp:255]     Train net output #0: loss = 0.20711 (* 1 = 0.20711 loss)
I0110 00:59:48.885396  4932 solver.cpp:631] Iteration 16100, lr = 1e-05
I0110 00:59:58.098981  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0705 > 20) by scale factor 0.830892
I0110 01:00:04.760498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.713 > 20) by scale factor 0.880555
I0110 01:00:33.271625  4932 solver.cpp:240] Iteration 16120, loss = 0.0654744
I0110 01:00:33.271708  4932 solver.cpp:255]     Train net output #0: loss = 0.0936052 (* 1 = 0.0936052 loss)
I0110 01:00:33.271718  4932 solver.cpp:631] Iteration 16120, lr = 1e-05
I0110 01:00:53.579231  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.781 > 20) by scale factor 0.877926
I0110 01:01:17.650300  4932 solver.cpp:240] Iteration 16140, loss = 0.04895
I0110 01:01:17.650380  4932 solver.cpp:255]     Train net output #0: loss = 0.0634303 (* 1 = 0.0634303 loss)
I0110 01:01:17.650390  4932 solver.cpp:631] Iteration 16140, lr = 1e-05
I0110 01:01:37.960073  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.061 > 20) by scale factor 0.767431
I0110 01:02:02.027953  4932 solver.cpp:240] Iteration 16160, loss = 0.0443193
I0110 01:02:02.028036  4932 solver.cpp:255]     Train net output #0: loss = 0.00628267 (* 1 = 0.00628267 loss)
I0110 01:02:02.028048  4932 solver.cpp:631] Iteration 16160, lr = 1e-05
I0110 01:02:46.410491  4932 solver.cpp:240] Iteration 16180, loss = 0.0609013
I0110 01:02:46.410569  4932 solver.cpp:255]     Train net output #0: loss = 0.245655 (* 1 = 0.245655 loss)
I0110 01:02:46.410579  4932 solver.cpp:631] Iteration 16180, lr = 1e-05
I0110 01:03:02.278595  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2073 > 20) by scale factor 0.989741
I0110 01:03:22.248682  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4341 > 20) by scale factor 0.978758
I0110 01:03:30.802368  4932 solver.cpp:240] Iteration 16200, loss = 0.0818364
I0110 01:03:30.802413  4932 solver.cpp:255]     Train net output #0: loss = 0.115963 (* 1 = 0.115963 loss)
I0110 01:03:30.802424  4932 solver.cpp:631] Iteration 16200, lr = 1e-05
I0110 01:04:15.185564  4932 solver.cpp:240] Iteration 16220, loss = 0.0894174
I0110 01:04:15.185642  4932 solver.cpp:255]     Train net output #0: loss = 0.00418005 (* 1 = 0.00418005 loss)
I0110 01:04:15.185652  4932 solver.cpp:631] Iteration 16220, lr = 1e-05
I0110 01:04:48.802734  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6506 > 20) by scale factor 0.779709
I0110 01:04:59.559734  4932 solver.cpp:240] Iteration 16240, loss = 0.0679885
I0110 01:04:59.559774  4932 solver.cpp:255]     Train net output #0: loss = 0.045302 (* 1 = 0.045302 loss)
I0110 01:04:59.559783  4932 solver.cpp:631] Iteration 16240, lr = 1e-05
I0110 01:05:33.183605  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5237 > 20) by scale factor 0.929207
I0110 01:05:43.941570  4932 solver.cpp:240] Iteration 16260, loss = 0.0775744
I0110 01:05:43.941609  4932 solver.cpp:255]     Train net output #0: loss = 0.0277975 (* 1 = 0.0277975 loss)
I0110 01:05:43.941617  4932 solver.cpp:631] Iteration 16260, lr = 1e-05
I0110 01:06:28.328728  4932 solver.cpp:240] Iteration 16280, loss = 0.0676287
I0110 01:06:28.328816  4932 solver.cpp:255]     Train net output #0: loss = 0.179288 (* 1 = 0.179288 loss)
I0110 01:06:28.328829  4932 solver.cpp:631] Iteration 16280, lr = 1e-05
I0110 01:06:28.669471  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3664 > 20) by scale factor 0.705059
I0110 01:07:08.610627  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8241 > 20) by scale factor 0.839487
I0110 01:07:12.712478  4932 solver.cpp:240] Iteration 16300, loss = 0.0525792
I0110 01:07:12.712520  4932 solver.cpp:255]     Train net output #0: loss = 0.000773262 (* 1 = 0.000773262 loss)
I0110 01:07:12.712529  4932 solver.cpp:631] Iteration 16300, lr = 1e-05
I0110 01:07:28.584342  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.068 > 20) by scale factor 0.949309
I0110 01:07:41.902858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.609 > 20) by scale factor 0.699081
I0110 01:07:57.100519  4932 solver.cpp:240] Iteration 16320, loss = 0.0683357
I0110 01:07:57.100555  4932 solver.cpp:255]     Train net output #0: loss = 0.00123761 (* 1 = 0.00123761 loss)
I0110 01:07:57.100564  4932 solver.cpp:631] Iteration 16320, lr = 1e-05
I0110 01:08:41.481279  4932 solver.cpp:240] Iteration 16340, loss = 0.0701956
I0110 01:08:41.481377  4932 solver.cpp:255]     Train net output #0: loss = 0.124758 (* 1 = 0.124758 loss)
I0110 01:08:41.481387  4932 solver.cpp:631] Iteration 16340, lr = 1e-05
I0110 01:08:50.693086  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3549 > 20) by scale factor 0.705345
I0110 01:09:08.442384  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.837 > 20) by scale factor 0.805249
I0110 01:09:12.884977  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.6999 > 20) by scale factor 0.651468
I0110 01:09:25.857410  4932 solver.cpp:240] Iteration 16360, loss = 0.105614
I0110 01:09:25.857444  4932 solver.cpp:255]     Train net output #0: loss = 0.129304 (* 1 = 0.129304 loss)
I0110 01:09:25.857451  4932 solver.cpp:631] Iteration 16360, lr = 1e-05
I0110 01:09:48.385416  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7333 > 20) by scale factor 0.721155
I0110 01:10:10.244081  4932 solver.cpp:240] Iteration 16380, loss = 0.0911927
I0110 01:10:10.244122  4932 solver.cpp:255]     Train net output #0: loss = 0.0258051 (* 1 = 0.0258051 loss)
I0110 01:10:10.244130  4932 solver.cpp:631] Iteration 16380, lr = 1e-05
I0110 01:10:21.681229  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.799 > 20) by scale factor 0.877232
I0110 01:10:54.621948  4932 solver.cpp:240] Iteration 16400, loss = 0.0585206
I0110 01:10:54.622033  4932 solver.cpp:255]     Train net output #0: loss = 0.0126952 (* 1 = 0.0126952 loss)
I0110 01:10:54.622045  4932 solver.cpp:631] Iteration 16400, lr = 1e-05
I0110 01:10:57.183360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4434 > 20) by scale factor 0.786058
I0110 01:11:26.033408  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3629 > 20) by scale factor 0.856059
I0110 01:11:28.253711  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4685 > 20) by scale factor 0.785284
I0110 01:11:39.009863  4932 solver.cpp:240] Iteration 16420, loss = 0.0930845
I0110 01:11:39.009907  4932 solver.cpp:255]     Train net output #0: loss = 0.00807651 (* 1 = 0.00807651 loss)
I0110 01:11:39.009920  4932 solver.cpp:631] Iteration 16420, lr = 1e-05
I0110 01:12:23.390097  4932 solver.cpp:240] Iteration 16440, loss = 0.0642404
I0110 01:12:23.390168  4932 solver.cpp:255]     Train net output #0: loss = 0.0431413 (* 1 = 0.0431413 loss)
I0110 01:12:23.390177  4932 solver.cpp:631] Iteration 16440, lr = 1e-05
I0110 01:12:25.948438  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9264 > 20) by scale factor 0.955729
I0110 01:12:30.392467  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4951 > 20) by scale factor 0.889083
I0110 01:12:39.267927  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1243 > 20) by scale factor 0.737347
I0110 01:13:07.775243  4932 solver.cpp:240] Iteration 16460, loss = 0.0816682
I0110 01:13:07.775319  4932 solver.cpp:255]     Train net output #0: loss = 0.0044451 (* 1 = 0.0044451 loss)
I0110 01:13:07.775329  4932 solver.cpp:631] Iteration 16460, lr = 1e-05
I0110 01:13:48.056445  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8516 > 20) by scale factor 0.693203
I0110 01:13:52.156903  4932 solver.cpp:240] Iteration 16480, loss = 0.103419
I0110 01:13:52.156945  4932 solver.cpp:255]     Train net output #0: loss = 0.438445 (* 1 = 0.438445 loss)
I0110 01:13:52.156956  4932 solver.cpp:631] Iteration 16480, lr = 1e-05
I0110 01:13:52.497355  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7135 > 20) by scale factor 0.777801
I0110 01:14:36.544623  4932 solver.cpp:240] Iteration 16500, loss = 0.039752
I0110 01:14:36.544697  4932 solver.cpp:255]     Train net output #0: loss = 0.0238459 (* 1 = 0.0238459 loss)
I0110 01:14:36.544708  4932 solver.cpp:631] Iteration 16500, lr = 1e-05
I0110 01:14:43.541303  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1198 > 20) by scale factor 0.829194
I0110 01:14:56.856112  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3063 > 20) by scale factor 0.822831
I0110 01:15:20.928778  4932 solver.cpp:240] Iteration 16520, loss = 0.0658367
I0110 01:15:20.928869  4932 solver.cpp:255]     Train net output #0: loss = 0.0390531 (* 1 = 0.0390531 loss)
I0110 01:15:20.928879  4932 solver.cpp:631] Iteration 16520, lr = 1e-05
I0110 01:16:05.302455  4932 solver.cpp:240] Iteration 16540, loss = 0.0333519
I0110 01:16:05.302526  4932 solver.cpp:255]     Train net output #0: loss = 0.0020869 (* 1 = 0.0020869 loss)
I0110 01:16:05.302537  4932 solver.cpp:631] Iteration 16540, lr = 1e-05
I0110 01:16:12.296555  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9657 > 20) by scale factor 0.953939
I0110 01:16:18.955060  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3982 > 20) by scale factor 0.892927
I0110 01:16:36.706511  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5109 > 20) by scale factor 0.88846
I0110 01:16:49.681217  4932 solver.cpp:240] Iteration 16560, loss = 0.0742549
I0110 01:16:49.681258  4932 solver.cpp:255]     Train net output #0: loss = 0.095354 (* 1 = 0.095354 loss)
I0110 01:16:49.681267  4932 solver.cpp:631] Iteration 16560, lr = 1e-05
I0110 01:17:29.974279  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8465 > 20) by scale factor 0.915479
I0110 01:17:34.074723  4932 solver.cpp:240] Iteration 16580, loss = 0.0892075
I0110 01:17:34.074754  4932 solver.cpp:255]     Train net output #0: loss = 0.151872 (* 1 = 0.151872 loss)
I0110 01:17:34.074764  4932 solver.cpp:631] Iteration 16580, lr = 1e-05
I0110 01:17:34.414017  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6361 > 20) by scale factor 0.811816
I0110 01:17:43.293217  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4228 > 20) by scale factor 0.933584
I0110 01:18:18.459237  4932 solver.cpp:240] Iteration 16600, loss = 0.05695
I0110 01:18:18.459319  4932 solver.cpp:255]     Train net output #0: loss = 0.0141642 (* 1 = 0.0141642 loss)
I0110 01:18:18.459332  4932 solver.cpp:631] Iteration 16600, lr = 1e-05
I0110 01:19:02.830757  4932 solver.cpp:240] Iteration 16620, loss = 0.0544215
I0110 01:19:02.830859  4932 solver.cpp:255]     Train net output #0: loss = 0.00623061 (* 1 = 0.00623061 loss)
I0110 01:19:02.830874  4932 solver.cpp:631] Iteration 16620, lr = 1e-05
I0110 01:19:32.032449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1417 > 20) by scale factor 0.992964
I0110 01:19:47.225303  4932 solver.cpp:240] Iteration 16640, loss = 0.0910209
I0110 01:19:47.225378  4932 solver.cpp:255]     Train net output #0: loss = 0.00419172 (* 1 = 0.00419172 loss)
I0110 01:19:47.225386  4932 solver.cpp:631] Iteration 16640, lr = 1e-05
I0110 01:20:31.600473  4932 solver.cpp:240] Iteration 16660, loss = 0.0532881
I0110 01:20:31.600561  4932 solver.cpp:255]     Train net output #0: loss = 0.118385 (* 1 = 0.118385 loss)
I0110 01:20:31.600574  4932 solver.cpp:631] Iteration 16660, lr = 1e-05
I0110 01:21:05.227450  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9937 > 20) by scale factor 0.90935
I0110 01:21:15.983289  4932 solver.cpp:240] Iteration 16680, loss = 0.0505499
I0110 01:21:15.983326  4932 solver.cpp:255]     Train net output #0: loss = 0.374567 (* 1 = 0.374567 loss)
I0110 01:21:15.983335  4932 solver.cpp:631] Iteration 16680, lr = 1e-05
I0110 01:21:16.322466  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5339 > 20) by scale factor 0.677188
I0110 01:21:18.544903  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0064 > 20) by scale factor 0.689503
I0110 01:21:22.985822  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5932 > 20) by scale factor 0.926216
I0110 01:22:00.376188  4932 solver.cpp:240] Iteration 16700, loss = 0.0679326
I0110 01:22:00.376286  4932 solver.cpp:255]     Train net output #0: loss = 0.00211679 (* 1 = 0.00211679 loss)
I0110 01:22:00.376294  4932 solver.cpp:631] Iteration 16700, lr = 1e-05
I0110 01:22:44.754813  4932 solver.cpp:240] Iteration 16720, loss = 0.0495513
I0110 01:22:44.754884  4932 solver.cpp:255]     Train net output #0: loss = 0.232958 (* 1 = 0.232958 loss)
I0110 01:22:44.754894  4932 solver.cpp:631] Iteration 16720, lr = 1e-05
I0110 01:22:56.189163  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.838 > 20) by scale factor 0.805219
I0110 01:23:29.129644  4932 solver.cpp:240] Iteration 16740, loss = 0.0508697
I0110 01:23:29.129714  4932 solver.cpp:255]     Train net output #0: loss = 0.0219128 (* 1 = 0.0219128 loss)
I0110 01:23:29.129724  4932 solver.cpp:631] Iteration 16740, lr = 1e-05
I0110 01:24:07.186571  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.216 > 20) by scale factor 0.942686
I0110 01:24:13.505396  4932 solver.cpp:240] Iteration 16760, loss = 0.0494577
I0110 01:24:13.505437  4932 solver.cpp:255]     Train net output #0: loss = 0.0372284 (* 1 = 0.0372284 loss)
I0110 01:24:13.505446  4932 solver.cpp:631] Iteration 16760, lr = 1e-05
I0110 01:24:27.156280  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7201 > 20) by scale factor 0.809058
I0110 01:24:42.691588  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9048 > 20) by scale factor 0.66879
I0110 01:24:57.886498  4932 solver.cpp:240] Iteration 16780, loss = 0.0741049
I0110 01:24:57.886540  4932 solver.cpp:255]     Train net output #0: loss = 0.00168958 (* 1 = 0.00168958 loss)
I0110 01:24:57.886549  4932 solver.cpp:631] Iteration 16780, lr = 1e-05
I0110 01:25:42.255980  4932 solver.cpp:240] Iteration 16800, loss = 0.0562722
I0110 01:25:42.256049  4932 solver.cpp:255]     Train net output #0: loss = 0.00136986 (* 1 = 0.00136986 loss)
I0110 01:25:42.256058  4932 solver.cpp:631] Iteration 16800, lr = 1e-05
I0110 01:25:53.690079  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5002 > 20) by scale factor 0.975599
I0110 01:26:13.659833  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.2398 > 20) by scale factor 0.601688
I0110 01:26:26.635670  4932 solver.cpp:240] Iteration 16820, loss = 0.102048
I0110 01:26:26.635702  4932 solver.cpp:255]     Train net output #0: loss = 0.17733 (* 1 = 0.17733 loss)
I0110 01:26:26.635711  4932 solver.cpp:631] Iteration 16820, lr = 1e-05
I0110 01:26:29.192823  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7128 > 20) by scale factor 0.67311
I0110 01:26:31.413404  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.5221 > 20) by scale factor 0.563031
I0110 01:26:58.049223  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2514 > 20) by scale factor 0.941112
I0110 01:27:00.270719  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.309 > 20) by scale factor 0.790231
I0110 01:27:11.026000  4932 solver.cpp:240] Iteration 16840, loss = 0.108986
I0110 01:27:11.026032  4932 solver.cpp:255]     Train net output #0: loss = 0.00769051 (* 1 = 0.00769051 loss)
I0110 01:27:11.026041  4932 solver.cpp:631] Iteration 16840, lr = 1e-05
I0110 01:27:22.465257  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5479 > 20) by scale factor 0.973334
I0110 01:27:35.781960  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4557 > 20) by scale factor 0.817804
I0110 01:27:49.097599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6671 > 20) by scale factor 0.810796
I0110 01:27:55.418033  4932 solver.cpp:240] Iteration 16860, loss = 0.0723599
I0110 01:27:55.418071  4932 solver.cpp:255]     Train net output #0: loss = 0.0512017 (* 1 = 0.0512017 loss)
I0110 01:27:55.418079  4932 solver.cpp:631] Iteration 16860, lr = 1e-05
I0110 01:28:04.629266  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1744 > 20) by scale factor 0.944538
I0110 01:28:06.849730  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.425 > 20) by scale factor 0.891861
I0110 01:28:39.790853  4932 solver.cpp:240] Iteration 16880, loss = 0.0724432
I0110 01:28:39.790926  4932 solver.cpp:255]     Train net output #0: loss = 0.00623739 (* 1 = 0.00623739 loss)
I0110 01:28:39.790935  4932 solver.cpp:631] Iteration 16880, lr = 1e-05
I0110 01:29:20.072903  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6487 > 20) by scale factor 0.923844
I0110 01:29:24.173521  4932 solver.cpp:240] Iteration 16900, loss = 0.0916099
I0110 01:29:24.173563  4932 solver.cpp:255]     Train net output #0: loss = 0.0249671 (* 1 = 0.0249671 loss)
I0110 01:29:24.173713  4932 solver.cpp:631] Iteration 16900, lr = 1e-05
I0110 01:29:31.169764  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2435 > 20) by scale factor 0.860456
I0110 01:30:00.039219  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1606 > 20) by scale factor 0.992034
I0110 01:30:08.588330  4932 solver.cpp:240] Iteration 16920, loss = 0.0742159
I0110 01:30:08.588368  4932 solver.cpp:255]     Train net output #0: loss = 0.0212819 (* 1 = 0.0212819 loss)
I0110 01:30:08.588378  4932 solver.cpp:631] Iteration 16920, lr = 1e-05
I0110 01:30:52.976253  4932 solver.cpp:240] Iteration 16940, loss = 0.0461564
I0110 01:30:52.976349  4932 solver.cpp:255]     Train net output #0: loss = 0.151612 (* 1 = 0.151612 loss)
I0110 01:30:52.976363  4932 solver.cpp:631] Iteration 16940, lr = 1e-05
I0110 01:31:06.626782  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.6443 > 20) by scale factor 0.632026
I0110 01:31:26.612589  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4634 > 20) by scale factor 0.977353
I0110 01:31:37.368114  4932 solver.cpp:240] Iteration 16960, loss = 0.0715025
I0110 01:31:37.368152  4932 solver.cpp:255]     Train net output #0: loss = 0.0235582 (* 1 = 0.0235582 loss)
I0110 01:31:37.368161  4932 solver.cpp:631] Iteration 16960, lr = 1e-05
I0110 01:32:06.566735  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2753 > 20) by scale factor 0.859279
I0110 01:32:21.769560  4932 solver.cpp:240] Iteration 16980, loss = 0.0676769
I0110 01:32:21.769601  4932 solver.cpp:255]     Train net output #0: loss = 0.0502609 (* 1 = 0.0502609 loss)
I0110 01:32:21.769609  4932 solver.cpp:631] Iteration 16980, lr = 1e-05
I0110 01:32:53.171303  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2025 > 20) by scale factor 0.989975
I0110 01:32:59.829223  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9042 > 20) by scale factor 0.873202
I0110 01:33:04.271541  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7682 > 20) by scale factor 0.878417
I0110 01:33:04.280652  4932 solver.cpp:424] Iteration 17000, Testing net (#0)
I0110 01:33:57.038823  4932 solver.cpp:481]     Test net output #0: accuracy = 0.816842
I0110 01:33:57.038898  4932 solver.cpp:481]     Test net output #1: loss = 0.920086 (* 1 = 0.920086 loss)
I0110 01:33:58.907300  4932 solver.cpp:240] Iteration 17000, loss = 0.0840257
I0110 01:33:58.907343  4932 solver.cpp:255]     Train net output #0: loss = 0.00899607 (* 1 = 0.00899607 loss)
I0110 01:33:58.907354  4932 solver.cpp:631] Iteration 17000, lr = 1e-05
I0110 01:34:01.466877  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9914 > 20) by scale factor 0.833631
I0110 01:34:41.410619  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4948 > 20) by scale factor 0.727411
I0110 01:34:43.292462  4932 solver.cpp:240] Iteration 17020, loss = 0.0737986
I0110 01:34:43.292503  4932 solver.cpp:255]     Train net output #0: loss = 0.191814 (* 1 = 0.191814 loss)
I0110 01:34:43.292634  4932 solver.cpp:631] Iteration 17020, lr = 1e-05
I0110 01:34:43.631620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1743 > 20) by scale factor 0.944543
I0110 01:35:27.939751  4932 solver.cpp:240] Iteration 17040, loss = 0.0389241
I0110 01:35:27.939846  4932 solver.cpp:255]     Train net output #0: loss = 0.00318592 (* 1 = 0.00318592 loss)
I0110 01:35:27.939857  4932 solver.cpp:631] Iteration 17040, lr = 1e-05
I0110 01:35:32.721885  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6446 > 20) by scale factor 0.92402
I0110 01:35:52.705588  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.007 > 20) by scale factor 0.99965
I0110 01:35:54.927870  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4087 > 20) by scale factor 0.81938
I0110 01:36:12.347012  4932 solver.cpp:240] Iteration 17060, loss = 0.0652711
I0110 01:36:12.347106  4932 solver.cpp:255]     Train net output #0: loss = 0.0294143 (* 1 = 0.0294143 loss)
I0110 01:36:12.347118  4932 solver.cpp:631] Iteration 17060, lr = 1e-05
I0110 01:36:43.755733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7222 > 20) by scale factor 0.843094
I0110 01:36:56.727618  4932 solver.cpp:240] Iteration 17080, loss = 0.0722919
I0110 01:36:56.727658  4932 solver.cpp:255]     Train net output #0: loss = 0.0620756 (* 1 = 0.0620756 loss)
I0110 01:36:56.727665  4932 solver.cpp:631] Iteration 17080, lr = 1e-05
I0110 01:37:17.044847  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0174 > 20) by scale factor 0.832729
I0110 01:37:41.112253  4932 solver.cpp:240] Iteration 17100, loss = 0.0877105
I0110 01:37:41.112294  4932 solver.cpp:255]     Train net output #0: loss = 0.217885 (* 1 = 0.217885 loss)
I0110 01:37:41.112303  4932 solver.cpp:631] Iteration 17100, lr = 1e-05
I0110 01:37:41.451472  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6543 > 20) by scale factor 0.811219
I0110 01:37:54.773165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 42.0085 > 20) by scale factor 0.476094
I0110 01:38:21.404489  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.541 > 20) by scale factor 0.814961
I0110 01:38:25.504400  4932 solver.cpp:240] Iteration 17120, loss = 0.106959
I0110 01:38:25.504478  4932 solver.cpp:255]     Train net output #0: loss = 0.185433 (* 1 = 0.185433 loss)
I0110 01:38:25.504488  4932 solver.cpp:631] Iteration 17120, lr = 1e-05
I0110 01:38:41.384001  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3911 > 20) by scale factor 0.680477
I0110 01:39:09.893707  4932 solver.cpp:240] Iteration 17140, loss = 0.0764415
I0110 01:39:09.893779  4932 solver.cpp:255]     Train net output #0: loss = 0.0357531 (* 1 = 0.0357531 loss)
I0110 01:39:09.893788  4932 solver.cpp:631] Iteration 17140, lr = 1e-05
I0110 01:39:54.271633  4932 solver.cpp:240] Iteration 17160, loss = 0.0533201
I0110 01:39:54.271718  4932 solver.cpp:255]     Train net output #0: loss = 0.0767867 (* 1 = 0.0767867 loss)
I0110 01:39:54.271729  4932 solver.cpp:631] Iteration 17160, lr = 1e-05
I0110 01:40:16.808615  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0481 > 20) by scale factor 0.831667
I0110 01:40:21.247926  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3899 > 20) by scale factor 0.93502
I0110 01:40:25.688509  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3906 > 20) by scale factor 0.934989
I0110 01:40:38.663960  4932 solver.cpp:240] Iteration 17180, loss = 0.098125
I0110 01:40:38.664011  4932 solver.cpp:255]     Train net output #0: loss = 0.0281827 (* 1 = 0.0281827 loss)
I0110 01:40:38.664022  4932 solver.cpp:631] Iteration 17180, lr = 1e-05
I0110 01:40:50.106839  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7529 > 20) by scale factor 0.747583
I0110 01:41:14.522904  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2289 > 20) by scale factor 0.899729
I0110 01:41:18.964210  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2685 > 20) by scale factor 0.898128
I0110 01:41:23.065528  4932 solver.cpp:240] Iteration 17200, loss = 0.083506
I0110 01:41:23.065570  4932 solver.cpp:255]     Train net output #0: loss = 0.110651 (* 1 = 0.110651 loss)
I0110 01:41:23.065696  4932 solver.cpp:631] Iteration 17200, lr = 1e-05
I0110 01:41:54.477684  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0092 > 20) by scale factor 0.689437
I0110 01:42:07.456651  4932 solver.cpp:240] Iteration 17220, loss = 0.0560322
I0110 01:42:07.456696  4932 solver.cpp:255]     Train net output #0: loss = 0.0113787 (* 1 = 0.0113787 loss)
I0110 01:42:07.456815  4932 solver.cpp:631] Iteration 17220, lr = 1e-05
I0110 01:42:47.738976  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1141 > 20) by scale factor 0.994328
I0110 01:42:51.840136  4932 solver.cpp:240] Iteration 17240, loss = 0.0736287
I0110 01:42:51.840171  4932 solver.cpp:255]     Train net output #0: loss = 0.0155897 (* 1 = 0.0155897 loss)
I0110 01:42:51.840180  4932 solver.cpp:631] Iteration 17240, lr = 1e-05
I0110 01:43:36.225905  4932 solver.cpp:240] Iteration 17260, loss = 0.072362
I0110 01:43:36.225998  4932 solver.cpp:255]     Train net output #0: loss = 0.0156174 (* 1 = 0.0156174 loss)
I0110 01:43:36.226011  4932 solver.cpp:631] Iteration 17260, lr = 1e-05
I0110 01:43:45.441699  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0123 > 20) by scale factor 0.832906
I0110 01:43:54.325292  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.977 > 20) by scale factor 0.769911
I0110 01:44:16.521610  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3208 > 20) by scale factor 0.984213
I0110 01:44:20.622191  4932 solver.cpp:240] Iteration 17280, loss = 0.093468
I0110 01:44:20.622226  4932 solver.cpp:255]     Train net output #0: loss = 0.044955 (* 1 = 0.044955 loss)
I0110 01:44:20.622234  4932 solver.cpp:631] Iteration 17280, lr = 1e-05
I0110 01:44:34.284822  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0403 > 20) by scale factor 0.768039
I0110 01:45:05.020001  4932 solver.cpp:240] Iteration 17300, loss = 0.0648076
I0110 01:45:05.020088  4932 solver.cpp:255]     Train net output #0: loss = 0.0844432 (* 1 = 0.0844432 loss)
I0110 01:45:05.020100  4932 solver.cpp:631] Iteration 17300, lr = 1e-05
I0110 01:45:41.016536  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4985 > 20) by scale factor 0.851118
I0110 01:45:49.553081  4932 solver.cpp:240] Iteration 17320, loss = 0.0478167
I0110 01:45:49.553125  4932 solver.cpp:255]     Train net output #0: loss = 0.0458371 (* 1 = 0.0458371 loss)
I0110 01:45:49.553136  4932 solver.cpp:631] Iteration 17320, lr = 1e-05
I0110 01:46:07.653961  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.5576 > 20) by scale factor 0.654501
I0110 01:46:18.745878  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1324 > 20) by scale factor 0.737127
I0110 01:46:33.942239  4932 solver.cpp:240] Iteration 17340, loss = 0.0707074
I0110 01:46:33.942287  4932 solver.cpp:255]     Train net output #0: loss = 0.0657623 (* 1 = 0.0657623 loss)
I0110 01:46:33.942301  4932 solver.cpp:631] Iteration 17340, lr = 1e-05
I0110 01:46:45.379506  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3385 > 20) by scale factor 0.789313
I0110 01:47:05.358680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6737 > 20) by scale factor 0.967414
I0110 01:47:18.335577  4932 solver.cpp:240] Iteration 17360, loss = 0.0732643
I0110 01:47:18.335620  4932 solver.cpp:255]     Train net output #0: loss = 0.108484 (* 1 = 0.108484 loss)
I0110 01:47:18.335629  4932 solver.cpp:631] Iteration 17360, lr = 1e-05
I0110 01:47:25.332408  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6342 > 20) by scale factor 0.811879
I0110 01:48:02.720718  4932 solver.cpp:240] Iteration 17380, loss = 0.0555169
I0110 01:48:02.720829  4932 solver.cpp:255]     Train net output #0: loss = 0.0591427 (* 1 = 0.0591427 loss)
I0110 01:48:02.720845  4932 solver.cpp:631] Iteration 17380, lr = 1e-05
I0110 01:48:47.118494  4932 solver.cpp:240] Iteration 17400, loss = 0.040986
I0110 01:48:47.118592  4932 solver.cpp:255]     Train net output #0: loss = 0.00440637 (* 1 = 0.00440637 loss)
I0110 01:48:47.118604  4932 solver.cpp:631] Iteration 17400, lr = 1e-05
I0110 01:48:54.117636  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1809 > 20) by scale factor 0.944248
I0110 01:49:05.217432  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3732 > 20) by scale factor 0.70489
I0110 01:49:25.198329  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4757 > 20) by scale factor 0.78506
I0110 01:49:31.524422  4932 solver.cpp:240] Iteration 17420, loss = 0.0917328
I0110 01:49:31.524456  4932 solver.cpp:255]     Train net output #0: loss = 0.0771867 (* 1 = 0.0771867 loss)
I0110 01:49:31.524466  4932 solver.cpp:631] Iteration 17420, lr = 1e-05
I0110 01:49:54.048802  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8519 > 20) by scale factor 0.959145
I0110 01:50:16.154676  4932 solver.cpp:240] Iteration 17440, loss = 0.084456
I0110 01:50:16.154743  4932 solver.cpp:255]     Train net output #0: loss = 0.22563 (* 1 = 0.22563 loss)
I0110 01:50:16.154753  4932 solver.cpp:631] Iteration 17440, lr = 1e-05
I0110 01:50:27.590178  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4702 > 20) by scale factor 0.977029
I0110 01:50:40.906307  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3875 > 20) by scale factor 0.935126
I0110 01:50:45.345749  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2982 > 20) by scale factor 0.985308
I0110 01:51:00.541240  4932 solver.cpp:240] Iteration 17460, loss = 0.0472391
I0110 01:51:00.541319  4932 solver.cpp:255]     Train net output #0: loss = 0.0133827 (* 1 = 0.0133827 loss)
I0110 01:51:00.541330  4932 solver.cpp:631] Iteration 17460, lr = 1e-05
I0110 01:51:32.059687  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4518 > 20) by scale factor 0.97791
I0110 01:51:45.045013  4932 solver.cpp:240] Iteration 17480, loss = 0.0573206
I0110 01:51:45.045055  4932 solver.cpp:255]     Train net output #0: loss = 0.0287379 (* 1 = 0.0287379 loss)
I0110 01:51:45.045176  4932 solver.cpp:631] Iteration 17480, lr = 1e-05
I0110 01:52:29.433822  4932 solver.cpp:240] Iteration 17500, loss = 0.0688549
I0110 01:52:29.433914  4932 solver.cpp:255]     Train net output #0: loss = 0.0195397 (* 1 = 0.0195397 loss)
I0110 01:52:29.433926  4932 solver.cpp:631] Iteration 17500, lr = 1e-05
I0110 01:53:13.829215  4932 solver.cpp:240] Iteration 17520, loss = 0.0756808
I0110 01:53:13.829296  4932 solver.cpp:255]     Train net output #0: loss = 0.00484135 (* 1 = 0.00484135 loss)
I0110 01:53:13.829308  4932 solver.cpp:631] Iteration 17520, lr = 1e-05
I0110 01:53:58.219466  4932 solver.cpp:240] Iteration 17540, loss = 0.0462237
I0110 01:53:58.219544  4932 solver.cpp:255]     Train net output #0: loss = 0.0139353 (* 1 = 0.0139353 loss)
I0110 01:53:58.219554  4932 solver.cpp:631] Iteration 17540, lr = 1e-05
I0110 01:54:25.192091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7036 > 20) by scale factor 0.696777
I0110 01:54:42.602010  4932 solver.cpp:240] Iteration 17560, loss = 0.0542571
I0110 01:54:42.602084  4932 solver.cpp:255]     Train net output #0: loss = 0.0027122 (* 1 = 0.0027122 loss)
I0110 01:54:42.602093  4932 solver.cpp:631] Iteration 17560, lr = 1e-05
I0110 01:54:45.158249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2641 > 20) by scale factor 0.824264
I0110 01:55:00.694236  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2625 > 20) by scale factor 0.761543
I0110 01:55:26.983641  4932 solver.cpp:240] Iteration 17580, loss = 0.0609633
I0110 01:55:26.983733  4932 solver.cpp:255]     Train net output #0: loss = 0.0267553 (* 1 = 0.0267553 loss)
I0110 01:55:26.983748  4932 solver.cpp:631] Iteration 17580, lr = 1e-05
I0110 01:56:11.362825  4932 solver.cpp:240] Iteration 17600, loss = 0.0616221
I0110 01:56:11.362923  4932 solver.cpp:255]     Train net output #0: loss = 0.0105585 (* 1 = 0.0105585 loss)
I0110 01:56:11.362937  4932 solver.cpp:631] Iteration 17600, lr = 1e-05
I0110 01:56:25.016544  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9495 > 20) by scale factor 0.954676
I0110 01:56:55.740967  4932 solver.cpp:240] Iteration 17620, loss = 0.0697
I0110 01:56:55.741062  4932 solver.cpp:255]     Train net output #0: loss = 0.0185684 (* 1 = 0.0185684 loss)
I0110 01:56:55.741075  4932 solver.cpp:631] Iteration 17620, lr = 1e-05
I0110 01:57:07.170653  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4325 > 20) by scale factor 0.786396
I0110 01:57:40.116164  4932 solver.cpp:240] Iteration 17640, loss = 0.0702866
I0110 01:57:40.116256  4932 solver.cpp:255]     Train net output #0: loss = 0.00290293 (* 1 = 0.00290293 loss)
I0110 01:57:40.116268  4932 solver.cpp:631] Iteration 17640, lr = 1e-05
I0110 01:58:20.395532  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.331 > 20) by scale factor 0.789546
I0110 01:58:24.494617  4932 solver.cpp:240] Iteration 17660, loss = 0.0725429
I0110 01:58:24.494655  4932 solver.cpp:255]     Train net output #0: loss = 0.00921384 (* 1 = 0.00921384 loss)
I0110 01:58:24.494668  4932 solver.cpp:631] Iteration 17660, lr = 1e-05
I0110 01:58:44.803463  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0981 > 20) by scale factor 0.905057
I0110 01:59:04.772929  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6488 > 20) by scale factor 0.883051
I0110 01:59:08.870671  4932 solver.cpp:240] Iteration 17680, loss = 0.0548529
I0110 01:59:08.870710  4932 solver.cpp:255]     Train net output #0: loss = 0.0219557 (* 1 = 0.0219557 loss)
I0110 01:59:08.870721  4932 solver.cpp:631] Iteration 17680, lr = 1e-05
I0110 01:59:53.278367  4932 solver.cpp:240] Iteration 17700, loss = 0.0598025
I0110 01:59:53.278453  4932 solver.cpp:255]     Train net output #0: loss = 0.0524168 (* 1 = 0.0524168 loss)
I0110 01:59:53.278465  4932 solver.cpp:631] Iteration 17700, lr = 1e-05
I0110 02:00:02.491256  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8676 > 20) by scale factor 0.914593
I0110 02:00:13.589030  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6308 > 20) by scale factor 0.88375
I0110 02:00:22.470623  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.946 > 20) by scale factor 0.954838
I0110 02:00:35.783784  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0689 > 20) by scale factor 0.86697
I0110 02:00:37.666795  4932 solver.cpp:240] Iteration 17720, loss = 0.116058
I0110 02:00:37.666841  4932 solver.cpp:255]     Train net output #0: loss = 0.0237471 (* 1 = 0.0237471 loss)
I0110 02:00:37.666851  4932 solver.cpp:631] Iteration 17720, lr = 1e-05
I0110 02:00:40.227859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1442 > 20) by scale factor 0.736806
I0110 02:01:20.161788  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8972 > 20) by scale factor 0.692108
I0110 02:01:22.043618  4932 solver.cpp:240] Iteration 17740, loss = 0.0719354
I0110 02:01:22.043663  4932 solver.cpp:255]     Train net output #0: loss = 0.0968633 (* 1 = 0.0968633 loss)
I0110 02:01:22.043798  4932 solver.cpp:631] Iteration 17740, lr = 1e-05
I0110 02:01:22.382930  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5779 > 20) by scale factor 0.885821
I0110 02:02:06.548910  4932 solver.cpp:240] Iteration 17760, loss = 0.0573899
I0110 02:02:06.549010  4932 solver.cpp:255]     Train net output #0: loss = 0.0336902 (* 1 = 0.0336902 loss)
I0110 02:02:06.549026  4932 solver.cpp:631] Iteration 17760, lr = 1e-05
I0110 02:02:29.088788  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2409 > 20) by scale factor 0.941582
I0110 02:02:42.402314  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1387 > 20) by scale factor 0.94613
I0110 02:02:50.943274  4932 solver.cpp:240] Iteration 17780, loss = 0.0654988
I0110 02:02:50.943313  4932 solver.cpp:255]     Train net output #0: loss = 0.00393218 (* 1 = 0.00393218 loss)
I0110 02:02:50.943323  4932 solver.cpp:631] Iteration 17780, lr = 1e-05
I0110 02:02:53.500784  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.375 > 20) by scale factor 0.855616
I0110 02:03:33.457103  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5169 > 20) by scale factor 0.929503
I0110 02:03:35.340198  4932 solver.cpp:240] Iteration 17800, loss = 0.102292
I0110 02:03:35.340240  4932 solver.cpp:255]     Train net output #0: loss = 0.100708 (* 1 = 0.100708 loss)
I0110 02:03:35.340250  4932 solver.cpp:631] Iteration 17800, lr = 1e-05
I0110 02:03:35.679502  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8414 > 20) by scale factor 0.915693
I0110 02:03:37.900851  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.84 > 20) by scale factor 0.838926
I0110 02:04:19.733232  4932 solver.cpp:240] Iteration 17820, loss = 0.0471971
I0110 02:04:19.733326  4932 solver.cpp:255]     Train net output #0: loss = 0.0139789 (* 1 = 0.0139789 loss)
I0110 02:04:19.733340  4932 solver.cpp:631] Iteration 17820, lr = 1e-05
I0110 02:04:35.601467  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0952 > 20) by scale factor 0.796965
I0110 02:05:04.115917  4932 solver.cpp:240] Iteration 17840, loss = 0.0654625
I0110 02:05:04.116039  4932 solver.cpp:255]     Train net output #0: loss = 0.0533748 (* 1 = 0.0533748 loss)
I0110 02:05:04.116056  4932 solver.cpp:631] Iteration 17840, lr = 1e-05
I0110 02:05:28.865852  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8613 > 20) by scale factor 0.773355
I0110 02:05:48.499933  4932 solver.cpp:240] Iteration 17860, loss = 0.0513081
I0110 02:05:48.500010  4932 solver.cpp:255]     Train net output #0: loss = 0.002555 (* 1 = 0.002555 loss)
I0110 02:05:48.500020  4932 solver.cpp:631] Iteration 17860, lr = 1e-05
I0110 02:05:53.277206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3235 > 20) by scale factor 0.984084
I0110 02:06:04.383170  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9203 > 20) by scale factor 0.742935
I0110 02:06:08.823787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.109 > 20) by scale factor 0.947462
I0110 02:06:32.897353  4932 solver.cpp:240] Iteration 17880, loss = 0.0831363
I0110 02:06:32.897428  4932 solver.cpp:255]     Train net output #0: loss = 0.0474297 (* 1 = 0.0474297 loss)
I0110 02:06:32.897439  4932 solver.cpp:631] Iteration 17880, lr = 1e-05
I0110 02:06:35.454807  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2784 > 20) by scale factor 0.986273
I0110 02:06:59.871469  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6388 > 20) by scale factor 0.969048
I0110 02:07:17.287487  4932 solver.cpp:240] Iteration 17900, loss = 0.0461444
I0110 02:07:17.287570  4932 solver.cpp:255]     Train net output #0: loss = 0.0220698 (* 1 = 0.0220698 loss)
I0110 02:07:17.287582  4932 solver.cpp:631] Iteration 17900, lr = 1e-05
I0110 02:07:28.723197  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.8674 > 20) by scale factor 0.6276
I0110 02:07:39.827659  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6249 > 20) by scale factor 0.9697
I0110 02:08:01.686981  4932 solver.cpp:240] Iteration 17920, loss = 0.0768271
I0110 02:08:01.687057  4932 solver.cpp:255]     Train net output #0: loss = 0.00864211 (* 1 = 0.00864211 loss)
I0110 02:08:01.687067  4932 solver.cpp:631] Iteration 17920, lr = 1e-05
I0110 02:08:46.069860  4932 solver.cpp:240] Iteration 17940, loss = 0.0631967
I0110 02:08:46.069967  4932 solver.cpp:255]     Train net output #0: loss = 0.0291797 (* 1 = 0.0291797 loss)
I0110 02:08:46.069980  4932 solver.cpp:631] Iteration 17940, lr = 1e-05
I0110 02:09:30.457589  4932 solver.cpp:240] Iteration 17960, loss = 0.0573071
I0110 02:09:30.457677  4932 solver.cpp:255]     Train net output #0: loss = 0.0374373 (* 1 = 0.0374373 loss)
I0110 02:09:30.457690  4932 solver.cpp:631] Iteration 17960, lr = 1e-05
I0110 02:09:35.237129  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.066 > 20) by scale factor 0.906372
I0110 02:09:57.431730  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1991 > 20) by scale factor 0.990145
I0110 02:09:59.655606  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4755 > 20) by scale factor 0.817143
I0110 02:10:08.538969  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6314 > 20) by scale factor 0.698533
I0110 02:10:14.857739  4932 solver.cpp:240] Iteration 17980, loss = 0.0925968
I0110 02:10:14.857779  4932 solver.cpp:255]     Train net output #0: loss = 0.0321409 (* 1 = 0.0321409 loss)
I0110 02:10:14.857787  4932 solver.cpp:631] Iteration 17980, lr = 1e-05
I0110 02:10:39.614823  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9374 > 20) by scale factor 0.66806
I0110 02:10:57.373844  4932 solver.cpp:424] Iteration 18000, Testing net (#0)
I0110 02:11:48.726641  4932 solver.cpp:481]     Test net output #0: accuracy = 0.842105
I0110 02:11:48.726722  4932 solver.cpp:481]     Test net output #1: loss = 0.763273 (* 1 = 0.763273 loss)
I0110 02:11:50.593801  4932 solver.cpp:240] Iteration 18000, loss = 0.0653358
I0110 02:11:50.593844  4932 solver.cpp:255]     Train net output #0: loss = 0.00259448 (* 1 = 0.00259448 loss)
I0110 02:11:50.593855  4932 solver.cpp:631] Iteration 18000, lr = 1e-05
I0110 02:12:08.689185  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4402 > 20) by scale factor 0.978465
I0110 02:12:28.654546  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.991 > 20) by scale factor 0.769498
I0110 02:12:30.877816  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1154 > 20) by scale factor 0.686921
I0110 02:12:34.981379  4932 solver.cpp:240] Iteration 18020, loss = 0.0934312
I0110 02:12:34.981426  4932 solver.cpp:255]     Train net output #0: loss = 0.000410349 (* 1 = 0.000410349 loss)
I0110 02:12:34.981436  4932 solver.cpp:631] Iteration 18020, lr = 1e-05
I0110 02:12:55.307173  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4775 > 20) by scale factor 0.678484
I0110 02:13:19.389449  4932 solver.cpp:240] Iteration 18040, loss = 0.0585069
I0110 02:13:19.389547  4932 solver.cpp:255]     Train net output #0: loss = 0.0612368 (* 1 = 0.0612368 loss)
I0110 02:13:19.389560  4932 solver.cpp:631] Iteration 18040, lr = 1e-05
I0110 02:14:03.754170  4932 solver.cpp:240] Iteration 18060, loss = 0.0644439
I0110 02:14:03.754261  4932 solver.cpp:255]     Train net output #0: loss = 0.0672824 (* 1 = 0.0672824 loss)
I0110 02:14:03.754274  4932 solver.cpp:631] Iteration 18060, lr = 1e-05
I0110 02:14:17.405194  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1606 > 20) by scale factor 0.992033
I0110 02:14:48.126278  4932 solver.cpp:240] Iteration 18080, loss = 0.0652966
I0110 02:14:48.126361  4932 solver.cpp:255]     Train net output #0: loss = 0.0176098 (* 1 = 0.0176098 loss)
I0110 02:14:48.126374  4932 solver.cpp:631] Iteration 18080, lr = 1e-05
I0110 02:14:57.341770  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5107 > 20) by scale factor 0.888467
I0110 02:15:32.501966  4932 solver.cpp:240] Iteration 18100, loss = 0.0652041
I0110 02:15:32.502043  4932 solver.cpp:255]     Train net output #0: loss = 0.0174219 (* 1 = 0.0174219 loss)
I0110 02:15:32.502051  4932 solver.cpp:631] Iteration 18100, lr = 1e-05
I0110 02:15:48.370913  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8964 > 20) by scale factor 0.803329
I0110 02:16:16.869938  4932 solver.cpp:240] Iteration 18120, loss = 0.084639
I0110 02:16:16.870024  4932 solver.cpp:255]     Train net output #0: loss = 0.00288797 (* 1 = 0.00288797 loss)
I0110 02:16:16.870034  4932 solver.cpp:631] Iteration 18120, lr = 1e-05
I0110 02:16:48.264034  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0942 > 20) by scale factor 0.995312
I0110 02:17:01.243840  4932 solver.cpp:240] Iteration 18140, loss = 0.0624592
I0110 02:17:01.243880  4932 solver.cpp:255]     Train net output #0: loss = 0.0726671 (* 1 = 0.0726671 loss)
I0110 02:17:01.243887  4932 solver.cpp:631] Iteration 18140, lr = 1e-05
I0110 02:17:45.618276  4932 solver.cpp:240] Iteration 18160, loss = 0.0765161
I0110 02:17:45.618355  4932 solver.cpp:255]     Train net output #0: loss = 0.319912 (* 1 = 0.319912 loss)
I0110 02:17:45.618366  4932 solver.cpp:631] Iteration 18160, lr = 1e-05
I0110 02:18:29.985337  4932 solver.cpp:240] Iteration 18180, loss = 0.0653256
I0110 02:18:29.985412  4932 solver.cpp:255]     Train net output #0: loss = 0.0998074 (* 1 = 0.0998074 loss)
I0110 02:18:29.985422  4932 solver.cpp:631] Iteration 18180, lr = 1e-05
I0110 02:18:41.410958  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.2997 > 20) by scale factor 0.583096
I0110 02:19:14.358119  4932 solver.cpp:240] Iteration 18200, loss = 0.0610332
I0110 02:19:14.358189  4932 solver.cpp:255]     Train net output #0: loss = 0.046644 (* 1 = 0.046644 loss)
I0110 02:19:14.358198  4932 solver.cpp:631] Iteration 18200, lr = 1e-05
I0110 02:19:16.915719  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9999 > 20) by scale factor 0.666668
I0110 02:19:41.341634  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1589 > 20) by scale factor 0.827851
I0110 02:19:58.755234  4932 solver.cpp:240] Iteration 18220, loss = 0.0709363
I0110 02:19:58.755303  4932 solver.cpp:255]     Train net output #0: loss = 0.0010627 (* 1 = 0.0010627 loss)
I0110 02:19:58.755313  4932 solver.cpp:631] Iteration 18220, lr = 1e-05
I0110 02:20:32.372998  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2249 > 20) by scale factor 0.861146
I0110 02:20:43.132524  4932 solver.cpp:240] Iteration 18240, loss = 0.0580137
I0110 02:20:43.132561  4932 solver.cpp:255]     Train net output #0: loss = 0.0805986 (* 1 = 0.0805986 loss)
I0110 02:20:43.132570  4932 solver.cpp:631] Iteration 18240, lr = 1e-05
I0110 02:20:50.125483  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3656 > 20) by scale factor 0.820828
I0110 02:21:27.506896  4932 solver.cpp:240] Iteration 18260, loss = 0.0588169
I0110 02:21:27.506978  4932 solver.cpp:255]     Train net output #0: loss = 0.219529 (* 1 = 0.219529 loss)
I0110 02:21:27.506990  4932 solver.cpp:631] Iteration 18260, lr = 1e-05
I0110 02:21:34.503497  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9748 > 20) by scale factor 0.667226
I0110 02:22:03.353055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3832 > 20) by scale factor 0.758057
I0110 02:22:11.893831  4932 solver.cpp:240] Iteration 18280, loss = 0.0797423
I0110 02:22:11.893870  4932 solver.cpp:255]     Train net output #0: loss = 0.00564091 (* 1 = 0.00564091 loss)
I0110 02:22:11.893879  4932 solver.cpp:631] Iteration 18280, lr = 1e-05
I0110 02:22:49.950817  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4829 > 20) by scale factor 0.656105
I0110 02:22:56.270351  4932 solver.cpp:240] Iteration 18300, loss = 0.0746417
I0110 02:22:56.270396  4932 solver.cpp:255]     Train net output #0: loss = 0.0124008 (* 1 = 0.0124008 loss)
I0110 02:22:56.270406  4932 solver.cpp:631] Iteration 18300, lr = 1e-05
I0110 02:23:40.647975  4932 solver.cpp:240] Iteration 18320, loss = 0.0675545
I0110 02:23:40.648053  4932 solver.cpp:255]     Train net output #0: loss = 0.0614648 (* 1 = 0.0614648 loss)
I0110 02:23:40.648063  4932 solver.cpp:631] Iteration 18320, lr = 1e-05
I0110 02:24:16.495828  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8667 > 20) by scale factor 0.773195
I0110 02:24:25.031515  4932 solver.cpp:240] Iteration 18340, loss = 0.0629599
I0110 02:24:25.031553  4932 solver.cpp:255]     Train net output #0: loss = 0.0266245 (* 1 = 0.0266245 loss)
I0110 02:24:25.031561  4932 solver.cpp:631] Iteration 18340, lr = 1e-05
I0110 02:25:09.408697  4932 solver.cpp:240] Iteration 18360, loss = 0.0645711
I0110 02:25:09.408774  4932 solver.cpp:255]     Train net output #0: loss = 0.155483 (* 1 = 0.155483 loss)
I0110 02:25:09.408784  4932 solver.cpp:631] Iteration 18360, lr = 1e-05
I0110 02:25:47.467028  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8428 > 20) by scale factor 0.87555
I0110 02:25:53.785322  4932 solver.cpp:240] Iteration 18380, loss = 0.0412365
I0110 02:25:53.785359  4932 solver.cpp:255]     Train net output #0: loss = 0.05393 (* 1 = 0.05393 loss)
I0110 02:25:53.785367  4932 solver.cpp:631] Iteration 18380, lr = 1e-05
I0110 02:26:25.185866  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9786 > 20) by scale factor 0.953352
I0110 02:26:38.160614  4932 solver.cpp:240] Iteration 18400, loss = 0.0842301
I0110 02:26:38.160651  4932 solver.cpp:255]     Train net output #0: loss = 0.0705725 (* 1 = 0.0705725 loss)
I0110 02:26:38.160660  4932 solver.cpp:631] Iteration 18400, lr = 1e-05
I0110 02:26:56.248390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5843 > 20) by scale factor 0.971615
I0110 02:27:22.531250  4932 solver.cpp:240] Iteration 18420, loss = 0.0477077
I0110 02:27:22.531287  4932 solver.cpp:255]     Train net output #0: loss = 0.0442634 (* 1 = 0.0442634 loss)
I0110 02:27:22.531296  4932 solver.cpp:631] Iteration 18420, lr = 1e-05
I0110 02:27:49.499816  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4444 > 20) by scale factor 0.978262
I0110 02:28:06.910384  4932 solver.cpp:240] Iteration 18440, loss = 0.0625952
I0110 02:28:06.910430  4932 solver.cpp:255]     Train net output #0: loss = 0.0482812 (* 1 = 0.0482812 loss)
I0110 02:28:06.910442  4932 solver.cpp:631] Iteration 18440, lr = 1e-05
I0110 02:28:18.342058  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7569 > 20) by scale factor 0.807857
I0110 02:28:51.286664  4932 solver.cpp:240] Iteration 18460, loss = 0.0707498
I0110 02:28:51.286736  4932 solver.cpp:255]     Train net output #0: loss = 0.394977 (* 1 = 0.394977 loss)
I0110 02:28:51.286744  4932 solver.cpp:631] Iteration 18460, lr = 1e-05
I0110 02:28:51.626015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7787 > 20) by scale factor 0.807145
I0110 02:29:35.665316  4932 solver.cpp:240] Iteration 18480, loss = 0.0623322
I0110 02:29:35.665405  4932 solver.cpp:255]     Train net output #0: loss = 0.00850902 (* 1 = 0.00850902 loss)
I0110 02:29:35.665417  4932 solver.cpp:631] Iteration 18480, lr = 1e-05
I0110 02:30:20.042467  4932 solver.cpp:240] Iteration 18500, loss = 0.0909854
I0110 02:30:20.042534  4932 solver.cpp:255]     Train net output #0: loss = 0.000334566 (* 1 = 0.000334566 loss)
I0110 02:30:20.042543  4932 solver.cpp:631] Iteration 18500, lr = 1e-05
I0110 02:30:29.255100  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3571 > 20) by scale factor 0.89457
I0110 02:30:55.880336  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1857 > 20) by scale factor 0.826936
I0110 02:31:04.413810  4932 solver.cpp:240] Iteration 18520, loss = 0.0752181
I0110 02:31:04.413841  4932 solver.cpp:255]     Train net output #0: loss = 0.0462274 (* 1 = 0.0462274 loss)
I0110 02:31:04.413851  4932 solver.cpp:631] Iteration 18520, lr = 1e-05
I0110 02:31:48.823348  4932 solver.cpp:240] Iteration 18540, loss = 0.0743699
I0110 02:31:48.823443  4932 solver.cpp:255]     Train net output #0: loss = 0.0869501 (* 1 = 0.0869501 loss)
I0110 02:31:48.823456  4932 solver.cpp:631] Iteration 18540, lr = 1e-05
I0110 02:32:33.196980  4932 solver.cpp:240] Iteration 18560, loss = 0.0508139
I0110 02:32:33.197119  4932 solver.cpp:255]     Train net output #0: loss = 0.140914 (* 1 = 0.140914 loss)
I0110 02:32:33.197135  4932 solver.cpp:631] Iteration 18560, lr = 1e-05
I0110 02:33:17.574908  4932 solver.cpp:240] Iteration 18580, loss = 0.0466506
I0110 02:33:17.574998  4932 solver.cpp:255]     Train net output #0: loss = 0.0123404 (* 1 = 0.0123404 loss)
I0110 02:33:17.575009  4932 solver.cpp:631] Iteration 18580, lr = 1e-05
I0110 02:34:01.953980  4932 solver.cpp:240] Iteration 18600, loss = 0.0486002
I0110 02:34:01.954071  4932 solver.cpp:255]     Train net output #0: loss = 0.120647 (* 1 = 0.120647 loss)
I0110 02:34:01.954082  4932 solver.cpp:631] Iteration 18600, lr = 1e-05
I0110 02:34:08.951015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1765 > 20) by scale factor 0.901857
I0110 02:34:46.327910  4932 solver.cpp:240] Iteration 18620, loss = 0.0493
I0110 02:34:46.327986  4932 solver.cpp:255]     Train net output #0: loss = 0.0191011 (* 1 = 0.0191011 loss)
I0110 02:34:46.327994  4932 solver.cpp:631] Iteration 18620, lr = 1e-05
I0110 02:34:59.976584  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4788 > 20) by scale factor 0.976621
I0110 02:35:04.417804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6135 > 20) by scale factor 0.970236
I0110 02:35:22.170660  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4611 > 20) by scale factor 0.890429
I0110 02:35:28.828594  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8056 > 20) by scale factor 0.917197
I0110 02:35:30.709547  4932 solver.cpp:240] Iteration 18640, loss = 0.0769918
I0110 02:35:30.709585  4932 solver.cpp:255]     Train net output #0: loss = 0.00351024 (* 1 = 0.00351024 loss)
I0110 02:35:30.709594  4932 solver.cpp:631] Iteration 18640, lr = 1e-05
I0110 02:36:15.082392  4932 solver.cpp:240] Iteration 18660, loss = 0.0609325
I0110 02:36:15.082482  4932 solver.cpp:255]     Train net output #0: loss = 0.0739902 (* 1 = 0.0739902 loss)
I0110 02:36:15.082494  4932 solver.cpp:631] Iteration 18660, lr = 1e-05
I0110 02:36:42.039778  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2925 > 20) by scale factor 0.985584
I0110 02:36:59.451262  4932 solver.cpp:240] Iteration 18680, loss = 0.0410729
I0110 02:36:59.451339  4932 solver.cpp:255]     Train net output #0: loss = 0.0214236 (* 1 = 0.0214236 loss)
I0110 02:36:59.451349  4932 solver.cpp:631] Iteration 18680, lr = 1e-05
I0110 02:37:37.511239  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9766 > 20) by scale factor 0.800749
I0110 02:37:43.832224  4932 solver.cpp:240] Iteration 18700, loss = 0.0260629
I0110 02:37:43.832263  4932 solver.cpp:255]     Train net output #0: loss = 0.0102793 (* 1 = 0.0102793 loss)
I0110 02:37:43.832275  4932 solver.cpp:631] Iteration 18700, lr = 1e-05
I0110 02:37:55.262272  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7672 > 20) by scale factor 0.841495
I0110 02:37:59.705309  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0988 > 20) by scale factor 0.664478
I0110 02:38:28.211607  4932 solver.cpp:240] Iteration 18720, loss = 0.112267
I0110 02:38:28.211686  4932 solver.cpp:255]     Train net output #0: loss = 0.00845817 (* 1 = 0.00845817 loss)
I0110 02:38:28.211696  4932 solver.cpp:631] Iteration 18720, lr = 1e-05
I0110 02:38:44.083923  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3237 > 20) by scale factor 0.822244
I0110 02:38:55.183157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.282 > 20) by scale factor 0.897584
I0110 02:39:12.596629  4932 solver.cpp:240] Iteration 18740, loss = 0.0881808
I0110 02:39:12.596698  4932 solver.cpp:255]     Train net output #0: loss = 0.107605 (* 1 = 0.107605 loss)
I0110 02:39:12.596707  4932 solver.cpp:631] Iteration 18740, lr = 1e-05
I0110 02:39:56.973958  4932 solver.cpp:240] Iteration 18760, loss = 0.0430416
I0110 02:39:56.974040  4932 solver.cpp:255]     Train net output #0: loss = 0.0719253 (* 1 = 0.0719253 loss)
I0110 02:39:56.974055  4932 solver.cpp:631] Iteration 18760, lr = 1e-05
I0110 02:40:23.942025  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.6558 > 20) by scale factor 0.652405
I0110 02:40:37.257310  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6782 > 20) by scale factor 0.697393
I0110 02:40:41.358911  4932 solver.cpp:240] Iteration 18780, loss = 0.0707758
I0110 02:40:41.358950  4932 solver.cpp:255]     Train net output #0: loss = 0.0417594 (* 1 = 0.0417594 loss)
I0110 02:40:41.358959  4932 solver.cpp:631] Iteration 18780, lr = 1e-05
I0110 02:40:55.007376  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.6907 > 20) by scale factor 0.6311
I0110 02:41:25.736033  4932 solver.cpp:240] Iteration 18800, loss = 0.0726335
I0110 02:41:25.736114  4932 solver.cpp:255]     Train net output #0: loss = 0.00380953 (* 1 = 0.00380953 loss)
I0110 02:41:25.736124  4932 solver.cpp:631] Iteration 18800, lr = 1e-05
I0110 02:41:57.131352  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7352 > 20) by scale factor 0.964542
I0110 02:42:10.110693  4932 solver.cpp:240] Iteration 18820, loss = 0.0835209
I0110 02:42:10.110733  4932 solver.cpp:255]     Train net output #0: loss = 0.474199 (* 1 = 0.474199 loss)
I0110 02:42:10.110857  4932 solver.cpp:631] Iteration 18820, lr = 1e-05
I0110 02:42:10.450054  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.1917 > 20) by scale factor 0.621278
I0110 02:42:19.330814  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7677 > 20) by scale factor 0.918793
I0110 02:42:23.774626  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5295 > 20) by scale factor 0.887724
I0110 02:42:34.880079  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0208 > 20) by scale factor 0.666205
I0110 02:42:39.321043  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0906 > 20) by scale factor 0.995492
I0110 02:42:41.542078  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8018 > 20) by scale factor 0.961457
I0110 02:42:54.524546  4932 solver.cpp:240] Iteration 18840, loss = 0.106482
I0110 02:42:54.524588  4932 solver.cpp:255]     Train net output #0: loss = 0.00406038 (* 1 = 0.00406038 loss)
I0110 02:42:54.524600  4932 solver.cpp:631] Iteration 18840, lr = 1e-05
I0110 02:43:38.916885  4932 solver.cpp:240] Iteration 18860, loss = 0.0476404
I0110 02:43:38.916962  4932 solver.cpp:255]     Train net output #0: loss = 0.0022772 (* 1 = 0.0022772 loss)
I0110 02:43:38.916972  4932 solver.cpp:631] Iteration 18860, lr = 1e-05
I0110 02:43:54.793319  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2119 > 20) by scale factor 0.900418
I0110 02:43:59.239794  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4794 > 20) by scale factor 0.97659
I0110 02:44:01.462534  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4747 > 20) by scale factor 0.88989
I0110 02:44:17.047374  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6478 > 20) by scale factor 0.88309
I0110 02:44:23.364763  4932 solver.cpp:240] Iteration 18880, loss = 0.0952742
I0110 02:44:23.364806  4932 solver.cpp:255]     Train net output #0: loss = 0.000537011 (* 1 = 0.000537011 loss)
I0110 02:44:23.364820  4932 solver.cpp:631] Iteration 18880, lr = 1e-05
I0110 02:44:25.925165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3269 > 20) by scale factor 0.98392
I0110 02:45:07.739640  4932 solver.cpp:240] Iteration 18900, loss = 0.045164
I0110 02:45:07.739733  4932 solver.cpp:255]     Train net output #0: loss = 0.0249681 (* 1 = 0.0249681 loss)
I0110 02:45:07.739745  4932 solver.cpp:631] Iteration 18900, lr = 1e-05
I0110 02:45:34.708618  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6264 > 20) by scale factor 0.924794
I0110 02:45:48.023705  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0716 > 20) by scale factor 0.738782
I0110 02:45:52.122951  4932 solver.cpp:240] Iteration 18920, loss = 0.0584663
I0110 02:45:52.122988  4932 solver.cpp:255]     Train net output #0: loss = 0.0390066 (* 1 = 0.0390066 loss)
I0110 02:45:52.122997  4932 solver.cpp:631] Iteration 18920, lr = 1e-05
I0110 02:46:10.215240  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3362 > 20) by scale factor 0.821822
I0110 02:46:36.512756  4932 solver.cpp:240] Iteration 18940, loss = 0.067069
I0110 02:46:36.512840  4932 solver.cpp:255]     Train net output #0: loss = 0.00148623 (* 1 = 0.00148623 loss)
I0110 02:46:36.512850  4932 solver.cpp:631] Iteration 18940, lr = 1e-05
I0110 02:47:20.881083  4932 solver.cpp:240] Iteration 18960, loss = 0.0506546
I0110 02:47:20.881170  4932 solver.cpp:255]     Train net output #0: loss = 0.0940733 (* 1 = 0.0940733 loss)
I0110 02:47:20.881182  4932 solver.cpp:631] Iteration 18960, lr = 1e-05
I0110 02:48:05.261790  4932 solver.cpp:240] Iteration 18980, loss = 0.0484734
I0110 02:48:05.261859  4932 solver.cpp:255]     Train net output #0: loss = 0.201863 (* 1 = 0.201863 loss)
I0110 02:48:05.261868  4932 solver.cpp:631] Iteration 18980, lr = 1e-05
I0110 02:48:05.600914  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6994 > 20) by scale factor 0.881082
I0110 02:48:47.779000  4932 solver.cpp:424] Iteration 19000, Testing net (#0)
I0110 02:49:40.824569  4932 solver.cpp:481]     Test net output #0: accuracy = 0.848421
I0110 02:49:40.824651  4932 solver.cpp:481]     Test net output #1: loss = 0.774993 (* 1 = 0.774993 loss)
I0110 02:49:42.691517  4932 solver.cpp:240] Iteration 19000, loss = 0.0691135
I0110 02:49:42.691552  4932 solver.cpp:255]     Train net output #0: loss = 0.00310607 (* 1 = 0.00310607 loss)
I0110 02:49:42.691560  4932 solver.cpp:631] Iteration 19000, lr = 1e-05
I0110 02:50:27.057194  4932 solver.cpp:240] Iteration 19020, loss = 0.0486274
I0110 02:50:27.057255  4932 solver.cpp:255]     Train net output #0: loss = 0.0210079 (* 1 = 0.0210079 loss)
I0110 02:50:27.057263  4932 solver.cpp:631] Iteration 19020, lr = 1e-05
I0110 02:51:11.428308  4932 solver.cpp:240] Iteration 19040, loss = 0.0895694
I0110 02:51:11.428381  4932 solver.cpp:255]     Train net output #0: loss = 0.152185 (* 1 = 0.152185 loss)
I0110 02:51:11.428391  4932 solver.cpp:631] Iteration 19040, lr = 1e-05
I0110 02:51:22.862609  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1691 > 20) by scale factor 0.991615
I0110 02:51:40.620642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6543 > 20) by scale factor 0.697975
I0110 02:51:55.814723  4932 solver.cpp:240] Iteration 19060, loss = 0.0684417
I0110 02:51:55.814810  4932 solver.cpp:255]     Train net output #0: loss = 0.0425609 (* 1 = 0.0425609 loss)
I0110 02:51:55.814821  4932 solver.cpp:631] Iteration 19060, lr = 1e-05
I0110 02:52:13.901686  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5235 > 20) by scale factor 0.815546
I0110 02:52:40.186400  4932 solver.cpp:240] Iteration 19080, loss = 0.0353171
I0110 02:52:40.186491  4932 solver.cpp:255]     Train net output #0: loss = 0.0192496 (* 1 = 0.0192496 loss)
I0110 02:52:40.186501  4932 solver.cpp:631] Iteration 19080, lr = 1e-05
I0110 02:52:56.055549  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3892 > 20) by scale factor 0.787736
I0110 02:53:11.588929  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2744 > 20) by scale factor 0.986468
I0110 02:53:13.808439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5805 > 20) by scale factor 0.971795
I0110 02:53:22.886342  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4984 > 20) by scale factor 0.930303
I0110 02:53:24.767738  4932 solver.cpp:240] Iteration 19100, loss = 0.0972867
I0110 02:53:24.767786  4932 solver.cpp:255]     Train net output #0: loss = 0.168376 (* 1 = 0.168376 loss)
I0110 02:53:24.767912  4932 solver.cpp:631] Iteration 19100, lr = 1e-05
I0110 02:53:25.106999  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6075 > 20) by scale factor 0.925603
I0110 02:53:27.328842  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7857 > 20) by scale factor 0.918034
I0110 02:53:47.316401  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4325 > 20) by scale factor 0.978831
I0110 02:54:09.175163  4932 solver.cpp:240] Iteration 19120, loss = 0.0506189
I0110 02:54:09.175211  4932 solver.cpp:255]     Train net output #0: loss = 0.00248878 (* 1 = 0.00248878 loss)
I0110 02:54:09.175326  4932 solver.cpp:631] Iteration 19120, lr = 1e-05
I0110 02:54:31.785614  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.629 > 20) by scale factor 0.75106
I0110 02:54:34.007963  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8987 > 20) by scale factor 0.873412
I0110 02:54:53.638526  4932 solver.cpp:240] Iteration 19140, loss = 0.0692837
I0110 02:54:53.638566  4932 solver.cpp:255]     Train net output #0: loss = 0.0722064 (* 1 = 0.0722064 loss)
I0110 02:54:53.638576  4932 solver.cpp:631] Iteration 19140, lr = 1e-05
I0110 02:55:13.957820  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4779 > 20) by scale factor 0.976663
I0110 02:55:38.041851  4932 solver.cpp:240] Iteration 19160, loss = 0.0746085
I0110 02:55:38.041892  4932 solver.cpp:255]     Train net output #0: loss = 0.379039 (* 1 = 0.379039 loss)
I0110 02:55:38.041901  4932 solver.cpp:631] Iteration 19160, lr = 1e-05
I0110 02:56:02.792842  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3 > 20) by scale factor 0.682593
I0110 02:56:22.434298  4932 solver.cpp:240] Iteration 19180, loss = 0.0335609
I0110 02:56:22.434345  4932 solver.cpp:255]     Train net output #0: loss = 0.0106214 (* 1 = 0.0106214 loss)
I0110 02:56:22.434356  4932 solver.cpp:631] Iteration 19180, lr = 1e-05
I0110 02:56:27.212074  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3499 > 20) by scale factor 0.982808
I0110 02:56:44.972122  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4277 > 20) by scale factor 0.891753
I0110 02:56:47.194253  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7162 > 20) by scale factor 0.88043
I0110 02:57:06.829277  4932 solver.cpp:240] Iteration 19200, loss = 0.101069
I0110 02:57:06.829314  4932 solver.cpp:255]     Train net output #0: loss = 0.25706 (* 1 = 0.25706 loss)
I0110 02:57:06.829322  4932 solver.cpp:631] Iteration 19200, lr = 1e-05
I0110 02:57:07.168491  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9595 > 20) by scale factor 0.910768
I0110 02:57:47.128252  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0365 > 20) by scale factor 0.798835
I0110 02:57:51.229004  4932 solver.cpp:240] Iteration 19220, loss = 0.0648246
I0110 02:57:51.229044  4932 solver.cpp:255]     Train net output #0: loss = 0.22918 (* 1 = 0.22918 loss)
I0110 02:57:51.229053  4932 solver.cpp:631] Iteration 19220, lr = 1e-05
I0110 02:58:11.547973  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4636 > 20) by scale factor 0.817541
I0110 02:58:35.624243  4932 solver.cpp:240] Iteration 19240, loss = 0.0710638
I0110 02:58:35.624337  4932 solver.cpp:255]     Train net output #0: loss = 0.0057225 (* 1 = 0.0057225 loss)
I0110 02:58:35.624351  4932 solver.cpp:631] Iteration 19240, lr = 1e-05
I0110 02:58:47.066565  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1506 > 20) by scale factor 0.863907
I0110 02:59:04.824833  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5865 > 20) by scale factor 0.847941
I0110 02:59:20.026695  4932 solver.cpp:240] Iteration 19260, loss = 0.0712103
I0110 02:59:20.026819  4932 solver.cpp:255]     Train net output #0: loss = 0.0128273 (* 1 = 0.0128273 loss)
I0110 02:59:20.026839  4932 solver.cpp:631] Iteration 19260, lr = 1e-05
I0110 02:59:29.241787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6032 > 20) by scale factor 0.884829
I0110 02:59:44.778311  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9862 > 20) by scale factor 0.953006
I0110 02:59:55.883170  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.679 > 20) by scale factor 0.967164
I0110 03:00:04.427767  4932 solver.cpp:240] Iteration 19280, loss = 0.0833984
I0110 03:00:04.427804  4932 solver.cpp:255]     Train net output #0: loss = 0.204978 (* 1 = 0.204978 loss)
I0110 03:00:04.427816  4932 solver.cpp:631] Iteration 19280, lr = 1e-05
I0110 03:00:31.402427  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4368 > 20) by scale factor 0.853358
I0110 03:00:38.067584  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9713 > 20) by scale factor 0.953683
I0110 03:00:48.824156  4932 solver.cpp:240] Iteration 19300, loss = 0.0661373
I0110 03:00:48.824205  4932 solver.cpp:255]     Train net output #0: loss = 0.00468979 (* 1 = 0.00468979 loss)
I0110 03:00:48.824218  4932 solver.cpp:631] Iteration 19300, lr = 1e-05
I0110 03:00:58.049682  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7776 > 20) by scale factor 0.918374
I0110 03:01:33.225337  4932 solver.cpp:240] Iteration 19320, loss = 0.0672269
I0110 03:01:33.225427  4932 solver.cpp:255]     Train net output #0: loss = 0.235124 (* 1 = 0.235124 loss)
I0110 03:01:33.225440  4932 solver.cpp:631] Iteration 19320, lr = 1e-05
I0110 03:02:13.520211  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2722 > 20) by scale factor 0.940194
I0110 03:02:17.623355  4932 solver.cpp:240] Iteration 19340, loss = 0.06473
I0110 03:02:17.623394  4932 solver.cpp:255]     Train net output #0: loss = 0.0155711 (* 1 = 0.0155711 loss)
I0110 03:02:17.623404  4932 solver.cpp:631] Iteration 19340, lr = 1e-05
I0110 03:03:02.012682  4932 solver.cpp:240] Iteration 19360, loss = 0.0411788
I0110 03:03:02.012773  4932 solver.cpp:255]     Train net output #0: loss = 0.0174312 (* 1 = 0.0174312 loss)
I0110 03:03:02.012784  4932 solver.cpp:631] Iteration 19360, lr = 1e-05
I0110 03:03:46.394436  4932 solver.cpp:240] Iteration 19380, loss = 0.0592819
I0110 03:03:46.394526  4932 solver.cpp:255]     Train net output #0: loss = 0.0308184 (* 1 = 0.0308184 loss)
I0110 03:03:46.394541  4932 solver.cpp:631] Iteration 19380, lr = 1e-05
I0110 03:03:48.955570  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2093 > 20) by scale factor 0.793359
I0110 03:04:30.782307  4932 solver.cpp:240] Iteration 19400, loss = 0.0669286
I0110 03:04:30.782385  4932 solver.cpp:255]     Train net output #0: loss = 0.00343372 (* 1 = 0.00343372 loss)
I0110 03:04:30.782395  4932 solver.cpp:631] Iteration 19400, lr = 1e-05
I0110 03:04:59.985882  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.039 > 20) by scale factor 0.868094
I0110 03:05:15.185210  4932 solver.cpp:240] Iteration 19420, loss = 0.0756112
I0110 03:05:15.185291  4932 solver.cpp:255]     Train net output #0: loss = 0.00376939 (* 1 = 0.00376939 loss)
I0110 03:05:15.185299  4932 solver.cpp:631] Iteration 19420, lr = 1e-05
I0110 03:05:59.572751  4932 solver.cpp:240] Iteration 19440, loss = 0.0592319
I0110 03:05:59.572839  4932 solver.cpp:255]     Train net output #0: loss = 0.0746988 (* 1 = 0.0746988 loss)
I0110 03:05:59.572850  4932 solver.cpp:631] Iteration 19440, lr = 1e-05
I0110 03:06:33.212936  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6007 > 20) by scale factor 0.97084
I0110 03:06:43.966056  4932 solver.cpp:240] Iteration 19460, loss = 0.0654813
I0110 03:06:43.966096  4932 solver.cpp:255]     Train net output #0: loss = 0.00788551 (* 1 = 0.00788551 loss)
I0110 03:06:43.966104  4932 solver.cpp:631] Iteration 19460, lr = 1e-05
I0110 03:07:02.063155  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4033 > 20) by scale factor 0.934434
I0110 03:07:28.362594  4932 solver.cpp:240] Iteration 19480, loss = 0.0476719
I0110 03:07:28.362689  4932 solver.cpp:255]     Train net output #0: loss = 0.00974169 (* 1 = 0.00974169 loss)
I0110 03:07:28.362699  4932 solver.cpp:631] Iteration 19480, lr = 1e-05
I0110 03:08:06.426311  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1033 > 20) by scale factor 0.865678
I0110 03:08:12.748937  4932 solver.cpp:240] Iteration 19500, loss = 0.0369048
I0110 03:08:12.748971  4932 solver.cpp:255]     Train net output #0: loss = 0.0970195 (* 1 = 0.0970195 loss)
I0110 03:08:12.748980  4932 solver.cpp:631] Iteration 19500, lr = 1e-05
I0110 03:08:24.187208  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9115 > 20) by scale factor 0.771857
I0110 03:08:44.155112  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1792 > 20) by scale factor 0.901745
I0110 03:08:57.139245  4932 solver.cpp:240] Iteration 19520, loss = 0.0714978
I0110 03:08:57.139278  4932 solver.cpp:255]     Train net output #0: loss = 0.0241383 (* 1 = 0.0241383 loss)
I0110 03:08:57.139287  4932 solver.cpp:631] Iteration 19520, lr = 1e-05
I0110 03:09:01.916568  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1001 > 20) by scale factor 0.904972
I0110 03:09:41.536738  4932 solver.cpp:240] Iteration 19540, loss = 0.0506156
I0110 03:09:41.536823  4932 solver.cpp:255]     Train net output #0: loss = 0.0174855 (* 1 = 0.0174855 loss)
I0110 03:09:41.536834  4932 solver.cpp:631] Iteration 19540, lr = 1e-05
I0110 03:10:25.924672  4932 solver.cpp:240] Iteration 19560, loss = 0.0685971
I0110 03:10:25.924774  4932 solver.cpp:255]     Train net output #0: loss = 0.22581 (* 1 = 0.22581 loss)
I0110 03:10:25.924788  4932 solver.cpp:631] Iteration 19560, lr = 1e-05
I0110 03:11:06.223937  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9305 > 20) by scale factor 0.771292
I0110 03:11:10.325155  4932 solver.cpp:240] Iteration 19580, loss = 0.0993299
I0110 03:11:10.325196  4932 solver.cpp:255]     Train net output #0: loss = 0.061078 (* 1 = 0.061078 loss)
I0110 03:11:10.325204  4932 solver.cpp:631] Iteration 19580, lr = 1e-05
I0110 03:11:54.713357  4932 solver.cpp:240] Iteration 19600, loss = 0.0642352
I0110 03:11:54.713443  4932 solver.cpp:255]     Train net output #0: loss = 0.0330099 (* 1 = 0.0330099 loss)
I0110 03:11:54.713455  4932 solver.cpp:631] Iteration 19600, lr = 1e-05
I0110 03:12:26.133949  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4298 > 20) by scale factor 0.978963
I0110 03:12:32.796448  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2223 > 20) by scale factor 0.989008
I0110 03:12:39.116725  4932 solver.cpp:240] Iteration 19620, loss = 0.0889309
I0110 03:12:39.116765  4932 solver.cpp:255]     Train net output #0: loss = 0.000952236 (* 1 = 0.000952236 loss)
I0110 03:12:39.116772  4932 solver.cpp:631] Iteration 19620, lr = 1e-05
I0110 03:13:23.513370  4932 solver.cpp:240] Iteration 19640, loss = 0.0374263
I0110 03:13:23.513461  4932 solver.cpp:255]     Train net output #0: loss = 0.0365506 (* 1 = 0.0365506 loss)
I0110 03:13:23.513474  4932 solver.cpp:631] Iteration 19640, lr = 1e-05
I0110 03:14:07.898726  4932 solver.cpp:240] Iteration 19660, loss = 0.0579156
I0110 03:14:07.898823  4932 solver.cpp:255]     Train net output #0: loss = 0.152975 (* 1 = 0.152975 loss)
I0110 03:14:07.898835  4932 solver.cpp:631] Iteration 19660, lr = 1e-05
I0110 03:14:21.556794  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5358 > 20) by scale factor 0.928687
I0110 03:14:50.419692  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4101 > 20) by scale factor 0.854331
I0110 03:14:52.302224  4932 solver.cpp:240] Iteration 19680, loss = 0.0670011
I0110 03:14:52.302268  4932 solver.cpp:255]     Train net output #0: loss = 0.0135716 (* 1 = 0.0135716 loss)
I0110 03:14:52.302279  4932 solver.cpp:631] Iteration 19680, lr = 1e-05
I0110 03:15:17.057494  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.304 > 20) by scale factor 0.760339
I0110 03:15:21.502444  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4248 > 20) by scale factor 0.9335
I0110 03:15:36.704727  4932 solver.cpp:240] Iteration 19700, loss = 0.0844096
I0110 03:15:36.704778  4932 solver.cpp:255]     Train net output #0: loss = 0.00633992 (* 1 = 0.00633992 loss)
I0110 03:15:36.704792  4932 solver.cpp:631] Iteration 19700, lr = 1e-05
I0110 03:15:43.704881  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3582 > 20) by scale factor 0.982404
I0110 03:15:57.028769  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7075 > 20) by scale factor 0.965832
I0110 03:16:21.099805  4932 solver.cpp:240] Iteration 19720, loss = 0.0788595
I0110 03:16:21.099846  4932 solver.cpp:255]     Train net output #0: loss = 0.02966 (* 1 = 0.02966 loss)
I0110 03:16:21.099855  4932 solver.cpp:631] Iteration 19720, lr = 1e-05
I0110 03:16:34.765048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7837 > 20) by scale factor 0.962291
I0110 03:16:41.423576  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3403 > 20) by scale factor 0.983271
I0110 03:16:52.526657  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.252 > 20) by scale factor 0.987558
I0110 03:16:54.748145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.91 > 20) by scale factor 0.95648
I0110 03:17:05.639609  4932 solver.cpp:240] Iteration 19740, loss = 0.0788928
I0110 03:17:05.639704  4932 solver.cpp:255]     Train net output #0: loss = 0.0504722 (* 1 = 0.0504722 loss)
I0110 03:17:05.639716  4932 solver.cpp:631] Iteration 19740, lr = 1e-05
I0110 03:17:08.197999  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.376 > 20) by scale factor 0.82048
I0110 03:17:10.418951  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3358 > 20) by scale factor 0.731642
I0110 03:17:17.084062  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1553 > 20) by scale factor 0.94539
I0110 03:17:19.307833  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0035 > 20) by scale factor 0.952224
I0110 03:17:41.507362  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.523 > 20) by scale factor 0.596606
I0110 03:17:50.048429  4932 solver.cpp:240] Iteration 19760, loss = 0.130124
I0110 03:17:50.048475  4932 solver.cpp:255]     Train net output #0: loss = 0.0539195 (* 1 = 0.0539195 loss)
I0110 03:17:50.048485  4932 solver.cpp:631] Iteration 19760, lr = 1e-05
I0110 03:17:54.829264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2781 > 20) by scale factor 0.939935
I0110 03:18:05.931110  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2558 > 20) by scale factor 0.898642
I0110 03:18:19.250794  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8295 > 20) by scale factor 0.718662
I0110 03:18:34.450314  4932 solver.cpp:240] Iteration 19780, loss = 0.080047
I0110 03:18:34.450363  4932 solver.cpp:255]     Train net output #0: loss = 0.00717079 (* 1 = 0.00717079 loss)
I0110 03:18:34.450376  4932 solver.cpp:631] Iteration 19780, lr = 1e-05
I0110 03:19:12.527544  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8298 > 20) by scale factor 0.774298
I0110 03:19:18.848440  4932 solver.cpp:240] Iteration 19800, loss = 0.113105
I0110 03:19:18.848480  4932 solver.cpp:255]     Train net output #0: loss = 0.0142048 (* 1 = 0.0142048 loss)
I0110 03:19:18.848489  4932 solver.cpp:631] Iteration 19800, lr = 1e-05
I0110 03:20:03.252472  4932 solver.cpp:240] Iteration 19820, loss = 0.0556096
I0110 03:20:03.252564  4932 solver.cpp:255]     Train net output #0: loss = 0.0152014 (* 1 = 0.0152014 loss)
I0110 03:20:03.252578  4932 solver.cpp:631] Iteration 19820, lr = 1e-05
I0110 03:20:47.642019  4932 solver.cpp:240] Iteration 19840, loss = 0.0512884
I0110 03:20:47.642134  4932 solver.cpp:255]     Train net output #0: loss = 0.139984 (* 1 = 0.139984 loss)
I0110 03:20:47.642146  4932 solver.cpp:631] Iteration 19840, lr = 1e-05
I0110 03:21:10.172441  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0551 > 20) by scale factor 0.99725
I0110 03:21:32.039364  4932 solver.cpp:240] Iteration 19860, loss = 0.0683155
I0110 03:21:32.039465  4932 solver.cpp:255]     Train net output #0: loss = 0.0156461 (* 1 = 0.0156461 loss)
I0110 03:21:32.039479  4932 solver.cpp:631] Iteration 19860, lr = 1e-05
I0110 03:21:34.602478  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.253 > 20) by scale factor 0.733865
I0110 03:22:16.437752  4932 solver.cpp:240] Iteration 19880, loss = 0.0550506
I0110 03:22:16.437831  4932 solver.cpp:255]     Train net output #0: loss = 0.0040522 (* 1 = 0.0040522 loss)
I0110 03:22:16.437841  4932 solver.cpp:631] Iteration 19880, lr = 1e-05
I0110 03:22:21.219862  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.0556 > 20) by scale factor 0.587276
I0110 03:22:30.100275  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3824 > 20) by scale factor 0.981238
I0110 03:23:00.836246  4932 solver.cpp:240] Iteration 19900, loss = 0.073807
I0110 03:23:00.836319  4932 solver.cpp:255]     Train net output #0: loss = 0.154965 (* 1 = 0.154965 loss)
I0110 03:23:00.836328  4932 solver.cpp:631] Iteration 19900, lr = 1e-05
I0110 03:23:34.475646  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0088 > 20) by scale factor 0.908726
I0110 03:23:41.140247  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.693 > 20) by scale factor 0.921955
I0110 03:23:45.242858  4932 solver.cpp:240] Iteration 19920, loss = 0.0849522
I0110 03:23:45.242903  4932 solver.cpp:255]     Train net output #0: loss = 0.129823 (* 1 = 0.129823 loss)
I0110 03:23:45.242913  4932 solver.cpp:631] Iteration 19920, lr = 1e-05
I0110 03:24:29.640278  4932 solver.cpp:240] Iteration 19940, loss = 0.0535095
I0110 03:24:29.640375  4932 solver.cpp:255]     Train net output #0: loss = 0.000316283 (* 1 = 0.000316283 loss)
I0110 03:24:29.640389  4932 solver.cpp:631] Iteration 19940, lr = 1e-05
I0110 03:25:14.026880  4932 solver.cpp:240] Iteration 19960, loss = 0.0651362
I0110 03:25:14.026950  4932 solver.cpp:255]     Train net output #0: loss = 0.0100275 (* 1 = 0.0100275 loss)
I0110 03:25:14.026960  4932 solver.cpp:631] Iteration 19960, lr = 1e-05
I0110 03:25:58.435156  4932 solver.cpp:240] Iteration 19980, loss = 0.0701626
I0110 03:25:58.435230  4932 solver.cpp:255]     Train net output #0: loss = 0.0923717 (* 1 = 0.0923717 loss)
I0110 03:25:58.435240  4932 solver.cpp:631] Iteration 19980, lr = 1e-05
I0110 03:26:36.509264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3705 > 20) by scale factor 0.758424
I0110 03:26:40.962165  4932 solver.cpp:424] Iteration 20000, Testing net (#0)
I0110 03:27:28.813005  4932 solver.cpp:481]     Test net output #0: accuracy = 0.812632
I0110 03:27:28.813108  4932 solver.cpp:481]     Test net output #1: loss = 0.910344 (* 1 = 0.910344 loss)
I0110 03:27:30.679117  4932 solver.cpp:240] Iteration 20000, loss = 0.0527551
I0110 03:27:30.679155  4932 solver.cpp:255]     Train net output #0: loss = 0.0328608 (* 1 = 0.0328608 loss)
I0110 03:27:30.679163  4932 solver.cpp:565] MultiStep Status: Iteration 20000, step = 2
I0110 03:27:30.703071  4932 solver.cpp:631] Iteration 20000, lr = 1e-06
I0110 03:27:33.237052  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3417 > 20) by scale factor 0.937133
I0110 03:27:42.121876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0332 > 20) by scale factor 0.73983
I0110 03:27:46.563805  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6234 > 20) by scale factor 0.675142
I0110 03:28:15.087102  4932 solver.cpp:240] Iteration 20020, loss = 0.105938
I0110 03:28:15.087199  4932 solver.cpp:255]     Train net output #0: loss = 0.178448 (* 1 = 0.178448 loss)
I0110 03:28:15.087214  4932 solver.cpp:631] Iteration 20020, lr = 1e-06
I0110 03:28:15.426601  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3064 > 20) by scale factor 0.822827
I0110 03:28:26.525705  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8196 > 20) by scale factor 0.774605
I0110 03:28:50.954326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.432 > 20) by scale factor 0.978858
I0110 03:28:55.396045  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3483 > 20) by scale factor 0.789009
I0110 03:28:59.497450  4932 solver.cpp:240] Iteration 20040, loss = 0.0769279
I0110 03:28:59.497494  4932 solver.cpp:255]     Train net output #0: loss = 0.128606 (* 1 = 0.128606 loss)
I0110 03:28:59.497505  4932 solver.cpp:631] Iteration 20040, lr = 1e-06
I0110 03:29:37.582504  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8071 > 20) by scale factor 0.719242
I0110 03:29:43.902681  4932 solver.cpp:240] Iteration 20060, loss = 0.0485375
I0110 03:29:43.902719  4932 solver.cpp:255]     Train net output #0: loss = 0.00789369 (* 1 = 0.00789369 loss)
I0110 03:29:43.902729  4932 solver.cpp:631] Iteration 20060, lr = 1e-06
I0110 03:29:50.898025  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3224 > 20) by scale factor 0.984138
I0110 03:29:57.560129  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7741 > 20) by scale factor 0.878189
I0110 03:29:59.782269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3176 > 20) by scale factor 0.93819
I0110 03:30:24.200368  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.108 > 20) by scale factor 0.829602
I0110 03:30:28.302603  4932 solver.cpp:240] Iteration 20080, loss = 0.0756197
I0110 03:30:28.302639  4932 solver.cpp:255]     Train net output #0: loss = 0.0649926 (* 1 = 0.0649926 loss)
I0110 03:30:28.302649  4932 solver.cpp:631] Iteration 20080, lr = 1e-06
I0110 03:30:57.501765  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7211 > 20) by scale factor 0.9652
I0110 03:31:08.603857  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.061 > 20) by scale factor 0.767429
I0110 03:31:12.704093  4932 solver.cpp:240] Iteration 20100, loss = 0.0670184
I0110 03:31:12.704144  4932 solver.cpp:255]     Train net output #0: loss = 0.0012583 (* 1 = 0.0012583 loss)
I0110 03:31:12.704155  4932 solver.cpp:631] Iteration 20100, lr = 1e-06
I0110 03:31:57.106406  4932 solver.cpp:240] Iteration 20120, loss = 0.0512669
I0110 03:31:57.106482  4932 solver.cpp:255]     Train net output #0: loss = 0.023983 (* 1 = 0.023983 loss)
I0110 03:31:57.106492  4932 solver.cpp:631] Iteration 20120, lr = 1e-06
I0110 03:31:59.664851  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0201 > 20) by scale factor 0.95147
I0110 03:32:06.329121  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7936 > 20) by scale factor 0.961833
I0110 03:32:41.506366  4932 solver.cpp:240] Iteration 20140, loss = 0.06083
I0110 03:32:41.506448  4932 solver.cpp:255]     Train net output #0: loss = 0.044123 (* 1 = 0.044123 loss)
I0110 03:32:41.506460  4932 solver.cpp:631] Iteration 20140, lr = 1e-06
I0110 03:32:44.066879  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.3104 > 20) by scale factor 0.618996
I0110 03:33:13.136544  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.691 > 20) by scale factor 0.881408
I0110 03:33:26.117127  4932 solver.cpp:240] Iteration 20160, loss = 0.0920701
I0110 03:33:26.117167  4932 solver.cpp:255]     Train net output #0: loss = 0.0176846 (* 1 = 0.0176846 loss)
I0110 03:33:26.117177  4932 solver.cpp:631] Iteration 20160, lr = 1e-06
I0110 03:33:28.675932  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4357 > 20) by scale factor 0.978678
I0110 03:33:41.994946  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8365 > 20) by scale factor 0.693565
I0110 03:34:10.503254  4932 solver.cpp:240] Iteration 20180, loss = 0.0869545
I0110 03:34:10.503355  4932 solver.cpp:255]     Train net output #0: loss = 0.0265669 (* 1 = 0.0265669 loss)
I0110 03:34:10.503366  4932 solver.cpp:631] Iteration 20180, lr = 1e-06
I0110 03:34:53.008015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8789 > 20) by scale factor 0.837561
I0110 03:34:54.890977  4932 solver.cpp:240] Iteration 20200, loss = 0.0596292
I0110 03:34:54.891022  4932 solver.cpp:255]     Train net output #0: loss = 0.071671 (* 1 = 0.071671 loss)
I0110 03:34:54.891033  4932 solver.cpp:631] Iteration 20200, lr = 1e-06
I0110 03:34:57.450908  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1027 > 20) by scale factor 0.994893
I0110 03:35:12.997831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.69 > 20) by scale factor 0.966651
I0110 03:35:24.102123  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9366 > 20) by scale factor 0.955267
I0110 03:35:32.986702  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0328 > 20) by scale factor 0.950896
I0110 03:35:39.311144  4932 solver.cpp:240] Iteration 20220, loss = 0.0773775
I0110 03:35:39.311182  4932 solver.cpp:255]     Train net output #0: loss = 0.134793 (* 1 = 0.134793 loss)
I0110 03:35:39.311193  4932 solver.cpp:631] Iteration 20220, lr = 1e-06
I0110 03:35:57.410037  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5716 > 20) by scale factor 0.886068
I0110 03:36:23.698894  4932 solver.cpp:240] Iteration 20240, loss = 0.0743063
I0110 03:36:23.698931  4932 solver.cpp:255]     Train net output #0: loss = 0.111375 (* 1 = 0.111375 loss)
I0110 03:36:23.698940  4932 solver.cpp:631] Iteration 20240, lr = 1e-06
I0110 03:36:30.696750  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.11 > 20) by scale factor 0.865426
I0110 03:36:41.790895  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.809 > 20) by scale factor 0.806159
I0110 03:37:08.081339  4932 solver.cpp:240] Iteration 20260, loss = 0.0855351
I0110 03:37:08.081409  4932 solver.cpp:255]     Train net output #0: loss = 0.116238 (* 1 = 0.116238 loss)
I0110 03:37:08.081418  4932 solver.cpp:631] Iteration 20260, lr = 1e-06
I0110 03:37:32.827625  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7853 > 20) by scale factor 0.806929
I0110 03:37:41.707576  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8629 > 20) by scale factor 0.773309
I0110 03:37:52.465256  4932 solver.cpp:240] Iteration 20280, loss = 0.0815484
I0110 03:37:52.465296  4932 solver.cpp:255]     Train net output #0: loss = 0.183794 (* 1 = 0.183794 loss)
I0110 03:37:52.465306  4932 solver.cpp:631] Iteration 20280, lr = 1e-06
I0110 03:37:52.804368  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5376 > 20) by scale factor 0.815077
I0110 03:37:59.467581  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.43 > 20) by scale factor 0.978954
I0110 03:38:36.854113  4932 solver.cpp:240] Iteration 20300, loss = 0.0410819
I0110 03:38:36.854187  4932 solver.cpp:255]     Train net output #0: loss = 0.0653335 (* 1 = 0.0653335 loss)
I0110 03:38:36.854197  4932 solver.cpp:631] Iteration 20300, lr = 1e-06
I0110 03:38:39.410821  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7981 > 20) by scale factor 0.961627
I0110 03:39:01.603833  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9928 > 20) by scale factor 0.666826
I0110 03:39:08.261868  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5445 > 20) by scale factor 0.849457
I0110 03:39:21.241487  4932 solver.cpp:240] Iteration 20320, loss = 0.0576512
I0110 03:39:21.241529  4932 solver.cpp:255]     Train net output #0: loss = 0.0101537 (* 1 = 0.0101537 loss)
I0110 03:39:21.241654  4932 solver.cpp:631] Iteration 20320, lr = 1e-06
I0110 03:39:35.026788  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9015 > 20) by scale factor 0.836767
I0110 03:39:52.777303  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4785 > 20) by scale factor 0.817044
I0110 03:39:59.438634  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8587 > 20) by scale factor 0.838269
I0110 03:40:05.759495  4932 solver.cpp:240] Iteration 20340, loss = 0.0844446
I0110 03:40:05.759536  4932 solver.cpp:255]     Train net output #0: loss = 0.071472 (* 1 = 0.071472 loss)
I0110 03:40:05.759544  4932 solver.cpp:631] Iteration 20340, lr = 1e-06
I0110 03:40:12.753556  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9799 > 20) by scale factor 0.909921
I0110 03:40:46.054103  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3706 > 20) by scale factor 0.935867
I0110 03:40:50.155874  4932 solver.cpp:240] Iteration 20360, loss = 0.0623848
I0110 03:40:50.155918  4932 solver.cpp:255]     Train net output #0: loss = 0.0528991 (* 1 = 0.0528991 loss)
I0110 03:40:50.155930  4932 solver.cpp:631] Iteration 20360, lr = 1e-06
I0110 03:41:08.259418  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7662 > 20) by scale factor 0.695261
I0110 03:41:28.249382  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7434 > 20) by scale factor 0.964163
I0110 03:41:34.572572  4932 solver.cpp:240] Iteration 20380, loss = 0.0895314
I0110 03:41:34.572615  4932 solver.cpp:255]     Train net output #0: loss = 0.502571 (* 1 = 0.502571 loss)
I0110 03:41:34.572628  4932 solver.cpp:631] Iteration 20380, lr = 1e-06
I0110 03:41:34.912972  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8337 > 20) by scale factor 0.745331
I0110 03:42:18.987089  4932 solver.cpp:240] Iteration 20400, loss = 0.0502823
I0110 03:42:18.987201  4932 solver.cpp:255]     Train net output #0: loss = 0.172683 (* 1 = 0.172683 loss)
I0110 03:42:18.987216  4932 solver.cpp:631] Iteration 20400, lr = 1e-06
I0110 03:42:19.327507  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4728 > 20) by scale factor 0.931413
I0110 03:43:03.367027  4932 solver.cpp:240] Iteration 20420, loss = 0.0254944
I0110 03:43:03.367110  4932 solver.cpp:255]     Train net output #0: loss = 0.00268346 (* 1 = 0.00268346 loss)
I0110 03:43:03.367121  4932 solver.cpp:631] Iteration 20420, lr = 1e-06
I0110 03:43:47.738754  4932 solver.cpp:240] Iteration 20440, loss = 0.0950995
I0110 03:43:47.738836  4932 solver.cpp:255]     Train net output #0: loss = 0.308148 (* 1 = 0.308148 loss)
I0110 03:43:47.738847  4932 solver.cpp:631] Iteration 20440, lr = 1e-06
I0110 03:43:48.078976  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.455 > 20) by scale factor 0.852698
I0110 03:44:12.488479  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.573 > 20) by scale factor 0.699962
I0110 03:44:32.127331  4932 solver.cpp:240] Iteration 20460, loss = 0.0655807
I0110 03:44:32.127426  4932 solver.cpp:255]     Train net output #0: loss = 0.00488222 (* 1 = 0.00488222 loss)
I0110 03:44:32.127439  4932 solver.cpp:631] Iteration 20460, lr = 1e-06
I0110 03:44:50.218585  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4195 > 20) by scale factor 0.853989
I0110 03:44:56.880473  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5367 > 20) by scale factor 0.88744
I0110 03:45:16.510493  4932 solver.cpp:240] Iteration 20480, loss = 0.0577047
I0110 03:45:16.510571  4932 solver.cpp:255]     Train net output #0: loss = 0.00260652 (* 1 = 0.00260652 loss)
I0110 03:45:16.510581  4932 solver.cpp:631] Iteration 20480, lr = 1e-06
I0110 03:46:00.888695  4932 solver.cpp:240] Iteration 20500, loss = 0.0564325
I0110 03:46:00.888800  4932 solver.cpp:255]     Train net output #0: loss = 0.170168 (* 1 = 0.170168 loss)
I0110 03:46:00.888818  4932 solver.cpp:631] Iteration 20500, lr = 1e-06
I0110 03:46:41.177968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4886 > 20) by scale factor 0.889338
I0110 03:46:45.275104  4932 solver.cpp:240] Iteration 20520, loss = 0.0815924
I0110 03:46:45.275142  4932 solver.cpp:255]     Train net output #0: loss = 0.409467 (* 1 = 0.409467 loss)
I0110 03:46:45.275151  4932 solver.cpp:631] Iteration 20520, lr = 1e-06
I0110 03:46:45.614428  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.5303 > 20) by scale factor 0.655087
I0110 03:47:29.663801  4932 solver.cpp:240] Iteration 20540, loss = 0.0912084
I0110 03:47:29.663861  4932 solver.cpp:255]     Train net output #0: loss = 0.0444851 (* 1 = 0.0444851 loss)
I0110 03:47:29.663869  4932 solver.cpp:631] Iteration 20540, lr = 1e-06
I0110 03:47:52.195358  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7496 > 20) by scale factor 0.919557
I0110 03:48:14.047863  4932 solver.cpp:240] Iteration 20560, loss = 0.0442324
I0110 03:48:14.047938  4932 solver.cpp:255]     Train net output #0: loss = 0.0124054 (* 1 = 0.0124054 loss)
I0110 03:48:14.047948  4932 solver.cpp:631] Iteration 20560, lr = 1e-06
I0110 03:48:58.424917  4932 solver.cpp:240] Iteration 20580, loss = 0.0405954
I0110 03:48:58.425004  4932 solver.cpp:255]     Train net output #0: loss = 0.00803704 (* 1 = 0.00803704 loss)
I0110 03:48:58.425015  4932 solver.cpp:631] Iteration 20580, lr = 1e-06
I0110 03:49:00.984165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5656 > 20) by scale factor 0.886305
I0110 03:49:42.805811  4932 solver.cpp:240] Iteration 20600, loss = 0.0795121
I0110 03:49:42.805891  4932 solver.cpp:255]     Train net output #0: loss = 0.0195495 (* 1 = 0.0195495 loss)
I0110 03:49:42.805902  4932 solver.cpp:631] Iteration 20600, lr = 1e-06
I0110 03:49:47.582018  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9182 > 20) by scale factor 0.836183
I0110 03:49:54.243145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0217 > 20) by scale factor 0.998914
I0110 03:50:27.208287  4932 solver.cpp:240] Iteration 20620, loss = 0.0673457
I0110 03:50:27.208384  4932 solver.cpp:255]     Train net output #0: loss = 0.0334757 (* 1 = 0.0334757 loss)
I0110 03:50:27.208396  4932 solver.cpp:631] Iteration 20620, lr = 1e-06
I0110 03:50:49.743670  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2175 > 20) by scale factor 0.793099
I0110 03:51:11.605448  4932 solver.cpp:240] Iteration 20640, loss = 0.0520224
I0110 03:51:11.605536  4932 solver.cpp:255]     Train net output #0: loss = 0.195876 (* 1 = 0.195876 loss)
I0110 03:51:11.605548  4932 solver.cpp:631] Iteration 20640, lr = 1e-06
I0110 03:51:55.986938  4932 solver.cpp:240] Iteration 20660, loss = 0.0696035
I0110 03:51:55.987023  4932 solver.cpp:255]     Train net output #0: loss = 0.00029091 (* 1 = 0.00029091 loss)
I0110 03:51:55.987035  4932 solver.cpp:631] Iteration 20660, lr = 1e-06
I0110 03:52:40.364662  4932 solver.cpp:240] Iteration 20680, loss = 0.0782098
I0110 03:52:40.364778  4932 solver.cpp:255]     Train net output #0: loss = 0.319356 (* 1 = 0.319356 loss)
I0110 03:52:40.364795  4932 solver.cpp:631] Iteration 20680, lr = 1e-06
I0110 03:52:40.705754  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5207 > 20) by scale factor 0.850316
I0110 03:52:42.929668  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1616 > 20) by scale factor 0.94511
I0110 03:52:51.810559  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1982 > 20) by scale factor 0.735341
I0110 03:53:18.443408  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.443 > 20) by scale factor 0.728784
I0110 03:53:24.762501  4932 solver.cpp:240] Iteration 20700, loss = 0.0731628
I0110 03:53:24.762540  4932 solver.cpp:255]     Train net output #0: loss = 0.072602 (* 1 = 0.072602 loss)
I0110 03:53:24.762548  4932 solver.cpp:631] Iteration 20700, lr = 1e-06
I0110 03:53:49.524799  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5669 > 20) by scale factor 0.972435
I0110 03:54:09.154829  4932 solver.cpp:240] Iteration 20720, loss = 0.06945
I0110 03:54:09.154872  4932 solver.cpp:255]     Train net output #0: loss = 0.177911 (* 1 = 0.177911 loss)
I0110 03:54:09.154990  4932 solver.cpp:631] Iteration 20720, lr = 1e-06
I0110 03:54:29.471184  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3369 > 20) by scale factor 0.857012
I0110 03:54:31.693043  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4838 > 20) by scale factor 0.930934
I0110 03:54:53.551473  4932 solver.cpp:240] Iteration 20740, loss = 0.104932
I0110 03:54:53.551511  4932 solver.cpp:255]     Train net output #0: loss = 0.291068 (* 1 = 0.291068 loss)
I0110 03:54:53.551519  4932 solver.cpp:631] Iteration 20740, lr = 1e-06
I0110 03:55:29.414363  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2651 > 20) by scale factor 0.791605
I0110 03:55:37.955385  4932 solver.cpp:240] Iteration 20760, loss = 0.0575664
I0110 03:55:37.955428  4932 solver.cpp:255]     Train net output #0: loss = 0.00480148 (* 1 = 0.00480148 loss)
I0110 03:55:37.955440  4932 solver.cpp:631] Iteration 20760, lr = 1e-06
I0110 03:55:42.736129  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8289 > 20) by scale factor 0.876081
I0110 03:56:09.372123  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9385 > 20) by scale factor 0.668036
I0110 03:56:22.351955  4932 solver.cpp:240] Iteration 20780, loss = 0.0870688
I0110 03:56:22.351991  4932 solver.cpp:255]     Train net output #0: loss = 0.0667044 (* 1 = 0.0667044 loss)
I0110 03:56:22.352000  4932 solver.cpp:631] Iteration 20780, lr = 1e-06
I0110 03:57:06.748550  4932 solver.cpp:240] Iteration 20800, loss = 0.0492788
I0110 03:57:06.748631  4932 solver.cpp:255]     Train net output #0: loss = 0.00574456 (* 1 = 0.00574456 loss)
I0110 03:57:06.748641  4932 solver.cpp:631] Iteration 20800, lr = 1e-06
I0110 03:57:42.601200  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3467 > 20) by scale factor 0.936913
I0110 03:57:51.143594  4932 solver.cpp:240] Iteration 20820, loss = 0.063328
I0110 03:57:51.143636  4932 solver.cpp:255]     Train net output #0: loss = 0.00311433 (* 1 = 0.00311433 loss)
I0110 03:57:51.143647  4932 solver.cpp:631] Iteration 20820, lr = 1e-06
I0110 03:58:04.803287  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2893 > 20) by scale factor 0.732887
I0110 03:58:11.464704  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2257 > 20) by scale factor 0.899859
I0110 03:58:33.661056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0394 > 20) by scale factor 0.998036
I0110 03:58:35.543164  4932 solver.cpp:240] Iteration 20840, loss = 0.0795077
I0110 03:58:35.543202  4932 solver.cpp:255]     Train net output #0: loss = 0.000846024 (* 1 = 0.000846024 loss)
I0110 03:58:35.543211  4932 solver.cpp:631] Iteration 20840, lr = 1e-06
I0110 03:58:53.638757  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1525 > 20) by scale factor 0.99243
I0110 03:59:19.935433  4932 solver.cpp:240] Iteration 20860, loss = 0.0639138
I0110 03:59:19.935525  4932 solver.cpp:255]     Train net output #0: loss = 0.0106237 (* 1 = 0.0106237 loss)
I0110 03:59:19.935542  4932 solver.cpp:631] Iteration 20860, lr = 1e-06
I0110 03:59:26.935430  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6805 > 20) by scale factor 0.844578
I0110 03:59:35.814378  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9854 > 20) by scale factor 0.909695
I0110 03:59:53.576562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.914 > 20) by scale factor 0.771783
I0110 04:00:04.332695  4932 solver.cpp:240] Iteration 20880, loss = 0.0800603
I0110 04:00:04.332728  4932 solver.cpp:255]     Train net output #0: loss = 0.0173724 (* 1 = 0.0173724 loss)
I0110 04:00:04.332743  4932 solver.cpp:631] Iteration 20880, lr = 1e-06
I0110 04:00:37.963450  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9412 > 20) by scale factor 0.801888
I0110 04:00:48.719036  4932 solver.cpp:240] Iteration 20900, loss = 0.0535052
I0110 04:00:48.719074  4932 solver.cpp:255]     Train net output #0: loss = 0.00984686 (* 1 = 0.00984686 loss)
I0110 04:00:48.719084  4932 solver.cpp:631] Iteration 20900, lr = 1e-06
I0110 04:01:33.110877  4932 solver.cpp:240] Iteration 20920, loss = 0.0403298
I0110 04:01:33.110954  4932 solver.cpp:255]     Train net output #0: loss = 0.0159833 (* 1 = 0.0159833 loss)
I0110 04:01:33.110963  4932 solver.cpp:631] Iteration 20920, lr = 1e-06
I0110 04:02:17.506361  4932 solver.cpp:240] Iteration 20940, loss = 0.0425478
I0110 04:02:17.506444  4932 solver.cpp:255]     Train net output #0: loss = 0.0391425 (* 1 = 0.0391425 loss)
I0110 04:02:17.506458  4932 solver.cpp:631] Iteration 20940, lr = 1e-06
I0110 04:02:33.388312  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0688 > 20) by scale factor 0.866974
I0110 04:02:42.267520  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8471 > 20) by scale factor 0.959366
I0110 04:02:57.809272  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7367 > 20) by scale factor 0.808517
I0110 04:03:01.910336  4932 solver.cpp:240] Iteration 20960, loss = 0.0906857
I0110 04:03:01.910368  4932 solver.cpp:255]     Train net output #0: loss = 0.187916 (* 1 = 0.187916 loss)
I0110 04:03:01.910377  4932 solver.cpp:631] Iteration 20960, lr = 1e-06
I0110 04:03:11.123950  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.195 > 20) by scale factor 0.901102
I0110 04:03:46.307292  4932 solver.cpp:240] Iteration 20980, loss = 0.0499588
I0110 04:03:46.307374  4932 solver.cpp:255]     Train net output #0: loss = 0.0445223 (* 1 = 0.0445223 loss)
I0110 04:03:46.307384  4932 solver.cpp:631] Iteration 20980, lr = 1e-06
I0110 04:03:57.744949  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8769 > 20) by scale factor 0.874244
I0110 04:04:15.499498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8166 > 20) by scale factor 0.876556
I0110 04:04:28.829695  4932 solver.cpp:424] Iteration 21000, Testing net (#0)
I0110 04:05:17.680269  4932 solver.cpp:481]     Test net output #0: accuracy = 0.821053
I0110 04:05:17.680359  4932 solver.cpp:481]     Test net output #1: loss = 0.932004 (* 1 = 0.932004 loss)
I0110 04:05:19.545446  4932 solver.cpp:240] Iteration 21000, loss = 0.0512055
I0110 04:05:19.545485  4932 solver.cpp:255]     Train net output #0: loss = 0.0139457 (* 1 = 0.0139457 loss)
I0110 04:05:19.545493  4932 solver.cpp:631] Iteration 21000, lr = 1e-06
I0110 04:05:53.160619  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4455 > 20) by scale factor 0.891046
I0110 04:05:59.820405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3035 > 20) by scale factor 0.706625
I0110 04:06:03.919670  4932 solver.cpp:240] Iteration 21020, loss = 0.102028
I0110 04:06:03.919710  4932 solver.cpp:255]     Train net output #0: loss = 0.0960716 (* 1 = 0.0960716 loss)
I0110 04:06:03.919720  4932 solver.cpp:631] Iteration 21020, lr = 1e-06
I0110 04:06:28.666210  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1466 > 20) by scale factor 0.992725
I0110 04:06:30.889822  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3705 > 20) by scale factor 0.758425
I0110 04:06:48.302973  4932 solver.cpp:240] Iteration 21040, loss = 0.0728173
I0110 04:06:48.303012  4932 solver.cpp:255]     Train net output #0: loss = 0.00766395 (* 1 = 0.00766395 loss)
I0110 04:06:48.303021  4932 solver.cpp:631] Iteration 21040, lr = 1e-06
I0110 04:07:30.814174  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4863 > 20) by scale factor 0.97626
I0110 04:07:32.696792  4932 solver.cpp:240] Iteration 21060, loss = 0.0639756
I0110 04:07:32.696825  4932 solver.cpp:255]     Train net output #0: loss = 0.0941445 (* 1 = 0.0941445 loss)
I0110 04:07:32.696832  4932 solver.cpp:631] Iteration 21060, lr = 1e-06
I0110 04:07:44.133793  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5367 > 20) by scale factor 0.849735
I0110 04:07:46.354720  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9496 > 20) by scale factor 0.835088
I0110 04:08:17.084086  4932 solver.cpp:240] Iteration 21080, loss = 0.0949322
I0110 04:08:17.084189  4932 solver.cpp:255]     Train net output #0: loss = 0.00738892 (* 1 = 0.00738892 loss)
I0110 04:08:17.084203  4932 solver.cpp:631] Iteration 21080, lr = 1e-06
I0110 04:08:52.923360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9373 > 20) by scale factor 0.955231
I0110 04:08:59.580711  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6847 > 20) by scale factor 0.966898
I0110 04:09:01.462400  4932 solver.cpp:240] Iteration 21100, loss = 0.0934684
I0110 04:09:01.462438  4932 solver.cpp:255]     Train net output #0: loss = 0.0196361 (* 1 = 0.0196361 loss)
I0110 04:09:01.462446  4932 solver.cpp:631] Iteration 21100, lr = 1e-06
I0110 04:09:39.521101  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3646 > 20) by scale factor 0.936129
I0110 04:09:45.838521  4932 solver.cpp:240] Iteration 21120, loss = 0.0455099
I0110 04:09:45.838559  4932 solver.cpp:255]     Train net output #0: loss = 0.111691 (* 1 = 0.111691 loss)
I0110 04:09:45.838568  4932 solver.cpp:631] Iteration 21120, lr = 1e-06
I0110 04:10:06.143678  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6891 > 20) by scale factor 0.966693
I0110 04:10:17.241176  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5635 > 20) by scale factor 0.972599
I0110 04:10:30.218986  4932 solver.cpp:240] Iteration 21140, loss = 0.0768009
I0110 04:10:30.219029  4932 solver.cpp:255]     Train net output #0: loss = 0.0249329 (* 1 = 0.0249329 loss)
I0110 04:10:30.219045  4932 solver.cpp:631] Iteration 21140, lr = 1e-06
I0110 04:11:14.591415  4932 solver.cpp:240] Iteration 21160, loss = 0.0503647
I0110 04:11:14.591495  4932 solver.cpp:255]     Train net output #0: loss = 0.0199372 (* 1 = 0.0199372 loss)
I0110 04:11:14.591506  4932 solver.cpp:631] Iteration 21160, lr = 1e-06
I0110 04:11:58.971380  4932 solver.cpp:240] Iteration 21180, loss = 0.0655592
I0110 04:11:58.971459  4932 solver.cpp:255]     Train net output #0: loss = 0.0101089 (* 1 = 0.0101089 loss)
I0110 04:11:58.971469  4932 solver.cpp:631] Iteration 21180, lr = 1e-06
I0110 04:12:17.061626  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2365 > 20) by scale factor 0.988312
I0110 04:12:43.360009  4932 solver.cpp:240] Iteration 21200, loss = 0.0506899
I0110 04:12:43.360085  4932 solver.cpp:255]     Train net output #0: loss = 0.00412214 (* 1 = 0.00412214 loss)
I0110 04:12:43.360096  4932 solver.cpp:631] Iteration 21200, lr = 1e-06
I0110 04:13:27.739543  4932 solver.cpp:240] Iteration 21220, loss = 0.0396181
I0110 04:13:27.739634  4932 solver.cpp:255]     Train net output #0: loss = 0.00764526 (* 1 = 0.00764526 loss)
I0110 04:13:27.739646  4932 solver.cpp:631] Iteration 21220, lr = 1e-06
I0110 04:14:08.018692  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4881 > 20) by scale factor 0.930749
I0110 04:14:12.119047  4932 solver.cpp:240] Iteration 21240, loss = 0.0822085
I0110 04:14:12.119087  4932 solver.cpp:255]     Train net output #0: loss = 0.000558873 (* 1 = 0.000558873 loss)
I0110 04:14:12.119097  4932 solver.cpp:631] Iteration 21240, lr = 1e-06
I0110 04:14:39.087815  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.582 > 20) by scale factor 0.813602
I0110 04:14:45.745229  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9299 > 20) by scale factor 0.955569
I0110 04:14:56.503643  4932 solver.cpp:240] Iteration 21260, loss = 0.107363
I0110 04:14:56.503690  4932 solver.cpp:255]     Train net output #0: loss = 0.331372 (* 1 = 0.331372 loss)
I0110 04:14:56.503700  4932 solver.cpp:631] Iteration 21260, lr = 1e-06
I0110 04:14:56.842813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9154 > 20) by scale factor 0.956232
I0110 04:15:40.877884  4932 solver.cpp:240] Iteration 21280, loss = 0.0372953
I0110 04:15:40.877980  4932 solver.cpp:255]     Train net output #0: loss = 0.0319977 (* 1 = 0.0319977 loss)
I0110 04:15:40.877991  4932 solver.cpp:631] Iteration 21280, lr = 1e-06
I0110 04:16:25.245615  4932 solver.cpp:240] Iteration 21300, loss = 0.0485035
I0110 04:16:25.245687  4932 solver.cpp:255]     Train net output #0: loss = 0.199421 (* 1 = 0.199421 loss)
I0110 04:16:25.245697  4932 solver.cpp:631] Iteration 21300, lr = 1e-06
I0110 04:16:41.119357  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5955 > 20) by scale factor 0.88513
I0110 04:17:09.629393  4932 solver.cpp:240] Iteration 21320, loss = 0.0563691
I0110 04:17:09.629462  4932 solver.cpp:255]     Train net output #0: loss = 0.0489709 (* 1 = 0.0489709 loss)
I0110 04:17:09.629472  4932 solver.cpp:631] Iteration 21320, lr = 1e-06
I0110 04:17:12.185722  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8102 > 20) by scale factor 0.694199
I0110 04:17:14.405752  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8037 > 20) by scale factor 0.719329
I0110 04:17:41.032209  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3759 > 20) by scale factor 0.73057
I0110 04:17:54.007450  4932 solver.cpp:240] Iteration 21340, loss = 0.104712
I0110 04:17:54.007490  4932 solver.cpp:255]     Train net output #0: loss = 0.250693 (* 1 = 0.250693 loss)
I0110 04:17:54.007500  4932 solver.cpp:631] Iteration 21340, lr = 1e-06
I0110 04:17:54.346681  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4834 > 20) by scale factor 0.889544
I0110 04:18:09.879626  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4247 > 20) by scale factor 0.979204
I0110 04:18:16.542059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1817 > 20) by scale factor 0.901646
I0110 04:18:38.386740  4932 solver.cpp:240] Iteration 21360, loss = 0.0572757
I0110 04:18:38.386783  4932 solver.cpp:255]     Train net output #0: loss = 0.043427 (* 1 = 0.043427 loss)
I0110 04:18:38.389930  4932 solver.cpp:631] Iteration 21360, lr = 1e-06
I0110 04:19:09.814812  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0567 > 20) by scale factor 0.997173
I0110 04:19:22.795215  4932 solver.cpp:240] Iteration 21380, loss = 0.0476667
I0110 04:19:22.795253  4932 solver.cpp:255]     Train net output #0: loss = 0.00344635 (* 1 = 0.00344635 loss)
I0110 04:19:22.795263  4932 solver.cpp:631] Iteration 21380, lr = 1e-06
I0110 04:20:07.198248  4932 solver.cpp:240] Iteration 21400, loss = 0.0531101
I0110 04:20:07.198331  4932 solver.cpp:255]     Train net output #0: loss = 0.00165867 (* 1 = 0.00165867 loss)
I0110 04:20:07.198343  4932 solver.cpp:631] Iteration 21400, lr = 1e-06
I0110 04:20:14.196076  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2747 > 20) by scale factor 0.986449
I0110 04:20:16.416775  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7678 > 20) by scale factor 0.918789
I0110 04:20:20.861591  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2242 > 20) by scale factor 0.942323
I0110 04:20:23.084535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.105 > 20) by scale factor 0.947644
I0110 04:20:43.063906  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0972 > 20) by scale factor 0.995163
I0110 04:20:47.504747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0051 > 20) by scale factor 0.999745
I0110 04:20:51.604794  4932 solver.cpp:240] Iteration 21420, loss = 0.108225
I0110 04:20:51.604836  4932 solver.cpp:255]     Train net output #0: loss = 0.130261 (* 1 = 0.130261 loss)
I0110 04:20:51.604846  4932 solver.cpp:631] Iteration 21420, lr = 1e-06
I0110 04:21:36.000032  4932 solver.cpp:240] Iteration 21440, loss = 0.0512313
I0110 04:21:36.000136  4932 solver.cpp:255]     Train net output #0: loss = 0.00539606 (* 1 = 0.00539606 loss)
I0110 04:21:36.000147  4932 solver.cpp:631] Iteration 21440, lr = 1e-06
I0110 04:22:20.389704  4932 solver.cpp:240] Iteration 21460, loss = 0.0401065
I0110 04:22:20.389801  4932 solver.cpp:255]     Train net output #0: loss = 0.00202947 (* 1 = 0.00202947 loss)
I0110 04:22:20.389813  4932 solver.cpp:631] Iteration 21460, lr = 1e-06
I0110 04:23:04.775166  4932 solver.cpp:240] Iteration 21480, loss = 0.0388944
I0110 04:23:04.775255  4932 solver.cpp:255]     Train net output #0: loss = 0.0851151 (* 1 = 0.0851151 loss)
I0110 04:23:04.775269  4932 solver.cpp:631] Iteration 21480, lr = 1e-06
I0110 04:23:22.878298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4738 > 20) by scale factor 0.931367
I0110 04:23:49.180385  4932 solver.cpp:240] Iteration 21500, loss = 0.0948175
I0110 04:23:49.180486  4932 solver.cpp:255]     Train net output #0: loss = 0.0445495 (* 1 = 0.0445495 loss)
I0110 04:23:49.180501  4932 solver.cpp:631] Iteration 21500, lr = 1e-06
I0110 04:24:16.153173  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0355 > 20) by scale factor 0.768183
I0110 04:24:33.574501  4932 solver.cpp:240] Iteration 21520, loss = 0.0786102
I0110 04:24:33.574584  4932 solver.cpp:255]     Train net output #0: loss = 0.0781329 (* 1 = 0.0781329 loss)
I0110 04:24:33.574595  4932 solver.cpp:631] Iteration 21520, lr = 1e-06
I0110 04:25:17.956004  4932 solver.cpp:240] Iteration 21540, loss = 0.074439
I0110 04:25:17.956085  4932 solver.cpp:255]     Train net output #0: loss = 0.0460918 (* 1 = 0.0460918 loss)
I0110 04:25:17.956097  4932 solver.cpp:631] Iteration 21540, lr = 1e-06
I0110 04:25:38.264277  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1812 > 20) by scale factor 0.709693
I0110 04:26:02.346058  4932 solver.cpp:240] Iteration 21560, loss = 0.0386024
I0110 04:26:02.346153  4932 solver.cpp:255]     Train net output #0: loss = 0.00119021 (* 1 = 0.00119021 loss)
I0110 04:26:02.346164  4932 solver.cpp:631] Iteration 21560, lr = 1e-06
I0110 04:26:35.974570  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4811 > 20) by scale factor 0.976511
I0110 04:26:44.848604  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5245 > 20) by scale factor 0.974444
I0110 04:26:46.729728  4932 solver.cpp:240] Iteration 21580, loss = 0.0651731
I0110 04:26:46.729775  4932 solver.cpp:255]     Train net output #0: loss = 0.0340055 (* 1 = 0.0340055 loss)
I0110 04:26:46.729786  4932 solver.cpp:631] Iteration 21580, lr = 1e-06
I0110 04:27:20.354496  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6226 > 20) by scale factor 0.724045
I0110 04:27:31.115001  4932 solver.cpp:240] Iteration 21600, loss = 0.0490259
I0110 04:27:31.115044  4932 solver.cpp:255]     Train net output #0: loss = 0.00271372 (* 1 = 0.00271372 loss)
I0110 04:27:31.115053  4932 solver.cpp:631] Iteration 21600, lr = 1e-06
I0110 04:28:15.518122  4932 solver.cpp:240] Iteration 21620, loss = 0.0636394
I0110 04:28:15.518216  4932 solver.cpp:255]     Train net output #0: loss = 0.146056 (* 1 = 0.146056 loss)
I0110 04:28:15.518229  4932 solver.cpp:631] Iteration 21620, lr = 1e-06
I0110 04:28:59.908112  4932 solver.cpp:240] Iteration 21640, loss = 0.057839
I0110 04:28:59.908195  4932 solver.cpp:255]     Train net output #0: loss = 0.219469 (* 1 = 0.219469 loss)
I0110 04:28:59.908207  4932 solver.cpp:631] Iteration 21640, lr = 1e-06
I0110 04:29:00.248633  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8275 > 20) by scale factor 0.876135
I0110 04:29:04.690202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9343 > 20) by scale factor 0.835619
I0110 04:29:09.128178  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.783 > 20) by scale factor 0.840936
I0110 04:29:44.302512  4932 solver.cpp:240] Iteration 21660, loss = 0.0673868
I0110 04:29:44.302606  4932 solver.cpp:255]     Train net output #0: loss = 0.0151174 (* 1 = 0.0151174 loss)
I0110 04:29:44.302616  4932 solver.cpp:631] Iteration 21660, lr = 1e-06
I0110 04:30:00.181221  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9909 > 20) by scale factor 0.952794
I0110 04:30:28.697383  4932 solver.cpp:240] Iteration 21680, loss = 0.0829938
I0110 04:30:28.697465  4932 solver.cpp:255]     Train net output #0: loss = 0.123799 (* 1 = 0.123799 loss)
I0110 04:30:28.697476  4932 solver.cpp:631] Iteration 21680, lr = 1e-06
I0110 04:31:13.085860  4932 solver.cpp:240] Iteration 21700, loss = 0.0318009
I0110 04:31:13.085929  4932 solver.cpp:255]     Train net output #0: loss = 0.0309456 (* 1 = 0.0309456 loss)
I0110 04:31:13.085939  4932 solver.cpp:631] Iteration 21700, lr = 1e-06
I0110 04:31:33.401373  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8993 > 20) by scale factor 0.873391
I0110 04:31:57.484060  4932 solver.cpp:240] Iteration 21720, loss = 0.0765404
I0110 04:31:57.484143  4932 solver.cpp:255]     Train net output #0: loss = 0.283845 (* 1 = 0.283845 loss)
I0110 04:31:57.484155  4932 solver.cpp:631] Iteration 21720, lr = 1e-06
I0110 04:32:22.229097  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.045 > 20) by scale factor 0.867868
I0110 04:32:35.548069  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.7385 > 20) by scale factor 0.630149
I0110 04:32:41.870908  4932 solver.cpp:240] Iteration 21740, loss = 0.0946001
I0110 04:32:41.870959  4932 solver.cpp:255]     Train net output #0: loss = 0.0240114 (* 1 = 0.0240114 loss)
I0110 04:32:41.870971  4932 solver.cpp:631] Iteration 21740, lr = 1e-06
I0110 04:33:19.945566  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1588 > 20) by scale factor 0.902577
I0110 04:33:26.264717  4932 solver.cpp:240] Iteration 21760, loss = 0.0817386
I0110 04:33:26.264750  4932 solver.cpp:255]     Train net output #0: loss = 0.288583 (* 1 = 0.288583 loss)
I0110 04:33:26.264760  4932 solver.cpp:631] Iteration 21760, lr = 1e-06
I0110 04:33:26.604266  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1673 > 20) by scale factor 0.944852
I0110 04:33:31.047449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6416 > 20) by scale factor 0.723547
I0110 04:34:02.112968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8916 > 20) by scale factor 0.873682
I0110 04:34:10.654422  4932 solver.cpp:240] Iteration 21780, loss = 0.0700058
I0110 04:34:10.654456  4932 solver.cpp:255]     Train net output #0: loss = 0.0178377 (* 1 = 0.0178377 loss)
I0110 04:34:10.654465  4932 solver.cpp:631] Iteration 21780, lr = 1e-06
I0110 04:34:15.429968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7596 > 20) by scale factor 0.841766
I0110 04:34:55.043920  4932 solver.cpp:240] Iteration 21800, loss = 0.0662385
I0110 04:34:55.044003  4932 solver.cpp:255]     Train net output #0: loss = 0.00389136 (* 1 = 0.00389136 loss)
I0110 04:34:55.044014  4932 solver.cpp:631] Iteration 21800, lr = 1e-06
I0110 04:35:04.263310  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8179 > 20) by scale factor 0.876506
I0110 04:35:08.706667  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9432 > 20) by scale factor 0.871716
I0110 04:35:37.562217  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9114 > 20) by scale factor 0.802845
I0110 04:35:39.443863  4932 solver.cpp:240] Iteration 21820, loss = 0.0817766
I0110 04:35:39.443913  4932 solver.cpp:255]     Train net output #0: loss = 0.129753 (* 1 = 0.129753 loss)
I0110 04:35:39.443925  4932 solver.cpp:631] Iteration 21820, lr = 1e-06
I0110 04:36:23.831871  4932 solver.cpp:240] Iteration 21840, loss = 0.0558206
I0110 04:36:23.831954  4932 solver.cpp:255]     Train net output #0: loss = 0.0622953 (* 1 = 0.0622953 loss)
I0110 04:36:23.831964  4932 solver.cpp:631] Iteration 21840, lr = 1e-06
I0110 04:36:24.171304  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5895 > 20) by scale factor 0.971371
I0110 04:36:57.467728  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0705 > 20) by scale factor 0.79775
I0110 04:37:08.232033  4932 solver.cpp:240] Iteration 21860, loss = 0.0486585
I0110 04:37:08.232072  4932 solver.cpp:255]     Train net output #0: loss = 0.00369603 (* 1 = 0.00369603 loss)
I0110 04:37:08.232082  4932 solver.cpp:631] Iteration 21860, lr = 1e-06
I0110 04:37:39.636360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.6512 > 20) by scale factor 0.612535
I0110 04:37:52.610430  4932 solver.cpp:240] Iteration 21880, loss = 0.071334
I0110 04:37:52.610467  4932 solver.cpp:255]     Train net output #0: loss = 0.138468 (* 1 = 0.138468 loss)
I0110 04:37:52.610476  4932 solver.cpp:631] Iteration 21880, lr = 1e-06
I0110 04:37:52.949347  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3461 > 20) by scale factor 0.982988
I0110 04:38:21.803164  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.496 > 20) by scale factor 0.9758
I0110 04:38:37.009246  4932 solver.cpp:240] Iteration 21900, loss = 0.0809399
I0110 04:38:37.009289  4932 solver.cpp:255]     Train net output #0: loss = 0.0023717 (* 1 = 0.0023717 loss)
I0110 04:38:37.009297  4932 solver.cpp:631] Iteration 21900, lr = 1e-06
I0110 04:38:41.792560  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4799 > 20) by scale factor 0.816997
I0110 04:39:08.422817  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.01 > 20) by scale factor 0.799679
I0110 04:39:21.406143  4932 solver.cpp:240] Iteration 21920, loss = 0.0805968
I0110 04:39:21.406185  4932 solver.cpp:255]     Train net output #0: loss = 0.0285465 (* 1 = 0.0285465 loss)
I0110 04:39:21.406194  4932 solver.cpp:631] Iteration 21920, lr = 1e-06
I0110 04:39:30.624095  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8494 > 20) by scale factor 0.773713
I0110 04:39:41.720990  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0993 > 20) by scale factor 0.905005
I0110 04:39:59.479558  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.015 > 20) by scale factor 0.908472
I0110 04:40:05.799865  4932 solver.cpp:240] Iteration 21940, loss = 0.0789403
I0110 04:40:05.799911  4932 solver.cpp:255]     Train net output #0: loss = 0.00919376 (* 1 = 0.00919376 loss)
I0110 04:40:05.799921  4932 solver.cpp:631] Iteration 21940, lr = 1e-06
I0110 04:40:35.002038  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3288 > 20) by scale factor 0.983824
I0110 04:40:50.197229  4932 solver.cpp:240] Iteration 21960, loss = 0.0675388
I0110 04:40:50.197268  4932 solver.cpp:255]     Train net output #0: loss = 0.0507754 (* 1 = 0.0507754 loss)
I0110 04:40:50.197278  4932 solver.cpp:631] Iteration 21960, lr = 1e-06
I0110 04:40:52.755831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1764 > 20) by scale factor 0.991256
I0110 04:40:59.413039  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9027 > 20) by scale factor 0.836726
I0110 04:41:34.590056  4932 solver.cpp:240] Iteration 21980, loss = 0.0900147
I0110 04:41:34.590119  4932 solver.cpp:255]     Train net output #0: loss = 0.132628 (* 1 = 0.132628 loss)
I0110 04:41:34.590128  4932 solver.cpp:631] Iteration 21980, lr = 1e-06
I0110 04:42:17.103829  4932 solver.cpp:424] Iteration 22000, Testing net (#0)
I0110 04:43:05.082056  4932 solver.cpp:481]     Test net output #0: accuracy = 0.846316
I0110 04:43:05.082149  4932 solver.cpp:481]     Test net output #1: loss = 0.759142 (* 1 = 0.759142 loss)
I0110 04:43:06.947976  4932 solver.cpp:240] Iteration 22000, loss = 0.0676811
I0110 04:43:06.948009  4932 solver.cpp:255]     Train net output #0: loss = 0.064448 (* 1 = 0.064448 loss)
I0110 04:43:06.948019  4932 solver.cpp:631] Iteration 22000, lr = 1e-06
I0110 04:43:20.602386  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0791 > 20) by scale factor 0.866585
I0110 04:43:25.040066  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1115 > 20) by scale factor 0.829478
I0110 04:43:47.230888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9669 > 20) by scale factor 0.910463
I0110 04:43:51.331552  4932 solver.cpp:240] Iteration 22020, loss = 0.094478
I0110 04:43:51.331584  4932 solver.cpp:255]     Train net output #0: loss = 0.0131423 (* 1 = 0.0131423 loss)
I0110 04:43:51.331593  4932 solver.cpp:631] Iteration 22020, lr = 1e-06
I0110 04:44:04.979914  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8656 > 20) by scale factor 0.91468
I0110 04:44:35.707530  4932 solver.cpp:240] Iteration 22040, loss = 0.0479541
I0110 04:44:35.707628  4932 solver.cpp:255]     Train net output #0: loss = 0.00440053 (* 1 = 0.00440053 loss)
I0110 04:44:35.707640  4932 solver.cpp:631] Iteration 22040, lr = 1e-06
I0110 04:45:20.084100  4932 solver.cpp:240] Iteration 22060, loss = 0.0459095
I0110 04:45:20.084189  4932 solver.cpp:255]     Train net output #0: loss = 0.00231095 (* 1 = 0.00231095 loss)
I0110 04:45:20.084200  4932 solver.cpp:631] Iteration 22060, lr = 1e-06
I0110 04:45:35.952383  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8413 > 20) by scale factor 0.875607
I0110 04:45:58.140700  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6527 > 20) by scale factor 0.968397
I0110 04:46:04.462898  4932 solver.cpp:240] Iteration 22080, loss = 0.0653944
I0110 04:46:04.462939  4932 solver.cpp:255]     Train net output #0: loss = 0.133187 (* 1 = 0.133187 loss)
I0110 04:46:04.462949  4932 solver.cpp:631] Iteration 22080, lr = 1e-06
I0110 04:46:40.294962  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3269 > 20) by scale factor 0.731879
I0110 04:46:48.832504  4932 solver.cpp:240] Iteration 22100, loss = 0.0631312
I0110 04:46:48.832551  4932 solver.cpp:255]     Train net output #0: loss = 0.244804 (* 1 = 0.244804 loss)
I0110 04:46:48.832561  4932 solver.cpp:631] Iteration 22100, lr = 1e-06
I0110 04:46:53.610796  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4805 > 20) by scale factor 0.889659
I0110 04:47:04.705291  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.2693 > 20) by scale factor 0.683309
I0110 04:47:33.217564  4932 solver.cpp:240] Iteration 22120, loss = 0.0472093
I0110 04:47:33.217638  4932 solver.cpp:255]     Train net output #0: loss = 0.00106285 (* 1 = 0.00106285 loss)
I0110 04:47:33.217648  4932 solver.cpp:631] Iteration 22120, lr = 1e-06
I0110 04:47:44.653486  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4219 > 20) by scale factor 0.8539
I0110 04:48:17.598780  4932 solver.cpp:240] Iteration 22140, loss = 0.0694374
I0110 04:48:17.598855  4932 solver.cpp:255]     Train net output #0: loss = 0.00248917 (* 1 = 0.00248917 loss)
I0110 04:48:17.598865  4932 solver.cpp:631] Iteration 22140, lr = 1e-06
I0110 04:48:35.683890  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5825 > 20) by scale factor 0.926678
I0110 04:48:53.438845  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1228 > 20) by scale factor 0.864948
I0110 04:49:01.971917  4932 solver.cpp:240] Iteration 22160, loss = 0.0755149
I0110 04:49:01.971951  4932 solver.cpp:255]     Train net output #0: loss = 0.0130618 (* 1 = 0.0130618 loss)
I0110 04:49:01.971961  4932 solver.cpp:631] Iteration 22160, lr = 1e-06
I0110 04:49:46.346105  4932 solver.cpp:240] Iteration 22180, loss = 0.0761292
I0110 04:49:46.346204  4932 solver.cpp:255]     Train net output #0: loss = 0.0219735 (* 1 = 0.0219735 loss)
I0110 04:49:46.346217  4932 solver.cpp:631] Iteration 22180, lr = 1e-06
I0110 04:50:13.311918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4141 > 20) by scale factor 0.892297
I0110 04:50:15.532526  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2352 > 20) by scale factor 0.825244
I0110 04:50:17.752670  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0414 > 20) by scale factor 0.768008
I0110 04:50:30.730945  4932 solver.cpp:240] Iteration 22200, loss = 0.0902158
I0110 04:50:30.730988  4932 solver.cpp:255]     Train net output #0: loss = 0.053662 (* 1 = 0.053662 loss)
I0110 04:50:30.730998  4932 solver.cpp:631] Iteration 22200, lr = 1e-06
I0110 04:51:15.119773  4932 solver.cpp:240] Iteration 22220, loss = 0.04345
I0110 04:51:15.119877  4932 solver.cpp:255]     Train net output #0: loss = 0.225335 (* 1 = 0.225335 loss)
I0110 04:51:15.119892  4932 solver.cpp:631] Iteration 22220, lr = 1e-06
I0110 04:51:42.080294  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6194 > 20) by scale factor 0.724128
I0110 04:51:44.300808  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2813 > 20) by scale factor 0.733102
I0110 04:51:59.500150  4932 solver.cpp:240] Iteration 22240, loss = 0.0652519
I0110 04:51:59.500221  4932 solver.cpp:255]     Train net output #0: loss = 0.00152042 (* 1 = 0.00152042 loss)
I0110 04:51:59.500229  4932 solver.cpp:631] Iteration 22240, lr = 1e-06
I0110 04:52:22.031091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3032 > 20) by scale factor 0.858251
I0110 04:52:26.470746  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.13 > 20) by scale factor 0.993543
I0110 04:52:43.883333  4932 solver.cpp:240] Iteration 22260, loss = 0.0750209
I0110 04:52:43.883405  4932 solver.cpp:255]     Train net output #0: loss = 0.00362975 (* 1 = 0.00362975 loss)
I0110 04:52:43.883415  4932 solver.cpp:631] Iteration 22260, lr = 1e-06
I0110 04:53:13.067864  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.887 > 20) by scale factor 0.772588
I0110 04:53:28.266633  4932 solver.cpp:240] Iteration 22280, loss = 0.0938986
I0110 04:53:28.266710  4932 solver.cpp:255]     Train net output #0: loss = 0.311589 (* 1 = 0.311589 loss)
I0110 04:53:28.266721  4932 solver.cpp:631] Iteration 22280, lr = 1e-06
I0110 04:54:12.651530  4932 solver.cpp:240] Iteration 22300, loss = 0.078603
I0110 04:54:12.651607  4932 solver.cpp:255]     Train net output #0: loss = 0.123281 (* 1 = 0.123281 loss)
I0110 04:54:12.651617  4932 solver.cpp:631] Iteration 22300, lr = 1e-06
I0110 04:54:15.209280  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3506 > 20) by scale factor 0.982772
I0110 04:54:32.965265  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5148 > 20) by scale factor 0.888306
I0110 04:54:57.047813  4932 solver.cpp:240] Iteration 22320, loss = 0.0589874
I0110 04:54:57.047897  4932 solver.cpp:255]     Train net output #0: loss = 0.00562987 (* 1 = 0.00562987 loss)
I0110 04:54:57.047909  4932 solver.cpp:631] Iteration 22320, lr = 1e-06
I0110 04:55:12.922787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.337 > 20) by scale factor 0.983428
I0110 04:55:41.427393  4932 solver.cpp:240] Iteration 22340, loss = 0.0807365
I0110 04:55:41.427466  4932 solver.cpp:255]     Train net output #0: loss = 0.0101915 (* 1 = 0.0101915 loss)
I0110 04:55:41.427476  4932 solver.cpp:631] Iteration 22340, lr = 1e-06
I0110 04:56:03.960822  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.438 > 20) by scale factor 0.891344
I0110 04:56:06.181648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9916 > 20) by scale factor 0.869882
I0110 04:56:25.813006  4932 solver.cpp:240] Iteration 22360, loss = 0.0796832
I0110 04:56:25.813098  4932 solver.cpp:255]     Train net output #0: loss = 0.0365673 (* 1 = 0.0365673 loss)
I0110 04:56:25.813112  4932 solver.cpp:631] Iteration 22360, lr = 1e-06
I0110 04:56:28.370059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8461 > 20) by scale factor 0.744988
I0110 04:56:55.006145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1407 > 20) by scale factor 0.828475
I0110 04:56:57.227788  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6641 > 20) by scale factor 0.882454
I0110 04:57:10.205235  4932 solver.cpp:240] Iteration 22380, loss = 0.0947679
I0110 04:57:10.205288  4932 solver.cpp:255]     Train net output #0: loss = 0.0119571 (* 1 = 0.0119571 loss)
I0110 04:57:10.205303  4932 solver.cpp:631] Iteration 22380, lr = 1e-06
I0110 04:57:54.609536  4932 solver.cpp:240] Iteration 22400, loss = 0.0449717
I0110 04:57:54.609618  4932 solver.cpp:255]     Train net output #0: loss = 0.0392726 (* 1 = 0.0392726 loss)
I0110 04:57:54.609628  4932 solver.cpp:631] Iteration 22400, lr = 1e-06
I0110 04:58:38.991989  4932 solver.cpp:240] Iteration 22420, loss = 0.0739131
I0110 04:58:38.992066  4932 solver.cpp:255]     Train net output #0: loss = 0.243011 (* 1 = 0.243011 loss)
I0110 04:58:38.992075  4932 solver.cpp:631] Iteration 22420, lr = 1e-06
I0110 04:58:45.988875  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9322 > 20) by scale factor 0.802176
I0110 04:58:52.647652  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8788 > 20) by scale factor 0.957909
I0110 04:58:54.868741  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6745 > 20) by scale factor 0.922745
I0110 04:59:23.375600  4932 solver.cpp:240] Iteration 22440, loss = 0.0932521
I0110 04:59:23.375682  4932 solver.cpp:255]     Train net output #0: loss = 0.00131961 (* 1 = 0.00131961 loss)
I0110 04:59:23.375692  4932 solver.cpp:631] Iteration 22440, lr = 1e-06
I0110 05:00:07.744921  4932 solver.cpp:240] Iteration 22460, loss = 0.0601395
I0110 05:00:07.745003  4932 solver.cpp:255]     Train net output #0: loss = 0.28999 (* 1 = 0.28999 loss)
I0110 05:00:07.745015  4932 solver.cpp:631] Iteration 22460, lr = 1e-06
I0110 05:00:52.127197  4932 solver.cpp:240] Iteration 22480, loss = 0.0326936
I0110 05:00:52.127270  4932 solver.cpp:255]     Train net output #0: loss = 0.0842496 (* 1 = 0.0842496 loss)
I0110 05:00:52.127280  4932 solver.cpp:631] Iteration 22480, lr = 1e-06
I0110 05:01:03.556368  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6475 > 20) by scale factor 0.96864
I0110 05:01:10.217056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5937 > 20) by scale factor 0.847684
I0110 05:01:36.503809  4932 solver.cpp:240] Iteration 22500, loss = 0.0660583
I0110 05:01:36.503901  4932 solver.cpp:255]     Train net output #0: loss = 0.0247543 (* 1 = 0.0247543 loss)
I0110 05:01:36.503913  4932 solver.cpp:631] Iteration 22500, lr = 1e-06
I0110 05:01:43.500994  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5757 > 20) by scale factor 0.885907
I0110 05:01:50.155761  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7522 > 20) by scale factor 0.919447
I0110 05:02:12.351531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4576 > 20) by scale factor 0.755928
I0110 05:02:20.893020  4932 solver.cpp:240] Iteration 22520, loss = 0.0881659
I0110 05:02:20.893060  4932 solver.cpp:255]     Train net output #0: loss = 0.208384 (* 1 = 0.208384 loss)
I0110 05:02:20.893075  4932 solver.cpp:631] Iteration 22520, lr = 1e-06
I0110 05:03:03.390223  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4464 > 20) by scale factor 0.978167
I0110 05:03:05.272796  4932 solver.cpp:240] Iteration 22540, loss = 0.0758143
I0110 05:03:05.272841  4932 solver.cpp:255]     Train net output #0: loss = 0.120615 (* 1 = 0.120615 loss)
I0110 05:03:05.272974  4932 solver.cpp:631] Iteration 22540, lr = 1e-06
I0110 05:03:05.612254  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3877 > 20) by scale factor 0.75793
I0110 05:03:14.545305  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5583 > 20) by scale factor 0.927715
I0110 05:03:49.717547  4932 solver.cpp:240] Iteration 22560, loss = 0.0381779
I0110 05:03:49.717650  4932 solver.cpp:255]     Train net output #0: loss = 0.00758812 (* 1 = 0.00758812 loss)
I0110 05:03:49.717663  4932 solver.cpp:631] Iteration 22560, lr = 1e-06
I0110 05:04:07.818655  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4586 > 20) by scale factor 0.78559
I0110 05:04:34.114454  4932 solver.cpp:240] Iteration 22580, loss = 0.0453273
I0110 05:04:34.114547  4932 solver.cpp:255]     Train net output #0: loss = 0.00528192 (* 1 = 0.00528192 loss)
I0110 05:04:34.114560  4932 solver.cpp:631] Iteration 22580, lr = 1e-06
I0110 05:04:49.993501  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.971 > 20) by scale factor 0.667312
I0110 05:05:18.499581  4932 solver.cpp:240] Iteration 22600, loss = 0.0644048
I0110 05:05:18.499675  4932 solver.cpp:255]     Train net output #0: loss = 0.209234 (* 1 = 0.209234 loss)
I0110 05:05:18.499686  4932 solver.cpp:631] Iteration 22600, lr = 1e-06
I0110 05:05:47.692831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9928 > 20) by scale factor 0.800231
I0110 05:05:49.913125  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8528 > 20) by scale factor 0.915214
I0110 05:06:02.887491  4932 solver.cpp:240] Iteration 22620, loss = 0.084096
I0110 05:06:02.887540  4932 solver.cpp:255]     Train net output #0: loss = 0.0298299 (* 1 = 0.0298299 loss)
I0110 05:06:02.887552  4932 solver.cpp:631] Iteration 22620, lr = 1e-06
I0110 05:06:05.447836  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.789 > 20) by scale factor 0.917894
I0110 05:06:36.527498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.173 > 20) by scale factor 0.9446
I0110 05:06:47.285639  4932 solver.cpp:240] Iteration 22640, loss = 0.0736014
I0110 05:06:47.285681  4932 solver.cpp:255]     Train net output #0: loss = 0.06671 (* 1 = 0.06671 loss)
I0110 05:06:47.285688  4932 solver.cpp:631] Iteration 22640, lr = 1e-06
I0110 05:07:31.665662  4932 solver.cpp:240] Iteration 22660, loss = 0.0368763
I0110 05:07:31.665742  4932 solver.cpp:255]     Train net output #0: loss = 0.00073656 (* 1 = 0.00073656 loss)
I0110 05:07:31.665752  4932 solver.cpp:631] Iteration 22660, lr = 1e-06
I0110 05:07:36.442157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5472 > 20) by scale factor 0.973369
I0110 05:07:51.974874  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.919 > 20) by scale factor 0.956068
I0110 05:07:54.193742  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9682 > 20) by scale factor 0.953823
I0110 05:08:16.053148  4932 solver.cpp:240] Iteration 22680, loss = 0.0962867
I0110 05:08:16.053239  4932 solver.cpp:255]     Train net output #0: loss = 0.00803928 (* 1 = 0.00803928 loss)
I0110 05:08:16.053253  4932 solver.cpp:631] Iteration 22680, lr = 1e-06
I0110 05:08:47.465271  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1239 > 20) by scale factor 0.993845
I0110 05:08:49.687217  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2434 > 20) by scale factor 0.987978
I0110 05:09:00.447813  4932 solver.cpp:240] Iteration 22700, loss = 0.0622258
I0110 05:09:00.447844  4932 solver.cpp:255]     Train net output #0: loss = 0.181033 (* 1 = 0.181033 loss)
I0110 05:09:00.447851  4932 solver.cpp:631] Iteration 22700, lr = 1e-06
I0110 05:09:11.881234  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.1818 > 20) by scale factor 0.602739
I0110 05:09:20.766865  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0546 > 20) by scale factor 0.83144
I0110 05:09:27.428406  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4422 > 20) by scale factor 0.97837
I0110 05:09:44.839853  4932 solver.cpp:240] Iteration 22720, loss = 0.101879
I0110 05:09:44.839885  4932 solver.cpp:255]     Train net output #0: loss = 0.171326 (* 1 = 0.171326 loss)
I0110 05:09:44.839895  4932 solver.cpp:631] Iteration 22720, lr = 1e-06
I0110 05:09:56.279769  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3753 > 20) by scale factor 0.893843
I0110 05:10:02.938539  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3332 > 20) by scale factor 0.789478
I0110 05:10:29.239693  4932 solver.cpp:240] Iteration 22740, loss = 0.0711885
I0110 05:10:29.239768  4932 solver.cpp:255]     Train net output #0: loss = 0.00427083 (* 1 = 0.00427083 loss)
I0110 05:10:29.239778  4932 solver.cpp:631] Iteration 22740, lr = 1e-06
I0110 05:11:13.627938  4932 solver.cpp:240] Iteration 22760, loss = 0.067876
I0110 05:11:13.628022  4932 solver.cpp:255]     Train net output #0: loss = 0.234875 (* 1 = 0.234875 loss)
I0110 05:11:13.628033  4932 solver.cpp:631] Iteration 22760, lr = 1e-06
I0110 05:11:13.968271  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1934 > 20) by scale factor 0.943692
I0110 05:11:58.017611  4932 solver.cpp:240] Iteration 22780, loss = 0.0842043
I0110 05:11:58.017706  4932 solver.cpp:255]     Train net output #0: loss = 0.171561 (* 1 = 0.171561 loss)
I0110 05:11:58.017719  4932 solver.cpp:631] Iteration 22780, lr = 1e-06
I0110 05:12:36.085361  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2262 > 20) by scale factor 0.734586
I0110 05:12:42.404294  4932 solver.cpp:240] Iteration 22800, loss = 0.0954315
I0110 05:12:42.404335  4932 solver.cpp:255]     Train net output #0: loss = 0.0956644 (* 1 = 0.0956644 loss)
I0110 05:12:42.404343  4932 solver.cpp:631] Iteration 22800, lr = 1e-06
I0110 05:13:02.710919  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7582 > 20) by scale factor 0.919195
I0110 05:13:26.784468  4932 solver.cpp:240] Iteration 22820, loss = 0.0489042
I0110 05:13:26.784554  4932 solver.cpp:255]     Train net output #0: loss = 0.00242603 (* 1 = 0.00242603 loss)
I0110 05:13:26.784566  4932 solver.cpp:631] Iteration 22820, lr = 1e-06
I0110 05:13:33.780375  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4912 > 20) by scale factor 0.754969
I0110 05:13:38.222192  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2334 > 20) by scale factor 0.792599
I0110 05:13:42.668648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1466 > 20) by scale factor 0.903071
I0110 05:14:04.868000  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9208 > 20) by scale factor 0.87257
I0110 05:14:11.186336  4932 solver.cpp:240] Iteration 22840, loss = 0.0745703
I0110 05:14:11.186375  4932 solver.cpp:255]     Train net output #0: loss = 0.120282 (* 1 = 0.120282 loss)
I0110 05:14:11.186383  4932 solver.cpp:631] Iteration 22840, lr = 1e-06
I0110 05:14:31.503211  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.054 > 20) by scale factor 0.997306
I0110 05:14:55.565822  4932 solver.cpp:240] Iteration 22860, loss = 0.0404223
I0110 05:14:55.565898  4932 solver.cpp:255]     Train net output #0: loss = 0.00877903 (* 1 = 0.00877903 loss)
I0110 05:14:55.565907  4932 solver.cpp:631] Iteration 22860, lr = 1e-06
I0110 05:14:58.125985  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.161 > 20) by scale factor 0.73635
I0110 05:15:13.661648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7123 > 20) by scale factor 0.809312
I0110 05:15:39.956990  4932 solver.cpp:240] Iteration 22880, loss = 0.0625376
I0110 05:15:39.957072  4932 solver.cpp:255]     Train net output #0: loss = 0.0989615 (* 1 = 0.0989615 loss)
I0110 05:15:39.957082  4932 solver.cpp:631] Iteration 22880, lr = 1e-06
I0110 05:16:24.340131  4932 solver.cpp:240] Iteration 22900, loss = 0.0423227
I0110 05:16:24.340241  4932 solver.cpp:255]     Train net output #0: loss = 0.0268361 (* 1 = 0.0268361 loss)
I0110 05:16:24.340257  4932 solver.cpp:631] Iteration 22900, lr = 1e-06
I0110 05:17:08.722183  4932 solver.cpp:240] Iteration 22920, loss = 0.0666111
I0110 05:17:08.722280  4932 solver.cpp:255]     Train net output #0: loss = 0.135237 (* 1 = 0.135237 loss)
I0110 05:17:08.722295  4932 solver.cpp:631] Iteration 22920, lr = 1e-06
I0110 05:17:53.099030  4932 solver.cpp:240] Iteration 22940, loss = 0.0690493
I0110 05:17:53.099100  4932 solver.cpp:255]     Train net output #0: loss = 0.115433 (* 1 = 0.115433 loss)
I0110 05:17:53.099110  4932 solver.cpp:631] Iteration 22940, lr = 1e-06
I0110 05:18:37.495370  4932 solver.cpp:240] Iteration 22960, loss = 0.0485374
I0110 05:18:37.495442  4932 solver.cpp:255]     Train net output #0: loss = 0.153183 (* 1 = 0.153183 loss)
I0110 05:18:37.495452  4932 solver.cpp:631] Iteration 22960, lr = 1e-06
I0110 05:18:44.488365  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.2686 > 20) by scale factor 0.601167
I0110 05:19:08.907481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8157 > 20) by scale factor 0.719019
I0110 05:19:21.880249  4932 solver.cpp:240] Iteration 22980, loss = 0.0950872
I0110 05:19:21.880295  4932 solver.cpp:255]     Train net output #0: loss = 0.00122258 (* 1 = 0.00122258 loss)
I0110 05:19:21.880306  4932 solver.cpp:631] Iteration 22980, lr = 1e-06
I0110 05:19:31.099246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7076 > 20) by scale factor 0.965831
I0110 05:20:04.394968  4932 solver.cpp:424] Iteration 23000, Testing net (#0)
I0110 05:20:53.556321  4932 solver.cpp:481]     Test net output #0: accuracy = 0.850526
I0110 05:20:53.556407  4932 solver.cpp:481]     Test net output #1: loss = 0.739942 (* 1 = 0.739942 loss)
I0110 05:20:55.422534  4932 solver.cpp:240] Iteration 23000, loss = 0.0386899
I0110 05:20:55.422574  4932 solver.cpp:255]     Train net output #0: loss = 0.000604633 (* 1 = 0.000604633 loss)
I0110 05:20:55.422582  4932 solver.cpp:631] Iteration 23000, lr = 1e-06
I0110 05:21:39.792129  4932 solver.cpp:240] Iteration 23020, loss = 0.0540147
I0110 05:21:39.792222  4932 solver.cpp:255]     Train net output #0: loss = 0.157439 (* 1 = 0.157439 loss)
I0110 05:21:39.792233  4932 solver.cpp:631] Iteration 23020, lr = 1e-06
I0110 05:22:24.154605  4932 solver.cpp:240] Iteration 23040, loss = 0.0544054
I0110 05:22:24.154690  4932 solver.cpp:255]     Train net output #0: loss = 0.0277381 (* 1 = 0.0277381 loss)
I0110 05:22:24.154698  4932 solver.cpp:631] Iteration 23040, lr = 1e-06
I0110 05:22:40.025557  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0653 > 20) by scale factor 0.94943
I0110 05:23:08.543162  4932 solver.cpp:240] Iteration 23060, loss = 0.0662206
I0110 05:23:08.543274  4932 solver.cpp:255]     Train net output #0: loss = 0.146261 (* 1 = 0.146261 loss)
I0110 05:23:08.543290  4932 solver.cpp:631] Iteration 23060, lr = 1e-06
I0110 05:23:19.988230  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0542 > 20) by scale factor 0.712905
I0110 05:23:48.833251  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6797 > 20) by scale factor 0.92252
I0110 05:23:52.933360  4932 solver.cpp:240] Iteration 23080, loss = 0.0820672
I0110 05:23:52.933398  4932 solver.cpp:255]     Train net output #0: loss = 0.0122073 (* 1 = 0.0122073 loss)
I0110 05:23:52.933408  4932 solver.cpp:631] Iteration 23080, lr = 1e-06
I0110 05:24:37.297376  4932 solver.cpp:240] Iteration 23100, loss = 0.054925
I0110 05:24:37.297442  4932 solver.cpp:255]     Train net output #0: loss = 0.0154819 (* 1 = 0.0154819 loss)
I0110 05:24:37.297452  4932 solver.cpp:631] Iteration 23100, lr = 1e-06
I0110 05:24:50.948091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5599 > 20) by scale factor 0.92765
I0110 05:25:13.139667  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2348 > 20) by scale factor 0.94185
I0110 05:25:21.684406  4932 solver.cpp:240] Iteration 23120, loss = 0.0746092
I0110 05:25:21.684454  4932 solver.cpp:255]     Train net output #0: loss = 0.0690192 (* 1 = 0.0690192 loss)
I0110 05:25:21.684465  4932 solver.cpp:631] Iteration 23120, lr = 1e-06
I0110 05:26:01.997794  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6638 > 20) by scale factor 0.9232
I0110 05:26:06.100252  4932 solver.cpp:240] Iteration 23140, loss = 0.0386216
I0110 05:26:06.100298  4932 solver.cpp:255]     Train net output #0: loss = 0.0137009 (* 1 = 0.0137009 loss)
I0110 05:26:06.100311  4932 solver.cpp:631] Iteration 23140, lr = 1e-06
I0110 05:26:50.516335  4932 solver.cpp:240] Iteration 23160, loss = 0.0834352
I0110 05:26:50.516422  4932 solver.cpp:255]     Train net output #0: loss = 0.146375 (* 1 = 0.146375 loss)
I0110 05:26:50.516434  4932 solver.cpp:631] Iteration 23160, lr = 1e-06
I0110 05:27:04.169842  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9839 > 20) by scale factor 0.953112
I0110 05:27:21.921020  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.485 > 20) by scale factor 0.67831
I0110 05:27:34.894459  4932 solver.cpp:240] Iteration 23180, loss = 0.097876
I0110 05:27:34.894495  4932 solver.cpp:255]     Train net output #0: loss = 0.124752 (* 1 = 0.124752 loss)
I0110 05:27:34.894505  4932 solver.cpp:631] Iteration 23180, lr = 1e-06
I0110 05:27:35.233413  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5028 > 20) by scale factor 0.975474
I0110 05:28:19.274163  4932 solver.cpp:240] Iteration 23200, loss = 0.0578767
I0110 05:28:19.274247  4932 solver.cpp:255]     Train net output #0: loss = 0.0203261 (* 1 = 0.0203261 loss)
I0110 05:28:19.274257  4932 solver.cpp:631] Iteration 23200, lr = 1e-06
I0110 05:28:39.583791  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5756 > 20) by scale factor 0.972024
I0110 05:28:41.805963  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6273 > 20) by scale factor 0.883887
I0110 05:29:03.670758  4932 solver.cpp:240] Iteration 23220, loss = 0.0709526
I0110 05:29:03.670846  4932 solver.cpp:255]     Train net output #0: loss = 0.00780054 (* 1 = 0.00780054 loss)
I0110 05:29:03.670859  4932 solver.cpp:631] Iteration 23220, lr = 1e-06
I0110 05:29:30.657008  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4204 > 20) by scale factor 0.892046
I0110 05:29:48.080278  4932 solver.cpp:240] Iteration 23240, loss = 0.0341796
I0110 05:29:48.080368  4932 solver.cpp:255]     Train net output #0: loss = 0.03734 (* 1 = 0.03734 loss)
I0110 05:29:48.080379  4932 solver.cpp:631] Iteration 23240, lr = 1e-06
I0110 05:30:01.741792  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4505 > 20) by scale factor 0.756129
I0110 05:30:32.468299  4932 solver.cpp:240] Iteration 23260, loss = 0.0855758
I0110 05:30:32.468389  4932 solver.cpp:255]     Train net output #0: loss = 0.0381336 (* 1 = 0.0381336 loss)
I0110 05:30:32.468401  4932 solver.cpp:631] Iteration 23260, lr = 1e-06
I0110 05:30:43.898520  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8044 > 20) by scale factor 0.746146
I0110 05:30:52.778865  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2253 > 20) by scale factor 0.988861
I0110 05:31:08.309649  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7123 > 20) by scale factor 0.777838
I0110 05:31:16.846999  4932 solver.cpp:240] Iteration 23280, loss = 0.0665387
I0110 05:31:16.847030  4932 solver.cpp:255]     Train net output #0: loss = 0.0597952 (* 1 = 0.0597952 loss)
I0110 05:31:16.847038  4932 solver.cpp:631] Iteration 23280, lr = 1e-06
I0110 05:32:01.216639  4932 solver.cpp:240] Iteration 23300, loss = 0.0448731
I0110 05:32:01.216709  4932 solver.cpp:255]     Train net output #0: loss = 4.26387e-05 (* 1 = 4.26387e-05 loss)
I0110 05:32:01.216719  4932 solver.cpp:631] Iteration 23300, lr = 1e-06
I0110 05:32:45.600258  4932 solver.cpp:240] Iteration 23320, loss = 0.0507792
I0110 05:32:45.600366  4932 solver.cpp:255]     Train net output #0: loss = 0.264483 (* 1 = 0.264483 loss)
I0110 05:32:45.600383  4932 solver.cpp:631] Iteration 23320, lr = 1e-06
I0110 05:32:45.940690  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4746 > 20) by scale factor 0.785094
I0110 05:33:21.440400  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6775 > 20) by scale factor 0.967236
I0110 05:33:29.981987  4932 solver.cpp:240] Iteration 23340, loss = 0.0525615
I0110 05:33:29.982033  4932 solver.cpp:255]     Train net output #0: loss = 0.000317879 (* 1 = 0.000317879 loss)
I0110 05:33:29.982156  4932 solver.cpp:631] Iteration 23340, lr = 1e-06
I0110 05:33:50.305325  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5971 > 20) by scale factor 0.781338
I0110 05:33:56.968124  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.7897 > 20) by scale factor 0.649568
I0110 05:34:08.059504  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.394 > 20) by scale factor 0.934843
I0110 05:34:10.282040  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3427 > 20) by scale factor 0.759224
I0110 05:34:14.385711  4932 solver.cpp:240] Iteration 23360, loss = 0.0882761
I0110 05:34:14.385751  4932 solver.cpp:255]     Train net output #0: loss = 0.0118965 (* 1 = 0.0118965 loss)
I0110 05:34:14.385761  4932 solver.cpp:631] Iteration 23360, lr = 1e-06
I0110 05:34:58.775393  4932 solver.cpp:240] Iteration 23380, loss = 0.0698547
I0110 05:34:58.775485  4932 solver.cpp:255]     Train net output #0: loss = 0.228309 (* 1 = 0.228309 loss)
I0110 05:34:58.775498  4932 solver.cpp:631] Iteration 23380, lr = 1e-06
I0110 05:35:39.055980  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5249 > 20) by scale factor 0.974427
I0110 05:35:43.155717  4932 solver.cpp:240] Iteration 23400, loss = 0.0801239
I0110 05:35:43.155763  4932 solver.cpp:255]     Train net output #0: loss = 0.255362 (* 1 = 0.255362 loss)
I0110 05:35:43.155776  4932 solver.cpp:631] Iteration 23400, lr = 1e-06
I0110 05:35:43.497031  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.547 > 20) by scale factor 0.782871
I0110 05:36:21.223562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3158 > 20) by scale factor 0.759999
I0110 05:36:27.541061  4932 solver.cpp:240] Iteration 23420, loss = 0.0751408
I0110 05:36:27.541101  4932 solver.cpp:255]     Train net output #0: loss = 0.0010546 (* 1 = 0.0010546 loss)
I0110 05:36:27.541110  4932 solver.cpp:631] Iteration 23420, lr = 1e-06
I0110 05:37:01.162236  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6133 > 20) by scale factor 0.846979
I0110 05:37:05.606242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7635 > 20) by scale factor 0.776291
I0110 05:37:11.928655  4932 solver.cpp:240] Iteration 23440, loss = 0.105652
I0110 05:37:11.928694  4932 solver.cpp:255]     Train net output #0: loss = 0.0195573 (* 1 = 0.0195573 loss)
I0110 05:37:11.928702  4932 solver.cpp:631] Iteration 23440, lr = 1e-06
I0110 05:37:16.702172  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2931 > 20) by scale factor 0.985558
I0110 05:37:38.889048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1993 > 20) by scale factor 0.763379
I0110 05:37:56.302078  4932 solver.cpp:240] Iteration 23460, loss = 0.0606177
I0110 05:37:56.302121  4932 solver.cpp:255]     Train net output #0: loss = 0.0276918 (* 1 = 0.0276918 loss)
I0110 05:37:56.302132  4932 solver.cpp:631] Iteration 23460, lr = 1e-06
I0110 05:38:27.710288  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3839 > 20) by scale factor 0.935283
I0110 05:38:40.686740  4932 solver.cpp:240] Iteration 23480, loss = 0.0928241
I0110 05:38:40.686787  4932 solver.cpp:255]     Train net output #0: loss = 0.00201196 (* 1 = 0.00201196 loss)
I0110 05:38:40.686800  4932 solver.cpp:631] Iteration 23480, lr = 1e-06
I0110 05:39:05.433837  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.076 > 20) by scale factor 0.996214
I0110 05:39:25.075917  4932 solver.cpp:240] Iteration 23500, loss = 0.0928347
I0110 05:39:25.075955  4932 solver.cpp:255]     Train net output #0: loss = 0.26432 (* 1 = 0.26432 loss)
I0110 05:39:25.075964  4932 solver.cpp:631] Iteration 23500, lr = 1e-06
I0110 05:40:09.465188  4932 solver.cpp:240] Iteration 23520, loss = 0.0543623
I0110 05:40:09.465258  4932 solver.cpp:255]     Train net output #0: loss = 0.0230432 (* 1 = 0.0230432 loss)
I0110 05:40:09.465270  4932 solver.cpp:631] Iteration 23520, lr = 1e-06
I0110 05:40:14.239747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.269 > 20) by scale factor 0.986728
I0110 05:40:23.116133  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8425 > 20) by scale factor 0.838838
I0110 05:40:53.845960  4932 solver.cpp:240] Iteration 23540, loss = 0.0766647
I0110 05:40:53.846021  4932 solver.cpp:255]     Train net output #0: loss = 0.040786 (* 1 = 0.040786 loss)
I0110 05:40:53.846030  4932 solver.cpp:631] Iteration 23540, lr = 1e-06
I0110 05:41:38.224812  4932 solver.cpp:240] Iteration 23560, loss = 0.0643699
I0110 05:41:38.224882  4932 solver.cpp:255]     Train net output #0: loss = 0.100835 (* 1 = 0.100835 loss)
I0110 05:41:38.224891  4932 solver.cpp:631] Iteration 23560, lr = 1e-06
I0110 05:41:54.093930  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1287 > 20) by scale factor 0.94658
I0110 05:42:00.760495  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4688 > 20) by scale factor 0.890123
I0110 05:42:22.611829  4932 solver.cpp:240] Iteration 23580, loss = 0.0783376
I0110 05:42:22.611901  4932 solver.cpp:255]     Train net output #0: loss = 0.00491931 (* 1 = 0.00491931 loss)
I0110 05:42:22.611910  4932 solver.cpp:631] Iteration 23580, lr = 1e-06
I0110 05:43:00.680166  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0571 > 20) by scale factor 0.798176
I0110 05:43:07.001204  4932 solver.cpp:240] Iteration 23600, loss = 0.0571898
I0110 05:43:07.001245  4932 solver.cpp:255]     Train net output #0: loss = 0.0251837 (* 1 = 0.0251837 loss)
I0110 05:43:07.001253  4932 solver.cpp:631] Iteration 23600, lr = 1e-06
I0110 05:43:18.435461  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3087 > 20) by scale factor 0.858047
I0110 05:43:51.384973  4932 solver.cpp:240] Iteration 23620, loss = 0.0527936
I0110 05:43:51.385057  4932 solver.cpp:255]     Train net output #0: loss = 0.00185375 (* 1 = 0.00185375 loss)
I0110 05:43:51.385069  4932 solver.cpp:631] Iteration 23620, lr = 1e-06
I0110 05:43:56.163465  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5915 > 20) by scale factor 0.72486
I0110 05:44:33.890540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4159 > 20) by scale factor 0.757121
I0110 05:44:35.774276  4932 solver.cpp:240] Iteration 23640, loss = 0.0746776
I0110 05:44:35.774323  4932 solver.cpp:255]     Train net output #0: loss = 0.00038723 (* 1 = 0.00038723 loss)
I0110 05:44:35.774335  4932 solver.cpp:631] Iteration 23640, lr = 1e-06
I0110 05:45:20.158267  4932 solver.cpp:240] Iteration 23660, loss = 0.0410403
I0110 05:45:20.158345  4932 solver.cpp:255]     Train net output #0: loss = 0.000226867 (* 1 = 0.000226867 loss)
I0110 05:45:20.158355  4932 solver.cpp:631] Iteration 23660, lr = 1e-06
I0110 05:46:04.536629  4932 solver.cpp:240] Iteration 23680, loss = 0.0463836
I0110 05:46:04.536701  4932 solver.cpp:255]     Train net output #0: loss = 0.152909 (* 1 = 0.152909 loss)
I0110 05:46:04.536711  4932 solver.cpp:631] Iteration 23680, lr = 1e-06
I0110 05:46:27.067756  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7186 > 20) by scale factor 0.92087
I0110 05:46:44.824836  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.195 > 20) by scale factor 0.709345
I0110 05:46:48.927383  4932 solver.cpp:240] Iteration 23700, loss = 0.071332
I0110 05:46:48.927438  4932 solver.cpp:255]     Train net output #0: loss = 0.0193442 (* 1 = 0.0193442 loss)
I0110 05:46:48.927449  4932 solver.cpp:631] Iteration 23700, lr = 1e-06
I0110 05:46:58.144775  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4002 > 20) by scale factor 0.892849
I0110 05:47:11.461789  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.3155 > 20) by scale factor 0.659728
I0110 05:47:33.306903  4932 solver.cpp:240] Iteration 23720, loss = 0.0806194
I0110 05:47:33.306979  4932 solver.cpp:255]     Train net output #0: loss = 0.171966 (* 1 = 0.171966 loss)
I0110 05:47:33.306989  4932 solver.cpp:631] Iteration 23720, lr = 1e-06
I0110 05:47:33.646070  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8191 > 20) by scale factor 0.960657
I0110 05:48:11.380818  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1775 > 20) by scale factor 0.991204
I0110 05:48:17.703753  4932 solver.cpp:240] Iteration 23740, loss = 0.088334
I0110 05:48:17.703799  4932 solver.cpp:255]     Train net output #0: loss = 0.127863 (* 1 = 0.127863 loss)
I0110 05:48:17.703809  4932 solver.cpp:631] Iteration 23740, lr = 1e-06
I0110 05:49:02.111035  4932 solver.cpp:240] Iteration 23760, loss = 0.0656058
I0110 05:49:02.111111  4932 solver.cpp:255]     Train net output #0: loss = 0.00233417 (* 1 = 0.00233417 loss)
I0110 05:49:02.111124  4932 solver.cpp:631] Iteration 23760, lr = 1e-06
I0110 05:49:11.329885  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2989 > 20) by scale factor 0.939014
I0110 05:49:20.213747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4413 > 20) by scale factor 0.818289
I0110 05:49:46.509620  4932 solver.cpp:240] Iteration 23780, loss = 0.0612135
I0110 05:49:46.509707  4932 solver.cpp:255]     Train net output #0: loss = 0.0269354 (* 1 = 0.0269354 loss)
I0110 05:49:46.509719  4932 solver.cpp:631] Iteration 23780, lr = 1e-06
I0110 05:50:30.916896  4932 solver.cpp:240] Iteration 23800, loss = 0.0615376
I0110 05:50:30.916980  4932 solver.cpp:255]     Train net output #0: loss = 0.012828 (* 1 = 0.012828 loss)
I0110 05:50:30.916991  4932 solver.cpp:631] Iteration 23800, lr = 1e-06
I0110 05:51:15.320713  4932 solver.cpp:240] Iteration 23820, loss = 0.0770195
I0110 05:51:15.320806  4932 solver.cpp:255]     Train net output #0: loss = 0.0360064 (* 1 = 0.0360064 loss)
I0110 05:51:15.320819  4932 solver.cpp:631] Iteration 23820, lr = 1e-06
I0110 05:51:59.702661  4932 solver.cpp:240] Iteration 23840, loss = 0.0415441
I0110 05:51:59.702731  4932 solver.cpp:255]     Train net output #0: loss = 0.00979749 (* 1 = 0.00979749 loss)
I0110 05:51:59.702740  4932 solver.cpp:631] Iteration 23840, lr = 1e-06
I0110 05:52:35.552798  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4109 > 20) by scale factor 0.979871
I0110 05:52:44.092185  4932 solver.cpp:240] Iteration 23860, loss = 0.0450384
I0110 05:52:44.092224  4932 solver.cpp:255]     Train net output #0: loss = 0.011067 (* 1 = 0.011067 loss)
I0110 05:52:44.092233  4932 solver.cpp:631] Iteration 23860, lr = 1e-06
I0110 05:53:28.479495  4932 solver.cpp:240] Iteration 23880, loss = 0.0792952
I0110 05:53:28.479568  4932 solver.cpp:255]     Train net output #0: loss = 0.187405 (* 1 = 0.187405 loss)
I0110 05:53:28.479578  4932 solver.cpp:631] Iteration 23880, lr = 1e-06
I0110 05:53:39.918431  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4089 > 20) by scale factor 0.934191
I0110 05:54:12.872591  4932 solver.cpp:240] Iteration 23900, loss = 0.0628423
I0110 05:54:12.872678  4932 solver.cpp:255]     Train net output #0: loss = 0.119849 (* 1 = 0.119849 loss)
I0110 05:54:12.872690  4932 solver.cpp:631] Iteration 23900, lr = 1e-06
I0110 05:54:15.434363  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7206 > 20) by scale factor 0.88026
I0110 05:54:57.283380  4932 solver.cpp:240] Iteration 23920, loss = 0.0569063
I0110 05:54:57.283486  4932 solver.cpp:255]     Train net output #0: loss = 0.114812 (* 1 = 0.114812 loss)
I0110 05:54:57.283501  4932 solver.cpp:631] Iteration 23920, lr = 1e-06
I0110 05:55:41.685089  4932 solver.cpp:240] Iteration 23940, loss = 0.04963
I0110 05:55:41.685179  4932 solver.cpp:255]     Train net output #0: loss = 0.0709396 (* 1 = 0.0709396 loss)
I0110 05:55:41.685191  4932 solver.cpp:631] Iteration 23940, lr = 1e-06
I0110 05:56:26.093230  4932 solver.cpp:240] Iteration 23960, loss = 0.0425121
I0110 05:56:26.093313  4932 solver.cpp:255]     Train net output #0: loss = 0.00394634 (* 1 = 0.00394634 loss)
I0110 05:56:26.093325  4932 solver.cpp:631] Iteration 23960, lr = 1e-06
I0110 05:56:53.076740  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8307 > 20) by scale factor 0.839253
I0110 05:57:04.180456  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9424 > 20) by scale factor 0.715758
I0110 05:57:06.403663  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3363 > 20) by scale factor 0.68175
I0110 05:57:10.507134  4932 solver.cpp:240] Iteration 23980, loss = 0.0701577
I0110 05:57:10.507179  4932 solver.cpp:255]     Train net output #0: loss = 0.0641353 (* 1 = 0.0641353 loss)
I0110 05:57:10.507189  4932 solver.cpp:631] Iteration 23980, lr = 1e-06
I0110 05:57:53.032361  4932 solver.cpp:424] Iteration 24000, Testing net (#0)
I0110 05:58:45.382895  4932 solver.cpp:481]     Test net output #0: accuracy = 0.816842
I0110 05:58:45.382998  4932 solver.cpp:481]     Test net output #1: loss = 0.906766 (* 1 = 0.906766 loss)
I0110 05:58:47.250027  4932 solver.cpp:240] Iteration 24000, loss = 0.0481251
I0110 05:58:47.250066  4932 solver.cpp:255]     Train net output #0: loss = 0.173157 (* 1 = 0.173157 loss)
I0110 05:58:47.250074  4932 solver.cpp:631] Iteration 24000, lr = 1e-06
I0110 05:59:25.310672  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6882 > 20) by scale factor 0.92216
I0110 05:59:31.629016  4932 solver.cpp:240] Iteration 24020, loss = 0.0434942
I0110 05:59:31.629061  4932 solver.cpp:255]     Train net output #0: loss = 0.0902153 (* 1 = 0.0902153 loss)
I0110 05:59:31.629072  4932 solver.cpp:631] Iteration 24020, lr = 1e-06
I0110 05:59:40.845435  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6585 > 20) by scale factor 0.923425
I0110 06:00:16.015421  4932 solver.cpp:240] Iteration 24040, loss = 0.0624255
I0110 06:00:16.015496  4932 solver.cpp:255]     Train net output #0: loss = 0.0090716 (* 1 = 0.0090716 loss)
I0110 06:00:16.015504  4932 solver.cpp:631] Iteration 24040, lr = 1e-06
I0110 06:00:27.447952  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6139 > 20) by scale factor 0.970218
I0110 06:00:49.643246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.613 > 20) by scale factor 0.884448
I0110 06:00:58.524257  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7446 > 20) by scale factor 0.67239
I0110 06:01:00.405954  4932 solver.cpp:240] Iteration 24060, loss = 0.0892228
I0110 06:01:00.405992  4932 solver.cpp:255]     Train net output #0: loss = 0.00721231 (* 1 = 0.00721231 loss)
I0110 06:01:00.406000  4932 solver.cpp:631] Iteration 24060, lr = 1e-06
I0110 06:01:29.591037  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5432 > 20) by scale factor 0.887185
I0110 06:01:34.029474  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1751 > 20) by scale factor 0.827296
I0110 06:01:36.253082  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8429 > 20) by scale factor 0.915631
I0110 06:01:44.797793  4932 solver.cpp:240] Iteration 24080, loss = 0.0743699
I0110 06:01:44.797834  4932 solver.cpp:255]     Train net output #0: loss = 0.0593634 (* 1 = 0.0593634 loss)
I0110 06:01:44.797843  4932 solver.cpp:631] Iteration 24080, lr = 1e-06
I0110 06:02:29.169442  4932 solver.cpp:240] Iteration 24100, loss = 0.0512474
I0110 06:02:29.169548  4932 solver.cpp:255]     Train net output #0: loss = 0.00763226 (* 1 = 0.00763226 loss)
I0110 06:02:29.169564  4932 solver.cpp:631] Iteration 24100, lr = 1e-06
I0110 06:03:00.582753  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8896 > 20) by scale factor 0.957416
I0110 06:03:07.241792  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2235 > 20) by scale factor 0.942354
I0110 06:03:13.560351  4932 solver.cpp:240] Iteration 24120, loss = 0.055012
I0110 06:03:13.560384  4932 solver.cpp:255]     Train net output #0: loss = 0.046275 (* 1 = 0.046275 loss)
I0110 06:03:13.560391  4932 solver.cpp:631] Iteration 24120, lr = 1e-06
I0110 06:03:27.216820  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9168 > 20) by scale factor 0.743029
I0110 06:03:40.535439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7295 > 20) by scale factor 0.920409
I0110 06:03:57.955149  4932 solver.cpp:240] Iteration 24140, loss = 0.0852797
I0110 06:03:57.955190  4932 solver.cpp:255]     Train net output #0: loss = 0.0308098 (* 1 = 0.0308098 loss)
I0110 06:03:57.955199  4932 solver.cpp:631] Iteration 24140, lr = 1e-06
I0110 06:04:02.735571  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2385 > 20) by scale factor 0.988218
I0110 06:04:42.350186  4932 solver.cpp:240] Iteration 24160, loss = 0.066529
I0110 06:04:42.350270  4932 solver.cpp:255]     Train net output #0: loss = 0.00439186 (* 1 = 0.00439186 loss)
I0110 06:04:42.350281  4932 solver.cpp:631] Iteration 24160, lr = 1e-06
I0110 06:05:07.095321  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4715 > 20) by scale factor 0.976968
I0110 06:05:24.850131  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6642 > 20) by scale factor 0.845159
I0110 06:05:26.733481  4932 solver.cpp:240] Iteration 24180, loss = 0.102372
I0110 06:05:26.733528  4932 solver.cpp:255]     Train net output #0: loss = 0.0222045 (* 1 = 0.0222045 loss)
I0110 06:05:26.733541  4932 solver.cpp:631] Iteration 24180, lr = 1e-06
I0110 06:05:35.950376  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8193 > 20) by scale factor 0.91662
I0110 06:05:38.171764  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1262 > 20) by scale factor 0.99373
I0110 06:06:11.125768  4932 solver.cpp:240] Iteration 24200, loss = 0.0760439
I0110 06:06:11.125838  4932 solver.cpp:255]     Train net output #0: loss = 0.132824 (* 1 = 0.132824 loss)
I0110 06:06:11.125847  4932 solver.cpp:631] Iteration 24200, lr = 1e-06
I0110 06:06:38.103080  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9665 > 20) by scale factor 0.870834
I0110 06:06:51.418601  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9308 > 20) by scale factor 0.802221
I0110 06:06:55.518414  4932 solver.cpp:240] Iteration 24220, loss = 0.088475
I0110 06:06:55.518445  4932 solver.cpp:255]     Train net output #0: loss = 0.0814403 (* 1 = 0.0814403 loss)
I0110 06:06:55.518455  4932 solver.cpp:631] Iteration 24220, lr = 1e-06
I0110 06:06:58.078011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1436 > 20) by scale factor 0.903195
I0110 06:07:06.966454  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.935 > 20) by scale factor 0.911786
I0110 06:07:39.923957  4932 solver.cpp:240] Iteration 24240, loss = 0.0483391
I0110 06:07:39.924034  4932 solver.cpp:255]     Train net output #0: loss = 0.018375 (* 1 = 0.018375 loss)
I0110 06:07:39.924044  4932 solver.cpp:631] Iteration 24240, lr = 1e-06
I0110 06:07:42.480321  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3602 > 20) by scale factor 0.894446
I0110 06:07:53.581271  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5197 > 20) by scale factor 0.88811
I0110 06:08:24.317034  4932 solver.cpp:240] Iteration 24260, loss = 0.0650213
I0110 06:08:24.317143  4932 solver.cpp:255]     Train net output #0: loss = 0.0222635 (* 1 = 0.0222635 loss)
I0110 06:08:24.317159  4932 solver.cpp:631] Iteration 24260, lr = 1e-06
I0110 06:08:26.877565  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9669 > 20) by scale factor 0.834484
I0110 06:09:08.707674  4932 solver.cpp:240] Iteration 24280, loss = 0.0453137
I0110 06:09:08.707751  4932 solver.cpp:255]     Train net output #0: loss = 0.00620761 (* 1 = 0.00620761 loss)
I0110 06:09:08.707761  4932 solver.cpp:631] Iteration 24280, lr = 1e-06
I0110 06:09:24.586869  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1499 > 20) by scale factor 0.795232
I0110 06:09:53.098088  4932 solver.cpp:240] Iteration 24300, loss = 0.0643647
I0110 06:09:53.098173  4932 solver.cpp:255]     Train net output #0: loss = 0.101193 (* 1 = 0.101193 loss)
I0110 06:09:53.098186  4932 solver.cpp:631] Iteration 24300, lr = 1e-06
I0110 06:10:37.489225  4932 solver.cpp:240] Iteration 24320, loss = 0.0281774
I0110 06:10:37.489320  4932 solver.cpp:255]     Train net output #0: loss = 0.0581477 (* 1 = 0.0581477 loss)
I0110 06:10:37.489334  4932 solver.cpp:631] Iteration 24320, lr = 1e-06
I0110 06:10:42.274379  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1126 > 20) by scale factor 0.86533
I0110 06:10:51.154880  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.745 > 20) by scale factor 0.964087
I0110 06:11:08.915401  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4254 > 20) by scale factor 0.756847
I0110 06:11:21.896466  4932 solver.cpp:240] Iteration 24340, loss = 0.0608943
I0110 06:11:21.896502  4932 solver.cpp:255]     Train net output #0: loss = 0.00242972 (* 1 = 0.00242972 loss)
I0110 06:11:21.896512  4932 solver.cpp:631] Iteration 24340, lr = 1e-06
I0110 06:11:33.329818  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8828 > 20) by scale factor 0.957727
I0110 06:11:39.989120  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5636 > 20) by scale factor 0.972592
I0110 06:11:42.213419  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0101 > 20) by scale factor 0.908673
I0110 06:11:59.967895  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0997 > 20) by scale factor 0.995039
I0110 06:12:06.286546  4932 solver.cpp:240] Iteration 24360, loss = 0.0531908
I0110 06:12:06.286584  4932 solver.cpp:255]     Train net output #0: loss = 0.000844956 (* 1 = 0.000844956 loss)
I0110 06:12:06.286593  4932 solver.cpp:631] Iteration 24360, lr = 1e-06
I0110 06:12:28.821774  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2541 > 20) by scale factor 0.733833
I0110 06:12:50.679213  4932 solver.cpp:240] Iteration 24380, loss = 0.0808288
I0110 06:12:50.679257  4932 solver.cpp:255]     Train net output #0: loss = 0.0297976 (* 1 = 0.0297976 loss)
I0110 06:12:50.679268  4932 solver.cpp:631] Iteration 24380, lr = 1e-06
I0110 06:13:10.989270  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0798 > 20) by scale factor 0.996024
I0110 06:13:35.057907  4932 solver.cpp:240] Iteration 24400, loss = 0.066196
I0110 06:13:35.057946  4932 solver.cpp:255]     Train net output #0: loss = 0.0898699 (* 1 = 0.0898699 loss)
I0110 06:13:35.057956  4932 solver.cpp:631] Iteration 24400, lr = 1e-06
I0110 06:13:42.057416  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6255 > 20) by scale factor 0.924832
I0110 06:14:19.455341  4932 solver.cpp:240] Iteration 24420, loss = 0.0619484
I0110 06:14:19.455406  4932 solver.cpp:255]     Train net output #0: loss = 0.0104887 (* 1 = 0.0104887 loss)
I0110 06:14:19.455418  4932 solver.cpp:631] Iteration 24420, lr = 1e-06
I0110 06:15:03.819823  4932 solver.cpp:240] Iteration 24440, loss = 0.0186371
I0110 06:15:03.819864  4932 solver.cpp:255]     Train net output #0: loss = 0.00507852 (* 1 = 0.00507852 loss)
I0110 06:15:03.819872  4932 solver.cpp:631] Iteration 24440, lr = 1e-06
I0110 06:15:48.213920  4932 solver.cpp:240] Iteration 24460, loss = 0.0394088
I0110 06:15:48.214010  4932 solver.cpp:255]     Train net output #0: loss = 0.0489379 (* 1 = 0.0489379 loss)
I0110 06:15:48.214018  4932 solver.cpp:631] Iteration 24460, lr = 1e-06
I0110 06:16:32.608542  4932 solver.cpp:240] Iteration 24480, loss = 0.0442898
I0110 06:16:32.608623  4932 solver.cpp:255]     Train net output #0: loss = 0.0186245 (* 1 = 0.0186245 loss)
I0110 06:16:32.608633  4932 solver.cpp:631] Iteration 24480, lr = 1e-06
I0110 06:16:41.820287  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0304 > 20) by scale factor 0.868417
I0110 06:17:16.984978  4932 solver.cpp:240] Iteration 24500, loss = 0.0592756
I0110 06:17:16.985059  4932 solver.cpp:255]     Train net output #0: loss = 0.00643854 (* 1 = 0.00643854 loss)
I0110 06:17:16.985071  4932 solver.cpp:631] Iteration 24500, lr = 1e-06
I0110 06:17:19.545675  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.453 > 20) by scale factor 0.756058
I0110 06:18:01.380364  4932 solver.cpp:240] Iteration 24520, loss = 0.0659873
I0110 06:18:01.380460  4932 solver.cpp:255]     Train net output #0: loss = 0.00392359 (* 1 = 0.00392359 loss)
I0110 06:18:01.380475  4932 solver.cpp:631] Iteration 24520, lr = 1e-06
I0110 06:18:12.822336  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7484 > 20) by scale factor 0.672306
I0110 06:18:28.360857  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.202 > 20) by scale factor 0.989999
I0110 06:18:45.772338  4932 solver.cpp:240] Iteration 24540, loss = 0.0942696
I0110 06:18:45.772413  4932 solver.cpp:255]     Train net output #0: loss = 0.0221757 (* 1 = 0.0221757 loss)
I0110 06:18:45.772423  4932 solver.cpp:631] Iteration 24540, lr = 1e-06
I0110 06:18:54.988035  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0289 > 20) by scale factor 0.868473
I0110 06:18:57.211468  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.3097 > 20) by scale factor 0.659854
I0110 06:19:06.089469  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6228 > 20) by scale factor 0.969801
I0110 06:19:19.403846  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4657 > 20) by scale factor 0.817472
I0110 06:19:21.624640  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4094 > 20) by scale factor 0.892484
I0110 06:19:30.163885  4932 solver.cpp:240] Iteration 24560, loss = 0.122485
I0110 06:19:30.163926  4932 solver.cpp:255]     Train net output #0: loss = 0.0185019 (* 1 = 0.0185019 loss)
I0110 06:19:30.163935  4932 solver.cpp:631] Iteration 24560, lr = 1e-06
I0110 06:20:14.555222  4932 solver.cpp:240] Iteration 24580, loss = 0.0556863
I0110 06:20:14.555310  4932 solver.cpp:255]     Train net output #0: loss = 0.019289 (* 1 = 0.019289 loss)
I0110 06:20:14.555322  4932 solver.cpp:631] Iteration 24580, lr = 1e-06
I0110 06:20:28.211483  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 38.2515 > 20) by scale factor 0.522855
I0110 06:20:45.973361  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5559 > 20) by scale factor 0.972956
I0110 06:20:58.946916  4932 solver.cpp:240] Iteration 24600, loss = 0.0825047
I0110 06:20:58.946956  4932 solver.cpp:255]     Train net output #0: loss = 0.0120918 (* 1 = 0.0120918 loss)
I0110 06:20:58.946964  4932 solver.cpp:631] Iteration 24600, lr = 1e-06
I0110 06:21:43.328997  4932 solver.cpp:240] Iteration 24620, loss = 0.0532477
I0110 06:21:43.329051  4932 solver.cpp:255]     Train net output #0: loss = 0.0038225 (* 1 = 0.0038225 loss)
I0110 06:21:43.329061  4932 solver.cpp:631] Iteration 24620, lr = 1e-06
I0110 06:22:05.854243  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1936 > 20) by scale factor 0.943679
I0110 06:22:14.735493  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5364 > 20) by scale factor 0.849748
I0110 06:22:27.712396  4932 solver.cpp:240] Iteration 24640, loss = 0.0696001
I0110 06:22:27.712440  4932 solver.cpp:255]     Train net output #0: loss = 0.130223 (* 1 = 0.130223 loss)
I0110 06:22:27.712448  4932 solver.cpp:631] Iteration 24640, lr = 1e-06
I0110 06:22:54.683259  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2399 > 20) by scale factor 0.708217
I0110 06:23:12.107300  4932 solver.cpp:240] Iteration 24660, loss = 0.0856708
I0110 06:23:12.107336  4932 solver.cpp:255]     Train net output #0: loss = 0.0847617 (* 1 = 0.0847617 loss)
I0110 06:23:12.107344  4932 solver.cpp:631] Iteration 24660, lr = 1e-06
I0110 06:23:27.975906  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7013 > 20) by scale factor 0.809673
I0110 06:23:56.490332  4932 solver.cpp:240] Iteration 24680, loss = 0.0754124
I0110 06:23:56.490370  4932 solver.cpp:255]     Train net output #0: loss = 0.0600988 (* 1 = 0.0600988 loss)
I0110 06:23:56.490381  4932 solver.cpp:631] Iteration 24680, lr = 1e-06
I0110 06:24:27.891599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9845 > 20) by scale factor 0.87015
I0110 06:24:34.555411  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2745 > 20) by scale factor 0.940093
I0110 06:24:40.873260  4932 solver.cpp:240] Iteration 24700, loss = 0.0744156
I0110 06:24:40.873294  4932 solver.cpp:255]     Train net output #0: loss = 0.0178252 (* 1 = 0.0178252 loss)
I0110 06:24:40.873303  4932 solver.cpp:631] Iteration 24700, lr = 1e-06
I0110 06:25:12.283074  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6759 > 20) by scale factor 0.72265
I0110 06:25:25.256824  4932 solver.cpp:240] Iteration 24720, loss = 0.0552195
I0110 06:25:25.256866  4932 solver.cpp:255]     Train net output #0: loss = 0.0788634 (* 1 = 0.0788634 loss)
I0110 06:25:25.256875  4932 solver.cpp:631] Iteration 24720, lr = 1e-06
I0110 06:25:25.596319  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2949 > 20) by scale factor 0.939191
I0110 06:25:47.785733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.667 > 20) by scale factor 0.88234
I0110 06:25:50.007074  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4007 > 20) by scale factor 0.757557
I0110 06:25:56.670485  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6922 > 20) by scale factor 0.84416
I0110 06:26:09.646373  4932 solver.cpp:240] Iteration 24740, loss = 0.0647745
I0110 06:26:09.646427  4932 solver.cpp:255]     Train net output #0: loss = 0.0325518 (* 1 = 0.0325518 loss)
I0110 06:26:09.646571  4932 solver.cpp:631] Iteration 24740, lr = 1e-06
I0110 06:26:54.038399  4932 solver.cpp:240] Iteration 24760, loss = 0.0333881
I0110 06:26:54.038492  4932 solver.cpp:255]     Train net output #0: loss = 0.00191558 (* 1 = 0.00191558 loss)
I0110 06:26:54.038506  4932 solver.cpp:631] Iteration 24760, lr = 1e-06
I0110 06:27:32.106830  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7933 > 20) by scale factor 0.806671
I0110 06:27:36.547837  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4587 > 20) by scale factor 0.728368
I0110 06:27:38.430677  4932 solver.cpp:240] Iteration 24780, loss = 0.0803958
I0110 06:27:38.430713  4932 solver.cpp:255]     Train net output #0: loss = 0.00114263 (* 1 = 0.00114263 loss)
I0110 06:27:38.430721  4932 solver.cpp:631] Iteration 24780, lr = 1e-06
I0110 06:27:40.987578  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3005 > 20) by scale factor 0.938947
I0110 06:27:58.746419  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0824 > 20) by scale factor 0.830481
I0110 06:28:22.813987  4932 solver.cpp:240] Iteration 24800, loss = 0.0704404
I0110 06:28:22.814071  4932 solver.cpp:255]     Train net output #0: loss = 0.0524714 (* 1 = 0.0524714 loss)
I0110 06:28:22.814082  4932 solver.cpp:631] Iteration 24800, lr = 1e-06
I0110 06:28:56.444471  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5102 > 20) by scale factor 0.929791
I0110 06:29:07.207597  4932 solver.cpp:240] Iteration 24820, loss = 0.0561469
I0110 06:29:07.207633  4932 solver.cpp:255]     Train net output #0: loss = 0.0054085 (* 1 = 0.0054085 loss)
I0110 06:29:07.207643  4932 solver.cpp:631] Iteration 24820, lr = 1e-06
I0110 06:29:23.085237  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5347 > 20) by scale factor 0.973963
I0110 06:29:51.597905  4932 solver.cpp:240] Iteration 24840, loss = 0.088699
I0110 06:29:51.597986  4932 solver.cpp:255]     Train net output #0: loss = 0.368053 (* 1 = 0.368053 loss)
I0110 06:29:51.597996  4932 solver.cpp:631] Iteration 24840, lr = 1e-06
I0110 06:30:27.437535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2284 > 20) by scale factor 0.89975
I0110 06:30:35.979333  4932 solver.cpp:240] Iteration 24860, loss = 0.0525841
I0110 06:30:35.979377  4932 solver.cpp:255]     Train net output #0: loss = 0.0657287 (* 1 = 0.0657287 loss)
I0110 06:30:35.979388  4932 solver.cpp:631] Iteration 24860, lr = 1e-06
I0110 06:31:20.373673  4932 solver.cpp:240] Iteration 24880, loss = 0.0537411
I0110 06:31:20.373746  4932 solver.cpp:255]     Train net output #0: loss = 0.00912548 (* 1 = 0.00912548 loss)
I0110 06:31:20.373757  4932 solver.cpp:631] Iteration 24880, lr = 1e-06
I0110 06:31:45.124327  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7963 > 20) by scale factor 0.877336
I0110 06:32:04.758649  4932 solver.cpp:240] Iteration 24900, loss = 0.0810373
I0110 06:32:04.758731  4932 solver.cpp:255]     Train net output #0: loss = 0.0537242 (* 1 = 0.0537242 loss)
I0110 06:32:04.758744  4932 solver.cpp:631] Iteration 24900, lr = 1e-06
I0110 06:32:25.073034  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5593 > 20) by scale factor 0.927674
I0110 06:32:49.369500  4932 solver.cpp:240] Iteration 24920, loss = 0.0755149
I0110 06:32:49.369572  4932 solver.cpp:255]     Train net output #0: loss = 0.0326201 (* 1 = 0.0326201 loss)
I0110 06:32:49.369582  4932 solver.cpp:631] Iteration 24920, lr = 1e-06
I0110 06:33:07.456735  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7451 > 20) by scale factor 0.776847
I0110 06:33:22.991016  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4806 > 20) by scale factor 0.931074
I0110 06:33:33.748575  4932 solver.cpp:240] Iteration 24940, loss = 0.0655423
I0110 06:33:33.748617  4932 solver.cpp:255]     Train net output #0: loss = 0.00869442 (* 1 = 0.00869442 loss)
I0110 06:33:33.748626  4932 solver.cpp:631] Iteration 24940, lr = 1e-06
I0110 06:34:16.241498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5236 > 20) by scale factor 0.929214
I0110 06:34:18.123508  4932 solver.cpp:240] Iteration 24960, loss = 0.0784531
I0110 06:34:18.123553  4932 solver.cpp:255]     Train net output #0: loss = 0.0505599 (* 1 = 0.0505599 loss)
I0110 06:34:18.123564  4932 solver.cpp:631] Iteration 24960, lr = 1e-06
I0110 06:34:22.903784  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8153 > 20) by scale factor 0.839798
I0110 06:35:02.502600  4932 solver.cpp:240] Iteration 24980, loss = 0.0629073
I0110 06:35:02.502689  4932 solver.cpp:255]     Train net output #0: loss = 0.0073214 (* 1 = 0.0073214 loss)
I0110 06:35:02.502701  4932 solver.cpp:631] Iteration 24980, lr = 1e-06
I0110 06:35:09.496045  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0381 > 20) by scale factor 0.768104
I0110 06:35:20.595110  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.7834 > 20) by scale factor 0.610066
I0110 06:35:42.782157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1263 > 20) by scale factor 0.946688
I0110 06:35:45.009805  4932 solver.cpp:424] Iteration 25000, Testing net (#0)
I0110 06:36:37.645422  4932 solver.cpp:481]     Test net output #0: accuracy = 0.82
I0110 06:36:37.645529  4932 solver.cpp:481]     Test net output #1: loss = 0.938283 (* 1 = 0.938283 loss)
I0110 06:36:39.513626  4932 solver.cpp:240] Iteration 25000, loss = 0.0985049
I0110 06:36:39.513670  4932 solver.cpp:255]     Train net output #0: loss = 0.117676 (* 1 = 0.117676 loss)
I0110 06:36:39.513681  4932 solver.cpp:631] Iteration 25000, lr = 1e-06
I0110 06:37:10.920281  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1341 > 20) by scale factor 0.946337
I0110 06:37:23.897436  4932 solver.cpp:240] Iteration 25020, loss = 0.0599345
I0110 06:37:23.897485  4932 solver.cpp:255]     Train net output #0: loss = 0.0943196 (* 1 = 0.0943196 loss)
I0110 06:37:23.897498  4932 solver.cpp:631] Iteration 25020, lr = 1e-06
I0110 06:37:35.333876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6156 > 20) by scale factor 0.884346
I0110 06:37:41.989192  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2378 > 20) by scale factor 0.792463
I0110 06:38:08.274488  4932 solver.cpp:240] Iteration 25040, loss = 0.0832565
I0110 06:38:08.274530  4932 solver.cpp:255]     Train net output #0: loss = 0.0024112 (* 1 = 0.0024112 loss)
I0110 06:38:08.274539  4932 solver.cpp:631] Iteration 25040, lr = 1e-06
I0110 06:38:52.661701  4932 solver.cpp:240] Iteration 25060, loss = 0.0650483
I0110 06:38:52.661808  4932 solver.cpp:255]     Train net output #0: loss = 0.017392 (* 1 = 0.017392 loss)
I0110 06:38:52.661823  4932 solver.cpp:631] Iteration 25060, lr = 1e-06
I0110 06:39:26.284498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.9176 > 20) by scale factor 0.626613
I0110 06:39:37.043215  4932 solver.cpp:240] Iteration 25080, loss = 0.0582541
I0110 06:39:37.043267  4932 solver.cpp:255]     Train net output #0: loss = 0.00221442 (* 1 = 0.00221442 loss)
I0110 06:39:37.043279  4932 solver.cpp:631] Iteration 25080, lr = 1e-06
I0110 06:40:12.887171  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1827 > 20) by scale factor 0.944165
I0110 06:40:21.425671  4932 solver.cpp:240] Iteration 25100, loss = 0.0368182
I0110 06:40:21.425714  4932 solver.cpp:255]     Train net output #0: loss = 0.0442184 (* 1 = 0.0442184 loss)
I0110 06:40:21.425725  4932 solver.cpp:631] Iteration 25100, lr = 1e-06
I0110 06:40:30.649379  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6245 > 20) by scale factor 0.969722
I0110 06:41:05.821354  4932 solver.cpp:240] Iteration 25120, loss = 0.0517031
I0110 06:41:05.821419  4932 solver.cpp:255]     Train net output #0: loss = 0.0137935 (* 1 = 0.0137935 loss)
I0110 06:41:05.821429  4932 solver.cpp:631] Iteration 25120, lr = 1e-06
I0110 06:41:50.212030  4932 solver.cpp:240] Iteration 25140, loss = 0.0663174
I0110 06:41:50.212113  4932 solver.cpp:255]     Train net output #0: loss = 0.095873 (* 1 = 0.095873 loss)
I0110 06:41:50.212123  4932 solver.cpp:631] Iteration 25140, lr = 1e-06
I0110 06:41:59.423729  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0065 > 20) by scale factor 0.869319
I0110 06:42:34.588526  4932 solver.cpp:240] Iteration 25160, loss = 0.0523797
I0110 06:42:34.588616  4932 solver.cpp:255]     Train net output #0: loss = 0.000552501 (* 1 = 0.000552501 loss)
I0110 06:42:34.588629  4932 solver.cpp:631] Iteration 25160, lr = 1e-06
I0110 06:42:48.245795  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3468 > 20) by scale factor 0.982958
I0110 06:43:08.214350  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.1351 > 20) by scale factor 0.60359
I0110 06:43:18.972584  4932 solver.cpp:240] Iteration 25180, loss = 0.077911
I0110 06:43:18.972635  4932 solver.cpp:255]     Train net output #0: loss = 0.250764 (* 1 = 0.250764 loss)
I0110 06:43:18.972652  4932 solver.cpp:631] Iteration 25180, lr = 1e-06
I0110 06:43:19.313688  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5255 > 20) by scale factor 0.974399
I0110 06:43:25.978890  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7851 > 20) by scale factor 0.694805
I0110 06:43:30.419333  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8338 > 20) by scale factor 0.805352
I0110 06:44:03.372620  4932 solver.cpp:240] Iteration 25200, loss = 0.0891498
I0110 06:44:03.372701  4932 solver.cpp:255]     Train net output #0: loss = 0.229037 (* 1 = 0.229037 loss)
I0110 06:44:03.372710  4932 solver.cpp:631] Iteration 25200, lr = 1e-06
I0110 06:44:19.247689  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7623 > 20) by scale factor 0.747321
I0110 06:44:47.762475  4932 solver.cpp:240] Iteration 25220, loss = 0.0574219
I0110 06:44:47.762552  4932 solver.cpp:255]     Train net output #0: loss = 0.0287418 (* 1 = 0.0287418 loss)
I0110 06:44:47.762563  4932 solver.cpp:631] Iteration 25220, lr = 1e-06
I0110 06:45:10.286818  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3108 > 20) by scale factor 0.732311
I0110 06:45:32.152386  4932 solver.cpp:240] Iteration 25240, loss = 0.0570209
I0110 06:45:32.152477  4932 solver.cpp:255]     Train net output #0: loss = 0.0107459 (* 1 = 0.0107459 loss)
I0110 06:45:32.152488  4932 solver.cpp:631] Iteration 25240, lr = 1e-06
I0110 06:46:16.531628  4932 solver.cpp:240] Iteration 25260, loss = 0.0609331
I0110 06:46:16.531703  4932 solver.cpp:255]     Train net output #0: loss = 0.0332133 (* 1 = 0.0332133 loss)
I0110 06:46:16.531713  4932 solver.cpp:631] Iteration 25260, lr = 1e-06
I0110 06:46:39.067245  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0113 > 20) by scale factor 0.951871
I0110 06:46:52.383364  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2791 > 20) by scale factor 0.859139
I0110 06:47:00.920035  4932 solver.cpp:240] Iteration 25280, loss = 0.0674566
I0110 06:47:00.920074  4932 solver.cpp:255]     Train net output #0: loss = 0.0112356 (* 1 = 0.0112356 loss)
I0110 06:47:00.920083  4932 solver.cpp:631] Iteration 25280, lr = 1e-06
I0110 06:47:36.766772  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 39.2075 > 20) by scale factor 0.510107
I0110 06:47:45.304438  4932 solver.cpp:240] Iteration 25300, loss = 0.0784606
I0110 06:47:45.304483  4932 solver.cpp:255]     Train net output #0: loss = 0.0121858 (* 1 = 0.0121858 loss)
I0110 06:47:45.304494  4932 solver.cpp:631] Iteration 25300, lr = 1e-06
I0110 06:48:29.687321  4932 solver.cpp:240] Iteration 25320, loss = 0.0653097
I0110 06:48:29.687417  4932 solver.cpp:255]     Train net output #0: loss = 0.000494828 (* 1 = 0.000494828 loss)
I0110 06:48:29.687432  4932 solver.cpp:631] Iteration 25320, lr = 1e-06
I0110 06:48:41.119611  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9376 > 20) by scale factor 0.668057
I0110 06:48:45.557257  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9801 > 20) by scale factor 0.909912
I0110 06:49:14.066195  4932 solver.cpp:240] Iteration 25340, loss = 0.0681814
I0110 06:49:14.066262  4932 solver.cpp:255]     Train net output #0: loss = 0.0092525 (* 1 = 0.0092525 loss)
I0110 06:49:14.066272  4932 solver.cpp:631] Iteration 25340, lr = 1e-06
I0110 06:49:21.062723  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9035 > 20) by scale factor 0.956778
I0110 06:49:47.694722  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1059 > 20) by scale factor 0.904734
I0110 06:49:52.134820  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5371 > 20) by scale factor 0.887426
I0110 06:49:54.356514  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5719 > 20) by scale factor 0.92713
I0110 06:49:58.456347  4932 solver.cpp:240] Iteration 25360, loss = 0.0681847
I0110 06:49:58.456380  4932 solver.cpp:255]     Train net output #0: loss = 0.111639 (* 1 = 0.111639 loss)
I0110 06:49:58.456389  4932 solver.cpp:631] Iteration 25360, lr = 1e-06
I0110 06:50:25.427985  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4349 > 20) by scale factor 0.89147
I0110 06:50:42.839684  4932 solver.cpp:240] Iteration 25380, loss = 0.0798316
I0110 06:50:42.839731  4932 solver.cpp:255]     Train net output #0: loss = 0.0218462 (* 1 = 0.0218462 loss)
I0110 06:50:42.839740  4932 solver.cpp:631] Iteration 25380, lr = 1e-06
I0110 06:51:20.907271  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0323 > 20) by scale factor 0.768275
I0110 06:51:27.226934  4932 solver.cpp:240] Iteration 25400, loss = 0.0475577
I0110 06:51:27.226981  4932 solver.cpp:255]     Train net output #0: loss = 0.00558595 (* 1 = 0.00558595 loss)
I0110 06:51:27.226992  4932 solver.cpp:631] Iteration 25400, lr = 1e-06
I0110 06:51:36.443960  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7683 > 20) by scale factor 0.776147
I0110 06:52:11.608742  4932 solver.cpp:240] Iteration 25420, loss = 0.0666213
I0110 06:52:11.608822  4932 solver.cpp:255]     Train net output #0: loss = 0.00219803 (* 1 = 0.00219803 loss)
I0110 06:52:11.608832  4932 solver.cpp:631] Iteration 25420, lr = 1e-06
I0110 06:52:23.046978  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5016 > 20) by scale factor 0.816275
I0110 06:52:38.586477  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6706 > 20) by scale factor 0.722788
I0110 06:52:43.025540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6779 > 20) by scale factor 0.967216
I0110 06:52:55.999783  4932 solver.cpp:240] Iteration 25440, loss = 0.0560735
I0110 06:52:55.999821  4932 solver.cpp:255]     Train net output #0: loss = 0.00567573 (* 1 = 0.00567573 loss)
I0110 06:52:55.999830  4932 solver.cpp:631] Iteration 25440, lr = 1e-06
I0110 06:53:20.743813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4198 > 20) by scale factor 0.979442
I0110 06:53:40.380429  4932 solver.cpp:240] Iteration 25460, loss = 0.0591315
I0110 06:53:40.380466  4932 solver.cpp:255]     Train net output #0: loss = 0.0104912 (* 1 = 0.0104912 loss)
I0110 06:53:40.380475  4932 solver.cpp:631] Iteration 25460, lr = 1e-06
I0110 06:53:56.251766  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3102 > 20) by scale factor 0.984727
I0110 06:54:20.666370  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1056 > 20) by scale factor 0.947617
I0110 06:54:24.765873  4932 solver.cpp:240] Iteration 25480, loss = 0.0627331
I0110 06:54:24.765915  4932 solver.cpp:255]     Train net output #0: loss = 0.280833 (* 1 = 0.280833 loss)
I0110 06:54:24.765924  4932 solver.cpp:631] Iteration 25480, lr = 1e-06
I0110 06:54:38.426432  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.345 > 20) by scale factor 0.895055
I0110 06:54:47.299639  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6121 > 20) by scale factor 0.925409
I0110 06:54:49.520869  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6689 > 20) by scale factor 0.967638
I0110 06:54:58.399441  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7654 > 20) by scale factor 0.878526
I0110 06:55:09.163125  4932 solver.cpp:240] Iteration 25500, loss = 0.0745249
I0110 06:55:09.163210  4932 solver.cpp:255]     Train net output #0: loss = 0.0157789 (* 1 = 0.0157789 loss)
I0110 06:55:09.163223  4932 solver.cpp:631] Iteration 25500, lr = 1e-06
I0110 06:55:51.669565  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8531 > 20) by scale factor 0.744793
I0110 06:55:53.553191  4932 solver.cpp:240] Iteration 25520, loss = 0.0845158
I0110 06:55:53.553238  4932 solver.cpp:255]     Train net output #0: loss = 0.000772996 (* 1 = 0.000772996 loss)
I0110 06:55:53.553251  4932 solver.cpp:631] Iteration 25520, lr = 1e-06
I0110 06:56:37.941854  4932 solver.cpp:240] Iteration 25540, loss = 0.0426758
I0110 06:56:37.941933  4932 solver.cpp:255]     Train net output #0: loss = 0.0355651 (* 1 = 0.0355651 loss)
I0110 06:56:37.941944  4932 solver.cpp:631] Iteration 25540, lr = 1e-06
I0110 06:57:00.474104  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7164 > 20) by scale factor 0.880421
I0110 06:57:22.336854  4932 solver.cpp:240] Iteration 25560, loss = 0.0776409
I0110 06:57:22.336936  4932 solver.cpp:255]     Train net output #0: loss = 0.0846718 (* 1 = 0.0846718 loss)
I0110 06:57:22.336946  4932 solver.cpp:631] Iteration 25560, lr = 1e-06
I0110 06:57:38.205734  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5109 > 20) by scale factor 0.726983
I0110 06:57:47.087154  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.287 > 20) by scale factor 0.93954
I0110 06:57:51.528863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3912 > 20) by scale factor 0.934964
I0110 06:58:06.728184  4932 solver.cpp:240] Iteration 25580, loss = 0.0884728
I0110 06:58:06.728258  4932 solver.cpp:255]     Train net output #0: loss = 0.119138 (* 1 = 0.119138 loss)
I0110 06:58:06.728269  4932 solver.cpp:631] Iteration 25580, lr = 1e-06
I0110 06:58:18.157840  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2536 > 20) by scale factor 0.987478
I0110 06:58:29.255697  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4989 > 20) by scale factor 0.93028
I0110 06:58:51.120081  4932 solver.cpp:240] Iteration 25600, loss = 0.0539833
I0110 06:58:51.120170  4932 solver.cpp:255]     Train net output #0: loss = 0.00571495 (* 1 = 0.00571495 loss)
I0110 06:58:51.120183  4932 solver.cpp:631] Iteration 25600, lr = 1e-06
I0110 06:59:00.339494  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9863 > 20) by scale factor 0.769635
I0110 06:59:26.969153  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1711 > 20) by scale factor 0.991519
I0110 06:59:35.501968  4932 solver.cpp:240] Iteration 25620, loss = 0.0820607
I0110 06:59:35.502007  4932 solver.cpp:255]     Train net output #0: loss = 0.185125 (* 1 = 0.185125 loss)
I0110 06:59:35.502022  4932 solver.cpp:631] Iteration 25620, lr = 1e-06
I0110 06:59:40.277436  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2649 > 20) by scale factor 0.898275
I0110 07:00:02.474752  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1218 > 20) by scale factor 0.765644
I0110 07:00:19.886811  4932 solver.cpp:240] Iteration 25640, loss = 0.0630035
I0110 07:00:19.886850  4932 solver.cpp:255]     Train net output #0: loss = 0.00025178 (* 1 = 0.00025178 loss)
I0110 07:00:19.886859  4932 solver.cpp:631] Iteration 25640, lr = 1e-06
I0110 07:00:29.097935  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5959 > 20) by scale factor 0.885117
I0110 07:00:31.318367  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2215 > 20) by scale factor 0.825714
I0110 07:00:35.760079  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6066 > 20) by scale factor 0.884697
I0110 07:01:00.175918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7056 > 20) by scale factor 0.778042
I0110 07:01:04.279897  4932 solver.cpp:240] Iteration 25660, loss = 0.0703116
I0110 07:01:04.279947  4932 solver.cpp:255]     Train net output #0: loss = 0.0393411 (* 1 = 0.0393411 loss)
I0110 07:01:04.280073  4932 solver.cpp:631] Iteration 25660, lr = 1e-06
I0110 07:01:48.680629  4932 solver.cpp:240] Iteration 25680, loss = 0.0379907
I0110 07:01:48.680733  4932 solver.cpp:255]     Train net output #0: loss = 0.260032 (* 1 = 0.260032 loss)
I0110 07:01:48.680749  4932 solver.cpp:631] Iteration 25680, lr = 1e-06
I0110 07:01:49.021888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7576 > 20) by scale factor 0.963502
I0110 07:01:53.466568  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7927 > 20) by scale factor 0.961877
I0110 07:02:33.068364  4932 solver.cpp:240] Iteration 25700, loss = 0.0708611
I0110 07:02:33.068470  4932 solver.cpp:255]     Train net output #0: loss = 0.00333452 (* 1 = 0.00333452 loss)
I0110 07:02:33.068485  4932 solver.cpp:631] Iteration 25700, lr = 1e-06
I0110 07:03:17.448613  4932 solver.cpp:240] Iteration 25720, loss = 0.0635656
I0110 07:03:17.448710  4932 solver.cpp:255]     Train net output #0: loss = 0.0131385 (* 1 = 0.0131385 loss)
I0110 07:03:17.448724  4932 solver.cpp:631] Iteration 25720, lr = 1e-06
I0110 07:03:48.856984  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9203 > 20) by scale factor 0.872589
I0110 07:04:01.835280  4932 solver.cpp:240] Iteration 25740, loss = 0.0562765
I0110 07:04:01.835327  4932 solver.cpp:255]     Train net output #0: loss = 0.00221288 (* 1 = 0.00221288 loss)
I0110 07:04:01.835340  4932 solver.cpp:631] Iteration 25740, lr = 1e-06
I0110 07:04:24.369833  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0411 > 20) by scale factor 0.83191
I0110 07:04:28.809600  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3798 > 20) by scale factor 0.730464
I0110 07:04:39.905172  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3602 > 20) by scale factor 0.788639
I0110 07:04:46.222123  4932 solver.cpp:240] Iteration 25760, loss = 0.0922395
I0110 07:04:46.222164  4932 solver.cpp:255]     Train net output #0: loss = 0.228494 (* 1 = 0.228494 loss)
I0110 07:04:46.222173  4932 solver.cpp:631] Iteration 25760, lr = 1e-06
I0110 07:05:30.609513  4932 solver.cpp:240] Iteration 25780, loss = 0.0507678
I0110 07:05:30.609609  4932 solver.cpp:255]     Train net output #0: loss = 0.0370702 (* 1 = 0.0370702 loss)
I0110 07:05:30.609622  4932 solver.cpp:631] Iteration 25780, lr = 1e-06
I0110 07:06:14.996740  4932 solver.cpp:240] Iteration 25800, loss = 0.0380849
I0110 07:06:14.996807  4932 solver.cpp:255]     Train net output #0: loss = 0.0228172 (* 1 = 0.0228172 loss)
I0110 07:06:14.996817  4932 solver.cpp:631] Iteration 25800, lr = 1e-06
I0110 07:06:59.382333  4932 solver.cpp:240] Iteration 25820, loss = 0.0854305
I0110 07:06:59.382419  4932 solver.cpp:255]     Train net output #0: loss = 0.285396 (* 1 = 0.285396 loss)
I0110 07:06:59.382432  4932 solver.cpp:631] Iteration 25820, lr = 1e-06
I0110 07:07:43.761911  4932 solver.cpp:240] Iteration 25840, loss = 0.0387676
I0110 07:07:43.762011  4932 solver.cpp:255]     Train net output #0: loss = 0.0025017 (* 1 = 0.0025017 loss)
I0110 07:07:43.762024  4932 solver.cpp:631] Iteration 25840, lr = 1e-06
I0110 07:08:08.511582  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2864 > 20) by scale factor 0.939567
I0110 07:08:28.151376  4932 solver.cpp:240] Iteration 25860, loss = 0.0417191
I0110 07:08:28.151453  4932 solver.cpp:255]     Train net output #0: loss = 0.252391 (* 1 = 0.252391 loss)
I0110 07:08:28.151461  4932 solver.cpp:631] Iteration 25860, lr = 1e-06
I0110 07:08:46.236742  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6266 > 20) by scale factor 0.698651
I0110 07:08:50.685844  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6751 > 20) by scale factor 0.92272
I0110 07:09:08.438032  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8586 > 20) by scale factor 0.914973
I0110 07:09:12.539783  4932 solver.cpp:240] Iteration 25880, loss = 0.104009
I0110 07:09:12.539822  4932 solver.cpp:255]     Train net output #0: loss = 0.0316457 (* 1 = 0.0316457 loss)
I0110 07:09:12.539831  4932 solver.cpp:631] Iteration 25880, lr = 1e-06
I0110 07:09:56.911320  4932 solver.cpp:240] Iteration 25900, loss = 0.0594339
I0110 07:09:56.911417  4932 solver.cpp:255]     Train net output #0: loss = 0.0014975 (* 1 = 0.0014975 loss)
I0110 07:09:56.911430  4932 solver.cpp:631] Iteration 25900, lr = 1e-06
I0110 07:10:41.303762  4932 solver.cpp:240] Iteration 25920, loss = 0.0547422
I0110 07:10:41.303836  4932 solver.cpp:255]     Train net output #0: loss = 0.188159 (* 1 = 0.188159 loss)
I0110 07:10:41.303845  4932 solver.cpp:631] Iteration 25920, lr = 1e-06
I0110 07:11:19.372673  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9178 > 20) by scale factor 0.9125
I0110 07:11:25.691577  4932 solver.cpp:240] Iteration 25940, loss = 0.0728476
I0110 07:11:25.691617  4932 solver.cpp:255]     Train net output #0: loss = 0.00618247 (* 1 = 0.00618247 loss)
I0110 07:11:25.691627  4932 solver.cpp:631] Iteration 25940, lr = 1e-06
I0110 07:11:30.468880  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4231 > 20) by scale factor 0.853859
I0110 07:11:34.914897  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6112 > 20) by scale factor 0.970345
I0110 07:11:46.014102  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7304 > 20) by scale factor 0.964767
I0110 07:12:10.084213  4932 solver.cpp:240] Iteration 25960, loss = 0.0788478
I0110 07:12:10.084303  4932 solver.cpp:255]     Train net output #0: loss = 0.0200765 (* 1 = 0.0200765 loss)
I0110 07:12:10.084316  4932 solver.cpp:631] Iteration 25960, lr = 1e-06
I0110 07:12:54.463634  4932 solver.cpp:240] Iteration 25980, loss = 0.0655479
I0110 07:12:54.463734  4932 solver.cpp:255]     Train net output #0: loss = 0.160967 (* 1 = 0.160967 loss)
I0110 07:12:54.463747  4932 solver.cpp:631] Iteration 25980, lr = 1e-06
I0110 07:12:59.245445  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2539 > 20) by scale factor 0.791956
I0110 07:13:36.965937  4932 solver.cpp:424] Iteration 26000, Testing net (#0)
I0110 07:14:29.015637  4932 solver.cpp:481]     Test net output #0: accuracy = 0.844211
I0110 07:14:29.015733  4932 solver.cpp:481]     Test net output #1: loss = 0.773383 (* 1 = 0.773383 loss)
I0110 07:14:30.886421  4932 solver.cpp:240] Iteration 26000, loss = 0.0804304
I0110 07:14:30.886467  4932 solver.cpp:255]     Train net output #0: loss = 0.0433663 (* 1 = 0.0433663 loss)
I0110 07:14:30.886479  4932 solver.cpp:631] Iteration 26000, lr = 1e-06
I0110 07:14:55.622861  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8748 > 20) by scale factor 0.914292
I0110 07:15:15.249359  4932 solver.cpp:240] Iteration 26020, loss = 0.0633154
I0110 07:15:15.249436  4932 solver.cpp:255]     Train net output #0: loss = 0.00685105 (* 1 = 0.00685105 loss)
I0110 07:15:15.249445  4932 solver.cpp:631] Iteration 26020, lr = 1e-06
I0110 07:15:28.903278  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4517 > 20) by scale factor 0.785801
I0110 07:15:48.875473  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1779 > 20) by scale factor 0.709775
I0110 07:15:51.100131  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4369 > 20) by scale factor 0.756519
I0110 07:15:59.639266  4932 solver.cpp:240] Iteration 26040, loss = 0.0749519
I0110 07:15:59.639297  4932 solver.cpp:255]     Train net output #0: loss = 0.00622188 (* 1 = 0.00622188 loss)
I0110 07:15:59.639307  4932 solver.cpp:631] Iteration 26040, lr = 1e-06
I0110 07:16:44.004367  4932 solver.cpp:240] Iteration 26060, loss = 0.0419634
I0110 07:16:44.004456  4932 solver.cpp:255]     Train net output #0: loss = 0.00399997 (* 1 = 0.00399997 loss)
I0110 07:16:44.004468  4932 solver.cpp:631] Iteration 26060, lr = 1e-06
I0110 07:16:51.005496  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9662 > 20) by scale factor 0.953915
I0110 07:17:15.405673  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6149 > 20) by scale factor 0.925288
I0110 07:17:28.382395  4932 solver.cpp:240] Iteration 26080, loss = 0.0556376
I0110 07:17:28.382434  4932 solver.cpp:255]     Train net output #0: loss = 0.1203 (* 1 = 0.1203 loss)
I0110 07:17:28.382442  4932 solver.cpp:631] Iteration 26080, lr = 1e-06
I0110 07:17:28.721488  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3198 > 20) by scale factor 0.938096
I0110 07:17:48.694881  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.686 > 20) by scale factor 0.881603
I0110 07:18:12.764776  4932 solver.cpp:240] Iteration 26100, loss = 0.0806782
I0110 07:18:12.764819  4932 solver.cpp:255]     Train net output #0: loss = 0.0123781 (* 1 = 0.0123781 loss)
I0110 07:18:12.764840  4932 solver.cpp:631] Iteration 26100, lr = 1e-06
I0110 07:18:53.042481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2855 > 20) by scale factor 0.73299
I0110 07:18:57.143652  4932 solver.cpp:240] Iteration 26120, loss = 0.0657231
I0110 07:18:57.143692  4932 solver.cpp:255]     Train net output #0: loss = 0.00530151 (* 1 = 0.00530151 loss)
I0110 07:18:57.143700  4932 solver.cpp:631] Iteration 26120, lr = 1e-06
I0110 07:19:04.136852  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8132 > 20) by scale factor 0.745901
I0110 07:19:13.015002  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3224 > 20) by scale factor 0.93798
I0110 07:19:15.235723  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0003 > 20) by scale factor 0.833323
I0110 07:19:17.456601  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6554 > 20) by scale factor 0.811181
I0110 07:19:24.115320  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5313 > 20) by scale factor 0.974122
I0110 07:19:41.526187  4932 solver.cpp:240] Iteration 26140, loss = 0.113652
I0110 07:19:41.526228  4932 solver.cpp:255]     Train net output #0: loss = 0.144728 (* 1 = 0.144728 loss)
I0110 07:19:41.526238  4932 solver.cpp:631] Iteration 26140, lr = 1e-06
I0110 07:19:57.397786  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5072 > 20) by scale factor 0.975265
I0110 07:20:04.054002  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3332 > 20) by scale factor 0.821923
I0110 07:20:06.274673  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7744 > 20) by scale factor 0.878179
I0110 07:20:15.151346  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9616 > 20) by scale factor 0.910681
I0110 07:20:25.906262  4932 solver.cpp:240] Iteration 26160, loss = 0.105063
I0110 07:20:25.906301  4932 solver.cpp:255]     Train net output #0: loss = 0.0104317 (* 1 = 0.0104317 loss)
I0110 07:20:25.906309  4932 solver.cpp:631] Iteration 26160, lr = 1e-06
I0110 07:20:30.684097  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5355 > 20) by scale factor 0.753706
I0110 07:20:52.871321  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8494 > 20) by scale factor 0.875297
I0110 07:21:10.280586  4932 solver.cpp:240] Iteration 26180, loss = 0.077464
I0110 07:21:10.280665  4932 solver.cpp:255]     Train net output #0: loss = 0.0742049 (* 1 = 0.0742049 loss)
I0110 07:21:10.280674  4932 solver.cpp:631] Iteration 26180, lr = 1e-06
I0110 07:21:41.680426  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.392 > 20) by scale factor 0.704423
I0110 07:21:54.656141  4932 solver.cpp:240] Iteration 26200, loss = 0.0658348
I0110 07:21:54.656196  4932 solver.cpp:255]     Train net output #0: loss = 0.00102271 (* 1 = 0.00102271 loss)
I0110 07:21:54.656211  4932 solver.cpp:631] Iteration 26200, lr = 1e-06
I0110 07:21:57.218082  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7591 > 20) by scale factor 0.841784
I0110 07:22:12.748466  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9941 > 20) by scale factor 0.869787
I0110 07:22:23.849517  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1969 > 20) by scale factor 0.901028
I0110 07:22:30.505867  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4627 > 20) by scale factor 0.890364
I0110 07:22:39.046015  4932 solver.cpp:240] Iteration 26220, loss = 0.0774867
I0110 07:22:39.046061  4932 solver.cpp:255]     Train net output #0: loss = 0.00360196 (* 1 = 0.00360196 loss)
I0110 07:22:39.046072  4932 solver.cpp:631] Iteration 26220, lr = 1e-06
I0110 07:23:10.450094  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0686 > 20) by scale factor 0.906266
I0110 07:23:23.425499  4932 solver.cpp:240] Iteration 26240, loss = 0.0655533
I0110 07:23:23.425540  4932 solver.cpp:255]     Train net output #0: loss = 0.000648314 (* 1 = 0.000648314 loss)
I0110 07:23:23.425551  4932 solver.cpp:631] Iteration 26240, lr = 1e-06
I0110 07:24:07.801525  4932 solver.cpp:240] Iteration 26260, loss = 0.0914532
I0110 07:24:07.801601  4932 solver.cpp:255]     Train net output #0: loss = 0.258648 (* 1 = 0.258648 loss)
I0110 07:24:07.801611  4932 solver.cpp:631] Iteration 26260, lr = 1e-06
I0110 07:24:23.679177  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4452 > 20) by scale factor 0.891058
I0110 07:24:34.777127  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6253 > 20) by scale factor 0.723975
I0110 07:24:45.872026  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7201 > 20) by scale factor 0.920804
I0110 07:24:50.311744  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9802 > 20) by scale factor 0.769816
I0110 07:24:52.193083  4932 solver.cpp:240] Iteration 26280, loss = 0.0631015
I0110 07:24:52.193114  4932 solver.cpp:255]     Train net output #0: loss = 0.0559389 (* 1 = 0.0559389 loss)
I0110 07:24:52.193122  4932 solver.cpp:631] Iteration 26280, lr = 1e-06
I0110 07:24:54.750234  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.0772 > 20) by scale factor 0.623496
I0110 07:25:10.281584  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1156 > 20) by scale factor 0.994252
I0110 07:25:36.578058  4932 solver.cpp:240] Iteration 26300, loss = 0.073256
I0110 07:25:36.578125  4932 solver.cpp:255]     Train net output #0: loss = 0.223208 (* 1 = 0.223208 loss)
I0110 07:25:36.578135  4932 solver.cpp:631] Iteration 26300, lr = 1e-06
I0110 07:25:45.792873  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1882 > 20) by scale factor 0.901379
I0110 07:26:01.336088  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2785 > 20) by scale factor 0.791187
I0110 07:26:20.979452  4932 solver.cpp:240] Iteration 26320, loss = 0.0751515
I0110 07:26:20.979542  4932 solver.cpp:255]     Train net output #0: loss = 0.105978 (* 1 = 0.105978 loss)
I0110 07:26:20.979553  4932 solver.cpp:631] Iteration 26320, lr = 1e-06
I0110 07:26:30.201107  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5245 > 20) by scale factor 0.701151
I0110 07:27:05.390790  4932 solver.cpp:240] Iteration 26340, loss = 0.109982
I0110 07:27:05.390866  4932 solver.cpp:255]     Train net output #0: loss = 0.321939 (* 1 = 0.321939 loss)
I0110 07:27:05.390878  4932 solver.cpp:631] Iteration 26340, lr = 1e-06
I0110 07:27:49.761595  4932 solver.cpp:240] Iteration 26360, loss = 0.0348567
I0110 07:27:49.761673  4932 solver.cpp:255]     Train net output #0: loss = 0.0608341 (* 1 = 0.0608341 loss)
I0110 07:27:49.761684  4932 solver.cpp:631] Iteration 26360, lr = 1e-06
I0110 07:28:34.132853  4932 solver.cpp:240] Iteration 26380, loss = 0.0390393
I0110 07:28:34.132922  4932 solver.cpp:255]     Train net output #0: loss = 0.0367987 (* 1 = 0.0367987 loss)
I0110 07:28:34.132932  4932 solver.cpp:631] Iteration 26380, lr = 1e-06
I0110 07:29:18.504957  4932 solver.cpp:240] Iteration 26400, loss = 0.063628
I0110 07:29:18.505028  4932 solver.cpp:255]     Train net output #0: loss = 0.0658324 (* 1 = 0.0658324 loss)
I0110 07:29:18.505038  4932 solver.cpp:631] Iteration 26400, lr = 1e-06
I0110 07:30:02.885258  4932 solver.cpp:240] Iteration 26420, loss = 0.0681803
I0110 07:30:02.885334  4932 solver.cpp:255]     Train net output #0: loss = 0.0629727 (* 1 = 0.0629727 loss)
I0110 07:30:02.885344  4932 solver.cpp:631] Iteration 26420, lr = 1e-06
I0110 07:30:30.094785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2639 > 20) by scale factor 0.940563
I0110 07:30:36.755918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4352 > 20) by scale factor 0.933043
I0110 07:30:49.730584  4932 solver.cpp:240] Iteration 26440, loss = 0.0694447
I0110 07:30:49.730633  4932 solver.cpp:255]     Train net output #0: loss = 0.00925986 (* 1 = 0.00925986 loss)
I0110 07:30:49.730643  4932 solver.cpp:631] Iteration 26440, lr = 1e-06
I0110 07:31:34.105731  4932 solver.cpp:240] Iteration 26460, loss = 0.0315869
I0110 07:31:34.105796  4932 solver.cpp:255]     Train net output #0: loss = 0.0483916 (* 1 = 0.0483916 loss)
I0110 07:31:34.105806  4932 solver.cpp:631] Iteration 26460, lr = 1e-06
I0110 07:31:36.668658  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4386 > 20) by scale factor 0.818378
I0110 07:31:47.769562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5827 > 20) by scale factor 0.699725
I0110 07:31:49.990442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6248 > 20) by scale factor 0.883988
I0110 07:32:18.501811  4932 solver.cpp:240] Iteration 26480, loss = 0.102254
I0110 07:32:18.501883  4932 solver.cpp:255]     Train net output #0: loss = 0.0279373 (* 1 = 0.0279373 loss)
I0110 07:32:18.501893  4932 solver.cpp:631] Iteration 26480, lr = 1e-06
I0110 07:33:01.002056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1207 > 20) by scale factor 0.904131
I0110 07:33:02.885355  4932 solver.cpp:240] Iteration 26500, loss = 0.0505018
I0110 07:33:02.885413  4932 solver.cpp:255]     Train net output #0: loss = 0.00226242 (* 1 = 0.00226242 loss)
I0110 07:33:02.885545  4932 solver.cpp:631] Iteration 26500, lr = 1e-06
I0110 07:33:27.638020  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0439 > 20) by scale factor 0.997811
I0110 07:33:29.859056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5481 > 20) by scale factor 0.814726
I0110 07:33:47.278789  4932 solver.cpp:240] Iteration 26520, loss = 0.079301
I0110 07:33:47.278872  4932 solver.cpp:255]     Train net output #0: loss = 0.00984032 (* 1 = 0.00984032 loss)
I0110 07:33:47.278883  4932 solver.cpp:631] Iteration 26520, lr = 1e-06
I0110 07:34:25.355623  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9215 > 20) by scale factor 0.955956
I0110 07:34:31.680497  4932 solver.cpp:240] Iteration 26540, loss = 0.0575286
I0110 07:34:31.680536  4932 solver.cpp:255]     Train net output #0: loss = 0.00106274 (* 1 = 0.00106274 loss)
I0110 07:34:31.680546  4932 solver.cpp:631] Iteration 26540, lr = 1e-06
I0110 07:34:49.774278  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5934 > 20) by scale factor 0.847695
I0110 07:35:37.068716  4932 solver.cpp:240] Iteration 26560, loss = 0.0614497
I0110 07:35:37.068792  4932 solver.cpp:255]     Train net output #0: loss = 0.0170388 (* 1 = 0.0170388 loss)
I0110 07:35:37.068802  4932 solver.cpp:631] Iteration 26560, lr = 1e-06
I0110 07:36:21.442036  4932 solver.cpp:240] Iteration 26580, loss = 0.0566301
I0110 07:36:21.442116  4932 solver.cpp:255]     Train net output #0: loss = 0.0437184 (* 1 = 0.0437184 loss)
I0110 07:36:21.442126  4932 solver.cpp:631] Iteration 26580, lr = 1e-06
I0110 07:36:32.878371  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3149 > 20) by scale factor 0.85782
I0110 07:37:05.830065  4932 solver.cpp:240] Iteration 26600, loss = 0.0636351
I0110 07:37:05.830140  4932 solver.cpp:255]     Train net output #0: loss = 0.0512491 (* 1 = 0.0512491 loss)
I0110 07:37:05.830152  4932 solver.cpp:631] Iteration 26600, lr = 1e-06
I0110 07:37:23.921157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2003 > 20) by scale factor 0.943383
I0110 07:37:41.678069  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8545 > 20) by scale factor 0.77356
I0110 07:37:50.215440  4932 solver.cpp:240] Iteration 26620, loss = 0.0438739
I0110 07:37:50.215484  4932 solver.cpp:255]     Train net output #0: loss = 0.0111783 (* 1 = 0.0111783 loss)
I0110 07:37:50.215497  4932 solver.cpp:631] Iteration 26620, lr = 1e-06
I0110 07:38:34.595898  4932 solver.cpp:240] Iteration 26640, loss = 0.0610883
I0110 07:38:34.595991  4932 solver.cpp:255]     Train net output #0: loss = 0.363902 (* 1 = 0.363902 loss)
I0110 07:38:34.596004  4932 solver.cpp:631] Iteration 26640, lr = 1e-06
I0110 07:38:34.935135  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8743 > 20) by scale factor 0.744204
I0110 07:38:39.374888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9865 > 20) by scale factor 0.870076
I0110 07:39:18.981422  4932 solver.cpp:240] Iteration 26660, loss = 0.0859041
I0110 07:39:18.981487  4932 solver.cpp:255]     Train net output #0: loss = 0.0016955 (* 1 = 0.0016955 loss)
I0110 07:39:18.981495  4932 solver.cpp:631] Iteration 26660, lr = 1e-06
I0110 07:39:39.297574  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7379 > 20) by scale factor 0.964419
I0110 07:40:03.372638  4932 solver.cpp:240] Iteration 26680, loss = 0.042215
I0110 07:40:03.372715  4932 solver.cpp:255]     Train net output #0: loss = 0.144925 (* 1 = 0.144925 loss)
I0110 07:40:03.372725  4932 solver.cpp:631] Iteration 26680, lr = 1e-06
I0110 07:40:37.000959  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6407 > 20) by scale factor 0.924184
I0110 07:40:47.756556  4932 solver.cpp:240] Iteration 26700, loss = 0.0613626
I0110 07:40:47.756603  4932 solver.cpp:255]     Train net output #0: loss = 0.0613364 (* 1 = 0.0613364 loss)
I0110 07:40:47.756613  4932 solver.cpp:631] Iteration 26700, lr = 1e-06
I0110 07:41:32.129084  4932 solver.cpp:240] Iteration 26720, loss = 0.0385728
I0110 07:41:32.129184  4932 solver.cpp:255]     Train net output #0: loss = 0.0448584 (* 1 = 0.0448584 loss)
I0110 07:41:32.129196  4932 solver.cpp:631] Iteration 26720, lr = 1e-06
I0110 07:42:16.502079  4932 solver.cpp:240] Iteration 26740, loss = 0.0636577
I0110 07:42:16.502172  4932 solver.cpp:255]     Train net output #0: loss = 0.089576 (* 1 = 0.089576 loss)
I0110 07:42:16.502184  4932 solver.cpp:631] Iteration 26740, lr = 1e-06
I0110 07:43:00.879745  4932 solver.cpp:240] Iteration 26760, loss = 0.0596325
I0110 07:43:00.879839  4932 solver.cpp:255]     Train net output #0: loss = 0.00813892 (* 1 = 0.00813892 loss)
I0110 07:43:00.879851  4932 solver.cpp:631] Iteration 26760, lr = 1e-06
I0110 07:43:16.748644  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7108 > 20) by scale factor 0.777884
I0110 07:43:36.719080  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3596 > 20) by scale factor 0.821033
I0110 07:43:45.254812  4932 solver.cpp:240] Iteration 26780, loss = 0.0757169
I0110 07:43:45.254853  4932 solver.cpp:255]     Train net output #0: loss = 0.0111865 (* 1 = 0.0111865 loss)
I0110 07:43:45.254861  4932 solver.cpp:631] Iteration 26780, lr = 1e-06
I0110 07:44:29.638774  4932 solver.cpp:240] Iteration 26800, loss = 0.0794438
I0110 07:44:29.638870  4932 solver.cpp:255]     Train net output #0: loss = 0.361154 (* 1 = 0.361154 loss)
I0110 07:44:29.638880  4932 solver.cpp:631] Iteration 26800, lr = 1e-06
I0110 07:44:29.978071  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8841 > 20) by scale factor 0.803725
I0110 07:45:09.920279  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5562 > 20) by scale factor 0.927809
I0110 07:45:14.021179  4932 solver.cpp:240] Iteration 26820, loss = 0.0822528
I0110 07:45:14.021220  4932 solver.cpp:255]     Train net output #0: loss = 0.0309794 (* 1 = 0.0309794 loss)
I0110 07:45:14.021229  4932 solver.cpp:631] Iteration 26820, lr = 1e-06
I0110 07:45:16.578579  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7781 > 20) by scale factor 0.918354
I0110 07:45:58.388146  4932 solver.cpp:240] Iteration 26840, loss = 0.0697354
I0110 07:45:58.388236  4932 solver.cpp:255]     Train net output #0: loss = 0.000120078 (* 1 = 0.000120078 loss)
I0110 07:45:58.388248  4932 solver.cpp:631] Iteration 26840, lr = 1e-06
I0110 07:46:42.765135  4932 solver.cpp:240] Iteration 26860, loss = 0.0375781
I0110 07:46:42.765231  4932 solver.cpp:255]     Train net output #0: loss = 0.00304026 (* 1 = 0.00304026 loss)
I0110 07:46:42.765245  4932 solver.cpp:631] Iteration 26860, lr = 1e-06
I0110 07:47:05.290282  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0452 > 20) by scale factor 0.907225
I0110 07:47:14.165936  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1864 > 20) by scale factor 0.901453
I0110 07:47:27.141676  4932 solver.cpp:240] Iteration 26880, loss = 0.0527989
I0110 07:47:27.141717  4932 solver.cpp:255]     Train net output #0: loss = 0.0133567 (* 1 = 0.0133567 loss)
I0110 07:47:27.141727  4932 solver.cpp:631] Iteration 26880, lr = 1e-06
I0110 07:47:38.574597  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0659 > 20) by scale factor 0.9494
I0110 07:48:05.203716  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2618 > 20) by scale factor 0.82434
I0110 07:48:11.522734  4932 solver.cpp:240] Iteration 26900, loss = 0.0730231
I0110 07:48:11.522771  4932 solver.cpp:255]     Train net output #0: loss = 0.0140496 (* 1 = 0.0140496 loss)
I0110 07:48:11.522783  4932 solver.cpp:631] Iteration 26900, lr = 1e-06
I0110 07:48:55.898123  4932 solver.cpp:240] Iteration 26920, loss = 0.0456868
I0110 07:48:55.898195  4932 solver.cpp:255]     Train net output #0: loss = 0.0739719 (* 1 = 0.0739719 loss)
I0110 07:48:55.898206  4932 solver.cpp:631] Iteration 26920, lr = 1e-06
I0110 07:49:29.520164  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0937 > 20) by scale factor 0.995336
I0110 07:49:38.395442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0288 > 20) by scale factor 0.998561
I0110 07:49:40.276537  4932 solver.cpp:240] Iteration 26940, loss = 0.0688431
I0110 07:49:40.276581  4932 solver.cpp:255]     Train net output #0: loss = 0.0655307 (* 1 = 0.0655307 loss)
I0110 07:49:40.276592  4932 solver.cpp:631] Iteration 26940, lr = 1e-06
I0110 07:50:24.656289  4932 solver.cpp:240] Iteration 26960, loss = 0.0817889
I0110 07:50:24.656368  4932 solver.cpp:255]     Train net output #0: loss = 0.0787555 (* 1 = 0.0787555 loss)
I0110 07:50:24.656376  4932 solver.cpp:631] Iteration 26960, lr = 1e-06
I0110 07:50:27.212491  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0503 > 20) by scale factor 0.867667
I0110 07:50:29.432899  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7372 > 20) by scale factor 0.879618
I0110 07:50:31.654904  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0609 > 20) by scale factor 0.906583
I0110 07:50:51.624349  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1982 > 20) by scale factor 0.763412
I0110 07:51:00.504851  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8571 > 20) by scale factor 0.958907
I0110 07:51:09.041808  4932 solver.cpp:240] Iteration 26980, loss = 0.0629697
I0110 07:51:09.041856  4932 solver.cpp:255]     Train net output #0: loss = 0.0258678 (* 1 = 0.0258678 loss)
I0110 07:51:09.041872  4932 solver.cpp:631] Iteration 26980, lr = 1e-06
I0110 07:51:42.665298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2168 > 20) by scale factor 0.989277
I0110 07:51:51.550278  4932 solver.cpp:424] Iteration 27000, Testing net (#0)
I0110 07:52:44.740952  4932 solver.cpp:481]     Test net output #0: accuracy = 0.845263
I0110 07:52:44.741051  4932 solver.cpp:481]     Test net output #1: loss = 0.745199 (* 1 = 0.745199 loss)
I0110 07:52:46.608563  4932 solver.cpp:240] Iteration 27000, loss = 0.0577929
I0110 07:52:46.608600  4932 solver.cpp:255]     Train net output #0: loss = 0.012749 (* 1 = 0.012749 loss)
I0110 07:52:46.608609  4932 solver.cpp:631] Iteration 27000, lr = 1e-06
I0110 07:53:18.009515  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3333 > 20) by scale factor 0.759494
I0110 07:53:20.231390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8423 > 20) by scale factor 0.773925
I0110 07:53:22.451934  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.254 > 20) by scale factor 0.76179
I0110 07:53:30.986557  4932 solver.cpp:240] Iteration 27020, loss = 0.100571
I0110 07:53:30.986596  4932 solver.cpp:255]     Train net output #0: loss = 0.0696249 (* 1 = 0.0696249 loss)
I0110 07:53:30.986604  4932 solver.cpp:631] Iteration 27020, lr = 1e-06
I0110 07:54:15.359911  4932 solver.cpp:240] Iteration 27040, loss = 0.0412415
I0110 07:54:15.360007  4932 solver.cpp:255]     Train net output #0: loss = 0.0118599 (* 1 = 0.0118599 loss)
I0110 07:54:15.360019  4932 solver.cpp:631] Iteration 27040, lr = 1e-06
I0110 07:54:35.670984  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7267 > 20) by scale factor 0.964938
I0110 07:54:59.742488  4932 solver.cpp:240] Iteration 27060, loss = 0.0505683
I0110 07:54:59.742557  4932 solver.cpp:255]     Train net output #0: loss = 0.0727202 (* 1 = 0.0727202 loss)
I0110 07:54:59.742566  4932 solver.cpp:631] Iteration 27060, lr = 1e-06
I0110 07:55:13.393667  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3943 > 20) by scale factor 0.893086
I0110 07:55:35.585748  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2386 > 20) by scale factor 0.762235
I0110 07:55:44.125031  4932 solver.cpp:240] Iteration 27080, loss = 0.0644611
I0110 07:55:44.125068  4932 solver.cpp:255]     Train net output #0: loss = 0.00909742 (* 1 = 0.00909742 loss)
I0110 07:55:44.125077  4932 solver.cpp:631] Iteration 27080, lr = 1e-06
I0110 07:56:28.500267  4932 solver.cpp:240] Iteration 27100, loss = 0.0487421
I0110 07:56:28.500345  4932 solver.cpp:255]     Train net output #0: loss = 0.0102603 (* 1 = 0.0102603 loss)
I0110 07:56:28.500357  4932 solver.cpp:631] Iteration 27100, lr = 1e-06
I0110 07:56:31.062094  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2703 > 20) by scale factor 0.761315
I0110 07:57:12.887816  4932 solver.cpp:240] Iteration 27120, loss = 0.0319383
I0110 07:57:12.887889  4932 solver.cpp:255]     Train net output #0: loss = 0.0206702 (* 1 = 0.0206702 loss)
I0110 07:57:12.887898  4932 solver.cpp:631] Iteration 27120, lr = 1e-06
I0110 07:57:39.846892  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7843 > 20) by scale factor 0.877797
I0110 07:57:57.257962  4932 solver.cpp:240] Iteration 27140, loss = 0.0628932
I0110 07:57:57.258033  4932 solver.cpp:255]     Train net output #0: loss = 0.0200799 (* 1 = 0.0200799 loss)
I0110 07:57:57.258041  4932 solver.cpp:631] Iteration 27140, lr = 1e-06
I0110 07:58:41.632345  4932 solver.cpp:240] Iteration 27160, loss = 0.0331453
I0110 07:58:41.632434  4932 solver.cpp:255]     Train net output #0: loss = 0.0695348 (* 1 = 0.0695348 loss)
I0110 07:58:41.632447  4932 solver.cpp:631] Iteration 27160, lr = 1e-06
I0110 07:58:53.064816  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6456 > 20) by scale factor 0.923976
I0110 07:58:57.502748  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2978 > 20) by scale factor 0.706769
I0110 07:59:26.008986  4932 solver.cpp:240] Iteration 27180, loss = 0.0594772
I0110 07:59:26.009069  4932 solver.cpp:255]     Train net output #0: loss = 0.0440232 (* 1 = 0.0440232 loss)
I0110 07:59:26.009079  4932 solver.cpp:631] Iteration 27180, lr = 1e-06
I0110 07:59:50.751929  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2378 > 20) by scale factor 0.89937
I0110 08:00:10.385049  4932 solver.cpp:240] Iteration 27200, loss = 0.0852348
I0110 08:00:10.385126  4932 solver.cpp:255]     Train net output #0: loss = 0.198994 (* 1 = 0.198994 loss)
I0110 08:00:10.385135  4932 solver.cpp:631] Iteration 27200, lr = 1e-06
I0110 08:00:10.724016  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4215 > 20) by scale factor 0.853916
I0110 08:00:30.692284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5896 > 20) by scale factor 0.724912
I0110 08:00:54.758163  4932 solver.cpp:240] Iteration 27220, loss = 0.0713388
I0110 08:00:54.758260  4932 solver.cpp:255]     Train net output #0: loss = 0.117371 (* 1 = 0.117371 loss)
I0110 08:00:54.758268  4932 solver.cpp:631] Iteration 27220, lr = 1e-06
I0110 08:01:06.194926  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4104 > 20) by scale factor 0.65767
I0110 08:01:12.850888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3413 > 20) by scale factor 0.789224
I0110 08:01:21.733224  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8583 > 20) by scale factor 0.74465
I0110 08:01:35.041311  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.3612 > 20) by scale factor 0.618024
I0110 08:01:39.139871  4932 solver.cpp:240] Iteration 27240, loss = 0.116348
I0110 08:01:39.139909  4932 solver.cpp:255]     Train net output #0: loss = 0.0322074 (* 1 = 0.0322074 loss)
I0110 08:01:39.139916  4932 solver.cpp:631] Iteration 27240, lr = 1e-06
I0110 08:01:41.697902  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9727 > 20) by scale factor 0.77004
I0110 08:02:23.519421  4932 solver.cpp:240] Iteration 27260, loss = 0.0633545
I0110 08:02:23.519511  4932 solver.cpp:255]     Train net output #0: loss = 0.188402 (* 1 = 0.188402 loss)
I0110 08:02:23.519525  4932 solver.cpp:631] Iteration 27260, lr = 1e-06
I0110 08:02:34.950381  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2005 > 20) by scale factor 0.990073
I0110 08:02:54.924638  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6063 > 20) by scale factor 0.925655
I0110 08:03:07.901623  4932 solver.cpp:240] Iteration 27280, loss = 0.0692641
I0110 08:03:07.901662  4932 solver.cpp:255]     Train net output #0: loss = 0.0045831 (* 1 = 0.0045831 loss)
I0110 08:03:07.901671  4932 solver.cpp:631] Iteration 27280, lr = 1e-06
I0110 08:03:52.275677  4932 solver.cpp:240] Iteration 27300, loss = 0.067326
I0110 08:03:52.275743  4932 solver.cpp:255]     Train net output #0: loss = 0.147511 (* 1 = 0.147511 loss)
I0110 08:03:52.275751  4932 solver.cpp:631] Iteration 27300, lr = 1e-06
I0110 08:04:36.657430  4932 solver.cpp:240] Iteration 27320, loss = 0.0560578
I0110 08:04:36.657500  4932 solver.cpp:255]     Train net output #0: loss = 0.234555 (* 1 = 0.234555 loss)
I0110 08:04:36.657508  4932 solver.cpp:631] Iteration 27320, lr = 1e-06
I0110 08:04:52.807646  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2533 > 20) by scale factor 0.987495
I0110 08:05:08.340817  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7934 > 20) by scale factor 0.746451
I0110 08:05:21.314949  4932 solver.cpp:240] Iteration 27340, loss = 0.0727655
I0110 08:05:21.314982  4932 solver.cpp:255]     Train net output #0: loss = 0.169146 (* 1 = 0.169146 loss)
I0110 08:05:21.314990  4932 solver.cpp:631] Iteration 27340, lr = 1e-06
I0110 08:05:32.747452  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4569 > 20) by scale factor 0.852627
I0110 08:05:43.845656  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0305 > 20) by scale factor 0.951001
I0110 08:06:05.694586  4932 solver.cpp:240] Iteration 27360, loss = 0.0552311
I0110 08:06:05.694631  4932 solver.cpp:255]     Train net output #0: loss = 0.0162938 (* 1 = 0.0162938 loss)
I0110 08:06:05.694757  4932 solver.cpp:631] Iteration 27360, lr = 1e-06
I0110 08:06:50.087116  4932 solver.cpp:240] Iteration 27380, loss = 0.0429204
I0110 08:06:50.087193  4932 solver.cpp:255]     Train net output #0: loss = 0.0973799 (* 1 = 0.0973799 loss)
I0110 08:06:50.087203  4932 solver.cpp:631] Iteration 27380, lr = 1e-06
I0110 08:07:34.462924  4932 solver.cpp:240] Iteration 27400, loss = 0.0645862
I0110 08:07:34.463006  4932 solver.cpp:255]     Train net output #0: loss = 0.0156423 (* 1 = 0.0156423 loss)
I0110 08:07:34.463017  4932 solver.cpp:631] Iteration 27400, lr = 1e-06
I0110 08:07:43.676601  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5071 > 20) by scale factor 0.754514
I0110 08:08:03.652704  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2804 > 20) by scale factor 0.986175
I0110 08:08:18.840142  4932 solver.cpp:240] Iteration 27420, loss = 0.0661368
I0110 08:08:18.840271  4932 solver.cpp:255]     Train net output #0: loss = 0.0249405 (* 1 = 0.0249405 loss)
I0110 08:08:18.840288  4932 solver.cpp:631] Iteration 27420, lr = 1e-06
I0110 08:09:03.218103  4932 solver.cpp:240] Iteration 27440, loss = 0.0330596
I0110 08:09:03.218166  4932 solver.cpp:255]     Train net output #0: loss = 0.0187127 (* 1 = 0.0187127 loss)
I0110 08:09:03.218178  4932 solver.cpp:631] Iteration 27440, lr = 1e-06
I0110 08:09:47.592747  4932 solver.cpp:240] Iteration 27460, loss = 0.045089
I0110 08:09:47.592836  4932 solver.cpp:255]     Train net output #0: loss = 0.0748859 (* 1 = 0.0748859 loss)
I0110 08:09:47.592849  4932 solver.cpp:631] Iteration 27460, lr = 1e-06
I0110 08:10:16.767663  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4587 > 20) by scale factor 0.932021
I0110 08:10:31.956624  4932 solver.cpp:240] Iteration 27480, loss = 0.0450496
I0110 08:10:31.956698  4932 solver.cpp:255]     Train net output #0: loss = 0.00126878 (* 1 = 0.00126878 loss)
I0110 08:10:31.956707  4932 solver.cpp:631] Iteration 27480, lr = 1e-06
I0110 08:10:43.389080  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1236 > 20) by scale factor 0.904011
I0110 08:11:01.138977  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4392 > 20) by scale factor 0.818359
I0110 08:11:07.799929  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6102 > 20) by scale factor 0.970394
I0110 08:11:16.336192  4932 solver.cpp:240] Iteration 27500, loss = 0.0965772
I0110 08:11:16.336232  4932 solver.cpp:255]     Train net output #0: loss = 0.00100881 (* 1 = 0.00100881 loss)
I0110 08:11:16.336249  4932 solver.cpp:631] Iteration 27500, lr = 1e-06
I0110 08:11:18.893218  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6704 > 20) by scale factor 0.81069
I0110 08:11:27.770120  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7848 > 20) by scale factor 0.962242
I0110 08:11:58.840265  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8107 > 20) by scale factor 0.745972
I0110 08:12:00.721815  4932 solver.cpp:240] Iteration 27520, loss = 0.0581684
I0110 08:12:00.721861  4932 solver.cpp:255]     Train net output #0: loss = 0.015501 (* 1 = 0.015501 loss)
I0110 08:12:00.721871  4932 solver.cpp:631] Iteration 27520, lr = 1e-06
I0110 08:12:45.094900  4932 solver.cpp:240] Iteration 27540, loss = 0.0703597
I0110 08:12:45.094980  4932 solver.cpp:255]     Train net output #0: loss = 0.0562679 (* 1 = 0.0562679 loss)
I0110 08:12:45.094992  4932 solver.cpp:631] Iteration 27540, lr = 1e-06
I0110 08:13:07.628597  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0859 > 20) by scale factor 0.830361
I0110 08:13:29.485425  4932 solver.cpp:240] Iteration 27560, loss = 0.0567039
I0110 08:13:29.485484  4932 solver.cpp:255]     Train net output #0: loss = 0.0242618 (* 1 = 0.0242618 loss)
I0110 08:13:29.485494  4932 solver.cpp:631] Iteration 27560, lr = 1e-06
I0110 08:14:13.863600  4932 solver.cpp:240] Iteration 27580, loss = 0.0917387
I0110 08:14:13.863659  4932 solver.cpp:255]     Train net output #0: loss = 0.198029 (* 1 = 0.198029 loss)
I0110 08:14:13.863668  4932 solver.cpp:631] Iteration 27580, lr = 1e-06
I0110 08:14:14.202769  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3074 > 20) by scale factor 0.858097
I0110 08:14:56.370601  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3518 > 20) by scale factor 0.982716
I0110 08:14:58.251667  4932 solver.cpp:240] Iteration 27600, loss = 0.0794559
I0110 08:14:58.251708  4932 solver.cpp:255]     Train net output #0: loss = 0.0865284 (* 1 = 0.0865284 loss)
I0110 08:14:58.251718  4932 solver.cpp:631] Iteration 27600, lr = 1e-06
I0110 08:15:42.638958  4932 solver.cpp:240] Iteration 27620, loss = 0.0550906
I0110 08:15:42.639070  4932 solver.cpp:255]     Train net output #0: loss = 0.00451011 (* 1 = 0.00451011 loss)
I0110 08:15:42.639082  4932 solver.cpp:631] Iteration 27620, lr = 1e-06
I0110 08:15:51.852388  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8307 > 20) by scale factor 0.960122
I0110 08:16:27.014536  4932 solver.cpp:240] Iteration 27640, loss = 0.079891
I0110 08:16:27.014612  4932 solver.cpp:255]     Train net output #0: loss = 0.00567513 (* 1 = 0.00567513 loss)
I0110 08:16:27.014622  4932 solver.cpp:631] Iteration 27640, lr = 1e-06
I0110 08:16:29.573590  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7448 > 20) by scale factor 0.695778
I0110 08:16:45.107909  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9747 > 20) by scale factor 0.95353
I0110 08:17:11.406365  4932 solver.cpp:240] Iteration 27660, loss = 0.0936648
I0110 08:17:11.406442  4932 solver.cpp:255]     Train net output #0: loss = 0.0163307 (* 1 = 0.0163307 loss)
I0110 08:17:11.406452  4932 solver.cpp:631] Iteration 27660, lr = 1e-06
I0110 08:17:31.713635  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6655 > 20) by scale factor 0.810849
I0110 08:17:36.154613  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2604 > 20) by scale factor 0.761602
I0110 08:17:51.686137  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5981 > 20) by scale factor 0.88503
I0110 08:17:55.784883  4932 solver.cpp:240] Iteration 27680, loss = 0.0692804
I0110 08:17:55.784927  4932 solver.cpp:255]     Train net output #0: loss = 0.0062017 (* 1 = 0.0062017 loss)
I0110 08:17:55.784939  4932 solver.cpp:631] Iteration 27680, lr = 1e-06
I0110 08:18:11.660648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7433 > 20) by scale factor 0.964168
I0110 08:18:40.168895  4932 solver.cpp:240] Iteration 27700, loss = 0.0484212
I0110 08:18:40.168992  4932 solver.cpp:255]     Train net output #0: loss = 0.0535888 (* 1 = 0.0535888 loss)
I0110 08:18:40.169005  4932 solver.cpp:631] Iteration 27700, lr = 1e-06
I0110 08:19:09.355011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8653 > 20) by scale factor 0.958531
I0110 08:19:24.546762  4932 solver.cpp:240] Iteration 27720, loss = 0.0496048
I0110 08:19:24.546823  4932 solver.cpp:255]     Train net output #0: loss = 0.0355931 (* 1 = 0.0355931 loss)
I0110 08:19:24.546831  4932 solver.cpp:631] Iteration 27720, lr = 1e-06
I0110 08:19:38.198776  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6303 > 20) by scale factor 0.812007
I0110 08:19:58.172366  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6 > 20) by scale factor 0.813009
I0110 08:20:08.932612  4932 solver.cpp:240] Iteration 27740, loss = 0.0775506
I0110 08:20:08.932652  4932 solver.cpp:255]     Train net output #0: loss = 0.120994 (* 1 = 0.120994 loss)
I0110 08:20:08.932662  4932 solver.cpp:631] Iteration 27740, lr = 1e-06
I0110 08:20:29.236112  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4877 > 20) by scale factor 0.702058
I0110 08:20:31.457902  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8851 > 20) by scale factor 0.772646
I0110 08:20:35.896136  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.439 > 20) by scale factor 0.97852
I0110 08:20:53.307814  4932 solver.cpp:240] Iteration 27760, loss = 0.0770945
I0110 08:20:53.307852  4932 solver.cpp:255]     Train net output #0: loss = 0.0951752 (* 1 = 0.0951752 loss)
I0110 08:20:53.307862  4932 solver.cpp:631] Iteration 27760, lr = 1e-06
I0110 08:21:04.741428  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3816 > 20) by scale factor 0.704681
I0110 08:21:31.365372  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8679 > 20) by scale factor 0.914582
I0110 08:21:37.681404  4932 solver.cpp:240] Iteration 27780, loss = 0.0878737
I0110 08:21:37.681471  4932 solver.cpp:255]     Train net output #0: loss = 0.0694257 (* 1 = 0.0694257 loss)
I0110 08:21:37.681480  4932 solver.cpp:631] Iteration 27780, lr = 1e-06
I0110 08:22:02.421412  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.6023 > 20) by scale factor 0.595198
I0110 08:22:22.052335  4932 solver.cpp:240] Iteration 27800, loss = 0.0637719
I0110 08:22:22.052424  4932 solver.cpp:255]     Train net output #0: loss = 0.152977 (* 1 = 0.152977 loss)
I0110 08:22:22.052436  4932 solver.cpp:631] Iteration 27800, lr = 1e-06
I0110 08:22:33.487782  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0637 > 20) by scale factor 0.867164
I0110 08:23:06.430029  4932 solver.cpp:240] Iteration 27820, loss = 0.0512562
I0110 08:23:06.430091  4932 solver.cpp:255]     Train net output #0: loss = 0.195068 (* 1 = 0.195068 loss)
I0110 08:23:06.430100  4932 solver.cpp:631] Iteration 27820, lr = 1e-06
I0110 08:23:50.797844  4932 solver.cpp:240] Iteration 27840, loss = 0.0421149
I0110 08:23:50.797912  4932 solver.cpp:255]     Train net output #0: loss = 0.0413054 (* 1 = 0.0413054 loss)
I0110 08:23:50.797922  4932 solver.cpp:631] Iteration 27840, lr = 1e-06
I0110 08:23:53.355756  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7749 > 20) by scale factor 0.841225
I0110 08:24:13.324928  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.206 > 20) by scale factor 0.861845
I0110 08:24:35.178452  4932 solver.cpp:240] Iteration 27860, loss = 0.094144
I0110 08:24:35.178546  4932 solver.cpp:255]     Train net output #0: loss = 0.231839 (* 1 = 0.231839 loss)
I0110 08:24:35.178560  4932 solver.cpp:631] Iteration 27860, lr = 1e-06
I0110 08:24:35.517882  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4904 > 20) by scale factor 0.784609
I0110 08:24:39.957850  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6626 > 20) by scale factor 0.923252
I0110 08:25:48.894804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8325 > 20) by scale factor 0.916067
I0110 08:26:18.001689  4932 solver.cpp:240] Iteration 27880, loss = 0.0839228
I0110 08:26:18.001719  4932 solver.cpp:255]     Train net output #0: loss = 0.250575 (* 1 = 0.250575 loss)
I0110 08:26:18.001727  4932 solver.cpp:631] Iteration 27880, lr = 1e-06
I0110 08:26:18.340600  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2777 > 20) by scale factor 0.89776
I0110 08:28:32.005944  4932 solver.cpp:240] Iteration 27900, loss = 0.0502277
I0110 08:28:32.006031  4932 solver.cpp:255]     Train net output #0: loss = 0.0218053 (* 1 = 0.0218053 loss)
I0110 08:28:32.006042  4932 solver.cpp:631] Iteration 27900, lr = 1e-06
I0110 08:29:50.515182  4932 solver.cpp:240] Iteration 27920, loss = 0.0420168
I0110 08:29:50.515275  4932 solver.cpp:255]     Train net output #0: loss = 0.0479722 (* 1 = 0.0479722 loss)
I0110 08:29:50.515286  4932 solver.cpp:631] Iteration 27920, lr = 1e-06
I0110 08:30:34.884158  4932 solver.cpp:240] Iteration 27940, loss = 0.046967
I0110 08:30:34.884245  4932 solver.cpp:255]     Train net output #0: loss = 0.19127 (* 1 = 0.19127 loss)
I0110 08:30:34.884258  4932 solver.cpp:631] Iteration 27940, lr = 1e-06
I0110 08:30:37.440745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.528 > 20) by scale factor 0.815395
I0110 08:31:15.160779  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8541 > 20) by scale factor 0.804696
I0110 08:31:19.263289  4932 solver.cpp:240] Iteration 27960, loss = 0.0752413
I0110 08:31:19.263329  4932 solver.cpp:255]     Train net output #0: loss = 0.0321886 (* 1 = 0.0321886 loss)
I0110 08:31:19.263341  4932 solver.cpp:631] Iteration 27960, lr = 1e-06
I0110 08:31:55.105499  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.11 > 20) by scale factor 0.82953
I0110 08:32:03.643736  4932 solver.cpp:240] Iteration 27980, loss = 0.0415109
I0110 08:32:03.643784  4932 solver.cpp:255]     Train net output #0: loss = 0.00541863 (* 1 = 0.00541863 loss)
I0110 08:32:03.643792  4932 solver.cpp:631] Iteration 27980, lr = 1e-06
I0110 08:32:23.948861  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0311 > 20) by scale factor 0.907809
I0110 08:32:46.149442  4932 solver.cpp:424] Iteration 28000, Testing net (#0)
I0110 08:33:35.414949  4932 solver.cpp:481]     Test net output #0: accuracy = 0.815789
I0110 08:33:35.415033  4932 solver.cpp:481]     Test net output #1: loss = 0.895212 (* 1 = 0.895212 loss)
I0110 08:33:37.280961  4932 solver.cpp:240] Iteration 28000, loss = 0.0305547
I0110 08:33:37.281004  4932 solver.cpp:255]     Train net output #0: loss = 0.00187893 (* 1 = 0.00187893 loss)
I0110 08:33:37.281014  4932 solver.cpp:631] Iteration 28000, lr = 1e-06
I0110 08:34:21.656318  4932 solver.cpp:240] Iteration 28020, loss = 0.0714775
I0110 08:34:21.656412  4932 solver.cpp:255]     Train net output #0: loss = 0.0209203 (* 1 = 0.0209203 loss)
I0110 08:34:21.656424  4932 solver.cpp:631] Iteration 28020, lr = 1e-06
I0110 08:35:06.037699  4932 solver.cpp:240] Iteration 28040, loss = 0.072533
I0110 08:35:06.037798  4932 solver.cpp:255]     Train net output #0: loss = 0.00318194 (* 1 = 0.00318194 loss)
I0110 08:35:06.037811  4932 solver.cpp:631] Iteration 28040, lr = 1e-06
I0110 08:35:50.404078  4932 solver.cpp:240] Iteration 28060, loss = 0.0468835
I0110 08:35:50.404173  4932 solver.cpp:255]     Train net output #0: loss = 0.0113282 (* 1 = 0.0113282 loss)
I0110 08:35:50.404186  4932 solver.cpp:631] Iteration 28060, lr = 1e-06
I0110 08:36:28.457710  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.716 > 20) by scale factor 0.880438
I0110 08:36:34.772891  4932 solver.cpp:240] Iteration 28080, loss = 0.0491331
I0110 08:36:34.772929  4932 solver.cpp:255]     Train net output #0: loss = 0.0155474 (* 1 = 0.0155474 loss)
I0110 08:36:34.772938  4932 solver.cpp:631] Iteration 28080, lr = 1e-06
I0110 08:37:19.142577  4932 solver.cpp:240] Iteration 28100, loss = 0.0719667
I0110 08:37:19.142643  4932 solver.cpp:255]     Train net output #0: loss = 0.13996 (* 1 = 0.13996 loss)
I0110 08:37:19.142653  4932 solver.cpp:631] Iteration 28100, lr = 1e-06
I0110 08:37:28.355767  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7983 > 20) by scale factor 0.877259
I0110 08:38:03.524404  4932 solver.cpp:240] Iteration 28120, loss = 0.0607781
I0110 08:38:03.524468  4932 solver.cpp:255]     Train net output #0: loss = 0.18391 (* 1 = 0.18391 loss)
I0110 08:38:03.524478  4932 solver.cpp:631] Iteration 28120, lr = 1e-06
I0110 08:38:39.368607  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5098 > 20) by scale factor 0.975146
I0110 08:38:47.904934  4932 solver.cpp:240] Iteration 28140, loss = 0.0668648
I0110 08:38:47.904966  4932 solver.cpp:255]     Train net output #0: loss = 0.0116991 (* 1 = 0.0116991 loss)
I0110 08:38:47.904974  4932 solver.cpp:631] Iteration 28140, lr = 1e-06
I0110 08:38:59.344841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6482 > 20) by scale factor 0.750519
I0110 08:39:32.281414  4932 solver.cpp:240] Iteration 28160, loss = 0.102406
I0110 08:39:32.281491  4932 solver.cpp:255]     Train net output #0: loss = 0.254474 (* 1 = 0.254474 loss)
I0110 08:39:32.281499  4932 solver.cpp:631] Iteration 28160, lr = 1e-06
I0110 08:39:39.274041  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7308 > 20) by scale factor 0.920353
I0110 08:40:16.655392  4932 solver.cpp:240] Iteration 28180, loss = 0.0467385
I0110 08:40:16.655483  4932 solver.cpp:255]     Train net output #0: loss = 0.0174499 (* 1 = 0.0174499 loss)
I0110 08:40:16.655496  4932 solver.cpp:631] Iteration 28180, lr = 1e-06
I0110 08:41:01.034219  4932 solver.cpp:240] Iteration 28200, loss = 0.0743744
I0110 08:41:01.034301  4932 solver.cpp:255]     Train net output #0: loss = 0.0483518 (* 1 = 0.0483518 loss)
I0110 08:41:01.034312  4932 solver.cpp:631] Iteration 28200, lr = 1e-06
I0110 08:41:45.416121  4932 solver.cpp:240] Iteration 28220, loss = 0.0791661
I0110 08:41:45.416191  4932 solver.cpp:255]     Train net output #0: loss = 0.112609 (* 1 = 0.112609 loss)
I0110 08:41:45.416203  4932 solver.cpp:631] Iteration 28220, lr = 1e-06
I0110 08:41:50.191567  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6953 > 20) by scale factor 0.722144
I0110 08:42:16.818151  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4909 > 20) by scale factor 0.889248
I0110 08:42:21.259152  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0779 > 20) by scale factor 0.830637
I0110 08:42:29.795855  4932 solver.cpp:240] Iteration 28240, loss = 0.112954
I0110 08:42:29.795892  4932 solver.cpp:255]     Train net output #0: loss = 0.120736 (* 1 = 0.120736 loss)
I0110 08:42:29.795902  4932 solver.cpp:631] Iteration 28240, lr = 1e-06
I0110 08:42:30.135125  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8041 > 20) by scale factor 0.961349
I0110 08:42:50.109031  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3441 > 20) by scale factor 0.937028
I0110 08:42:54.549360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5054 > 20) by scale factor 0.754563
I0110 08:42:58.987650  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1653 > 20) by scale factor 0.944945
I0110 08:43:14.177580  4932 solver.cpp:240] Iteration 28260, loss = 0.0827066
I0110 08:43:14.177619  4932 solver.cpp:255]     Train net output #0: loss = 0.000719193 (* 1 = 0.000719193 loss)
I0110 08:43:14.177628  4932 solver.cpp:631] Iteration 28260, lr = 1e-06
I0110 08:43:50.009934  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0246 > 20) by scale factor 0.68907
I0110 08:43:58.547538  4932 solver.cpp:240] Iteration 28280, loss = 0.0844391
I0110 08:43:58.547582  4932 solver.cpp:255]     Train net output #0: loss = 0.0202348 (* 1 = 0.0202348 loss)
I0110 08:43:58.547593  4932 solver.cpp:631] Iteration 28280, lr = 1e-06
I0110 08:44:42.918633  4932 solver.cpp:240] Iteration 28300, loss = 0.0437664
I0110 08:44:42.918714  4932 solver.cpp:255]     Train net output #0: loss = 0.00190766 (* 1 = 0.00190766 loss)
I0110 08:44:42.918725  4932 solver.cpp:631] Iteration 28300, lr = 1e-06
I0110 08:45:27.306713  4932 solver.cpp:240] Iteration 28320, loss = 0.0574107
I0110 08:45:27.306816  4932 solver.cpp:255]     Train net output #0: loss = 0.00681922 (* 1 = 0.00681922 loss)
I0110 08:45:27.306831  4932 solver.cpp:631] Iteration 28320, lr = 1e-06
I0110 08:46:11.683454  4932 solver.cpp:240] Iteration 28340, loss = 0.0603657
I0110 08:46:11.683535  4932 solver.cpp:255]     Train net output #0: loss = 0.000285739 (* 1 = 0.000285739 loss)
I0110 08:46:11.683547  4932 solver.cpp:631] Iteration 28340, lr = 1e-06
I0110 08:46:25.333535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3306 > 20) by scale factor 0.983741
I0110 08:46:56.054757  4932 solver.cpp:240] Iteration 28360, loss = 0.0688319
I0110 08:46:56.054826  4932 solver.cpp:255]     Train net output #0: loss = 0.117954 (* 1 = 0.117954 loss)
I0110 08:46:56.054836  4932 solver.cpp:631] Iteration 28360, lr = 1e-06
I0110 08:46:56.394057  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0887 > 20) by scale factor 0.995584
I0110 08:47:18.585731  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1565 > 20) by scale factor 0.992237
I0110 08:47:20.806219  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.493 > 20) by scale factor 0.655888
I0110 08:47:23.029439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0834 > 20) by scale factor 0.905657
I0110 08:47:40.444753  4932 solver.cpp:240] Iteration 28380, loss = 0.0588714
I0110 08:47:40.444834  4932 solver.cpp:255]     Train net output #0: loss = 0.00854786 (* 1 = 0.00854786 loss)
I0110 08:47:40.444845  4932 solver.cpp:631] Iteration 28380, lr = 1e-06
I0110 08:48:24.815417  4932 solver.cpp:240] Iteration 28400, loss = 0.0661459
I0110 08:48:24.815681  4932 solver.cpp:255]     Train net output #0: loss = 0.0746761 (* 1 = 0.0746761 loss)
I0110 08:48:24.815698  4932 solver.cpp:631] Iteration 28400, lr = 1e-06
I0110 08:49:09.209455  4932 solver.cpp:240] Iteration 28420, loss = 0.0476464
I0110 08:49:09.209542  4932 solver.cpp:255]     Train net output #0: loss = 0.00422688 (* 1 = 0.00422688 loss)
I0110 08:49:09.209553  4932 solver.cpp:631] Iteration 28420, lr = 1e-06
I0110 08:49:33.971755  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2511 > 20) by scale factor 0.707937
I0110 08:49:53.611259  4932 solver.cpp:240] Iteration 28440, loss = 0.0860471
I0110 08:49:53.611353  4932 solver.cpp:255]     Train net output #0: loss = 0.0057272 (* 1 = 0.0057272 loss)
I0110 08:49:53.611366  4932 solver.cpp:631] Iteration 28440, lr = 1e-06
I0110 08:50:38.002266  4932 solver.cpp:240] Iteration 28460, loss = 0.0392229
I0110 08:50:38.002363  4932 solver.cpp:255]     Train net output #0: loss = 0.0060706 (* 1 = 0.0060706 loss)
I0110 08:50:38.002377  4932 solver.cpp:631] Iteration 28460, lr = 1e-06
I0110 08:50:40.563550  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7764 > 20) by scale factor 0.962632
I0110 08:51:07.192687  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.241 > 20) by scale factor 0.860548
I0110 08:51:22.388545  4932 solver.cpp:240] Iteration 28480, loss = 0.0805878
I0110 08:51:22.388638  4932 solver.cpp:255]     Train net output #0: loss = 0.0204298 (* 1 = 0.0204298 loss)
I0110 08:51:22.388653  4932 solver.cpp:631] Iteration 28480, lr = 1e-06
I0110 08:51:40.490128  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2956 > 20) by scale factor 0.985437
I0110 08:51:56.028911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3141 > 20) by scale factor 0.790072
I0110 08:52:06.787636  4932 solver.cpp:240] Iteration 28500, loss = 0.068784
I0110 08:52:06.787675  4932 solver.cpp:255]     Train net output #0: loss = 0.0150569 (* 1 = 0.0150569 loss)
I0110 08:52:06.787684  4932 solver.cpp:631] Iteration 28500, lr = 1e-06
I0110 08:52:18.223471  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1662 > 20) by scale factor 0.944905
I0110 08:52:51.177634  4932 solver.cpp:240] Iteration 28520, loss = 0.0505124
I0110 08:52:51.177706  4932 solver.cpp:255]     Train net output #0: loss = 0.0135292 (* 1 = 0.0135292 loss)
I0110 08:52:51.177716  4932 solver.cpp:631] Iteration 28520, lr = 1e-06
I0110 08:53:35.575206  4932 solver.cpp:240] Iteration 28540, loss = 0.0501278
I0110 08:53:35.575289  4932 solver.cpp:255]     Train net output #0: loss = 0.000616064 (* 1 = 0.000616064 loss)
I0110 08:53:35.575301  4932 solver.cpp:631] Iteration 28540, lr = 1e-06
I0110 08:53:42.570848  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4744 > 20) by scale factor 0.817182
I0110 08:54:19.968708  4932 solver.cpp:240] Iteration 28560, loss = 0.0972312
I0110 08:54:19.968770  4932 solver.cpp:255]     Train net output #0: loss = 0.176862 (* 1 = 0.176862 loss)
I0110 08:54:19.968782  4932 solver.cpp:631] Iteration 28560, lr = 1e-06
I0110 08:54:53.600159  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.703 > 20) by scale factor 0.880939
I0110 08:55:04.360612  4932 solver.cpp:240] Iteration 28580, loss = 0.0731467
I0110 08:55:04.360656  4932 solver.cpp:255]     Train net output #0: loss = 0.00239607 (* 1 = 0.00239607 loss)
I0110 08:55:04.360669  4932 solver.cpp:631] Iteration 28580, lr = 1e-06
I0110 08:55:48.762574  4932 solver.cpp:240] Iteration 28600, loss = 0.0649295
I0110 08:55:48.762646  4932 solver.cpp:255]     Train net output #0: loss = 0.283862 (* 1 = 0.283862 loss)
I0110 08:55:48.762656  4932 solver.cpp:631] Iteration 28600, lr = 1e-06
I0110 08:55:49.102036  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1816 > 20) by scale factor 0.763895
I0110 08:56:33.161202  4932 solver.cpp:240] Iteration 28620, loss = 0.0824155
I0110 08:56:33.161285  4932 solver.cpp:255]     Train net output #0: loss = 0.0251182 (* 1 = 0.0251182 loss)
I0110 08:56:33.161296  4932 solver.cpp:631] Iteration 28620, lr = 1e-06
I0110 08:56:40.159443  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6291 > 20) by scale factor 0.969503
I0110 08:56:51.263710  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7867 > 20) by scale factor 0.775594
I0110 08:57:17.558202  4932 solver.cpp:240] Iteration 28640, loss = 0.108156
I0110 08:57:17.558289  4932 solver.cpp:255]     Train net output #0: loss = 0.200335 (* 1 = 0.200335 loss)
I0110 08:57:17.558301  4932 solver.cpp:631] Iteration 28640, lr = 1e-06
I0110 08:57:17.898576  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6409 > 20) by scale factor 0.968952
I0110 08:58:00.084110  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5157 > 20) by scale factor 0.974863
I0110 08:58:01.965625  4932 solver.cpp:240] Iteration 28660, loss = 0.058047
I0110 08:58:01.965670  4932 solver.cpp:255]     Train net output #0: loss = 0.00447741 (* 1 = 0.00447741 loss)
I0110 08:58:01.965687  4932 solver.cpp:631] Iteration 28660, lr = 1e-06
I0110 08:58:28.944610  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0477 > 20) by scale factor 0.798477
I0110 08:58:46.358925  4932 solver.cpp:240] Iteration 28680, loss = 0.0653934
I0110 08:58:46.359035  4932 solver.cpp:255]     Train net output #0: loss = 0.112309 (* 1 = 0.112309 loss)
I0110 08:58:46.359047  4932 solver.cpp:631] Iteration 28680, lr = 1e-06
I0110 08:59:30.752238  4932 solver.cpp:240] Iteration 28700, loss = 0.0855465
I0110 08:59:30.752344  4932 solver.cpp:255]     Train net output #0: loss = 0.0409309 (* 1 = 0.0409309 loss)
I0110 08:59:30.752360  4932 solver.cpp:631] Iteration 28700, lr = 1e-06
I0110 08:59:39.966256  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5917 > 20) by scale factor 0.813282
I0110 09:00:06.616206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8973 > 20) by scale factor 0.957062
I0110 09:00:15.153357  4932 solver.cpp:240] Iteration 28720, loss = 0.0674042
I0110 09:00:15.153398  4932 solver.cpp:255]     Train net output #0: loss = 0.0557221 (* 1 = 0.0557221 loss)
I0110 09:00:15.153406  4932 solver.cpp:631] Iteration 28720, lr = 1e-06
I0110 09:00:59.541815  4932 solver.cpp:240] Iteration 28740, loss = 0.0474286
I0110 09:00:59.541913  4932 solver.cpp:255]     Train net output #0: loss = 0.0859667 (* 1 = 0.0859667 loss)
I0110 09:00:59.541924  4932 solver.cpp:631] Iteration 28740, lr = 1e-06
I0110 09:00:59.880859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0649 > 20) by scale factor 0.996764
I0110 09:01:02.104056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2621 > 20) by scale factor 0.898386
I0110 09:01:24.304608  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2553 > 20) by scale factor 0.860019
I0110 09:01:43.946532  4932 solver.cpp:240] Iteration 28760, loss = 0.086213
I0110 09:01:43.946621  4932 solver.cpp:255]     Train net output #0: loss = 0.0191231 (* 1 = 0.0191231 loss)
I0110 09:01:43.946635  4932 solver.cpp:631] Iteration 28760, lr = 1e-06
I0110 09:02:15.360047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1582 > 20) by scale factor 0.945261
I0110 09:02:22.020185  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1167 > 20) by scale factor 0.994199
I0110 09:02:28.345188  4932 solver.cpp:240] Iteration 28780, loss = 0.0539582
I0110 09:02:28.345237  4932 solver.cpp:255]     Train net output #0: loss = 0.0423475 (* 1 = 0.0423475 loss)
I0110 09:02:28.345379  4932 solver.cpp:631] Iteration 28780, lr = 1e-06
I0110 09:02:42.003825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4501 > 20) by scale factor 0.852876
I0110 09:02:53.106457  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6811 > 20) by scale factor 0.88179
I0110 09:03:12.749474  4932 solver.cpp:240] Iteration 28800, loss = 0.0543167
I0110 09:03:12.749518  4932 solver.cpp:255]     Train net output #0: loss = 0.0143833 (* 1 = 0.0143833 loss)
I0110 09:03:12.749532  4932 solver.cpp:631] Iteration 28800, lr = 1e-06
I0110 09:03:17.532603  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5458 > 20) by scale factor 0.928254
I0110 09:03:24.194162  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7325 > 20) by scale factor 0.920281
I0110 09:03:44.170087  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0142 > 20) by scale factor 0.908505
I0110 09:03:53.055497  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3785 > 20) by scale factor 0.855487
I0110 09:03:57.156249  4932 solver.cpp:240] Iteration 28820, loss = 0.124093
I0110 09:03:57.156323  4932 solver.cpp:255]     Train net output #0: loss = 0.0213243 (* 1 = 0.0213243 loss)
I0110 09:03:57.156333  4932 solver.cpp:631] Iteration 28820, lr = 1e-06
I0110 09:04:08.598425  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.191 > 20) by scale factor 0.901268
I0110 09:04:35.239087  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.72 > 20) by scale factor 0.843169
I0110 09:04:41.562415  4932 solver.cpp:240] Iteration 28840, loss = 0.0799823
I0110 09:04:41.562453  4932 solver.cpp:255]     Train net output #0: loss = 0.00919168 (* 1 = 0.00919168 loss)
I0110 09:04:41.562463  4932 solver.cpp:631] Iteration 28840, lr = 1e-06
I0110 09:05:04.100388  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5627 > 20) by scale factor 0.700214
I0110 09:05:19.644186  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4256 > 20) by scale factor 0.818811
I0110 09:05:25.968808  4932 solver.cpp:240] Iteration 28860, loss = 0.0605106
I0110 09:05:25.968847  4932 solver.cpp:255]     Train net output #0: loss = 0.0255889 (* 1 = 0.0255889 loss)
I0110 09:05:25.968858  4932 solver.cpp:631] Iteration 28860, lr = 1e-06
I0110 09:06:10.367283  4932 solver.cpp:240] Iteration 28880, loss = 0.0616514
I0110 09:06:10.367362  4932 solver.cpp:255]     Train net output #0: loss = 0.0182238 (* 1 = 0.0182238 loss)
I0110 09:06:10.367373  4932 solver.cpp:631] Iteration 28880, lr = 1e-06
I0110 09:06:48.447660  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9737 > 20) by scale factor 0.910178
I0110 09:06:54.767532  4932 solver.cpp:240] Iteration 28900, loss = 0.0718499
I0110 09:06:54.767577  4932 solver.cpp:255]     Train net output #0: loss = 0.167601 (* 1 = 0.167601 loss)
I0110 09:06:54.767588  4932 solver.cpp:631] Iteration 28900, lr = 1e-06
I0110 09:07:35.059460  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.212 > 20) by scale factor 0.861625
I0110 09:07:39.159595  4932 solver.cpp:240] Iteration 28920, loss = 0.0787067
I0110 09:07:39.159636  4932 solver.cpp:255]     Train net output #0: loss = 0.0721179 (* 1 = 0.0721179 loss)
I0110 09:07:39.159644  4932 solver.cpp:631] Iteration 28920, lr = 1e-06
I0110 09:08:08.348146  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2051 > 20) by scale factor 0.989847
I0110 09:08:10.570855  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6365 > 20) by scale factor 0.750848
I0110 09:08:23.553289  4932 solver.cpp:240] Iteration 28940, loss = 0.0794451
I0110 09:08:23.553328  4932 solver.cpp:255]     Train net output #0: loss = 0.00726985 (* 1 = 0.00726985 loss)
I0110 09:08:23.553336  4932 solver.cpp:631] Iteration 28940, lr = 1e-06
I0110 09:09:07.936117  4932 solver.cpp:240] Iteration 28960, loss = 0.0632116
I0110 09:09:07.936205  4932 solver.cpp:255]     Train net output #0: loss = 0.0485954 (* 1 = 0.0485954 loss)
I0110 09:09:07.936218  4932 solver.cpp:631] Iteration 28960, lr = 1e-06
I0110 09:09:28.254284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6 > 20) by scale factor 0.847458
I0110 09:09:52.322360  4932 solver.cpp:240] Iteration 28980, loss = 0.0728132
I0110 09:09:52.322484  4932 solver.cpp:255]     Train net output #0: loss = 0.00702758 (* 1 = 0.00702758 loss)
I0110 09:09:52.322499  4932 solver.cpp:631] Iteration 28980, lr = 1e-06
I0110 09:10:23.735319  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0375 > 20) by scale factor 0.768122
I0110 09:10:34.843603  4932 solver.cpp:424] Iteration 29000, Testing net (#0)
I0110 09:11:23.921280  4932 solver.cpp:481]     Test net output #0: accuracy = 0.823158
I0110 09:11:23.921371  4932 solver.cpp:481]     Test net output #1: loss = 0.938325 (* 1 = 0.938325 loss)
I0110 09:11:25.787092  4932 solver.cpp:240] Iteration 29000, loss = 0.0872677
I0110 09:11:25.787123  4932 solver.cpp:255]     Train net output #0: loss = 0.0570498 (* 1 = 0.0570498 loss)
I0110 09:11:25.787132  4932 solver.cpp:631] Iteration 29000, lr = 1e-06
I0110 09:12:10.158792  4932 solver.cpp:240] Iteration 29020, loss = 0.0442487
I0110 09:12:10.158879  4932 solver.cpp:255]     Train net output #0: loss = 0.0350675 (* 1 = 0.0350675 loss)
I0110 09:12:10.158891  4932 solver.cpp:631] Iteration 29020, lr = 1e-06
I0110 09:12:54.530953  4932 solver.cpp:240] Iteration 29040, loss = 0.058497
I0110 09:12:54.531042  4932 solver.cpp:255]     Train net output #0: loss = 0.0470103 (* 1 = 0.0470103 loss)
I0110 09:12:54.531054  4932 solver.cpp:631] Iteration 29040, lr = 1e-06
I0110 09:13:38.904428  4932 solver.cpp:240] Iteration 29060, loss = 0.0492709
I0110 09:13:38.904536  4932 solver.cpp:255]     Train net output #0: loss = 0.224794 (* 1 = 0.224794 loss)
I0110 09:13:38.904551  4932 solver.cpp:631] Iteration 29060, lr = 1e-06
I0110 09:13:52.553779  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9037 > 20) by scale factor 0.956768
I0110 09:13:56.997563  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8681 > 20) by scale factor 0.804242
I0110 09:14:03.655103  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0089 > 20) by scale factor 0.908725
I0110 09:14:21.405524  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2722 > 20) by scale factor 0.986574
I0110 09:14:23.285868  4932 solver.cpp:240] Iteration 29080, loss = 0.0940852
I0110 09:14:23.285914  4932 solver.cpp:255]     Train net output #0: loss = 0.0131044 (* 1 = 0.0131044 loss)
I0110 09:14:23.286065  4932 solver.cpp:631] Iteration 29080, lr = 1e-06
I0110 09:14:25.845729  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3912 > 20) by scale factor 0.980816
I0110 09:14:39.410642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.367 > 20) by scale factor 0.894175
I0110 09:15:07.920992  4932 solver.cpp:240] Iteration 29100, loss = 0.0668769
I0110 09:15:07.921077  4932 solver.cpp:255]     Train net output #0: loss = 0.274342 (* 1 = 0.274342 loss)
I0110 09:15:07.921085  4932 solver.cpp:631] Iteration 29100, lr = 1e-06
I0110 09:15:17.134263  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7038 > 20) by scale factor 0.9215
I0110 09:15:41.548656  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.211 > 20) by scale factor 0.900453
I0110 09:15:52.306145  4932 solver.cpp:240] Iteration 29120, loss = 0.0775433
I0110 09:15:52.306187  4932 solver.cpp:255]     Train net output #0: loss = 0.0521367 (* 1 = 0.0521367 loss)
I0110 09:15:52.306196  4932 solver.cpp:631] Iteration 29120, lr = 1e-06
I0110 09:16:03.745988  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4957 > 20) by scale factor 0.81647
I0110 09:16:05.966743  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4853 > 20) by scale factor 0.976312
I0110 09:16:17.063791  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.0511 > 20) by scale factor 0.587353
I0110 09:16:36.699601  4932 solver.cpp:240] Iteration 29140, loss = 0.122065
I0110 09:16:36.699651  4932 solver.cpp:255]     Train net output #0: loss = 0.0449263 (* 1 = 0.0449263 loss)
I0110 09:16:36.699671  4932 solver.cpp:631] Iteration 29140, lr = 1e-06
I0110 09:17:21.689074  4932 solver.cpp:240] Iteration 29160, loss = 0.0410891
I0110 09:17:21.689163  4932 solver.cpp:255]     Train net output #0: loss = 0.235066 (* 1 = 0.235066 loss)
I0110 09:17:21.689175  4932 solver.cpp:631] Iteration 29160, lr = 1e-06
I0110 09:17:44.208941  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4611 > 20) by scale factor 0.852473
I0110 09:18:06.066464  4932 solver.cpp:240] Iteration 29180, loss = 0.0490542
I0110 09:18:06.066536  4932 solver.cpp:255]     Train net output #0: loss = 0.00223654 (* 1 = 0.00223654 loss)
I0110 09:18:06.066546  4932 solver.cpp:631] Iteration 29180, lr = 1e-06
I0110 09:18:15.278430  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3729 > 20) by scale factor 0.788243
I0110 09:18:46.350507  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9065 > 20) by scale factor 0.836592
I0110 09:18:50.449628  4932 solver.cpp:240] Iteration 29200, loss = 0.111167
I0110 09:18:50.449674  4932 solver.cpp:255]     Train net output #0: loss = 0.00317657 (* 1 = 0.00317657 loss)
I0110 09:18:50.449686  4932 solver.cpp:631] Iteration 29200, lr = 1e-06
I0110 09:19:34.825214  4932 solver.cpp:240] Iteration 29220, loss = 0.0509208
I0110 09:19:34.825297  4932 solver.cpp:255]     Train net output #0: loss = 0.0114618 (* 1 = 0.0114618 loss)
I0110 09:19:34.825307  4932 solver.cpp:631] Iteration 29220, lr = 1e-06
I0110 09:19:41.823760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.704 > 20) by scale factor 0.843741
I0110 09:20:19.214051  4932 solver.cpp:240] Iteration 29240, loss = 0.0862224
I0110 09:20:19.214148  4932 solver.cpp:255]     Train net output #0: loss = 0.00656277 (* 1 = 0.00656277 loss)
I0110 09:20:19.214159  4932 solver.cpp:631] Iteration 29240, lr = 1e-06
I0110 09:20:32.865674  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.085 > 20) by scale factor 0.948539
I0110 09:21:03.595625  4932 solver.cpp:240] Iteration 29260, loss = 0.0590629
I0110 09:21:03.595708  4932 solver.cpp:255]     Train net output #0: loss = 0.0658742 (* 1 = 0.0658742 loss)
I0110 09:21:03.595721  4932 solver.cpp:631] Iteration 29260, lr = 1e-06
I0110 09:21:47.972961  4932 solver.cpp:240] Iteration 29280, loss = 0.0670084
I0110 09:21:47.973057  4932 solver.cpp:255]     Train net output #0: loss = 0.00288943 (* 1 = 0.00288943 loss)
I0110 09:21:47.973070  4932 solver.cpp:631] Iteration 29280, lr = 1e-06
I0110 09:22:03.841545  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0953 > 20) by scale factor 0.948078
I0110 09:22:32.350888  4932 solver.cpp:240] Iteration 29300, loss = 0.0842022
I0110 09:22:32.350962  4932 solver.cpp:255]     Train net output #0: loss = 0.00626714 (* 1 = 0.00626714 loss)
I0110 09:22:32.350972  4932 solver.cpp:631] Iteration 29300, lr = 1e-06
I0110 09:23:16.728742  4932 solver.cpp:240] Iteration 29320, loss = 0.0464444
I0110 09:23:16.728818  4932 solver.cpp:255]     Train net output #0: loss = 0.0466729 (* 1 = 0.0466729 loss)
I0110 09:23:16.728827  4932 solver.cpp:631] Iteration 29320, lr = 1e-06
I0110 09:24:01.121745  4932 solver.cpp:240] Iteration 29340, loss = 0.0665232
I0110 09:24:01.121822  4932 solver.cpp:255]     Train net output #0: loss = 0.00621966 (* 1 = 0.00621966 loss)
I0110 09:24:01.121832  4932 solver.cpp:631] Iteration 29340, lr = 1e-06
I0110 09:24:39.187361  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4284 > 20) by scale factor 0.703522
I0110 09:24:45.507335  4932 solver.cpp:240] Iteration 29360, loss = 0.0579653
I0110 09:24:45.507374  4932 solver.cpp:255]     Train net output #0: loss = 0.10044 (* 1 = 0.10044 loss)
I0110 09:24:45.507382  4932 solver.cpp:631] Iteration 29360, lr = 1e-06
I0110 09:24:54.726253  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1238 > 20) by scale factor 0.99385
I0110 09:25:08.045352  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1107 > 20) by scale factor 0.994495
I0110 09:25:29.902657  4932 solver.cpp:240] Iteration 29380, loss = 0.064609
I0110 09:25:29.902730  4932 solver.cpp:255]     Train net output #0: loss = 0.00534571 (* 1 = 0.00534571 loss)
I0110 09:25:29.902740  4932 solver.cpp:631] Iteration 29380, lr = 1e-06
I0110 09:26:14.286336  4932 solver.cpp:240] Iteration 29400, loss = 0.0466638
I0110 09:26:14.286412  4932 solver.cpp:255]     Train net output #0: loss = 0.199425 (* 1 = 0.199425 loss)
I0110 09:26:14.286422  4932 solver.cpp:631] Iteration 29400, lr = 1e-06
I0110 09:26:14.625344  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.492 > 20) by scale factor 0.615535
I0110 09:26:23.507369  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5617 > 20) by scale factor 0.972681
I0110 09:26:50.136251  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0123 > 20) by scale factor 0.713971
I0110 09:26:56.795460  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3489 > 20) by scale factor 0.982856
I0110 09:26:58.677057  4932 solver.cpp:240] Iteration 29420, loss = 0.0908281
I0110 09:26:58.677098  4932 solver.cpp:255]     Train net output #0: loss = 0.0187078 (* 1 = 0.0187078 loss)
I0110 09:26:58.677110  4932 solver.cpp:631] Iteration 29420, lr = 1e-06
I0110 09:27:10.112586  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1202 > 20) by scale factor 0.829179
I0110 09:27:12.333500  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5252 > 20) by scale factor 0.850151
I0110 09:27:14.556059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2467 > 20) by scale factor 0.941325
I0110 09:27:32.313827  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1375 > 20) by scale factor 0.736989
I0110 09:27:43.072784  4932 solver.cpp:240] Iteration 29440, loss = 0.116051
I0110 09:27:43.072830  4932 solver.cpp:255]     Train net output #0: loss = 0.0324588 (* 1 = 0.0324588 loss)
I0110 09:27:43.072950  4932 solver.cpp:631] Iteration 29440, lr = 1e-06
I0110 09:27:47.850370  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1996 > 20) by scale factor 0.99012
I0110 09:28:27.470582  4932 solver.cpp:240] Iteration 29460, loss = 0.0553657
I0110 09:28:27.470675  4932 solver.cpp:255]     Train net output #0: loss = 0.239514 (* 1 = 0.239514 loss)
I0110 09:28:27.470688  4932 solver.cpp:631] Iteration 29460, lr = 1e-06
I0110 09:28:27.811091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0575 > 20) by scale factor 0.94978
I0110 09:28:38.908707  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2626 > 20) by scale factor 0.987038
I0110 09:29:11.867319  4932 solver.cpp:240] Iteration 29480, loss = 0.0568067
I0110 09:29:11.867398  4932 solver.cpp:255]     Train net output #0: loss = 0.0219008 (* 1 = 0.0219008 loss)
I0110 09:29:11.867408  4932 solver.cpp:631] Iteration 29480, lr = 1e-06
I0110 09:29:18.861488  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5176 > 20) by scale factor 0.974771
I0110 09:29:36.615903  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2427 > 20) by scale factor 0.899172
I0110 09:29:56.253237  4932 solver.cpp:240] Iteration 29500, loss = 0.0622571
I0110 09:29:56.253316  4932 solver.cpp:255]     Train net output #0: loss = 0.00293153 (* 1 = 0.00293153 loss)
I0110 09:29:56.253327  4932 solver.cpp:631] Iteration 29500, lr = 1e-06
I0110 09:30:40.652225  4932 solver.cpp:240] Iteration 29520, loss = 0.0389802
I0110 09:30:40.652302  4932 solver.cpp:255]     Train net output #0: loss = 0.011281 (* 1 = 0.011281 loss)
I0110 09:30:40.652312  4932 solver.cpp:631] Iteration 29520, lr = 1e-06
I0110 09:31:00.966745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.3552 > 20) by scale factor 0.535401
I0110 09:31:05.409484  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6238 > 20) by scale factor 0.924907
I0110 09:31:20.943080  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9566 > 20) by scale factor 0.801391
I0110 09:31:25.045366  4932 solver.cpp:240] Iteration 29540, loss = 0.102026
I0110 09:31:25.045408  4932 solver.cpp:255]     Train net output #0: loss = 0.113494 (* 1 = 0.113494 loss)
I0110 09:31:25.045419  4932 solver.cpp:631] Iteration 29540, lr = 1e-06
I0110 09:31:38.698899  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8073 > 20) by scale factor 0.746066
I0110 09:31:43.139787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4772 > 20) by scale factor 0.727877
I0110 09:32:09.435992  4932 solver.cpp:240] Iteration 29560, loss = 0.0943492
I0110 09:32:09.436074  4932 solver.cpp:255]     Train net output #0: loss = 0.0182093 (* 1 = 0.0182093 loss)
I0110 09:32:09.436084  4932 solver.cpp:631] Iteration 29560, lr = 1e-06
I0110 09:32:27.525379  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7497 > 20) by scale factor 0.96387
I0110 09:32:40.840941  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2733 > 20) by scale factor 0.940145
I0110 09:32:53.825326  4932 solver.cpp:240] Iteration 29580, loss = 0.0679726
I0110 09:32:53.825371  4932 solver.cpp:255]     Train net output #0: loss = 0.0451089 (* 1 = 0.0451089 loss)
I0110 09:32:53.825381  4932 solver.cpp:631] Iteration 29580, lr = 1e-06
I0110 09:33:03.036370  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.724 > 20) by scale factor 0.80893
I0110 09:33:38.196527  4932 solver.cpp:240] Iteration 29600, loss = 0.0678195
I0110 09:33:38.196617  4932 solver.cpp:255]     Train net output #0: loss = 0.00360256 (* 1 = 0.00360256 loss)
I0110 09:33:38.196632  4932 solver.cpp:631] Iteration 29600, lr = 1e-06
I0110 09:34:05.162394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.284 > 20) by scale factor 0.760918
I0110 09:34:22.572285  4932 solver.cpp:240] Iteration 29620, loss = 0.0622875
I0110 09:34:22.572352  4932 solver.cpp:255]     Train net output #0: loss = 0.00186523 (* 1 = 0.00186523 loss)
I0110 09:34:22.572361  4932 solver.cpp:631] Iteration 29620, lr = 1e-06
I0110 09:35:06.953794  4932 solver.cpp:240] Iteration 29640, loss = 0.0569558
I0110 09:35:06.953867  4932 solver.cpp:255]     Train net output #0: loss = 0.0582583 (* 1 = 0.0582583 loss)
I0110 09:35:06.953877  4932 solver.cpp:631] Iteration 29640, lr = 1e-06
I0110 09:35:09.512490  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4825 > 20) by scale factor 0.889582
I0110 09:35:33.917807  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3833 > 20) by scale factor 0.893522
I0110 09:35:51.330011  4932 solver.cpp:240] Iteration 29660, loss = 0.0819216
I0110 09:35:51.330096  4932 solver.cpp:255]     Train net output #0: loss = 0.0511662 (* 1 = 0.0511662 loss)
I0110 09:35:51.330108  4932 solver.cpp:631] Iteration 29660, lr = 1e-06
I0110 09:36:02.766348  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6245 > 20) by scale factor 0.924875
I0110 09:36:04.985718  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5048 > 20) by scale factor 0.701636
I0110 09:36:35.714735  4932 solver.cpp:240] Iteration 29680, loss = 0.0833867
I0110 09:36:35.714803  4932 solver.cpp:255]     Train net output #0: loss = 0.0060486 (* 1 = 0.0060486 loss)
I0110 09:36:35.714812  4932 solver.cpp:631] Iteration 29680, lr = 1e-06
I0110 09:36:56.018738  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.325 > 20) by scale factor 0.984008
I0110 09:37:02.679745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8112 > 20) by scale factor 0.876763
I0110 09:37:04.900830  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4037 > 20) by scale factor 0.934417
I0110 09:37:07.122664  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.631 > 20) by scale factor 0.780305
I0110 09:37:20.103524  4932 solver.cpp:240] Iteration 29700, loss = 0.108564
I0110 09:37:20.103562  4932 solver.cpp:255]     Train net output #0: loss = 0.00699876 (* 1 = 0.00699876 loss)
I0110 09:37:20.103571  4932 solver.cpp:631] Iteration 29700, lr = 1e-06
I0110 09:37:53.719651  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3072 > 20) by scale factor 0.822801
I0110 09:38:00.379034  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3369 > 20) by scale factor 0.983434
I0110 09:38:04.481899  4932 solver.cpp:240] Iteration 29720, loss = 0.0611023
I0110 09:38:04.481945  4932 solver.cpp:255]     Train net output #0: loss = 0.067827 (* 1 = 0.067827 loss)
I0110 09:38:04.481956  4932 solver.cpp:631] Iteration 29720, lr = 1e-06
I0110 09:38:44.753106  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7354 > 20) by scale factor 0.964532
I0110 09:38:48.851663  4932 solver.cpp:240] Iteration 29740, loss = 0.0653854
I0110 09:38:48.851701  4932 solver.cpp:255]     Train net output #0: loss = 0.0588975 (* 1 = 0.0588975 loss)
I0110 09:38:48.851709  4932 solver.cpp:631] Iteration 29740, lr = 1e-06
I0110 09:39:33.225790  4932 solver.cpp:240] Iteration 29760, loss = 0.0609027
I0110 09:39:33.225865  4932 solver.cpp:255]     Train net output #0: loss = 0.00977124 (* 1 = 0.00977124 loss)
I0110 09:39:33.225874  4932 solver.cpp:631] Iteration 29760, lr = 1e-06
I0110 09:40:17.604506  4932 solver.cpp:240] Iteration 29780, loss = 0.0313008
I0110 09:40:17.604598  4932 solver.cpp:255]     Train net output #0: loss = 0.00242132 (* 1 = 0.00242132 loss)
I0110 09:40:17.604609  4932 solver.cpp:631] Iteration 29780, lr = 1e-06
I0110 09:41:01.992069  4932 solver.cpp:240] Iteration 29800, loss = 0.0291041
I0110 09:41:01.992146  4932 solver.cpp:255]     Train net output #0: loss = 0.0117907 (* 1 = 0.0117907 loss)
I0110 09:41:01.992154  4932 solver.cpp:631] Iteration 29800, lr = 1e-06
I0110 09:41:04.548878  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5322 > 20) by scale factor 0.974079
I0110 09:41:46.376863  4932 solver.cpp:240] Iteration 29820, loss = 0.0245093
I0110 09:41:46.376950  4932 solver.cpp:255]     Train net output #0: loss = 0.0261562 (* 1 = 0.0261562 loss)
I0110 09:41:46.376958  4932 solver.cpp:631] Iteration 29820, lr = 1e-06
I0110 09:42:04.465016  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6715 > 20) by scale factor 0.922869
I0110 09:42:30.754001  4932 solver.cpp:240] Iteration 29840, loss = 0.0542429
I0110 09:42:30.754088  4932 solver.cpp:255]     Train net output #0: loss = 0.0746353 (* 1 = 0.0746353 loss)
I0110 09:42:30.754101  4932 solver.cpp:631] Iteration 29840, lr = 1e-06
I0110 09:42:42.185252  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9122 > 20) by scale factor 0.872896
I0110 09:43:15.134472  4932 solver.cpp:240] Iteration 29860, loss = 0.101479
I0110 09:43:15.134541  4932 solver.cpp:255]     Train net output #0: loss = 0.048584 (* 1 = 0.048584 loss)
I0110 09:43:15.134549  4932 solver.cpp:631] Iteration 29860, lr = 1e-06
I0110 09:43:59.519618  4932 solver.cpp:240] Iteration 29880, loss = 0.0576801
I0110 09:43:59.519681  4932 solver.cpp:255]     Train net output #0: loss = 0.021504 (* 1 = 0.021504 loss)
I0110 09:43:59.519691  4932 solver.cpp:631] Iteration 29880, lr = 1e-06
I0110 09:44:43.892592  4932 solver.cpp:240] Iteration 29900, loss = 0.0533252
I0110 09:44:43.892676  4932 solver.cpp:255]     Train net output #0: loss = 0.0632501 (* 1 = 0.0632501 loss)
I0110 09:44:43.892688  4932 solver.cpp:631] Iteration 29900, lr = 1e-06
I0110 09:45:28.264617  4932 solver.cpp:240] Iteration 29920, loss = 0.0480841
I0110 09:45:28.264693  4932 solver.cpp:255]     Train net output #0: loss = 0.0114531 (* 1 = 0.0114531 loss)
I0110 09:45:28.264703  4932 solver.cpp:631] Iteration 29920, lr = 1e-06
I0110 09:45:53.011409  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9358 > 20) by scale factor 0.691185
I0110 09:46:12.640285  4932 solver.cpp:240] Iteration 29940, loss = 0.0835587
I0110 09:46:12.640374  4932 solver.cpp:255]     Train net output #0: loss = 0.076503 (* 1 = 0.076503 loss)
I0110 09:46:12.640384  4932 solver.cpp:631] Iteration 29940, lr = 1e-06
I0110 09:46:24.071113  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5068 > 20) by scale factor 0.784103
I0110 09:46:26.293908  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0225 > 20) by scale factor 0.740123
I0110 09:46:28.515403  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4047 > 20) by scale factor 0.934376
I0110 09:46:35.173806  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2617 > 20) by scale factor 0.824345
I0110 09:46:37.396167  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7012 > 20) by scale factor 0.921609
I0110 09:46:57.025908  4932 solver.cpp:240] Iteration 29960, loss = 0.127297
I0110 09:46:57.025995  4932 solver.cpp:255]     Train net output #0: loss = 0.0282618 (* 1 = 0.0282618 loss)
I0110 09:46:57.026006  4932 solver.cpp:631] Iteration 29960, lr = 1e-06
I0110 09:47:10.685205  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2228 > 20) by scale factor 0.762696
I0110 09:47:41.407559  4932 solver.cpp:240] Iteration 29980, loss = 0.0691544
I0110 09:47:41.407635  4932 solver.cpp:255]     Train net output #0: loss = 0.0467945 (* 1 = 0.0467945 loss)
I0110 09:47:41.407645  4932 solver.cpp:631] Iteration 29980, lr = 1e-06
I0110 09:47:43.966012  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.091 > 20) by scale factor 0.766549
I0110 09:48:17.253825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9448 > 20) by scale factor 0.911376
I0110 09:48:23.925186  4932 solver.cpp:424] Iteration 30000, Testing net (#0)
I0110 09:49:12.756897  4932 solver.cpp:481]     Test net output #0: accuracy = 0.842105
I0110 09:49:12.756989  4932 solver.cpp:481]     Test net output #1: loss = 0.779318 (* 1 = 0.779318 loss)
I0110 09:49:14.623280  4932 solver.cpp:240] Iteration 30000, loss = 0.0739566
I0110 09:49:14.623322  4932 solver.cpp:255]     Train net output #0: loss = 0.163231 (* 1 = 0.163231 loss)
I0110 09:49:14.623332  4932 solver.cpp:565] MultiStep Status: Iteration 30000, step = 3
I0110 09:49:14.640717  4932 solver.cpp:631] Iteration 30000, lr = 1e-07
I0110 09:49:19.402549  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.372 > 20) by scale factor 0.981739
I0110 09:49:28.284394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1887 > 20) by scale factor 0.943901
I0110 09:49:39.384997  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4534 > 20) by scale factor 0.852754
I0110 09:49:59.023988  4932 solver.cpp:240] Iteration 30020, loss = 0.0586831
I0110 09:49:59.024071  4932 solver.cpp:255]     Train net output #0: loss = 0.00822072 (* 1 = 0.00822072 loss)
I0110 09:49:59.024082  4932 solver.cpp:631] Iteration 30020, lr = 1e-07
I0110 09:50:01.581665  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4829 > 20) by scale factor 0.727724
I0110 09:50:19.336577  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2081 > 20) by scale factor 0.793397
I0110 09:50:25.993518  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.338 > 20) by scale factor 0.983383
I0110 09:50:34.875224  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0197 > 20) by scale factor 0.951487
I0110 09:50:43.415603  4932 solver.cpp:240] Iteration 30040, loss = 0.0888657
I0110 09:50:43.415632  4932 solver.cpp:255]     Train net output #0: loss = 0.00396967 (* 1 = 0.00396967 loss)
I0110 09:50:43.415640  4932 solver.cpp:631] Iteration 30040, lr = 1e-07
I0110 09:51:25.921758  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7125 > 20) by scale factor 0.92113
I0110 09:51:27.804667  4932 solver.cpp:240] Iteration 30060, loss = 0.0418804
I0110 09:51:27.804708  4932 solver.cpp:255]     Train net output #0: loss = 0.0576403 (* 1 = 0.0576403 loss)
I0110 09:51:27.804718  4932 solver.cpp:631] Iteration 30060, lr = 1e-07
I0110 09:51:39.246387  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2523 > 20) by scale factor 0.761837
I0110 09:52:03.665132  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5403 > 20) by scale factor 0.973697
I0110 09:52:12.209769  4932 solver.cpp:240] Iteration 30080, loss = 0.100119
I0110 09:52:12.209810  4932 solver.cpp:255]     Train net output #0: loss = 0.165177 (* 1 = 0.165177 loss)
I0110 09:52:12.209818  4932 solver.cpp:631] Iteration 30080, lr = 1e-07
I0110 09:52:56.597425  4932 solver.cpp:240] Iteration 30100, loss = 0.0909706
I0110 09:52:56.597508  4932 solver.cpp:255]     Train net output #0: loss = 0.0420474 (* 1 = 0.0420474 loss)
I0110 09:52:56.597522  4932 solver.cpp:631] Iteration 30100, lr = 1e-07
I0110 09:53:25.789479  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6723 > 20) by scale factor 0.84487
I0110 09:53:40.986316  4932 solver.cpp:240] Iteration 30120, loss = 0.0382618
I0110 09:53:40.986394  4932 solver.cpp:255]     Train net output #0: loss = 0.00878758 (* 1 = 0.00878758 loss)
I0110 09:53:40.986405  4932 solver.cpp:631] Iteration 30120, lr = 1e-07
I0110 09:53:45.762893  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5658 > 20) by scale factor 0.848688
I0110 09:53:52.423151  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6877 > 20) by scale factor 0.96676
I0110 09:53:59.088116  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5353 > 20) by scale factor 0.849787
I0110 09:54:25.386132  4932 solver.cpp:240] Iteration 30140, loss = 0.10233
I0110 09:54:25.386205  4932 solver.cpp:255]     Train net output #0: loss = 0.0398958 (* 1 = 0.0398958 loss)
I0110 09:54:25.386215  4932 solver.cpp:631] Iteration 30140, lr = 1e-07
I0110 09:55:09.766630  4932 solver.cpp:240] Iteration 30160, loss = 0.0522488
I0110 09:55:09.766702  4932 solver.cpp:255]     Train net output #0: loss = 0.183354 (* 1 = 0.183354 loss)
I0110 09:55:09.766711  4932 solver.cpp:631] Iteration 30160, lr = 1e-07
I0110 09:55:16.762648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7061 > 20) by scale factor 0.965899
I0110 09:55:25.646716  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.883 > 20) by scale factor 0.692448
I0110 09:55:45.617630  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3955 > 20) by scale factor 0.980608
I0110 09:55:54.157837  4932 solver.cpp:240] Iteration 30180, loss = 0.0611852
I0110 09:55:54.157879  4932 solver.cpp:255]     Train net output #0: loss = 0.0127375 (* 1 = 0.0127375 loss)
I0110 09:55:54.157891  4932 solver.cpp:631] Iteration 30180, lr = 1e-07
I0110 09:56:12.256086  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4417 > 20) by scale factor 0.932763
I0110 09:56:14.477324  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4571 > 20) by scale factor 0.932093
I0110 09:56:34.444417  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9555 > 20) by scale factor 0.910932
I0110 09:56:38.545343  4932 solver.cpp:240] Iteration 30200, loss = 0.0581615
I0110 09:56:38.545383  4932 solver.cpp:255]     Train net output #0: loss = 0.00490614 (* 1 = 0.00490614 loss)
I0110 09:56:38.545392  4932 solver.cpp:631] Iteration 30200, lr = 1e-07
I0110 09:57:14.381055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2426 > 20) by scale factor 0.988014
I0110 09:57:22.918032  4932 solver.cpp:240] Iteration 30220, loss = 0.0379971
I0110 09:57:22.918076  4932 solver.cpp:255]     Train net output #0: loss = 0.017425 (* 1 = 0.017425 loss)
I0110 09:57:22.918087  4932 solver.cpp:631] Iteration 30220, lr = 1e-07
I0110 09:57:25.477877  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6161 > 20) by scale factor 0.812477
I0110 09:58:07.308925  4932 solver.cpp:240] Iteration 30240, loss = 0.0801986
I0110 09:58:07.309064  4932 solver.cpp:255]     Train net output #0: loss = 0.0316927 (* 1 = 0.0316927 loss)
I0110 09:58:07.309082  4932 solver.cpp:631] Iteration 30240, lr = 1e-07
I0110 09:58:51.684069  4932 solver.cpp:240] Iteration 30260, loss = 0.0600375
I0110 09:58:51.684164  4932 solver.cpp:255]     Train net output #0: loss = 0.229807 (* 1 = 0.229807 loss)
I0110 09:58:51.684177  4932 solver.cpp:631] Iteration 30260, lr = 1e-07
I0110 09:59:12.000488  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8155 > 20) by scale factor 0.960821
I0110 09:59:18.662518  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2558 > 20) by scale factor 0.824546
I0110 09:59:36.074504  4932 solver.cpp:240] Iteration 30280, loss = 0.121945
I0110 09:59:36.074591  4932 solver.cpp:255]     Train net output #0: loss = 0.231831 (* 1 = 0.231831 loss)
I0110 09:59:36.074604  4932 solver.cpp:631] Iteration 30280, lr = 1e-07
I0110 10:00:09.701606  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1229 > 20) by scale factor 0.993894
I0110 10:00:11.921084  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.33 > 20) by scale factor 0.705966
I0110 10:00:20.454921  4932 solver.cpp:240] Iteration 30300, loss = 0.0593446
I0110 10:00:20.454959  4932 solver.cpp:255]     Train net output #0: loss = 0.028328 (* 1 = 0.028328 loss)
I0110 10:00:20.454970  4932 solver.cpp:631] Iteration 30300, lr = 1e-07
I0110 10:00:47.430289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1208 > 20) by scale factor 0.993996
I0110 10:01:04.840020  4932 solver.cpp:240] Iteration 30320, loss = 0.0595354
I0110 10:01:04.840068  4932 solver.cpp:255]     Train net output #0: loss = 0.0623144 (* 1 = 0.0623144 loss)
I0110 10:01:04.840081  4932 solver.cpp:631] Iteration 30320, lr = 1e-07
I0110 10:01:45.124332  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.6208 > 20) by scale factor 0.65315
I0110 10:01:49.224459  4932 solver.cpp:240] Iteration 30340, loss = 0.072655
I0110 10:01:49.224498  4932 solver.cpp:255]     Train net output #0: loss = 0.0445453 (* 1 = 0.0445453 loss)
I0110 10:01:49.224509  4932 solver.cpp:631] Iteration 30340, lr = 1e-07
I0110 10:02:31.719645  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1547 > 20) by scale factor 0.992324
I0110 10:02:33.601455  4932 solver.cpp:240] Iteration 30360, loss = 0.0630461
I0110 10:02:33.601498  4932 solver.cpp:255]     Train net output #0: loss = 0.0206627 (* 1 = 0.0206627 loss)
I0110 10:02:33.601511  4932 solver.cpp:631] Iteration 30360, lr = 1e-07
I0110 10:03:17.982909  4932 solver.cpp:240] Iteration 30380, loss = 0.0484236
I0110 10:03:17.983006  4932 solver.cpp:255]     Train net output #0: loss = 0.0321133 (* 1 = 0.0321133 loss)
I0110 10:03:17.983021  4932 solver.cpp:631] Iteration 30380, lr = 1e-07
I0110 10:03:38.299132  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1494 > 20) by scale factor 0.902961
I0110 10:03:40.520069  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3284 > 20) by scale factor 0.706005
I0110 10:04:02.376219  4932 solver.cpp:240] Iteration 30400, loss = 0.0894202
I0110 10:04:02.376296  4932 solver.cpp:255]     Train net output #0: loss = 0.348944 (* 1 = 0.348944 loss)
I0110 10:04:02.376305  4932 solver.cpp:631] Iteration 30400, lr = 1e-07
I0110 10:04:35.996237  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4664 > 20) by scale factor 0.728162
I0110 10:04:44.880535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.464 > 20) by scale factor 0.656513
I0110 10:04:46.762260  4932 solver.cpp:240] Iteration 30420, loss = 0.0839867
I0110 10:04:46.762298  4932 solver.cpp:255]     Train net output #0: loss = 0.0156846 (* 1 = 0.0156846 loss)
I0110 10:04:46.762308  4932 solver.cpp:631] Iteration 30420, lr = 1e-07
I0110 10:04:53.754470  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7477 > 20) by scale factor 0.879209
I0110 10:05:04.851552  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2509 > 20) by scale factor 0.941138
I0110 10:05:31.148175  4932 solver.cpp:240] Iteration 30440, loss = 0.109678
I0110 10:05:31.148277  4932 solver.cpp:255]     Train net output #0: loss = 0.0648898 (* 1 = 0.0648898 loss)
I0110 10:05:31.148290  4932 solver.cpp:631] Iteration 30440, lr = 1e-07
I0110 10:05:44.804316  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0442 > 20) by scale factor 0.831801
I0110 10:06:15.530580  4932 solver.cpp:240] Iteration 30460, loss = 0.0306202
I0110 10:06:15.530658  4932 solver.cpp:255]     Train net output #0: loss = 0.00227829 (* 1 = 0.00227829 loss)
I0110 10:06:15.530668  4932 solver.cpp:631] Iteration 30460, lr = 1e-07
I0110 10:06:59.913136  4932 solver.cpp:240] Iteration 30480, loss = 0.0649262
I0110 10:06:59.913213  4932 solver.cpp:255]     Train net output #0: loss = 0.00156315 (* 1 = 0.00156315 loss)
I0110 10:06:59.913223  4932 solver.cpp:631] Iteration 30480, lr = 1e-07
I0110 10:07:31.323014  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6219 > 20) by scale factor 0.884099
I0110 10:07:44.299032  4932 solver.cpp:240] Iteration 30500, loss = 0.0854836
I0110 10:07:44.299077  4932 solver.cpp:255]     Train net output #0: loss = 0.0523444 (* 1 = 0.0523444 loss)
I0110 10:07:44.299088  4932 solver.cpp:631] Iteration 30500, lr = 1e-07
I0110 10:07:51.297072  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6339 > 20) by scale factor 0.969278
I0110 10:08:20.157328  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1482 > 20) by scale factor 0.992644
I0110 10:08:26.819533  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.5492 > 20) by scale factor 0.654682
I0110 10:08:28.704257  4932 solver.cpp:240] Iteration 30520, loss = 0.0748443
I0110 10:08:28.704293  4932 solver.cpp:255]     Train net output #0: loss = 0.102377 (* 1 = 0.102377 loss)
I0110 10:08:28.704305  4932 solver.cpp:631] Iteration 30520, lr = 1e-07
I0110 10:09:13.093873  4932 solver.cpp:240] Iteration 30540, loss = 0.0449008
I0110 10:09:13.093941  4932 solver.cpp:255]     Train net output #0: loss = 0.00128999 (* 1 = 0.00128999 loss)
I0110 10:09:13.093950  4932 solver.cpp:631] Iteration 30540, lr = 1e-07
I0110 10:09:57.482350  4932 solver.cpp:240] Iteration 30560, loss = 0.0580999
I0110 10:09:57.482424  4932 solver.cpp:255]     Train net output #0: loss = 0.201674 (* 1 = 0.201674 loss)
I0110 10:09:57.482434  4932 solver.cpp:631] Iteration 30560, lr = 1e-07
I0110 10:10:04.475579  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2288 > 20) by scale factor 0.988689
I0110 10:10:24.449863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.139 > 20) by scale factor 0.663591
I0110 10:10:28.891906  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9404 > 20) by scale factor 0.955093
I0110 10:10:31.113962  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4041 > 20) by scale factor 0.980195
I0110 10:10:39.988620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5426 > 20) by scale factor 0.887208
I0110 10:10:41.870241  4932 solver.cpp:240] Iteration 30580, loss = 0.0903903
I0110 10:10:41.870281  4932 solver.cpp:255]     Train net output #0: loss = 0.0938244 (* 1 = 0.0938244 loss)
I0110 10:10:41.870296  4932 solver.cpp:631] Iteration 30580, lr = 1e-07
I0110 10:10:59.962968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.117 > 20) by scale factor 0.947104
I0110 10:11:02.186712  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5831 > 20) by scale factor 0.97167
I0110 10:11:06.627197  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3659 > 20) by scale factor 0.705073
I0110 10:11:22.154347  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4719 > 20) by scale factor 0.976949
I0110 10:11:26.252681  4932 solver.cpp:240] Iteration 30600, loss = 0.0801529
I0110 10:11:26.252722  4932 solver.cpp:255]     Train net output #0: loss = 0.0426203 (* 1 = 0.0426203 loss)
I0110 10:11:26.252732  4932 solver.cpp:631] Iteration 30600, lr = 1e-07
I0110 10:11:28.809331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2202 > 20) by scale factor 0.98911
I0110 10:11:53.222409  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4384 > 20) by scale factor 0.756476
I0110 10:12:04.320762  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4805 > 20) by scale factor 0.727788
I0110 10:12:10.642150  4932 solver.cpp:240] Iteration 30620, loss = 0.0917617
I0110 10:12:10.642189  4932 solver.cpp:255]     Train net output #0: loss = 0.00424549 (* 1 = 0.00424549 loss)
I0110 10:12:10.642199  4932 solver.cpp:631] Iteration 30620, lr = 1e-07
I0110 10:12:55.019088  4932 solver.cpp:240] Iteration 30640, loss = 0.0524452
I0110 10:12:55.019181  4932 solver.cpp:255]     Train net output #0: loss = 0.263796 (* 1 = 0.263796 loss)
I0110 10:12:55.019193  4932 solver.cpp:631] Iteration 30640, lr = 1e-07
I0110 10:13:39.396803  4932 solver.cpp:240] Iteration 30660, loss = 0.0225137
I0110 10:13:39.396903  4932 solver.cpp:255]     Train net output #0: loss = 0.0265886 (* 1 = 0.0265886 loss)
I0110 10:13:39.396916  4932 solver.cpp:631] Iteration 30660, lr = 1e-07
I0110 10:13:41.959954  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0982 > 20) by scale factor 0.995116
I0110 10:13:53.054539  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5312 > 20) by scale factor 0.974126
I0110 10:14:13.027137  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6843 > 20) by scale factor 0.922325
I0110 10:14:19.686803  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1835 > 20) by scale factor 0.901571
I0110 10:14:23.785264  4932 solver.cpp:240] Iteration 30680, loss = 0.0749615
I0110 10:14:23.785305  4932 solver.cpp:255]     Train net output #0: loss = 0.00422739 (* 1 = 0.00422739 loss)
I0110 10:14:23.785313  4932 solver.cpp:631] Iteration 30680, lr = 1e-07
I0110 10:14:46.312628  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4916 > 20) by scale factor 0.784573
I0110 10:15:08.164788  4932 solver.cpp:240] Iteration 30700, loss = 0.0660373
I0110 10:15:08.164827  4932 solver.cpp:255]     Train net output #0: loss = 0.0598503 (* 1 = 0.0598503 loss)
I0110 10:15:08.164837  4932 solver.cpp:631] Iteration 30700, lr = 1e-07
I0110 10:15:52.542418  4932 solver.cpp:240] Iteration 30720, loss = 0.0404125
I0110 10:15:52.542506  4932 solver.cpp:255]     Train net output #0: loss = 0.0152453 (* 1 = 0.0152453 loss)
I0110 10:15:52.542520  4932 solver.cpp:631] Iteration 30720, lr = 1e-07
I0110 10:16:36.920256  4932 solver.cpp:240] Iteration 30740, loss = 0.0588926
I0110 10:16:36.920321  4932 solver.cpp:255]     Train net output #0: loss = 0.0593567 (* 1 = 0.0593567 loss)
I0110 10:16:36.920332  4932 solver.cpp:631] Iteration 30740, lr = 1e-07
I0110 10:17:21.296800  4932 solver.cpp:240] Iteration 30760, loss = 0.0827404
I0110 10:17:21.296867  4932 solver.cpp:255]     Train net output #0: loss = 0.00297021 (* 1 = 0.00297021 loss)
I0110 10:17:21.296876  4932 solver.cpp:631] Iteration 30760, lr = 1e-07
I0110 10:17:23.852851  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.017 > 20) by scale factor 0.951613
I0110 10:17:30.511509  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9446 > 20) by scale factor 0.9549
I0110 10:17:39.391151  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2658 > 20) by scale factor 0.70757
I0110 10:18:05.681695  4932 solver.cpp:240] Iteration 30780, loss = 0.0655923
I0110 10:18:05.681784  4932 solver.cpp:255]     Train net output #0: loss = 0.00560498 (* 1 = 0.00560498 loss)
I0110 10:18:05.681798  4932 solver.cpp:631] Iteration 30780, lr = 1e-07
I0110 10:18:50.054020  4932 solver.cpp:240] Iteration 30800, loss = 0.0451331
I0110 10:18:50.054112  4932 solver.cpp:255]     Train net output #0: loss = 0.0614939 (* 1 = 0.0614939 loss)
I0110 10:18:50.054127  4932 solver.cpp:631] Iteration 30800, lr = 1e-07
I0110 10:18:59.273068  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1052 > 20) by scale factor 0.904765
I0110 10:19:23.674495  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6737 > 20) by scale factor 0.749802
I0110 10:19:34.432368  4932 solver.cpp:240] Iteration 30820, loss = 0.0590842
I0110 10:19:34.432415  4932 solver.cpp:255]     Train net output #0: loss = 0.022083 (* 1 = 0.022083 loss)
I0110 10:19:34.432426  4932 solver.cpp:631] Iteration 30820, lr = 1e-07
I0110 10:19:36.991688  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6449 > 20) by scale factor 0.924006
I0110 10:19:50.313787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6238 > 20) by scale factor 0.884027
I0110 10:19:54.755205  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5671 > 20) by scale factor 0.972427
I0110 10:20:18.839651  4932 solver.cpp:240] Iteration 30840, loss = 0.0674111
I0110 10:20:18.839696  4932 solver.cpp:255]     Train net output #0: loss = 0.0259839 (* 1 = 0.0259839 loss)
I0110 10:20:18.839709  4932 solver.cpp:631] Iteration 30840, lr = 1e-07
I0110 10:20:45.824579  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5191 > 20) by scale factor 0.974703
I0110 10:20:48.047209  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6195 > 20) by scale factor 0.812364
I0110 10:21:03.252327  4932 solver.cpp:240] Iteration 30860, loss = 0.0745401
I0110 10:21:03.252372  4932 solver.cpp:255]     Train net output #0: loss = 0.0180385 (* 1 = 0.0180385 loss)
I0110 10:21:03.252383  4932 solver.cpp:631] Iteration 30860, lr = 1e-07
I0110 10:21:05.812332  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4513 > 20) by scale factor 0.852831
I0110 10:21:23.573469  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.3813 > 20) by scale factor 0.581712
I0110 10:21:47.652441  4932 solver.cpp:240] Iteration 30880, loss = 0.0615697
I0110 10:21:47.652484  4932 solver.cpp:255]     Train net output #0: loss = 0.01309 (* 1 = 0.01309 loss)
I0110 10:21:47.652496  4932 solver.cpp:631] Iteration 30880, lr = 1e-07
I0110 10:22:10.190239  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5035 > 20) by scale factor 0.816212
I0110 10:22:25.731722  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1728 > 20) by scale factor 0.827377
I0110 10:22:32.058948  4932 solver.cpp:240] Iteration 30900, loss = 0.0597399
I0110 10:22:32.058993  4932 solver.cpp:255]     Train net output #0: loss = 0.000808676 (* 1 = 0.000808676 loss)
I0110 10:22:32.059005  4932 solver.cpp:631] Iteration 30900, lr = 1e-07
I0110 10:23:10.141496  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5599 > 20) by scale factor 0.972768
I0110 10:23:12.365460  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6101 > 20) by scale factor 0.925493
I0110 10:23:16.469046  4932 solver.cpp:240] Iteration 30920, loss = 0.0740345
I0110 10:23:16.469091  4932 solver.cpp:255]     Train net output #0: loss = 0.00300649 (* 1 = 0.00300649 loss)
I0110 10:23:16.469102  4932 solver.cpp:631] Iteration 30920, lr = 1e-07
I0110 10:24:00.875286  4932 solver.cpp:240] Iteration 30940, loss = 0.0615932
I0110 10:24:00.875368  4932 solver.cpp:255]     Train net output #0: loss = 0.0115919 (* 1 = 0.0115919 loss)
I0110 10:24:00.875380  4932 solver.cpp:631] Iteration 30940, lr = 1e-07
I0110 10:24:05.657443  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4306 > 20) by scale factor 0.978926
I0110 10:24:12.318949  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2151 > 20) by scale factor 0.900288
I0110 10:24:34.504720  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4103 > 20) by scale factor 0.892448
I0110 10:24:45.265429  4932 solver.cpp:240] Iteration 30960, loss = 0.101689
I0110 10:24:45.265458  4932 solver.cpp:255]     Train net output #0: loss = 0.133383 (* 1 = 0.133383 loss)
I0110 10:24:45.265467  4932 solver.cpp:631] Iteration 30960, lr = 1e-07
I0110 10:24:45.604457  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9721 > 20) by scale factor 0.953648
I0110 10:25:01.141540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.042 > 20) by scale factor 0.90736
I0110 10:25:16.672814  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1736 > 20) by scale factor 0.944573
I0110 10:25:29.648537  4932 solver.cpp:240] Iteration 30980, loss = 0.0776841
I0110 10:25:29.648573  4932 solver.cpp:255]     Train net output #0: loss = 0.0038928 (* 1 = 0.0038928 loss)
I0110 10:25:29.648582  4932 solver.cpp:631] Iteration 30980, lr = 1e-07
I0110 10:25:49.965222  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7162 > 20) by scale factor 0.880428
I0110 10:26:01.066293  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8888 > 20) by scale factor 0.772535
I0110 10:26:07.724169  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4914 > 20) by scale factor 0.655922
I0110 10:26:12.176213  4932 solver.cpp:424] Iteration 31000, Testing net (#0)
I0110 10:27:00.860591  4932 solver.cpp:481]     Test net output #0: accuracy = 0.847368
I0110 10:27:00.860671  4932 solver.cpp:481]     Test net output #1: loss = 0.74492 (* 1 = 0.74492 loss)
I0110 10:27:02.726938  4932 solver.cpp:240] Iteration 31000, loss = 0.043403
I0110 10:27:02.726974  4932 solver.cpp:255]     Train net output #0: loss = 0.00431577 (* 1 = 0.00431577 loss)
I0110 10:27:02.726982  4932 solver.cpp:631] Iteration 31000, lr = 1e-07
I0110 10:27:29.686414  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4314 > 20) by scale factor 0.891609
I0110 10:27:47.093485  4932 solver.cpp:240] Iteration 31020, loss = 0.099538
I0110 10:27:47.093595  4932 solver.cpp:255]     Train net output #0: loss = 0.0414368 (* 1 = 0.0414368 loss)
I0110 10:27:47.093611  4932 solver.cpp:631] Iteration 31020, lr = 1e-07
I0110 10:27:51.872246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6731 > 20) by scale factor 0.882102
I0110 10:28:31.470142  4932 solver.cpp:240] Iteration 31040, loss = 0.0713644
I0110 10:28:31.470228  4932 solver.cpp:255]     Train net output #0: loss = 0.176737 (* 1 = 0.176737 loss)
I0110 10:28:31.470238  4932 solver.cpp:631] Iteration 31040, lr = 1e-07
I0110 10:28:42.903177  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0682 > 20) by scale factor 0.996601
I0110 10:28:45.125115  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6763 > 20) by scale factor 0.778928
I0110 10:29:09.528318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4234 > 20) by scale factor 0.891925
I0110 10:29:15.845017  4932 solver.cpp:240] Iteration 31060, loss = 0.0691009
I0110 10:29:15.845055  4932 solver.cpp:255]     Train net output #0: loss = 0.000153768 (* 1 = 0.000153768 loss)
I0110 10:29:15.845063  4932 solver.cpp:631] Iteration 31060, lr = 1e-07
I0110 10:29:36.150773  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7023 > 20) by scale factor 0.966077
I0110 10:30:00.219137  4932 solver.cpp:240] Iteration 31080, loss = 0.0714363
I0110 10:30:00.219229  4932 solver.cpp:255]     Train net output #0: loss = 0.120017 (* 1 = 0.120017 loss)
I0110 10:30:00.219241  4932 solver.cpp:631] Iteration 31080, lr = 1e-07
I0110 10:30:11.651685  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9981 > 20) by scale factor 0.740792
I0110 10:30:27.183082  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4777 > 20) by scale factor 0.97667
I0110 10:30:44.589550  4932 solver.cpp:240] Iteration 31100, loss = 0.0929264
I0110 10:30:44.589637  4932 solver.cpp:255]     Train net output #0: loss = 0.00126937 (* 1 = 0.00126937 loss)
I0110 10:30:44.589646  4932 solver.cpp:631] Iteration 31100, lr = 1e-07
I0110 10:30:58.241634  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0543 > 20) by scale factor 0.798265
I0110 10:31:20.427772  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.779 > 20) by scale factor 0.918315
I0110 10:31:28.962810  4932 solver.cpp:240] Iteration 31120, loss = 0.0663988
I0110 10:31:28.962849  4932 solver.cpp:255]     Train net output #0: loss = 0.0122277 (* 1 = 0.0122277 loss)
I0110 10:31:28.962858  4932 solver.cpp:631] Iteration 31120, lr = 1e-07
I0110 10:32:00.362540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.967 > 20) by scale factor 0.870816
I0110 10:32:13.336450  4932 solver.cpp:240] Iteration 31140, loss = 0.0570322
I0110 10:32:13.336493  4932 solver.cpp:255]     Train net output #0: loss = 0.0169649 (* 1 = 0.0169649 loss)
I0110 10:32:13.336504  4932 solver.cpp:631] Iteration 31140, lr = 1e-07
I0110 10:32:18.111623  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.666 > 20) by scale factor 0.845095
I0110 10:32:24.769023  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0786 > 20) by scale factor 0.866605
I0110 10:32:57.713595  4932 solver.cpp:240] Iteration 31160, loss = 0.0920588
I0110 10:32:57.713661  4932 solver.cpp:255]     Train net output #0: loss = 0.00532347 (* 1 = 0.00532347 loss)
I0110 10:32:57.713671  4932 solver.cpp:631] Iteration 31160, lr = 1e-07
I0110 10:33:24.667793  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4132 > 20) by scale factor 0.729576
I0110 10:33:42.076820  4932 solver.cpp:240] Iteration 31180, loss = 0.0881885
I0110 10:33:42.076890  4932 solver.cpp:255]     Train net output #0: loss = 0.14771 (* 1 = 0.14771 loss)
I0110 10:33:42.076900  4932 solver.cpp:631] Iteration 31180, lr = 1e-07
I0110 10:34:26.447937  4932 solver.cpp:240] Iteration 31200, loss = 0.0705943
I0110 10:34:26.448009  4932 solver.cpp:255]     Train net output #0: loss = 0.113469 (* 1 = 0.113469 loss)
I0110 10:34:26.448019  4932 solver.cpp:631] Iteration 31200, lr = 1e-07
I0110 10:34:29.005151  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1508 > 20) by scale factor 0.686088
I0110 10:35:10.820083  4932 solver.cpp:240] Iteration 31220, loss = 0.0777088
I0110 10:35:10.820157  4932 solver.cpp:255]     Train net output #0: loss = 0.0695387 (* 1 = 0.0695387 loss)
I0110 10:35:10.820165  4932 solver.cpp:631] Iteration 31220, lr = 1e-07
I0110 10:35:17.813562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3343 > 20) by scale factor 0.983558
I0110 10:35:55.188798  4932 solver.cpp:240] Iteration 31240, loss = 0.0703371
I0110 10:35:55.188870  4932 solver.cpp:255]     Train net output #0: loss = 0.0129507 (* 1 = 0.0129507 loss)
I0110 10:35:55.188879  4932 solver.cpp:631] Iteration 31240, lr = 1e-07
I0110 10:36:11.052338  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.474 > 20) by scale factor 0.931359
I0110 10:36:39.549957  4932 solver.cpp:240] Iteration 31260, loss = 0.0961104
I0110 10:36:39.550030  4932 solver.cpp:255]     Train net output #0: loss = 0.225706 (* 1 = 0.225706 loss)
I0110 10:36:39.550040  4932 solver.cpp:631] Iteration 31260, lr = 1e-07
I0110 10:36:39.889449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8554 > 20) by scale factor 0.838385
I0110 10:37:23.927726  4932 solver.cpp:240] Iteration 31280, loss = 0.0475871
I0110 10:37:23.927803  4932 solver.cpp:255]     Train net output #0: loss = 0.00839983 (* 1 = 0.00839983 loss)
I0110 10:37:23.927812  4932 solver.cpp:631] Iteration 31280, lr = 1e-07
I0110 10:37:37.574072  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9655 > 20) by scale factor 0.953946
I0110 10:38:08.301260  4932 solver.cpp:240] Iteration 31300, loss = 0.0604016
I0110 10:38:08.301354  4932 solver.cpp:255]     Train net output #0: loss = 0.0321394 (* 1 = 0.0321394 loss)
I0110 10:38:08.301364  4932 solver.cpp:631] Iteration 31300, lr = 1e-07
I0110 10:38:19.734760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8506 > 20) by scale factor 0.959204
I0110 10:38:52.671545  4932 solver.cpp:240] Iteration 31320, loss = 0.039617
I0110 10:38:52.671619  4932 solver.cpp:255]     Train net output #0: loss = 0.00775568 (* 1 = 0.00775568 loss)
I0110 10:38:52.671629  4932 solver.cpp:631] Iteration 31320, lr = 1e-07
I0110 10:39:10.759598  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9527 > 20) by scale factor 0.911051
I0110 10:39:37.046504  4932 solver.cpp:240] Iteration 31340, loss = 0.0401141
I0110 10:39:37.046596  4932 solver.cpp:255]     Train net output #0: loss = 0.0452481 (* 1 = 0.0452481 loss)
I0110 10:39:37.046608  4932 solver.cpp:631] Iteration 31340, lr = 1e-07
I0110 10:40:21.413067  4932 solver.cpp:240] Iteration 31360, loss = 0.0659473
I0110 10:40:21.413156  4932 solver.cpp:255]     Train net output #0: loss = 0.00336387 (* 1 = 0.00336387 loss)
I0110 10:40:21.413169  4932 solver.cpp:631] Iteration 31360, lr = 1e-07
I0110 10:40:59.458967  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6684 > 20) by scale factor 0.923004
I0110 10:41:01.678994  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4816 > 20) by scale factor 0.851732
I0110 10:41:05.779495  4932 solver.cpp:240] Iteration 31380, loss = 0.0664313
I0110 10:41:05.779541  4932 solver.cpp:255]     Train net output #0: loss = 0.156777 (* 1 = 0.156777 loss)
I0110 10:41:05.779553  4932 solver.cpp:631] Iteration 31380, lr = 1e-07
I0110 10:41:50.150362  4932 solver.cpp:240] Iteration 31400, loss = 0.0491774
I0110 10:41:50.150437  4932 solver.cpp:255]     Train net output #0: loss = 0.114622 (* 1 = 0.114622 loss)
I0110 10:41:50.150449  4932 solver.cpp:631] Iteration 31400, lr = 1e-07
I0110 10:42:06.015434  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.482 > 20) by scale factor 0.931011
I0110 10:42:34.525475  4932 solver.cpp:240] Iteration 31420, loss = 0.0387555
I0110 10:42:34.525540  4932 solver.cpp:255]     Train net output #0: loss = 0.00709455 (* 1 = 0.00709455 loss)
I0110 10:42:34.525549  4932 solver.cpp:631] Iteration 31420, lr = 1e-07
I0110 10:43:18.889171  4932 solver.cpp:240] Iteration 31440, loss = 0.0541127
I0110 10:43:18.889241  4932 solver.cpp:255]     Train net output #0: loss = 0.143926 (* 1 = 0.143926 loss)
I0110 10:43:18.889251  4932 solver.cpp:631] Iteration 31440, lr = 1e-07
I0110 10:43:30.323789  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.017 > 20) by scale factor 0.868924
I0110 10:43:45.855607  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8238 > 20) by scale factor 0.960439
I0110 10:44:03.265321  4932 solver.cpp:240] Iteration 31460, loss = 0.0633936
I0110 10:44:03.265404  4932 solver.cpp:255]     Train net output #0: loss = 0.00477135 (* 1 = 0.00477135 loss)
I0110 10:44:03.265417  4932 solver.cpp:631] Iteration 31460, lr = 1e-07
I0110 10:44:34.667243  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6541 > 20) by scale factor 0.697981
I0110 10:44:47.645048  4932 solver.cpp:240] Iteration 31480, loss = 0.0678249
I0110 10:44:47.645098  4932 solver.cpp:255]     Train net output #0: loss = 0.0907618 (* 1 = 0.0907618 loss)
I0110 10:44:47.645112  4932 solver.cpp:631] Iteration 31480, lr = 1e-07
I0110 10:45:07.958009  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3533 > 20) by scale factor 0.637891
I0110 10:45:16.833642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1172 > 20) by scale factor 0.994172
I0110 10:45:32.023699  4932 solver.cpp:240] Iteration 31500, loss = 0.0840772
I0110 10:45:32.023741  4932 solver.cpp:255]     Train net output #0: loss = 0.0296023 (* 1 = 0.0296023 loss)
I0110 10:45:32.023761  4932 solver.cpp:631] Iteration 31500, lr = 1e-07
I0110 10:46:16.399195  4932 solver.cpp:240] Iteration 31520, loss = 0.0581548
I0110 10:46:16.399298  4932 solver.cpp:255]     Train net output #0: loss = 0.0175927 (* 1 = 0.0175927 loss)
I0110 10:46:16.399308  4932 solver.cpp:631] Iteration 31520, lr = 1e-07
I0110 10:46:21.172883  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6754 > 20) by scale factor 0.967331
I0110 10:47:00.764060  4932 solver.cpp:240] Iteration 31540, loss = 0.0470702
I0110 10:47:00.764153  4932 solver.cpp:255]     Train net output #0: loss = 0.13437 (* 1 = 0.13437 loss)
I0110 10:47:00.764164  4932 solver.cpp:631] Iteration 31540, lr = 1e-07
I0110 10:47:05.542002  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.1276 > 20) by scale factor 0.603726
I0110 10:47:21.072299  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0988 > 20) by scale factor 0.995085
I0110 10:47:45.138190  4932 solver.cpp:240] Iteration 31560, loss = 0.0531461
I0110 10:47:45.138267  4932 solver.cpp:255]     Train net output #0: loss = 0.0057076 (* 1 = 0.0057076 loss)
I0110 10:47:45.138275  4932 solver.cpp:631] Iteration 31560, lr = 1e-07
I0110 10:48:01.005528  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8927 > 20) by scale factor 0.87364
I0110 10:48:20.981587  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6641 > 20) by scale factor 0.967861
I0110 10:48:27.639644  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0784 > 20) by scale factor 0.7975
I0110 10:48:29.521049  4932 solver.cpp:240] Iteration 31580, loss = 0.0819649
I0110 10:48:29.521087  4932 solver.cpp:255]     Train net output #0: loss = 0.0498961 (* 1 = 0.0498961 loss)
I0110 10:48:29.521096  4932 solver.cpp:631] Iteration 31580, lr = 1e-07
I0110 10:48:36.515319  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6208 > 20) by scale factor 0.925034
I0110 10:49:09.787803  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8449 > 20) by scale factor 0.804995
I0110 10:49:13.889626  4932 solver.cpp:240] Iteration 31600, loss = 0.103558
I0110 10:49:13.889672  4932 solver.cpp:255]     Train net output #0: loss = 0.0126874 (* 1 = 0.0126874 loss)
I0110 10:49:13.889683  4932 solver.cpp:631] Iteration 31600, lr = 1e-07
I0110 10:49:51.942123  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4306 > 20) by scale factor 0.818645
I0110 10:49:58.259578  4932 solver.cpp:240] Iteration 31620, loss = 0.065595
I0110 10:49:58.259619  4932 solver.cpp:255]     Train net output #0: loss = 0.032723 (* 1 = 0.032723 loss)
I0110 10:49:58.259629  4932 solver.cpp:631] Iteration 31620, lr = 1e-07
I0110 10:50:40.748517  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1747 > 20) by scale factor 0.79445
I0110 10:50:42.629640  4932 solver.cpp:240] Iteration 31640, loss = 0.0345242
I0110 10:50:42.629681  4932 solver.cpp:255]     Train net output #0: loss = 0.0603053 (* 1 = 0.0603053 loss)
I0110 10:50:42.629691  4932 solver.cpp:631] Iteration 31640, lr = 1e-07
I0110 10:50:47.405167  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1281 > 20) by scale factor 0.946608
I0110 10:50:49.625496  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0875 > 20) by scale factor 0.948431
I0110 10:50:58.506806  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3278 > 20) by scale factor 0.937744
I0110 10:51:27.008754  4932 solver.cpp:240] Iteration 31660, loss = 0.0818605
I0110 10:51:27.008822  4932 solver.cpp:255]     Train net output #0: loss = 0.0599149 (* 1 = 0.0599149 loss)
I0110 10:51:27.008832  4932 solver.cpp:631] Iteration 31660, lr = 1e-07
I0110 10:51:29.565379  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4497 > 20) by scale factor 0.852891
I0110 10:51:38.444959  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7094 > 20) by scale factor 0.921261
I0110 10:52:11.381245  4932 solver.cpp:240] Iteration 31680, loss = 0.0367902
I0110 10:52:11.381357  4932 solver.cpp:255]     Train net output #0: loss = 0.00311126 (* 1 = 0.00311126 loss)
I0110 10:52:11.381371  4932 solver.cpp:631] Iteration 31680, lr = 1e-07
I0110 10:52:55.740303  4932 solver.cpp:240] Iteration 31700, loss = 0.0411218
I0110 10:52:55.740392  4932 solver.cpp:255]     Train net output #0: loss = 0.0152754 (* 1 = 0.0152754 loss)
I0110 10:52:55.740404  4932 solver.cpp:631] Iteration 31700, lr = 1e-07
I0110 10:53:16.051604  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3027 > 20) by scale factor 0.790431
I0110 10:53:18.271821  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0789 > 20) by scale factor 0.996069
I0110 10:53:40.120427  4932 solver.cpp:240] Iteration 31720, loss = 0.0861883
I0110 10:53:40.120507  4932 solver.cpp:255]     Train net output #0: loss = 0.260208 (* 1 = 0.260208 loss)
I0110 10:53:40.120517  4932 solver.cpp:631] Iteration 31720, lr = 1e-07
I0110 10:53:40.459930  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.15 > 20) by scale factor 0.86393
I0110 10:54:07.084977  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9434 > 20) by scale factor 0.911434
I0110 10:54:24.493926  4932 solver.cpp:240] Iteration 31740, loss = 0.041155
I0110 10:54:24.494005  4932 solver.cpp:255]     Train net output #0: loss = 0.0866595 (* 1 = 0.0866595 loss)
I0110 10:54:24.494016  4932 solver.cpp:631] Iteration 31740, lr = 1e-07
I0110 10:55:08.863934  4932 solver.cpp:240] Iteration 31760, loss = 0.0604961
I0110 10:55:08.864007  4932 solver.cpp:255]     Train net output #0: loss = 0.097746 (* 1 = 0.097746 loss)
I0110 10:55:08.864017  4932 solver.cpp:631] Iteration 31760, lr = 1e-07
I0110 10:55:09.202885  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9503 > 20) by scale factor 0.835063
I0110 10:55:20.297803  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.817 > 20) by scale factor 0.839736
I0110 10:55:22.519202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7783 > 20) by scale factor 0.878028
I0110 10:55:53.243791  4932 solver.cpp:240] Iteration 31780, loss = 0.0606993
I0110 10:55:53.243865  4932 solver.cpp:255]     Train net output #0: loss = 0.0205737 (* 1 = 0.0205737 loss)
I0110 10:55:53.243875  4932 solver.cpp:631] Iteration 31780, lr = 1e-07
I0110 10:55:55.802438  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.497 > 20) by scale factor 0.701829
I0110 10:56:11.333693  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0137 > 20) by scale factor 0.999314
I0110 10:56:24.647788  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9217 > 20) by scale factor 0.802513
I0110 10:56:37.621399  4932 solver.cpp:240] Iteration 31800, loss = 0.089847
I0110 10:56:37.621438  4932 solver.cpp:255]     Train net output #0: loss = 0.061345 (* 1 = 0.061345 loss)
I0110 10:56:37.621445  4932 solver.cpp:631] Iteration 31800, lr = 1e-07
I0110 10:56:46.835242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5173 > 20) by scale factor 0.974785
I0110 10:57:21.989991  4932 solver.cpp:240] Iteration 31820, loss = 0.0502025
I0110 10:57:21.990063  4932 solver.cpp:255]     Train net output #0: loss = 0.0248823 (* 1 = 0.0248823 loss)
I0110 10:57:21.990072  4932 solver.cpp:631] Iteration 31820, lr = 1e-07
I0110 10:57:44.515089  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3286 > 20) by scale factor 0.895714
I0110 10:58:00.047760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1781 > 20) by scale factor 0.79434
I0110 10:58:06.366448  4932 solver.cpp:240] Iteration 31840, loss = 0.0793924
I0110 10:58:06.366492  4932 solver.cpp:255]     Train net output #0: loss = 0.0424225 (* 1 = 0.0424225 loss)
I0110 10:58:06.366510  4932 solver.cpp:631] Iteration 31840, lr = 1e-07
I0110 10:58:50.741633  4932 solver.cpp:240] Iteration 31860, loss = 0.0777594
I0110 10:58:50.741734  4932 solver.cpp:255]     Train net output #0: loss = 0.120342 (* 1 = 0.120342 loss)
I0110 10:58:50.741744  4932 solver.cpp:631] Iteration 31860, lr = 1e-07
I0110 10:59:35.109246  4932 solver.cpp:240] Iteration 31880, loss = 0.0335133
I0110 10:59:35.109338  4932 solver.cpp:255]     Train net output #0: loss = 0.0137066 (* 1 = 0.0137066 loss)
I0110 10:59:35.109350  4932 solver.cpp:631] Iteration 31880, lr = 1e-07
I0110 11:00:19.472144  4932 solver.cpp:240] Iteration 31900, loss = 0.0685207
I0110 11:00:19.472218  4932 solver.cpp:255]     Train net output #0: loss = 0.0730452 (* 1 = 0.0730452 loss)
I0110 11:00:19.472229  4932 solver.cpp:631] Iteration 31900, lr = 1e-07
I0110 11:00:24.247318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.074 > 20) by scale factor 0.866776
I0110 11:00:41.997288  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9719 > 20) by scale factor 0.870628
I0110 11:00:44.219419  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.376 > 20) by scale factor 0.565355
I0110 11:01:01.968871  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9375 > 20) by scale factor 0.835509
I0110 11:01:03.850630  4932 solver.cpp:240] Iteration 31920, loss = 0.0834971
I0110 11:01:03.850661  4932 solver.cpp:255]     Train net output #0: loss = 0.0281804 (* 1 = 0.0281804 loss)
I0110 11:01:03.850669  4932 solver.cpp:631] Iteration 31920, lr = 1e-07
I0110 11:01:08.630383  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0777 > 20) by scale factor 0.866637
I0110 11:01:48.223886  4932 solver.cpp:240] Iteration 31940, loss = 0.0831305
I0110 11:01:48.223969  4932 solver.cpp:255]     Train net output #0: loss = 0.169645 (* 1 = 0.169645 loss)
I0110 11:01:48.223981  4932 solver.cpp:631] Iteration 31940, lr = 1e-07
I0110 11:02:32.596144  4932 solver.cpp:240] Iteration 31960, loss = 0.0575574
I0110 11:02:32.596210  4932 solver.cpp:255]     Train net output #0: loss = 0.00808821 (* 1 = 0.00808821 loss)
I0110 11:02:32.596218  4932 solver.cpp:631] Iteration 31960, lr = 1e-07
I0110 11:03:08.435917  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4945 > 20) by scale factor 0.754874
I0110 11:03:16.973039  4932 solver.cpp:240] Iteration 31980, loss = 0.0622559
I0110 11:03:16.973090  4932 solver.cpp:255]     Train net output #0: loss = 0.0210127 (* 1 = 0.0210127 loss)
I0110 11:03:16.973217  4932 solver.cpp:631] Iteration 31980, lr = 1e-07
I0110 11:03:59.506376  4932 solver.cpp:424] Iteration 32000, Testing net (#0)
I0110 11:04:51.382592  4932 solver.cpp:481]     Test net output #0: accuracy = 0.82
I0110 11:04:51.382673  4932 solver.cpp:481]     Test net output #1: loss = 0.895621 (* 1 = 0.895621 loss)
I0110 11:04:53.249202  4932 solver.cpp:240] Iteration 32000, loss = 0.0215823
I0110 11:04:53.249238  4932 solver.cpp:255]     Train net output #0: loss = 0.0136344 (* 1 = 0.0136344 loss)
I0110 11:04:53.249248  4932 solver.cpp:631] Iteration 32000, lr = 1e-07
I0110 11:05:37.624258  4932 solver.cpp:240] Iteration 32020, loss = 0.0475186
I0110 11:05:37.624351  4932 solver.cpp:255]     Train net output #0: loss = 0.00739512 (* 1 = 0.00739512 loss)
I0110 11:05:37.624364  4932 solver.cpp:631] Iteration 32020, lr = 1e-07
I0110 11:05:40.183017  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2505 > 20) by scale factor 0.860195
I0110 11:05:53.504633  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3706 > 20) by scale factor 0.89403
I0110 11:06:11.262977  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9234 > 20) by scale factor 0.74285
I0110 11:06:22.025315  4932 solver.cpp:240] Iteration 32040, loss = 0.0797486
I0110 11:06:22.025365  4932 solver.cpp:255]     Train net output #0: loss = 0.00642942 (* 1 = 0.00642942 loss)
I0110 11:06:22.025388  4932 solver.cpp:631] Iteration 32040, lr = 1e-07
I0110 11:06:33.464270  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0351 > 20) by scale factor 0.832117
I0110 11:07:04.532879  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1068 > 20) by scale factor 0.766083
I0110 11:07:06.413136  4932 solver.cpp:240] Iteration 32060, loss = 0.0693907
I0110 11:07:06.413172  4932 solver.cpp:255]     Train net output #0: loss = 0.00404718 (* 1 = 0.00404718 loss)
I0110 11:07:06.413180  4932 solver.cpp:631] Iteration 32060, lr = 1e-07
I0110 11:07:28.943604  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9806 > 20) by scale factor 0.909895
I0110 11:07:48.925597  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.528 > 20) by scale factor 0.783452
I0110 11:07:50.806700  4932 solver.cpp:240] Iteration 32080, loss = 0.0826472
I0110 11:07:50.806740  4932 solver.cpp:255]     Train net output #0: loss = 0.113344 (* 1 = 0.113344 loss)
I0110 11:07:50.806749  4932 solver.cpp:631] Iteration 32080, lr = 1e-07
I0110 11:07:55.583279  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3617 > 20) by scale factor 0.982238
I0110 11:08:06.681550  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6642 > 20) by scale factor 0.810891
I0110 11:08:35.196162  4932 solver.cpp:240] Iteration 32100, loss = 0.067467
I0110 11:08:35.196249  4932 solver.cpp:255]     Train net output #0: loss = 0.0354357 (* 1 = 0.0354357 loss)
I0110 11:08:35.196262  4932 solver.cpp:631] Iteration 32100, lr = 1e-07
I0110 11:08:44.410902  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.455 > 20) by scale factor 0.932184
I0110 11:09:19.578500  4932 solver.cpp:240] Iteration 32120, loss = 0.045885
I0110 11:09:19.578574  4932 solver.cpp:255]     Train net output #0: loss = 0.0387904 (* 1 = 0.0387904 loss)
I0110 11:09:19.578583  4932 solver.cpp:631] Iteration 32120, lr = 1e-07
I0110 11:09:22.136075  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1074 > 20) by scale factor 0.904676
I0110 11:09:33.232110  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7092 > 20) by scale factor 0.921269
I0110 11:10:03.963599  4932 solver.cpp:240] Iteration 32140, loss = 0.0812358
I0110 11:10:03.963668  4932 solver.cpp:255]     Train net output #0: loss = 0.102216 (* 1 = 0.102216 loss)
I0110 11:10:03.963678  4932 solver.cpp:631] Iteration 32140, lr = 1e-07
I0110 11:10:48.337944  4932 solver.cpp:240] Iteration 32160, loss = 0.0892197
I0110 11:10:48.338012  4932 solver.cpp:255]     Train net output #0: loss = 0.181139 (* 1 = 0.181139 loss)
I0110 11:10:48.338022  4932 solver.cpp:631] Iteration 32160, lr = 1e-07
I0110 11:10:48.678445  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5012 > 20) by scale factor 0.888842
I0110 11:11:01.997265  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0608 > 20) by scale factor 0.99697
I0110 11:11:32.730612  4932 solver.cpp:240] Iteration 32180, loss = 0.059674
I0110 11:11:32.730687  4932 solver.cpp:255]     Train net output #0: loss = 0.112551 (* 1 = 0.112551 loss)
I0110 11:11:32.730696  4932 solver.cpp:631] Iteration 32180, lr = 1e-07
I0110 11:12:17.108358  4932 solver.cpp:240] Iteration 32200, loss = 0.0613959
I0110 11:12:17.108439  4932 solver.cpp:255]     Train net output #0: loss = 0.0227256 (* 1 = 0.0227256 loss)
I0110 11:12:17.108449  4932 solver.cpp:631] Iteration 32200, lr = 1e-07
I0110 11:13:01.495252  4932 solver.cpp:240] Iteration 32220, loss = 0.0739576
I0110 11:13:01.495334  4932 solver.cpp:255]     Train net output #0: loss = 0.00415069 (* 1 = 0.00415069 loss)
I0110 11:13:01.495347  4932 solver.cpp:631] Iteration 32220, lr = 1e-07
I0110 11:13:45.866804  4932 solver.cpp:240] Iteration 32240, loss = 0.0504238
I0110 11:13:45.866899  4932 solver.cpp:255]     Train net output #0: loss = 0.0146058 (* 1 = 0.0146058 loss)
I0110 11:13:45.866914  4932 solver.cpp:631] Iteration 32240, lr = 1e-07
I0110 11:14:30.252743  4932 solver.cpp:240] Iteration 32260, loss = 0.0603925
I0110 11:14:30.252838  4932 solver.cpp:255]     Train net output #0: loss = 0.338874 (* 1 = 0.338874 loss)
I0110 11:14:30.252849  4932 solver.cpp:631] Iteration 32260, lr = 1e-07
I0110 11:15:03.885838  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9255 > 20) by scale factor 0.835928
I0110 11:15:14.649643  4932 solver.cpp:240] Iteration 32280, loss = 0.0489157
I0110 11:15:14.649684  4932 solver.cpp:255]     Train net output #0: loss = 0.218815 (* 1 = 0.218815 loss)
I0110 11:15:14.649694  4932 solver.cpp:631] Iteration 32280, lr = 1e-07
I0110 11:15:46.057031  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6727 > 20) by scale factor 0.67402
I0110 11:15:59.028807  4932 solver.cpp:240] Iteration 32300, loss = 0.0995041
I0110 11:15:59.028854  4932 solver.cpp:255]     Train net output #0: loss = 0.00104981 (* 1 = 0.00104981 loss)
I0110 11:15:59.028867  4932 solver.cpp:631] Iteration 32300, lr = 1e-07
I0110 11:16:43.408381  4932 solver.cpp:240] Iteration 32320, loss = 0.0649919
I0110 11:16:43.408475  4932 solver.cpp:255]     Train net output #0: loss = 0.0419908 (* 1 = 0.0419908 loss)
I0110 11:16:43.408490  4932 solver.cpp:631] Iteration 32320, lr = 1e-07
I0110 11:16:57.063580  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1139 > 20) by scale factor 0.947245
I0110 11:17:27.799151  4932 solver.cpp:240] Iteration 32340, loss = 0.0471063
I0110 11:17:27.799227  4932 solver.cpp:255]     Train net output #0: loss = 0.00278219 (* 1 = 0.00278219 loss)
I0110 11:17:27.799237  4932 solver.cpp:631] Iteration 32340, lr = 1e-07
I0110 11:17:41.458168  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4786 > 20) by scale factor 0.976629
I0110 11:17:52.559986  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7332 > 20) by scale factor 0.672648
I0110 11:18:12.197327  4932 solver.cpp:240] Iteration 32360, loss = 0.0619308
I0110 11:18:12.197415  4932 solver.cpp:255]     Train net output #0: loss = 0.0119702 (* 1 = 0.0119702 loss)
I0110 11:18:12.197427  4932 solver.cpp:631] Iteration 32360, lr = 1e-07
I0110 11:18:56.589995  4932 solver.cpp:240] Iteration 32380, loss = 0.0481026
I0110 11:18:56.590070  4932 solver.cpp:255]     Train net output #0: loss = 0.0154197 (* 1 = 0.0154197 loss)
I0110 11:18:56.590081  4932 solver.cpp:631] Iteration 32380, lr = 1e-07
I0110 11:19:40.970428  4932 solver.cpp:240] Iteration 32400, loss = 0.0647788
I0110 11:19:40.970491  4932 solver.cpp:255]     Train net output #0: loss = 0.0033973 (* 1 = 0.0033973 loss)
I0110 11:19:40.970500  4932 solver.cpp:631] Iteration 32400, lr = 1e-07
I0110 11:19:52.401950  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5344 > 20) by scale factor 0.928745
I0110 11:20:03.501305  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5887 > 20) by scale factor 0.675935
I0110 11:20:25.356863  4932 solver.cpp:240] Iteration 32420, loss = 0.0950957
I0110 11:20:25.356931  4932 solver.cpp:255]     Train net output #0: loss = 0.0265647 (* 1 = 0.0265647 loss)
I0110 11:20:25.356941  4932 solver.cpp:631] Iteration 32420, lr = 1e-07
I0110 11:20:47.891896  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8299 > 20) by scale factor 0.960157
I0110 11:21:03.425580  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3258 > 20) by scale factor 0.822173
I0110 11:21:09.743988  4932 solver.cpp:240] Iteration 32440, loss = 0.0695295
I0110 11:21:09.744026  4932 solver.cpp:255]     Train net output #0: loss = 0.0328337 (* 1 = 0.0328337 loss)
I0110 11:21:09.744036  4932 solver.cpp:631] Iteration 32440, lr = 1e-07
I0110 11:21:50.023681  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0169 > 20) by scale factor 0.868927
I0110 11:21:54.125448  4932 solver.cpp:240] Iteration 32460, loss = 0.0545634
I0110 11:21:54.125491  4932 solver.cpp:255]     Train net output #0: loss = 0.014747 (* 1 = 0.014747 loss)
I0110 11:21:54.125643  4932 solver.cpp:631] Iteration 32460, lr = 1e-07
I0110 11:21:56.685807  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9399 > 20) by scale factor 0.835424
I0110 11:22:21.103402  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6745 > 20) by scale factor 0.967377
I0110 11:22:36.640841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1855 > 20) by scale factor 0.901489
I0110 11:22:38.522668  4932 solver.cpp:240] Iteration 32480, loss = 0.044526
I0110 11:22:38.522709  4932 solver.cpp:255]     Train net output #0: loss = 0.00109555 (* 1 = 0.00109555 loss)
I0110 11:22:38.522718  4932 solver.cpp:631] Iteration 32480, lr = 1e-07
I0110 11:23:03.276235  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.541 > 20) by scale factor 0.928464
I0110 11:23:09.931991  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4121 > 20) by scale factor 0.819266
I0110 11:23:21.026159  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4157 > 20) by scale factor 0.97964
I0110 11:23:22.907395  4932 solver.cpp:240] Iteration 32500, loss = 0.0782344
I0110 11:23:22.907433  4932 solver.cpp:255]     Train net output #0: loss = 0.0319893 (* 1 = 0.0319893 loss)
I0110 11:23:22.907444  4932 solver.cpp:631] Iteration 32500, lr = 1e-07
I0110 11:23:47.665052  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7012 > 20) by scale factor 0.921609
I0110 11:24:07.306424  4932 solver.cpp:240] Iteration 32520, loss = 0.0829977
I0110 11:24:07.306470  4932 solver.cpp:255]     Train net output #0: loss = 0.0539081 (* 1 = 0.0539081 loss)
I0110 11:24:07.306483  4932 solver.cpp:631] Iteration 32520, lr = 1e-07
I0110 11:24:47.592242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6449 > 20) by scale factor 0.968762
I0110 11:24:51.693059  4932 solver.cpp:240] Iteration 32540, loss = 0.0520552
I0110 11:24:51.693095  4932 solver.cpp:255]     Train net output #0: loss = 0.0200179 (* 1 = 0.0200179 loss)
I0110 11:24:51.693104  4932 solver.cpp:631] Iteration 32540, lr = 1e-07
I0110 11:25:25.331004  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6881 > 20) by scale factor 0.922163
I0110 11:25:36.089484  4932 solver.cpp:240] Iteration 32560, loss = 0.0484132
I0110 11:25:36.089524  4932 solver.cpp:255]     Train net output #0: loss = 0.0610563 (* 1 = 0.0610563 loss)
I0110 11:25:36.089534  4932 solver.cpp:631] Iteration 32560, lr = 1e-07
I0110 11:25:47.522869  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6604 > 20) by scale factor 0.845294
I0110 11:25:56.401845  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.158 > 20) by scale factor 0.827884
I0110 11:25:58.624800  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9379 > 20) by scale factor 0.955204
I0110 11:26:20.471359  4932 solver.cpp:240] Iteration 32580, loss = 0.103704
I0110 11:26:20.471398  4932 solver.cpp:255]     Train net output #0: loss = 0.0916005 (* 1 = 0.0916005 loss)
I0110 11:26:20.471408  4932 solver.cpp:631] Iteration 32580, lr = 1e-07
I0110 11:26:23.029605  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.048 > 20) by scale factor 0.867753
I0110 11:27:00.765249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3366 > 20) by scale factor 0.857024
I0110 11:27:04.866629  4932 solver.cpp:240] Iteration 32600, loss = 0.0603631
I0110 11:27:04.866675  4932 solver.cpp:255]     Train net output #0: loss = 0.0232105 (* 1 = 0.0232105 loss)
I0110 11:27:04.866686  4932 solver.cpp:631] Iteration 32600, lr = 1e-07
I0110 11:27:11.861032  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.685 > 20) by scale factor 0.810208
I0110 11:27:22.966531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7737 > 20) by scale factor 0.962756
I0110 11:27:36.282120  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8919 > 20) by scale factor 0.837104
I0110 11:27:49.261617  4932 solver.cpp:240] Iteration 32620, loss = 0.106834
I0110 11:27:49.261657  4932 solver.cpp:255]     Train net output #0: loss = 0.0381722 (* 1 = 0.0381722 loss)
I0110 11:27:49.261669  4932 solver.cpp:631] Iteration 32620, lr = 1e-07
I0110 11:28:09.581138  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3908 > 20) by scale factor 0.757839
I0110 11:28:33.658438  4932 solver.cpp:240] Iteration 32640, loss = 0.0701046
I0110 11:28:33.658469  4932 solver.cpp:255]     Train net output #0: loss = 0.038624 (* 1 = 0.038624 loss)
I0110 11:28:33.658478  4932 solver.cpp:631] Iteration 32640, lr = 1e-07
I0110 11:28:42.873057  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7442 > 20) by scale factor 0.80827
I0110 11:28:53.977072  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7114 > 20) by scale factor 0.921174
I0110 11:29:18.052989  4932 solver.cpp:240] Iteration 32660, loss = 0.0649665
I0110 11:29:18.053051  4932 solver.cpp:255]     Train net output #0: loss = 0.0905567 (* 1 = 0.0905567 loss)
I0110 11:29:18.053062  4932 solver.cpp:631] Iteration 32660, lr = 1e-07
I0110 11:29:31.712975  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4997 > 20) by scale factor 0.975623
I0110 11:29:47.253857  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7085 > 20) by scale factor 0.880729
I0110 11:30:02.449455  4932 solver.cpp:240] Iteration 32680, loss = 0.078682
I0110 11:30:02.449515  4932 solver.cpp:255]     Train net output #0: loss = 0.0633987 (* 1 = 0.0633987 loss)
I0110 11:30:02.449527  4932 solver.cpp:631] Iteration 32680, lr = 1e-07
I0110 11:30:11.666122  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3185 > 20) by scale factor 0.938153
I0110 11:30:46.832499  4932 solver.cpp:240] Iteration 32700, loss = 0.0587887
I0110 11:30:46.832586  4932 solver.cpp:255]     Train net output #0: loss = 0.146005 (* 1 = 0.146005 loss)
I0110 11:30:46.832598  4932 solver.cpp:631] Iteration 32700, lr = 1e-07
I0110 11:31:31.206681  4932 solver.cpp:240] Iteration 32720, loss = 0.0357527
I0110 11:31:31.206759  4932 solver.cpp:255]     Train net output #0: loss = 0.0120283 (* 1 = 0.0120283 loss)
I0110 11:31:31.206769  4932 solver.cpp:631] Iteration 32720, lr = 1e-07
I0110 11:32:15.592335  4932 solver.cpp:240] Iteration 32740, loss = 0.0565553
I0110 11:32:15.592417  4932 solver.cpp:255]     Train net output #0: loss = 0.0267051 (* 1 = 0.0267051 loss)
I0110 11:32:15.592427  4932 solver.cpp:631] Iteration 32740, lr = 1e-07
I0110 11:32:59.977691  4932 solver.cpp:240] Iteration 32760, loss = 0.0977784
I0110 11:32:59.977764  4932 solver.cpp:255]     Train net output #0: loss = 5.21489e-05 (* 1 = 5.21489e-05 loss)
I0110 11:32:59.977774  4932 solver.cpp:631] Iteration 32760, lr = 1e-07
I0110 11:33:44.364656  4932 solver.cpp:240] Iteration 32780, loss = 0.0588978
I0110 11:33:44.364740  4932 solver.cpp:255]     Train net output #0: loss = 0.160344 (* 1 = 0.160344 loss)
I0110 11:33:44.364751  4932 solver.cpp:631] Iteration 32780, lr = 1e-07
I0110 11:33:51.361182  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.319 > 20) by scale factor 0.600258
I0110 11:34:00.243911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8977 > 20) by scale factor 0.772269
I0110 11:34:09.125694  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4755 > 20) by scale factor 0.976777
I0110 11:34:28.766697  4932 solver.cpp:240] Iteration 32800, loss = 0.0910902
I0110 11:34:28.766790  4932 solver.cpp:255]     Train net output #0: loss = 0.00171054 (* 1 = 0.00171054 loss)
I0110 11:34:28.766803  4932 solver.cpp:631] Iteration 32800, lr = 1e-07
I0110 11:35:13.144731  4932 solver.cpp:240] Iteration 32820, loss = 0.0564177
I0110 11:35:13.144800  4932 solver.cpp:255]     Train net output #0: loss = 0.216592 (* 1 = 0.216592 loss)
I0110 11:35:13.144809  4932 solver.cpp:631] Iteration 32820, lr = 1e-07
I0110 11:35:13.483800  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.038 > 20) by scale factor 0.998101
I0110 11:35:20.147518  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8166 > 20) by scale factor 0.774696
I0110 11:35:57.534601  4932 solver.cpp:240] Iteration 32840, loss = 0.0613723
I0110 11:35:57.534687  4932 solver.cpp:255]     Train net output #0: loss = 0.0597997 (* 1 = 0.0597997 loss)
I0110 11:35:57.534698  4932 solver.cpp:631] Iteration 32840, lr = 1e-07
I0110 11:36:08.966282  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8284 > 20) by scale factor 0.745479
I0110 11:36:41.916837  4932 solver.cpp:240] Iteration 32860, loss = 0.058831
I0110 11:36:41.916896  4932 solver.cpp:255]     Train net output #0: loss = 0.0166054 (* 1 = 0.0166054 loss)
I0110 11:36:41.916906  4932 solver.cpp:631] Iteration 32860, lr = 1e-07
I0110 11:36:55.579547  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9962 > 20) by scale factor 0.869709
I0110 11:37:26.307003  4932 solver.cpp:240] Iteration 32880, loss = 0.0709553
I0110 11:37:26.307109  4932 solver.cpp:255]     Train net output #0: loss = 0.240511 (* 1 = 0.240511 loss)
I0110 11:37:26.307126  4932 solver.cpp:631] Iteration 32880, lr = 1e-07
I0110 11:37:26.647408  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5913 > 20) by scale factor 0.971282
I0110 11:37:46.628044  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4266 > 20) by scale factor 0.891799
I0110 11:37:48.848196  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5669 > 20) by scale factor 0.927347
I0110 11:38:06.606802  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5792 > 20) by scale factor 0.971856
I0110 11:38:10.706079  4932 solver.cpp:240] Iteration 32900, loss = 0.0897863
I0110 11:38:10.706117  4932 solver.cpp:255]     Train net output #0: loss = 0.00141468 (* 1 = 0.00141468 loss)
I0110 11:38:10.706126  4932 solver.cpp:631] Iteration 32900, lr = 1e-07
I0110 11:38:31.015396  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1827 > 20) by scale factor 0.99095
I0110 11:38:46.556712  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3402 > 20) by scale factor 0.983273
I0110 11:38:55.098950  4932 solver.cpp:240] Iteration 32920, loss = 0.0790149
I0110 11:38:55.098990  4932 solver.cpp:255]     Train net output #0: loss = 0.138948 (* 1 = 0.138948 loss)
I0110 11:38:55.099000  4932 solver.cpp:631] Iteration 32920, lr = 1e-07
I0110 11:38:55.438432  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.763 > 20) by scale factor 0.650131
I0110 11:38:59.879302  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5454 > 20) by scale factor 0.700638
I0110 11:39:37.613044  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 39.584 > 20) by scale factor 0.505255
I0110 11:39:39.497845  4932 solver.cpp:240] Iteration 32940, loss = 0.064561
I0110 11:39:39.497890  4932 solver.cpp:255]     Train net output #0: loss = 0.00468343 (* 1 = 0.00468343 loss)
I0110 11:39:39.497902  4932 solver.cpp:631] Iteration 32940, lr = 1e-07
I0110 11:40:19.783982  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1153 > 20) by scale factor 0.686923
I0110 11:40:23.883965  4932 solver.cpp:240] Iteration 32960, loss = 0.056842
I0110 11:40:23.884016  4932 solver.cpp:255]     Train net output #0: loss = 0.019217 (* 1 = 0.019217 loss)
I0110 11:40:23.884028  4932 solver.cpp:631] Iteration 32960, lr = 1e-07
I0110 11:40:53.075481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9896 > 20) by scale factor 0.666897
I0110 11:41:08.269430  4932 solver.cpp:240] Iteration 32980, loss = 0.0687431
I0110 11:41:08.269470  4932 solver.cpp:255]     Train net output #0: loss = 0.00616058 (* 1 = 0.00616058 loss)
I0110 11:41:08.269480  4932 solver.cpp:631] Iteration 32980, lr = 1e-07
I0110 11:41:15.271836  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5351 > 20) by scale factor 0.887505
I0110 11:41:28.586192  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3455 > 20) by scale factor 0.895037
I0110 11:41:50.792191  4932 solver.cpp:424] Iteration 33000, Testing net (#0)
I0110 11:42:42.592782  4932 solver.cpp:481]     Test net output #0: accuracy = 0.823158
I0110 11:42:42.592872  4932 solver.cpp:481]     Test net output #1: loss = 0.932046 (* 1 = 0.932046 loss)
I0110 11:42:44.459223  4932 solver.cpp:240] Iteration 33000, loss = 0.0830844
I0110 11:42:44.459261  4932 solver.cpp:255]     Train net output #0: loss = 0.0755005 (* 1 = 0.0755005 loss)
I0110 11:42:44.459270  4932 solver.cpp:631] Iteration 33000, lr = 1e-07
I0110 11:43:28.825795  4932 solver.cpp:240] Iteration 33020, loss = 0.0685363
I0110 11:43:28.825889  4932 solver.cpp:255]     Train net output #0: loss = 0.0959385 (* 1 = 0.0959385 loss)
I0110 11:43:28.825902  4932 solver.cpp:631] Iteration 33020, lr = 1e-07
I0110 11:43:35.823110  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0808 > 20) by scale factor 0.797422
I0110 11:44:13.205569  4932 solver.cpp:240] Iteration 33040, loss = 0.0945075
I0110 11:44:13.205626  4932 solver.cpp:255]     Train net output #0: loss = 0.0147388 (* 1 = 0.0147388 loss)
I0110 11:44:13.205637  4932 solver.cpp:631] Iteration 33040, lr = 1e-07
I0110 11:44:26.854856  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8376 > 20) by scale factor 0.875749
I0110 11:44:40.169838  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2568 > 20) by scale factor 0.761707
I0110 11:44:57.578794  4932 solver.cpp:240] Iteration 33060, loss = 0.0958515
I0110 11:44:57.578886  4932 solver.cpp:255]     Train net output #0: loss = 0.0263396 (* 1 = 0.0263396 loss)
I0110 11:44:57.578900  4932 solver.cpp:631] Iteration 33060, lr = 1e-07
I0110 11:45:06.800096  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3977 > 20) by scale factor 0.819749
I0110 11:45:15.682411  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7125 > 20) by scale factor 0.843437
I0110 11:45:26.783290  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9323 > 20) by scale factor 0.955462
I0110 11:45:31.227514  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0498 > 20) by scale factor 0.950127
I0110 11:45:41.990205  4932 solver.cpp:240] Iteration 33080, loss = 0.0947871
I0110 11:45:41.990250  4932 solver.cpp:255]     Train net output #0: loss = 0.0215311 (* 1 = 0.0215311 loss)
I0110 11:45:41.990262  4932 solver.cpp:631] Iteration 33080, lr = 1e-07
I0110 11:46:13.388480  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.0322 > 20) by scale factor 0.644492
I0110 11:46:26.362236  4932 solver.cpp:240] Iteration 33100, loss = 0.0832631
I0110 11:46:26.362277  4932 solver.cpp:255]     Train net output #0: loss = 0.0131867 (* 1 = 0.0131867 loss)
I0110 11:46:26.362285  4932 solver.cpp:631] Iteration 33100, lr = 1e-07
I0110 11:46:35.578706  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1605 > 20) by scale factor 0.764512
I0110 11:47:10.740936  4932 solver.cpp:240] Iteration 33120, loss = 0.0851061
I0110 11:47:10.741031  4932 solver.cpp:255]     Train net output #0: loss = 0.00878589 (* 1 = 0.00878589 loss)
I0110 11:47:10.741045  4932 solver.cpp:631] Iteration 33120, lr = 1e-07
I0110 11:47:37.702797  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0194 > 20) by scale factor 0.951501
I0110 11:47:39.923488  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8557 > 20) by scale factor 0.958969
I0110 11:47:55.117414  4932 solver.cpp:240] Iteration 33140, loss = 0.0579443
I0110 11:47:55.117493  4932 solver.cpp:255]     Train net output #0: loss = 0.0726453 (* 1 = 0.0726453 loss)
I0110 11:47:55.117503  4932 solver.cpp:631] Iteration 33140, lr = 1e-07
I0110 11:48:04.328120  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0273 > 20) by scale factor 0.799127
I0110 11:48:17.649237  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.804 > 20) by scale factor 0.719321
I0110 11:48:39.498595  4932 solver.cpp:240] Iteration 33160, loss = 0.08968
I0110 11:48:39.498687  4932 solver.cpp:255]     Train net output #0: loss = 0.0595639 (* 1 = 0.0595639 loss)
I0110 11:48:39.498698  4932 solver.cpp:631] Iteration 33160, lr = 1e-07
I0110 11:48:53.147301  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7105 > 20) by scale factor 0.809371
I0110 11:49:06.464434  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5298 > 20) by scale factor 0.815335
I0110 11:49:22.000304  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7192 > 20) by scale factor 0.880313
I0110 11:49:23.880394  4932 solver.cpp:240] Iteration 33180, loss = 0.0736787
I0110 11:49:23.880426  4932 solver.cpp:255]     Train net output #0: loss = 0.00722893 (* 1 = 0.00722893 loss)
I0110 11:49:23.880435  4932 solver.cpp:631] Iteration 33180, lr = 1e-07
I0110 11:50:01.943377  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7276 > 20) by scale factor 0.777374
I0110 11:50:04.164614  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8335 > 20) by scale factor 0.959993
I0110 11:50:08.262928  4932 solver.cpp:240] Iteration 33200, loss = 0.0574569
I0110 11:50:08.262962  4932 solver.cpp:255]     Train net output #0: loss = 0.0105113 (* 1 = 0.0105113 loss)
I0110 11:50:08.262971  4932 solver.cpp:631] Iteration 33200, lr = 1e-07
I0110 11:50:52.640703  4932 solver.cpp:240] Iteration 33220, loss = 0.0519465
I0110 11:50:52.640786  4932 solver.cpp:255]     Train net output #0: loss = 0.000878308 (* 1 = 0.000878308 loss)
I0110 11:50:52.640797  4932 solver.cpp:631] Iteration 33220, lr = 1e-07
I0110 11:51:37.016746  4932 solver.cpp:240] Iteration 33240, loss = 0.0602856
I0110 11:51:37.016832  4932 solver.cpp:255]     Train net output #0: loss = 0.16852 (* 1 = 0.16852 loss)
I0110 11:51:37.016845  4932 solver.cpp:631] Iteration 33240, lr = 1e-07
I0110 11:52:21.394412  4932 solver.cpp:240] Iteration 33260, loss = 0.0625728
I0110 11:52:21.394480  4932 solver.cpp:255]     Train net output #0: loss = 0.31185 (* 1 = 0.31185 loss)
I0110 11:52:21.394490  4932 solver.cpp:631] Iteration 33260, lr = 1e-07
I0110 11:52:21.733495  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4491 > 20) by scale factor 0.818027
I0110 11:52:32.828011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0231 > 20) by scale factor 0.951336
I0110 11:53:05.773156  4932 solver.cpp:240] Iteration 33280, loss = 0.0636758
I0110 11:53:05.773233  4932 solver.cpp:255]     Train net output #0: loss = 0.176629 (* 1 = 0.176629 loss)
I0110 11:53:05.773243  4932 solver.cpp:631] Iteration 33280, lr = 1e-07
I0110 11:53:50.151667  4932 solver.cpp:240] Iteration 33300, loss = 0.0450367
I0110 11:53:50.151741  4932 solver.cpp:255]     Train net output #0: loss = 0.173938 (* 1 = 0.173938 loss)
I0110 11:53:50.151751  4932 solver.cpp:631] Iteration 33300, lr = 1e-07
I0110 11:53:50.490633  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5705 > 20) by scale factor 0.927191
I0110 11:53:57.152489  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3525 > 20) by scale factor 0.856441
I0110 11:54:03.811079  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7682 > 20) by scale factor 0.918773
I0110 11:54:32.660457  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.0507 > 20) by scale factor 0.58736
I0110 11:54:34.541569  4932 solver.cpp:240] Iteration 33320, loss = 0.0967125
I0110 11:54:34.541616  4932 solver.cpp:255]     Train net output #0: loss = 0.0639362 (* 1 = 0.0639362 loss)
I0110 11:54:34.541628  4932 solver.cpp:631] Iteration 33320, lr = 1e-07
I0110 11:54:37.100026  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0565 > 20) by scale factor 0.949826
I0110 11:54:39.320636  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0055 > 20) by scale factor 0.799824
I0110 11:55:18.917696  4932 solver.cpp:240] Iteration 33340, loss = 0.0764051
I0110 11:55:18.917803  4932 solver.cpp:255]     Train net output #0: loss = 0.00620212 (* 1 = 0.00620212 loss)
I0110 11:55:18.917816  4932 solver.cpp:631] Iteration 33340, lr = 1e-07
I0110 11:55:41.457270  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7189 > 20) by scale factor 0.843208
I0110 11:56:03.305644  4932 solver.cpp:240] Iteration 33360, loss = 0.0713379
I0110 11:56:03.305730  4932 solver.cpp:255]     Train net output #0: loss = 0.0482 (* 1 = 0.0482 loss)
I0110 11:56:03.305743  4932 solver.cpp:631] Iteration 33360, lr = 1e-07
I0110 11:56:19.178525  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3317 > 20) by scale factor 0.759541
I0110 11:56:47.682131  4932 solver.cpp:240] Iteration 33380, loss = 0.055468
I0110 11:56:47.682209  4932 solver.cpp:255]     Train net output #0: loss = 0.0741306 (* 1 = 0.0741306 loss)
I0110 11:56:47.682219  4932 solver.cpp:631] Iteration 33380, lr = 1e-07
I0110 11:57:32.053552  4932 solver.cpp:240] Iteration 33400, loss = 0.0326487
I0110 11:57:32.053622  4932 solver.cpp:255]     Train net output #0: loss = 0.00323606 (* 1 = 0.00323606 loss)
I0110 11:57:32.053632  4932 solver.cpp:631] Iteration 33400, lr = 1e-07
I0110 11:57:59.020297  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5121 > 20) by scale factor 0.850625
I0110 11:58:16.429827  4932 solver.cpp:240] Iteration 33420, loss = 0.0565721
I0110 11:58:16.429899  4932 solver.cpp:255]     Train net output #0: loss = 0.00676517 (* 1 = 0.00676517 loss)
I0110 11:58:16.429909  4932 solver.cpp:631] Iteration 33420, lr = 1e-07
I0110 11:58:18.987514  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5201 > 20) by scale factor 0.929362
I0110 11:58:54.493371  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4321 > 20) by scale factor 0.756655
I0110 11:59:00.815462  4932 solver.cpp:240] Iteration 33440, loss = 0.0515581
I0110 11:59:00.815503  4932 solver.cpp:255]     Train net output #0: loss = 0.0900257 (* 1 = 0.0900257 loss)
I0110 11:59:00.815513  4932 solver.cpp:631] Iteration 33440, lr = 1e-07
I0110 11:59:30.001469  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6613 > 20) by scale factor 0.923306
I0110 11:59:38.879035  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2434 > 20) by scale factor 0.899143
I0110 11:59:45.195890  4932 solver.cpp:240] Iteration 33460, loss = 0.0854128
I0110 11:59:45.195936  4932 solver.cpp:255]     Train net output #0: loss = 0.000652289 (* 1 = 0.000652289 loss)
I0110 11:59:45.195948  4932 solver.cpp:631] Iteration 33460, lr = 1e-07
I0110 11:59:52.193934  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.544 > 20) by scale factor 0.849472
I0110 11:59:58.848884  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6017 > 20) by scale factor 0.69926
I0110 12:00:29.571785  4932 solver.cpp:240] Iteration 33480, loss = 0.0593835
I0110 12:00:29.571861  4932 solver.cpp:255]     Train net output #0: loss = 0.101737 (* 1 = 0.101737 loss)
I0110 12:00:29.571871  4932 solver.cpp:631] Iteration 33480, lr = 1e-07
I0110 12:00:29.910691  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4607 > 20) by scale factor 0.931938
I0110 12:00:41.008009  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6339 > 20) by scale factor 0.969277
I0110 12:01:13.951022  4932 solver.cpp:240] Iteration 33500, loss = 0.0652274
I0110 12:01:13.951104  4932 solver.cpp:255]     Train net output #0: loss = 0.0643292 (* 1 = 0.0643292 loss)
I0110 12:01:13.951115  4932 solver.cpp:631] Iteration 33500, lr = 1e-07
I0110 12:01:58.326309  4932 solver.cpp:240] Iteration 33520, loss = 0.0664938
I0110 12:01:58.326421  4932 solver.cpp:255]     Train net output #0: loss = 0.0124121 (* 1 = 0.0124121 loss)
I0110 12:01:58.326434  4932 solver.cpp:631] Iteration 33520, lr = 1e-07
I0110 12:02:27.527596  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1116 > 20) by scale factor 0.947345
I0110 12:02:31.971328  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.406 > 20) by scale factor 0.934319
I0110 12:02:34.194588  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.111 > 20) by scale factor 0.947375
I0110 12:02:42.737753  4932 solver.cpp:240] Iteration 33540, loss = 0.0863498
I0110 12:02:42.737807  4932 solver.cpp:255]     Train net output #0: loss = 0.00358093 (* 1 = 0.00358093 loss)
I0110 12:02:42.737823  4932 solver.cpp:631] Iteration 33540, lr = 1e-07
I0110 12:02:54.180268  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.39 > 20) by scale factor 0.855066
I0110 12:02:56.402236  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3927 > 20) by scale factor 0.980743
I0110 12:03:27.145603  4932 solver.cpp:240] Iteration 33560, loss = 0.0511767
I0110 12:03:27.145678  4932 solver.cpp:255]     Train net output #0: loss = 0.00409527 (* 1 = 0.00409527 loss)
I0110 12:03:27.145686  4932 solver.cpp:631] Iteration 33560, lr = 1e-07
I0110 12:03:36.359169  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2412 > 20) by scale factor 0.762159
I0110 12:03:38.580415  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.014 > 20) by scale factor 0.740357
I0110 12:04:07.424818  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8412 > 20) by scale factor 0.805116
I0110 12:04:11.526401  4932 solver.cpp:240] Iteration 33580, loss = 0.0804852
I0110 12:04:11.526439  4932 solver.cpp:255]     Train net output #0: loss = 0.000609592 (* 1 = 0.000609592 loss)
I0110 12:04:11.526450  4932 solver.cpp:631] Iteration 33580, lr = 1e-07
I0110 12:04:40.698218  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3922 > 20) by scale factor 0.854985
I0110 12:04:51.797602  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3458 > 20) by scale factor 0.983003
I0110 12:04:55.902573  4932 solver.cpp:240] Iteration 33600, loss = 0.0795006
I0110 12:04:55.902618  4932 solver.cpp:255]     Train net output #0: loss = 0.0127174 (* 1 = 0.0127174 loss)
I0110 12:04:55.902631  4932 solver.cpp:631] Iteration 33600, lr = 1e-07
I0110 12:05:09.551208  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2397 > 20) by scale factor 0.899292
I0110 12:05:40.272336  4932 solver.cpp:240] Iteration 33620, loss = 0.121885
I0110 12:05:40.272414  4932 solver.cpp:255]     Train net output #0: loss = 0.0333156 (* 1 = 0.0333156 loss)
I0110 12:05:40.272424  4932 solver.cpp:631] Iteration 33620, lr = 1e-07
I0110 12:05:45.049559  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4438 > 20) by scale factor 0.756321
I0110 12:06:24.653455  4932 solver.cpp:240] Iteration 33640, loss = 0.0598358
I0110 12:06:24.653532  4932 solver.cpp:255]     Train net output #0: loss = 0.0966281 (* 1 = 0.0966281 loss)
I0110 12:06:24.653542  4932 solver.cpp:631] Iteration 33640, lr = 1e-07
I0110 12:06:24.992487  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2858 > 20) by scale factor 0.939593
I0110 12:06:29.433513  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.68 > 20) by scale factor 0.631314
I0110 12:06:42.756242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2316 > 20) by scale factor 0.988553
I0110 12:06:49.411782  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6363 > 20) by scale factor 0.969165
I0110 12:07:04.947296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.752 > 20) by scale factor 0.919456
I0110 12:07:09.045634  4932 solver.cpp:240] Iteration 33660, loss = 0.0767745
I0110 12:07:09.045677  4932 solver.cpp:255]     Train net output #0: loss = 0.0273515 (* 1 = 0.0273515 loss)
I0110 12:07:09.045687  4932 solver.cpp:631] Iteration 33660, lr = 1e-07
I0110 12:07:22.699975  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0883 > 20) by scale factor 0.948394
I0110 12:07:27.137544  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6397 > 20) by scale factor 0.924227
I0110 12:07:31.578532  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8883 > 20) by scale factor 0.873807
I0110 12:07:33.801187  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1686 > 20) by scale factor 0.944797
I0110 12:07:40.462460  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1825 > 20) by scale factor 0.901612
I0110 12:07:53.443488  4932 solver.cpp:240] Iteration 33680, loss = 0.104654
I0110 12:07:53.443527  4932 solver.cpp:255]     Train net output #0: loss = 0.0647868 (* 1 = 0.0647868 loss)
I0110 12:07:53.443537  4932 solver.cpp:631] Iteration 33680, lr = 1e-07
I0110 12:08:22.628645  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9821 > 20) by scale factor 0.909833
I0110 12:08:27.070233  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3497 > 20) by scale factor 0.936781
I0110 12:08:37.827204  4932 solver.cpp:240] Iteration 33700, loss = 0.0768962
I0110 12:08:37.827250  4932 solver.cpp:255]     Train net output #0: loss = 0.200195 (* 1 = 0.200195 loss)
I0110 12:08:37.827261  4932 solver.cpp:631] Iteration 33700, lr = 1e-07
I0110 12:09:04.801508  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5201 > 20) by scale factor 0.754145
I0110 12:09:22.214658  4932 solver.cpp:240] Iteration 33720, loss = 0.0966916
I0110 12:09:22.214694  4932 solver.cpp:255]     Train net output #0: loss = 0.275327 (* 1 = 0.275327 loss)
I0110 12:09:22.214704  4932 solver.cpp:631] Iteration 33720, lr = 1e-07
I0110 12:09:22.553824  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.022 > 20) by scale factor 0.740137
I0110 12:10:06.600553  4932 solver.cpp:240] Iteration 33740, loss = 0.0489818
I0110 12:10:06.600621  4932 solver.cpp:255]     Train net output #0: loss = 0.0140163 (* 1 = 0.0140163 loss)
I0110 12:10:06.600631  4932 solver.cpp:631] Iteration 33740, lr = 1e-07
I0110 12:10:18.037499  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.321 > 20) by scale factor 0.659609
I0110 12:10:50.991262  4932 solver.cpp:240] Iteration 33760, loss = 0.0911616
I0110 12:10:50.991334  4932 solver.cpp:255]     Train net output #0: loss = 0.400601 (* 1 = 0.400601 loss)
I0110 12:10:50.991343  4932 solver.cpp:631] Iteration 33760, lr = 1e-07
I0110 12:11:15.736465  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5034 > 20) by scale factor 0.850941
I0110 12:11:24.612610  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.861 > 20) by scale factor 0.958727
I0110 12:11:35.375377  4932 solver.cpp:240] Iteration 33780, loss = 0.0930368
I0110 12:11:35.375416  4932 solver.cpp:255]     Train net output #0: loss = 0.0419585 (* 1 = 0.0419585 loss)
I0110 12:11:35.375425  4932 solver.cpp:631] Iteration 33780, lr = 1e-07
I0110 12:11:51.244863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2844 > 20) by scale factor 0.823575
I0110 12:11:53.468058  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7531 > 20) by scale factor 0.72064
I0110 12:12:04.565222  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7092 > 20) by scale factor 0.921269
I0110 12:12:15.665992  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.4281 > 20) by scale factor 0.549027
I0110 12:12:19.766420  4932 solver.cpp:240] Iteration 33800, loss = 0.110203
I0110 12:12:19.766458  4932 solver.cpp:255]     Train net output #0: loss = 0.0192509 (* 1 = 0.0192509 loss)
I0110 12:12:19.766474  4932 solver.cpp:631] Iteration 33800, lr = 1e-07
I0110 12:12:22.323424  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4554 > 20) by scale factor 0.977735
I0110 12:12:40.073577  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1744 > 20) by scale factor 0.863023
I0110 12:13:04.147527  4932 solver.cpp:240] Iteration 33820, loss = 0.0944391
I0110 12:13:04.147567  4932 solver.cpp:255]     Train net output #0: loss = 0.282178 (* 1 = 0.282178 loss)
I0110 12:13:04.147581  4932 solver.cpp:631] Iteration 33820, lr = 1e-07
I0110 12:13:11.142431  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4345 > 20) by scale factor 0.891486
I0110 12:13:48.519536  4932 solver.cpp:240] Iteration 33840, loss = 0.0640688
I0110 12:13:48.519614  4932 solver.cpp:255]     Train net output #0: loss = 0.00697376 (* 1 = 0.00697376 loss)
I0110 12:13:48.519625  4932 solver.cpp:631] Iteration 33840, lr = 1e-07
I0110 12:14:04.388993  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3747 > 20) by scale factor 0.788186
I0110 12:14:32.897629  4932 solver.cpp:240] Iteration 33860, loss = 0.0849452
I0110 12:14:32.897716  4932 solver.cpp:255]     Train net output #0: loss = 0.0136683 (* 1 = 0.0136683 loss)
I0110 12:14:32.897729  4932 solver.cpp:631] Iteration 33860, lr = 1e-07
I0110 12:14:35.457283  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5901 > 20) by scale factor 0.847813
I0110 12:14:55.435453  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9858 > 20) by scale factor 0.833826
I0110 12:15:17.289662  4932 solver.cpp:240] Iteration 33880, loss = 0.0881951
I0110 12:15:17.289739  4932 solver.cpp:255]     Train net output #0: loss = 0.00456864 (* 1 = 0.00456864 loss)
I0110 12:15:17.289749  4932 solver.cpp:631] Iteration 33880, lr = 1e-07
I0110 12:15:24.288548  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.7715 > 20) by scale factor 0.649951
I0110 12:15:46.480260  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7362 > 20) by scale factor 0.920125
I0110 12:15:50.926956  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1221 > 20) by scale factor 0.99393
I0110 12:16:01.685073  4932 solver.cpp:240] Iteration 33900, loss = 0.0686031
I0110 12:16:01.685108  4932 solver.cpp:255]     Train net output #0: loss = 0.00794925 (* 1 = 0.00794925 loss)
I0110 12:16:01.685118  4932 solver.cpp:631] Iteration 33900, lr = 1e-07
I0110 12:16:46.059406  4932 solver.cpp:240] Iteration 33920, loss = 0.0539975
I0110 12:16:46.059497  4932 solver.cpp:255]     Train net output #0: loss = 0.00018182 (* 1 = 0.00018182 loss)
I0110 12:16:46.059510  4932 solver.cpp:631] Iteration 33920, lr = 1e-07
I0110 12:17:30.436885  4932 solver.cpp:240] Iteration 33940, loss = 0.0435638
I0110 12:17:30.436969  4932 solver.cpp:255]     Train net output #0: loss = 0.00535507 (* 1 = 0.00535507 loss)
I0110 12:17:30.436978  4932 solver.cpp:631] Iteration 33940, lr = 1e-07
I0110 12:17:37.438837  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3881 > 20) by scale factor 0.980965
I0110 12:18:10.723314  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2653 > 20) by scale factor 0.85965
I0110 12:18:14.824709  4932 solver.cpp:240] Iteration 33960, loss = 0.05765
I0110 12:18:14.824759  4932 solver.cpp:255]     Train net output #0: loss = 0.0185492 (* 1 = 0.0185492 loss)
I0110 12:18:14.824771  4932 solver.cpp:631] Iteration 33960, lr = 1e-07
I0110 12:18:41.789237  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4462 > 20) by scale factor 0.932567
I0110 12:18:50.669405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9603 > 20) by scale factor 0.801274
I0110 12:18:59.206838  4932 solver.cpp:240] Iteration 33980, loss = 0.0686223
I0110 12:18:59.206869  4932 solver.cpp:255]     Train net output #0: loss = 0.0582107 (* 1 = 0.0582107 loss)
I0110 12:18:59.206878  4932 solver.cpp:631] Iteration 33980, lr = 1e-07
I0110 12:19:41.719844  4932 solver.cpp:424] Iteration 34000, Testing net (#0)
I0110 12:20:33.489845  4932 solver.cpp:481]     Test net output #0: accuracy = 0.844211
I0110 12:20:33.489933  4932 solver.cpp:481]     Test net output #1: loss = 0.771104 (* 1 = 0.771104 loss)
I0110 12:20:35.356372  4932 solver.cpp:240] Iteration 34000, loss = 0.0410324
I0110 12:20:35.356402  4932 solver.cpp:255]     Train net output #0: loss = 0.0362578 (* 1 = 0.0362578 loss)
I0110 12:20:35.356411  4932 solver.cpp:631] Iteration 34000, lr = 1e-07
I0110 12:21:06.753891  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1602 > 20) by scale factor 0.992055
I0110 12:21:19.727427  4932 solver.cpp:240] Iteration 34020, loss = 0.0606732
I0110 12:21:19.727481  4932 solver.cpp:255]     Train net output #0: loss = 0.0015241 (* 1 = 0.0015241 loss)
I0110 12:21:19.727496  4932 solver.cpp:631] Iteration 34020, lr = 1e-07
I0110 12:22:04.136466  4932 solver.cpp:240] Iteration 34040, loss = 0.0662281
I0110 12:22:04.136564  4932 solver.cpp:255]     Train net output #0: loss = 0.0293074 (* 1 = 0.0293074 loss)
I0110 12:22:04.136579  4932 solver.cpp:631] Iteration 34040, lr = 1e-07
I0110 12:22:48.511281  4932 solver.cpp:240] Iteration 34060, loss = 0.0566954
I0110 12:22:48.511356  4932 solver.cpp:255]     Train net output #0: loss = 0.156074 (* 1 = 0.156074 loss)
I0110 12:22:48.511366  4932 solver.cpp:631] Iteration 34060, lr = 1e-07
I0110 12:22:48.850489  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3592 > 20) by scale factor 0.894486
I0110 12:23:31.039201  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4954 > 20) by scale factor 0.975827
I0110 12:23:32.921134  4932 solver.cpp:240] Iteration 34080, loss = 0.0529057
I0110 12:23:32.921180  4932 solver.cpp:255]     Train net output #0: loss = 0.125687 (* 1 = 0.125687 loss)
I0110 12:23:32.921191  4932 solver.cpp:631] Iteration 34080, lr = 1e-07
I0110 12:24:17.333336  4932 solver.cpp:240] Iteration 34100, loss = 0.0528546
I0110 12:24:17.333425  4932 solver.cpp:255]     Train net output #0: loss = 0.00209184 (* 1 = 0.00209184 loss)
I0110 12:24:17.333438  4932 solver.cpp:631] Iteration 34100, lr = 1e-07
I0110 12:25:01.743602  4932 solver.cpp:240] Iteration 34120, loss = 0.025239
I0110 12:25:01.743685  4932 solver.cpp:255]     Train net output #0: loss = 0.0199933 (* 1 = 0.0199933 loss)
I0110 12:25:01.743697  4932 solver.cpp:631] Iteration 34120, lr = 1e-07
I0110 12:25:28.726687  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6945 > 20) by scale factor 0.921892
I0110 12:25:46.155462  4932 solver.cpp:240] Iteration 34140, loss = 0.0662114
I0110 12:25:46.155570  4932 solver.cpp:255]     Train net output #0: loss = 0.421025 (* 1 = 0.421025 loss)
I0110 12:25:46.155586  4932 solver.cpp:631] Iteration 34140, lr = 1e-07
I0110 12:25:46.496299  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3883 > 20) by scale factor 0.893322
I0110 12:25:53.159911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7787 > 20) by scale factor 0.746862
I0110 12:25:55.381639  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6007 > 20) by scale factor 0.88493
I0110 12:26:04.264894  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.069 > 20) by scale factor 0.665137
I0110 12:26:15.368407  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4644 > 20) by scale factor 0.931774
I0110 12:26:30.570971  4932 solver.cpp:240] Iteration 34160, loss = 0.0730489
I0110 12:26:30.571056  4932 solver.cpp:255]     Train net output #0: loss = 0.00367121 (* 1 = 0.00367121 loss)
I0110 12:26:30.571068  4932 solver.cpp:631] Iteration 34160, lr = 1e-07
I0110 12:26:46.441840  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7335 > 20) by scale factor 0.842691
I0110 12:27:04.194479  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.746 > 20) by scale factor 0.91971
I0110 12:27:14.948626  4932 solver.cpp:240] Iteration 34180, loss = 0.0683199
I0110 12:27:14.948657  4932 solver.cpp:255]     Train net output #0: loss = 0.0415631 (* 1 = 0.0415631 loss)
I0110 12:27:14.948667  4932 solver.cpp:631] Iteration 34180, lr = 1e-07
I0110 12:27:55.227270  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.072 > 20) by scale factor 0.830839
I0110 12:27:59.327038  4932 solver.cpp:240] Iteration 34200, loss = 0.0696096
I0110 12:27:59.327075  4932 solver.cpp:255]     Train net output #0: loss = 0.113041 (* 1 = 0.113041 loss)
I0110 12:27:59.327085  4932 solver.cpp:631] Iteration 34200, lr = 1e-07
I0110 12:27:59.666266  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9731 > 20) by scale factor 0.953604
I0110 12:28:30.740054  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0191 > 20) by scale factor 0.999045
I0110 12:28:43.717883  4932 solver.cpp:240] Iteration 34220, loss = 0.0391633
I0110 12:28:43.717926  4932 solver.cpp:255]     Train net output #0: loss = 0.0530509 (* 1 = 0.0530509 loss)
I0110 12:28:43.717936  4932 solver.cpp:631] Iteration 34220, lr = 1e-07
I0110 12:28:50.711580  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0621 > 20) by scale factor 0.949573
I0110 12:28:59.590157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7001 > 20) by scale factor 0.921655
I0110 12:29:08.465745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9683 > 20) by scale factor 0.770169
I0110 12:29:21.780441  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3466 > 20) by scale factor 0.705553
I0110 12:29:28.104449  4932 solver.cpp:240] Iteration 34240, loss = 0.108525
I0110 12:29:28.104496  4932 solver.cpp:255]     Train net output #0: loss = 0.0456795 (* 1 = 0.0456795 loss)
I0110 12:29:28.104507  4932 solver.cpp:631] Iteration 34240, lr = 1e-07
I0110 12:30:06.172978  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.372 > 20) by scale factor 0.730673
I0110 12:30:10.612085  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.52 > 20) by scale factor 0.888101
I0110 12:30:12.493589  4932 solver.cpp:240] Iteration 34260, loss = 0.0706623
I0110 12:30:12.493628  4932 solver.cpp:255]     Train net output #0: loss = 0.191625 (* 1 = 0.191625 loss)
I0110 12:30:12.493636  4932 solver.cpp:631] Iteration 34260, lr = 1e-07
I0110 12:30:12.832691  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.394 > 20) by scale factor 0.893098
I0110 12:30:35.016674  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.1312 > 20) by scale factor 0.553538
I0110 12:30:56.864624  4932 solver.cpp:240] Iteration 34280, loss = 0.0788035
I0110 12:30:56.864713  4932 solver.cpp:255]     Train net output #0: loss = 0.00107402 (* 1 = 0.00107402 loss)
I0110 12:30:56.864727  4932 solver.cpp:631] Iteration 34280, lr = 1e-07
I0110 12:31:19.393343  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7743 > 20) by scale factor 0.841243
I0110 12:31:21.612947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7525 > 20) by scale factor 0.807998
I0110 12:31:23.835623  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8762 > 20) by scale factor 0.837654
I0110 12:31:26.056673  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4775 > 20) by scale factor 0.851879
I0110 12:31:30.495594  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4423 > 20) by scale factor 0.891175
I0110 12:31:41.253691  4932 solver.cpp:240] Iteration 34300, loss = 0.0692055
I0110 12:31:41.253732  4932 solver.cpp:255]     Train net output #0: loss = 0.0181799 (* 1 = 0.0181799 loss)
I0110 12:31:41.253742  4932 solver.cpp:631] Iteration 34300, lr = 1e-07
I0110 12:32:14.867143  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5359 > 20) by scale factor 0.815132
I0110 12:32:25.624083  4932 solver.cpp:240] Iteration 34320, loss = 0.0767384
I0110 12:32:25.624124  4932 solver.cpp:255]     Train net output #0: loss = 0.0213907 (* 1 = 0.0213907 loss)
I0110 12:32:25.624133  4932 solver.cpp:631] Iteration 34320, lr = 1e-07
I0110 12:32:54.811388  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2214 > 20) by scale factor 0.942443
I0110 12:33:03.695799  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7464 > 20) by scale factor 0.747764
I0110 12:33:05.916322  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1727 > 20) by scale factor 0.794512
I0110 12:33:10.015203  4932 solver.cpp:240] Iteration 34340, loss = 0.103875
I0110 12:33:10.015244  4932 solver.cpp:255]     Train net output #0: loss = 0.456405 (* 1 = 0.456405 loss)
I0110 12:33:10.015254  4932 solver.cpp:631] Iteration 34340, lr = 1e-07
I0110 12:33:10.354454  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9282 > 20) by scale factor 0.771362
I0110 12:33:30.321799  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1089 > 20) by scale factor 0.766023
I0110 12:33:41.417390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7902 > 20) by scale factor 0.746542
I0110 12:33:54.399340  4932 solver.cpp:240] Iteration 34360, loss = 0.0655153
I0110 12:33:54.399384  4932 solver.cpp:255]     Train net output #0: loss = 0.0987462 (* 1 = 0.0987462 loss)
I0110 12:33:54.399394  4932 solver.cpp:631] Iteration 34360, lr = 1e-07
I0110 12:33:56.957742  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4864 > 20) by scale factor 0.976256
I0110 12:33:59.177392  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6694 > 20) by scale factor 0.697608
I0110 12:34:32.458206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4975 > 20) by scale factor 0.851153
I0110 12:34:38.776285  4932 solver.cpp:240] Iteration 34380, loss = 0.0826067
I0110 12:34:38.776316  4932 solver.cpp:255]     Train net output #0: loss = 0.0859793 (* 1 = 0.0859793 loss)
I0110 12:34:38.776325  4932 solver.cpp:631] Iteration 34380, lr = 1e-07
I0110 12:35:12.398264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2926 > 20) by scale factor 0.823296
I0110 12:35:19.059595  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9747 > 20) by scale factor 0.714931
I0110 12:35:23.158886  4932 solver.cpp:240] Iteration 34400, loss = 0.0673781
I0110 12:35:23.158924  4932 solver.cpp:255]     Train net output #0: loss = 0.103154 (* 1 = 0.103154 loss)
I0110 12:35:23.158936  4932 solver.cpp:631] Iteration 34400, lr = 1e-07
I0110 12:35:45.691627  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4744 > 20) by scale factor 0.97683
I0110 12:36:07.545282  4932 solver.cpp:240] Iteration 34420, loss = 0.0577094
I0110 12:36:07.545322  4932 solver.cpp:255]     Train net output #0: loss = 0.10439 (* 1 = 0.10439 loss)
I0110 12:36:07.545332  4932 solver.cpp:631] Iteration 34420, lr = 1e-07
I0110 12:36:36.737020  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3859 > 20) by scale factor 0.855216
I0110 12:36:51.930833  4932 solver.cpp:240] Iteration 34440, loss = 0.0626483
I0110 12:36:51.930879  4932 solver.cpp:255]     Train net output #0: loss = 0.000159569 (* 1 = 0.000159569 loss)
I0110 12:36:51.930891  4932 solver.cpp:631] Iteration 34440, lr = 1e-07
I0110 12:37:36.303772  4932 solver.cpp:240] Iteration 34460, loss = 0.0684191
I0110 12:37:36.303850  4932 solver.cpp:255]     Train net output #0: loss = 0.112687 (* 1 = 0.112687 loss)
I0110 12:37:36.303860  4932 solver.cpp:631] Iteration 34460, lr = 1e-07
I0110 12:38:03.266770  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3994 > 20) by scale factor 0.934605
I0110 12:38:18.799741  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0854 > 20) by scale factor 0.866347
I0110 12:38:20.681834  4932 solver.cpp:240] Iteration 34480, loss = 0.0760309
I0110 12:38:20.681874  4932 solver.cpp:255]     Train net output #0: loss = 0.110748 (* 1 = 0.110748 loss)
I0110 12:38:20.681884  4932 solver.cpp:631] Iteration 34480, lr = 1e-07
I0110 12:38:21.021242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3199 > 20) by scale factor 0.759881
I0110 12:38:27.677134  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2602 > 20) by scale factor 0.940723
I0110 12:39:05.062352  4932 solver.cpp:240] Iteration 34500, loss = 0.0875582
I0110 12:39:05.062427  4932 solver.cpp:255]     Train net output #0: loss = 0.0144791 (* 1 = 0.0144791 loss)
I0110 12:39:05.062436  4932 solver.cpp:631] Iteration 34500, lr = 1e-07
I0110 12:39:49.440073  4932 solver.cpp:240] Iteration 34520, loss = 0.0458551
I0110 12:39:49.440137  4932 solver.cpp:255]     Train net output #0: loss = 0.0733686 (* 1 = 0.0733686 loss)
I0110 12:39:49.440148  4932 solver.cpp:631] Iteration 34520, lr = 1e-07
I0110 12:40:29.721238  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9367 > 20) by scale factor 0.802032
I0110 12:40:33.820366  4932 solver.cpp:240] Iteration 34540, loss = 0.0628323
I0110 12:40:33.820413  4932 solver.cpp:255]     Train net output #0: loss = 0.00641921 (* 1 = 0.00641921 loss)
I0110 12:40:33.820425  4932 solver.cpp:631] Iteration 34540, lr = 1e-07
I0110 12:41:18.207177  4932 solver.cpp:240] Iteration 34560, loss = 0.055308
I0110 12:41:18.207275  4932 solver.cpp:255]     Train net output #0: loss = 0.0057447 (* 1 = 0.0057447 loss)
I0110 12:41:18.207290  4932 solver.cpp:631] Iteration 34560, lr = 1e-07
I0110 12:41:22.991852  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.481 > 20) by scale factor 0.976514
I0110 12:41:47.396675  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.9047 > 20) by scale factor 0.607815
I0110 12:42:02.590041  4932 solver.cpp:240] Iteration 34580, loss = 0.0775263
I0110 12:42:02.590121  4932 solver.cpp:255]     Train net output #0: loss = 0.0652822 (* 1 = 0.0652822 loss)
I0110 12:42:02.590132  4932 solver.cpp:631] Iteration 34580, lr = 1e-07
I0110 12:42:14.021586  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5897 > 20) by scale factor 0.813348
I0110 12:42:20.681427  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6121 > 20) by scale factor 0.847025
I0110 12:42:38.428086  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0382 > 20) by scale factor 0.950652
I0110 12:42:46.965229  4932 solver.cpp:240] Iteration 34600, loss = 0.0750544
I0110 12:42:46.965282  4932 solver.cpp:255]     Train net output #0: loss = 0.0045101 (* 1 = 0.0045101 loss)
I0110 12:42:46.965297  4932 solver.cpp:631] Iteration 34600, lr = 1e-07
I0110 12:43:31.335744  4932 solver.cpp:240] Iteration 34620, loss = 0.0456242
I0110 12:43:31.335809  4932 solver.cpp:255]     Train net output #0: loss = 0.116761 (* 1 = 0.116761 loss)
I0110 12:43:31.335819  4932 solver.cpp:631] Iteration 34620, lr = 1e-07
I0110 12:43:42.769294  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2093 > 20) by scale factor 0.708986
I0110 12:44:11.619689  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5866 > 20) by scale factor 0.84794
I0110 12:44:15.721092  4932 solver.cpp:240] Iteration 34640, loss = 0.125823
I0110 12:44:15.721124  4932 solver.cpp:255]     Train net output #0: loss = 0.0856153 (* 1 = 0.0856153 loss)
I0110 12:44:15.721134  4932 solver.cpp:631] Iteration 34640, lr = 1e-07
I0110 12:44:16.060451  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8596 > 20) by scale factor 0.874906
I0110 12:44:38.256999  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.119 > 20) by scale factor 0.994087
I0110 12:45:00.109061  4932 solver.cpp:240] Iteration 34660, loss = 0.045849
I0110 12:45:00.109170  4932 solver.cpp:255]     Train net output #0: loss = 0.00106303 (* 1 = 0.00106303 loss)
I0110 12:45:00.109189  4932 solver.cpp:631] Iteration 34660, lr = 1e-07
I0110 12:45:18.200711  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6112 > 20) by scale factor 0.675419
I0110 12:45:44.485463  4932 solver.cpp:240] Iteration 34680, loss = 0.0598645
I0110 12:45:44.485543  4932 solver.cpp:255]     Train net output #0: loss = 0.00702527 (* 1 = 0.00702527 loss)
I0110 12:45:44.485553  4932 solver.cpp:631] Iteration 34680, lr = 1e-07
I0110 12:45:49.261320  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6442 > 20) by scale factor 0.779902
I0110 12:46:28.873247  4932 solver.cpp:240] Iteration 34700, loss = 0.0675813
I0110 12:46:28.873322  4932 solver.cpp:255]     Train net output #0: loss = 0.0755018 (* 1 = 0.0755018 loss)
I0110 12:46:28.873332  4932 solver.cpp:631] Iteration 34700, lr = 1e-07
I0110 12:46:38.087604  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1291 > 20) by scale factor 0.993587
I0110 12:47:13.255944  4932 solver.cpp:240] Iteration 34720, loss = 0.0726265
I0110 12:47:13.256017  4932 solver.cpp:255]     Train net output #0: loss = 0.0447698 (* 1 = 0.0447698 loss)
I0110 12:47:13.256027  4932 solver.cpp:631] Iteration 34720, lr = 1e-07
I0110 12:47:24.689180  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7305 > 20) by scale factor 0.842799
I0110 12:47:35.788333  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2981 > 20) by scale factor 0.985316
I0110 12:47:57.638877  4932 solver.cpp:240] Iteration 34740, loss = 0.0954578
I0110 12:47:57.638955  4932 solver.cpp:255]     Train net output #0: loss = 0.00163372 (* 1 = 0.00163372 loss)
I0110 12:47:57.638967  4932 solver.cpp:631] Iteration 34740, lr = 1e-07
I0110 12:48:42.011013  4932 solver.cpp:240] Iteration 34760, loss = 0.0284563
I0110 12:48:42.011096  4932 solver.cpp:255]     Train net output #0: loss = 0.0308852 (* 1 = 0.0308852 loss)
I0110 12:48:42.011108  4932 solver.cpp:631] Iteration 34760, lr = 1e-07
I0110 12:48:51.224814  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9305 > 20) by scale factor 0.802232
I0110 12:48:57.880662  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2461 > 20) by scale factor 0.899034
I0110 12:49:22.289520  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6172 > 20) by scale factor 0.884284
I0110 12:49:26.390069  4932 solver.cpp:240] Iteration 34780, loss = 0.119261
I0110 12:49:26.390110  4932 solver.cpp:255]     Train net output #0: loss = 0.0741746 (* 1 = 0.0741746 loss)
I0110 12:49:26.390120  4932 solver.cpp:631] Iteration 34780, lr = 1e-07
I0110 12:49:37.821657  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3989 > 20) by scale factor 0.704252
I0110 12:50:10.772310  4932 solver.cpp:240] Iteration 34800, loss = 0.0511004
I0110 12:50:10.772393  4932 solver.cpp:255]     Train net output #0: loss = 0.0178142 (* 1 = 0.0178142 loss)
I0110 12:50:10.772403  4932 solver.cpp:631] Iteration 34800, lr = 1e-07
I0110 12:50:55.148387  4932 solver.cpp:240] Iteration 34820, loss = 0.0520135
I0110 12:50:55.148459  4932 solver.cpp:255]     Train net output #0: loss = 0.0671458 (* 1 = 0.0671458 loss)
I0110 12:50:55.148470  4932 solver.cpp:631] Iteration 34820, lr = 1e-07
I0110 12:51:33.207506  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2413 > 20) by scale factor 0.792353
I0110 12:51:39.530419  4932 solver.cpp:240] Iteration 34840, loss = 0.0526481
I0110 12:51:39.530468  4932 solver.cpp:255]     Train net output #0: loss = 0.000741818 (* 1 = 0.000741818 loss)
I0110 12:51:39.530481  4932 solver.cpp:631] Iteration 34840, lr = 1e-07
I0110 12:52:23.903055  4932 solver.cpp:240] Iteration 34860, loss = 0.0650579
I0110 12:52:23.903126  4932 solver.cpp:255]     Train net output #0: loss = 0.0385691 (* 1 = 0.0385691 loss)
I0110 12:52:23.903136  4932 solver.cpp:631] Iteration 34860, lr = 1e-07
I0110 12:52:37.561056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0667 > 20) by scale factor 0.831025
I0110 12:53:08.295933  4932 solver.cpp:240] Iteration 34880, loss = 0.0420591
I0110 12:53:08.296020  4932 solver.cpp:255]     Train net output #0: loss = 0.0226769 (* 1 = 0.0226769 loss)
I0110 12:53:08.296030  4932 solver.cpp:631] Iteration 34880, lr = 1e-07
I0110 12:53:44.132221  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1918 > 20) by scale factor 0.990502
I0110 12:53:52.666299  4932 solver.cpp:240] Iteration 34900, loss = 0.047825
I0110 12:53:52.666342  4932 solver.cpp:255]     Train net output #0: loss = 0.00118209 (* 1 = 0.00118209 loss)
I0110 12:53:52.666354  4932 solver.cpp:631] Iteration 34900, lr = 1e-07
I0110 12:53:55.226935  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0854 > 20) by scale factor 0.830379
I0110 12:54:10.757993  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6579 > 20) by scale factor 0.674357
I0110 12:54:37.044464  4932 solver.cpp:240] Iteration 34920, loss = 0.0652036
I0110 12:54:37.044544  4932 solver.cpp:255]     Train net output #0: loss = 0.00117234 (* 1 = 0.00117234 loss)
I0110 12:54:37.044554  4932 solver.cpp:631] Iteration 34920, lr = 1e-07
I0110 12:55:01.796532  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5465 > 20) by scale factor 0.9734
I0110 12:55:21.430399  4932 solver.cpp:240] Iteration 34940, loss = 0.0577087
I0110 12:55:21.430479  4932 solver.cpp:255]     Train net output #0: loss = 0.00944761 (* 1 = 0.00944761 loss)
I0110 12:55:21.430490  4932 solver.cpp:631] Iteration 34940, lr = 1e-07
I0110 12:55:57.269665  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3103 > 20) by scale factor 0.682354
I0110 12:56:05.806229  4932 solver.cpp:240] Iteration 34960, loss = 0.03653
I0110 12:56:05.806268  4932 solver.cpp:255]     Train net output #0: loss = 0.029916 (* 1 = 0.029916 loss)
I0110 12:56:05.806277  4932 solver.cpp:631] Iteration 34960, lr = 1e-07
I0110 12:56:17.240350  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8853 > 20) by scale factor 0.717223
I0110 12:56:19.460770  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0035 > 20) by scale factor 0.83321
I0110 12:56:28.349135  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6249 > 20) by scale factor 0.751178
I0110 12:56:32.788462  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3242 > 20) by scale factor 0.937901
I0110 12:56:50.204231  4932 solver.cpp:240] Iteration 34980, loss = 0.0670203
I0110 12:56:50.204269  4932 solver.cpp:255]     Train net output #0: loss = 0.0146301 (* 1 = 0.0146301 loss)
I0110 12:56:50.204279  4932 solver.cpp:631] Iteration 34980, lr = 1e-07
I0110 12:57:01.632678  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1479 > 20) by scale factor 0.903021
I0110 12:57:32.707465  4932 solver.cpp:424] Iteration 35000, Testing net (#0)
I0110 12:58:23.944252  4932 solver.cpp:481]     Test net output #0: accuracy = 0.841053
I0110 12:58:23.944344  4932 solver.cpp:481]     Test net output #1: loss = 0.755255 (* 1 = 0.755255 loss)
I0110 12:58:25.811411  4932 solver.cpp:240] Iteration 35000, loss = 0.0600424
I0110 12:58:25.811450  4932 solver.cpp:255]     Train net output #0: loss = 0.064269 (* 1 = 0.064269 loss)
I0110 12:58:25.811460  4932 solver.cpp:631] Iteration 35000, lr = 1e-07
I0110 12:59:01.649193  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6631 > 20) by scale factor 0.845198
I0110 12:59:10.186813  4932 solver.cpp:240] Iteration 35020, loss = 0.052765
I0110 12:59:10.186854  4932 solver.cpp:255]     Train net output #0: loss = 0.0814929 (* 1 = 0.0814929 loss)
I0110 12:59:10.186863  4932 solver.cpp:631] Iteration 35020, lr = 1e-07
I0110 12:59:23.832382  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1705 > 20) by scale factor 0.944712
I0110 12:59:54.557682  4932 solver.cpp:240] Iteration 35040, loss = 0.0458575
I0110 12:59:54.557791  4932 solver.cpp:255]     Train net output #0: loss = 0.000325099 (* 1 = 0.000325099 loss)
I0110 12:59:54.557802  4932 solver.cpp:631] Iteration 35040, lr = 1e-07
I0110 12:59:59.334437  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0021 > 20) by scale factor 0.799934
I0110 13:00:08.213373  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1758 > 20) by scale factor 0.991286
I0110 13:00:38.938810  4932 solver.cpp:240] Iteration 35060, loss = 0.0583481
I0110 13:00:38.938905  4932 solver.cpp:255]     Train net output #0: loss = 0.0142257 (* 1 = 0.0142257 loss)
I0110 13:00:38.938917  4932 solver.cpp:631] Iteration 35060, lr = 1e-07
I0110 13:01:12.553283  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2851 > 20) by scale factor 0.897461
I0110 13:01:14.776515  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4146 > 20) by scale factor 0.933941
I0110 13:01:23.314080  4932 solver.cpp:240] Iteration 35080, loss = 0.0743553
I0110 13:01:23.314117  4932 solver.cpp:255]     Train net output #0: loss = 0.00319266 (* 1 = 0.00319266 loss)
I0110 13:01:23.314126  4932 solver.cpp:631] Iteration 35080, lr = 1e-07
I0110 13:01:39.183884  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4645 > 20) by scale factor 0.817512
I0110 13:01:48.060454  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8548 > 20) by scale factor 0.959011
I0110 13:02:07.682992  4932 solver.cpp:240] Iteration 35100, loss = 0.0882622
I0110 13:02:07.683033  4932 solver.cpp:255]     Train net output #0: loss = 0.00308217 (* 1 = 0.00308217 loss)
I0110 13:02:07.683043  4932 solver.cpp:631] Iteration 35100, lr = 1e-07
I0110 13:02:10.242493  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3432 > 20) by scale factor 0.705637
I0110 13:02:52.062077  4932 solver.cpp:240] Iteration 35120, loss = 0.0919233
I0110 13:02:52.062167  4932 solver.cpp:255]     Train net output #0: loss = 0.507397 (* 1 = 0.507397 loss)
I0110 13:02:52.062180  4932 solver.cpp:631] Iteration 35120, lr = 1e-07
I0110 13:02:52.402806  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.7466 > 20) by scale factor 0.592652
I0110 13:03:03.498380  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2894 > 20) by scale factor 0.732884
I0110 13:03:27.909317  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5072 > 20) by scale factor 0.850801
I0110 13:03:36.446362  4932 solver.cpp:240] Iteration 35140, loss = 0.0662613
I0110 13:03:36.446401  4932 solver.cpp:255]     Train net output #0: loss = 0.00357787 (* 1 = 0.00357787 loss)
I0110 13:03:36.446410  4932 solver.cpp:631] Iteration 35140, lr = 1e-07
I0110 13:03:39.003008  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5318 > 20) by scale factor 0.726432
I0110 13:04:16.724885  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3538 > 20) by scale factor 0.821228
I0110 13:04:20.827402  4932 solver.cpp:240] Iteration 35160, loss = 0.0592958
I0110 13:04:20.827435  4932 solver.cpp:255]     Train net output #0: loss = 0.0192525 (* 1 = 0.0192525 loss)
I0110 13:04:20.827445  4932 solver.cpp:631] Iteration 35160, lr = 1e-07
I0110 13:04:43.346268  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5632 > 20) by scale factor 0.782374
I0110 13:05:05.194329  4932 solver.cpp:240] Iteration 35180, loss = 0.0610472
I0110 13:05:05.194409  4932 solver.cpp:255]     Train net output #0: loss = 0.0144963 (* 1 = 0.0144963 loss)
I0110 13:05:05.194419  4932 solver.cpp:631] Iteration 35180, lr = 1e-07
I0110 13:05:49.566750  4932 solver.cpp:240] Iteration 35200, loss = 0.0494853
I0110 13:05:49.566828  4932 solver.cpp:255]     Train net output #0: loss = 0.0155575 (* 1 = 0.0155575 loss)
I0110 13:05:49.566839  4932 solver.cpp:631] Iteration 35200, lr = 1e-07
I0110 13:05:52.124843  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8634 > 20) by scale factor 0.874762
I0110 13:05:54.346365  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9427 > 20) by scale factor 0.801838
I0110 13:05:56.567993  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7626 > 20) by scale factor 0.878634
I0110 13:05:58.788192  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0274 > 20) by scale factor 0.868529
I0110 13:06:33.947043  4932 solver.cpp:240] Iteration 35220, loss = 0.0774178
I0110 13:06:33.947283  4932 solver.cpp:255]     Train net output #0: loss = 0.18584 (* 1 = 0.18584 loss)
I0110 13:06:33.947299  4932 solver.cpp:631] Iteration 35220, lr = 1e-07
I0110 13:07:14.251194  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1796 > 20) by scale factor 0.763953
I0110 13:07:18.353576  4932 solver.cpp:240] Iteration 35240, loss = 0.0455969
I0110 13:07:18.353615  4932 solver.cpp:255]     Train net output #0: loss = 0.0161046 (* 1 = 0.0161046 loss)
I0110 13:07:18.353623  4932 solver.cpp:631] Iteration 35240, lr = 1e-07
I0110 13:07:25.357177  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6003 > 20) by scale factor 0.97086
I0110 13:07:34.234771  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6896 > 20) by scale factor 0.966668
I0110 13:08:02.753162  4932 solver.cpp:240] Iteration 35260, loss = 0.095322
I0110 13:08:02.753237  4932 solver.cpp:255]     Train net output #0: loss = 0.0413394 (* 1 = 0.0413394 loss)
I0110 13:08:02.753248  4932 solver.cpp:631] Iteration 35260, lr = 1e-07
I0110 13:08:18.629015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4882 > 20) by scale factor 0.930742
I0110 13:08:47.141806  4932 solver.cpp:240] Iteration 35280, loss = 0.0507758
I0110 13:08:47.141878  4932 solver.cpp:255]     Train net output #0: loss = 0.0499541 (* 1 = 0.0499541 loss)
I0110 13:08:47.141887  4932 solver.cpp:631] Iteration 35280, lr = 1e-07
I0110 13:09:31.531136  4932 solver.cpp:240] Iteration 35300, loss = 0.0796393
I0110 13:09:31.531232  4932 solver.cpp:255]     Train net output #0: loss = 0.0600082 (* 1 = 0.0600082 loss)
I0110 13:09:31.531246  4932 solver.cpp:631] Iteration 35300, lr = 1e-07
I0110 13:09:45.196871  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7043 > 20) by scale factor 0.84373
I0110 13:10:15.924557  4932 solver.cpp:240] Iteration 35320, loss = 0.0607234
I0110 13:10:15.924630  4932 solver.cpp:255]     Train net output #0: loss = 0.06506 (* 1 = 0.06506 loss)
I0110 13:10:15.924640  4932 solver.cpp:631] Iteration 35320, lr = 1e-07
I0110 13:11:00.320765  4932 solver.cpp:240] Iteration 35340, loss = 0.0745284
I0110 13:11:00.320837  4932 solver.cpp:255]     Train net output #0: loss = 0.00401983 (* 1 = 0.00401983 loss)
I0110 13:11:00.320847  4932 solver.cpp:631] Iteration 35340, lr = 1e-07
I0110 13:11:13.978070  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.381 > 20) by scale factor 0.935409
I0110 13:11:29.516383  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6735 > 20) by scale factor 0.844826
I0110 13:11:42.835211  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2033 > 20) by scale factor 0.94325
I0110 13:11:44.717876  4932 solver.cpp:240] Iteration 35360, loss = 0.0752677
I0110 13:11:44.717914  4932 solver.cpp:255]     Train net output #0: loss = 0.0112227 (* 1 = 0.0112227 loss)
I0110 13:11:44.717923  4932 solver.cpp:631] Iteration 35360, lr = 1e-07
I0110 13:11:51.713521  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9958 > 20) by scale factor 0.909263
I0110 13:12:27.228606  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2103 > 20) by scale factor 0.763059
I0110 13:12:29.111098  4932 solver.cpp:240] Iteration 35380, loss = 0.0704805
I0110 13:12:29.111126  4932 solver.cpp:255]     Train net output #0: loss = 0.0175384 (* 1 = 0.0175384 loss)
I0110 13:12:29.111135  4932 solver.cpp:631] Iteration 35380, lr = 1e-07
I0110 13:13:13.501649  4932 solver.cpp:240] Iteration 35400, loss = 0.119582
I0110 13:13:13.501760  4932 solver.cpp:255]     Train net output #0: loss = 0.0692329 (* 1 = 0.0692329 loss)
I0110 13:13:13.501773  4932 solver.cpp:631] Iteration 35400, lr = 1e-07
I0110 13:13:29.377122  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4534 > 20) by scale factor 0.977833
I0110 13:13:44.923151  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8743 > 20) by scale factor 0.837722
I0110 13:13:57.897243  4932 solver.cpp:240] Iteration 35420, loss = 0.0905407
I0110 13:13:57.897280  4932 solver.cpp:255]     Train net output #0: loss = 0.00213061 (* 1 = 0.00213061 loss)
I0110 13:13:57.897289  4932 solver.cpp:631] Iteration 35420, lr = 1e-07
I0110 13:14:42.287570  4932 solver.cpp:240] Iteration 35440, loss = 0.0326797
I0110 13:14:42.287659  4932 solver.cpp:255]     Train net output #0: loss = 0.00150152 (* 1 = 0.00150152 loss)
I0110 13:14:42.287672  4932 solver.cpp:631] Iteration 35440, lr = 1e-07
I0110 13:14:55.942015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4252 > 20) by scale factor 0.933479
I0110 13:15:00.383584  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4847 > 20) by scale factor 0.816836
I0110 13:15:26.686712  4932 solver.cpp:240] Iteration 35460, loss = 0.0577205
I0110 13:15:26.686786  4932 solver.cpp:255]     Train net output #0: loss = 0.0123155 (* 1 = 0.0123155 loss)
I0110 13:15:26.686796  4932 solver.cpp:631] Iteration 35460, lr = 1e-07
I0110 13:16:02.531245  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6819 > 20) by scale factor 0.881759
I0110 13:16:11.066448  4932 solver.cpp:240] Iteration 35480, loss = 0.0496891
I0110 13:16:11.066491  4932 solver.cpp:255]     Train net output #0: loss = 0.119342 (* 1 = 0.119342 loss)
I0110 13:16:11.066503  4932 solver.cpp:631] Iteration 35480, lr = 1e-07
I0110 13:16:55.453593  4932 solver.cpp:240] Iteration 35500, loss = 0.0417953
I0110 13:16:55.453661  4932 solver.cpp:255]     Train net output #0: loss = 0.0436205 (* 1 = 0.0436205 loss)
I0110 13:16:55.453671  4932 solver.cpp:631] Iteration 35500, lr = 1e-07
I0110 13:17:39.846997  4932 solver.cpp:240] Iteration 35520, loss = 0.0712816
I0110 13:17:39.847071  4932 solver.cpp:255]     Train net output #0: loss = 0.00297588 (* 1 = 0.00297588 loss)
I0110 13:17:39.847081  4932 solver.cpp:631] Iteration 35520, lr = 1e-07
I0110 13:18:15.704078  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.8312 > 20) by scale factor 0.609176
I0110 13:18:24.242694  4932 solver.cpp:240] Iteration 35540, loss = 0.0511087
I0110 13:18:24.242740  4932 solver.cpp:255]     Train net output #0: loss = 0.0852396 (* 1 = 0.0852396 loss)
I0110 13:18:24.242753  4932 solver.cpp:631] Iteration 35540, lr = 1e-07
I0110 13:18:55.655853  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.6654 > 20) by scale factor 0.612268
I0110 13:19:04.536811  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7215 > 20) by scale factor 0.777558
I0110 13:19:08.637742  4932 solver.cpp:240] Iteration 35560, loss = 0.0714349
I0110 13:19:08.637780  4932 solver.cpp:255]     Train net output #0: loss = 0.115026 (* 1 = 0.115026 loss)
I0110 13:19:08.637790  4932 solver.cpp:631] Iteration 35560, lr = 1e-07
I0110 13:19:53.033658  4932 solver.cpp:240] Iteration 35580, loss = 0.0476438
I0110 13:19:53.033746  4932 solver.cpp:255]     Train net output #0: loss = 0.0517723 (* 1 = 0.0517723 loss)
I0110 13:19:53.033758  4932 solver.cpp:631] Iteration 35580, lr = 1e-07
I0110 13:20:06.684866  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.062 > 20) by scale factor 0.712708
I0110 13:20:24.449934  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2964 > 20) by scale factor 0.985397
I0110 13:20:37.434803  4932 solver.cpp:240] Iteration 35600, loss = 0.0607221
I0110 13:20:37.434842  4932 solver.cpp:255]     Train net output #0: loss = 0.0104536 (* 1 = 0.0104536 loss)
I0110 13:20:37.434859  4932 solver.cpp:631] Iteration 35600, lr = 1e-07
I0110 13:21:21.829818  4932 solver.cpp:240] Iteration 35620, loss = 0.0577079
I0110 13:21:21.829902  4932 solver.cpp:255]     Train net output #0: loss = 0.18257 (* 1 = 0.18257 loss)
I0110 13:21:21.829913  4932 solver.cpp:631] Iteration 35620, lr = 1e-07
I0110 13:21:22.170378  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0123 > 20) by scale factor 0.908584
I0110 13:22:06.225307  4932 solver.cpp:240] Iteration 35640, loss = 0.0485273
I0110 13:22:06.225392  4932 solver.cpp:255]     Train net output #0: loss = 0.00962488 (* 1 = 0.00962488 loss)
I0110 13:22:06.225405  4932 solver.cpp:631] Iteration 35640, lr = 1e-07
I0110 13:22:17.664897  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.681 > 20) by scale factor 0.922465
I0110 13:22:33.206528  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0757 > 20) by scale factor 0.996231
I0110 13:22:50.628583  4932 solver.cpp:240] Iteration 35660, loss = 0.0590844
I0110 13:22:50.628660  4932 solver.cpp:255]     Train net output #0: loss = 0.0429608 (* 1 = 0.0429608 loss)
I0110 13:22:50.628671  4932 solver.cpp:631] Iteration 35660, lr = 1e-07
I0110 13:22:53.187228  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7846 > 20) by scale factor 0.918082
I0110 13:23:35.018332  4932 solver.cpp:240] Iteration 35680, loss = 0.0711835
I0110 13:23:35.018421  4932 solver.cpp:255]     Train net output #0: loss = 0.22681 (* 1 = 0.22681 loss)
I0110 13:23:35.018434  4932 solver.cpp:631] Iteration 35680, lr = 1e-07
I0110 13:23:42.020102  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1082 > 20) by scale factor 0.99462
I0110 13:24:19.420205  4932 solver.cpp:240] Iteration 35700, loss = 0.062894
I0110 13:24:19.420282  4932 solver.cpp:255]     Train net output #0: loss = 0.000112333 (* 1 = 0.000112333 loss)
I0110 13:24:19.420294  4932 solver.cpp:631] Iteration 35700, lr = 1e-07
I0110 13:24:26.416841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.9177 > 20) by scale factor 0.626612
I0110 13:24:30.855965  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7592 > 20) by scale factor 0.720483
I0110 13:24:48.616027  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8384 > 20) by scale factor 0.87572
I0110 13:25:03.816727  4932 solver.cpp:240] Iteration 35720, loss = 0.0834085
I0110 13:25:03.816807  4932 solver.cpp:255]     Train net output #0: loss = 0.00477308 (* 1 = 0.00477308 loss)
I0110 13:25:03.816818  4932 solver.cpp:631] Iteration 35720, lr = 1e-07
I0110 13:25:48.210091  4932 solver.cpp:240] Iteration 35740, loss = 0.0483854
I0110 13:25:48.210178  4932 solver.cpp:255]     Train net output #0: loss = 0.0407151 (* 1 = 0.0407151 loss)
I0110 13:25:48.210191  4932 solver.cpp:631] Iteration 35740, lr = 1e-07
I0110 13:26:26.284359  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4523 > 20) by scale factor 0.728536
I0110 13:26:32.607844  4932 solver.cpp:240] Iteration 35760, loss = 0.0627362
I0110 13:26:32.607882  4932 solver.cpp:255]     Train net output #0: loss = 0.0610593 (* 1 = 0.0610593 loss)
I0110 13:26:32.607892  4932 solver.cpp:631] Iteration 35760, lr = 1e-07
I0110 13:27:12.899590  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.539 > 20) by scale factor 0.783116
I0110 13:27:17.002939  4932 solver.cpp:240] Iteration 35780, loss = 0.0503655
I0110 13:27:17.002977  4932 solver.cpp:255]     Train net output #0: loss = 0.0663803 (* 1 = 0.0663803 loss)
I0110 13:27:17.002987  4932 solver.cpp:631] Iteration 35780, lr = 1e-07
I0110 13:27:32.876404  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3527 > 20) by scale factor 0.982673
I0110 13:27:52.852717  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0348 > 20) by scale factor 0.868253
I0110 13:28:01.391151  4932 solver.cpp:240] Iteration 35800, loss = 0.0870771
I0110 13:28:01.391199  4932 solver.cpp:255]     Train net output #0: loss = 0.071259 (* 1 = 0.071259 loss)
I0110 13:28:01.391211  4932 solver.cpp:631] Iteration 35800, lr = 1e-07
I0110 13:28:45.791427  4932 solver.cpp:240] Iteration 35820, loss = 0.0493431
I0110 13:28:45.791482  4932 solver.cpp:255]     Train net output #0: loss = 0.063842 (* 1 = 0.063842 loss)
I0110 13:28:45.791491  4932 solver.cpp:631] Iteration 35820, lr = 1e-07
I0110 13:29:10.551681  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3435 > 20) by scale factor 0.895114
I0110 13:29:17.529558  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6645 > 20) by scale factor 0.845146
I0110 13:29:30.510815  4932 solver.cpp:240] Iteration 35840, loss = 0.0711835
I0110 13:29:30.510854  4932 solver.cpp:255]     Train net output #0: loss = 0.00616273 (* 1 = 0.00616273 loss)
I0110 13:29:30.510864  4932 solver.cpp:631] Iteration 35840, lr = 1e-07
I0110 13:29:44.167062  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4731 > 20) by scale factor 0.976893
I0110 13:30:14.907393  4932 solver.cpp:240] Iteration 35860, loss = 0.0566323
I0110 13:30:14.907476  4932 solver.cpp:255]     Train net output #0: loss = 0.0299271 (* 1 = 0.0299271 loss)
I0110 13:30:14.907488  4932 solver.cpp:631] Iteration 35860, lr = 1e-07
I0110 13:30:59.292665  4932 solver.cpp:240] Iteration 35880, loss = 0.0635077
I0110 13:30:59.292748  4932 solver.cpp:255]     Train net output #0: loss = 0.205786 (* 1 = 0.205786 loss)
I0110 13:30:59.292760  4932 solver.cpp:631] Iteration 35880, lr = 1e-07
I0110 13:30:59.631980  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0087 > 20) by scale factor 0.869237
I0110 13:31:04.071576  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8847 > 20) by scale factor 0.803707
I0110 13:31:19.612088  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.825 > 20) by scale factor 0.876233
I0110 13:31:37.374461  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.358 > 20) by scale factor 0.982413
I0110 13:31:43.693042  4932 solver.cpp:240] Iteration 35900, loss = 0.0740782
I0110 13:31:43.693079  4932 solver.cpp:255]     Train net output #0: loss = 0.0237127 (* 1 = 0.0237127 loss)
I0110 13:31:43.693089  4932 solver.cpp:631] Iteration 35900, lr = 1e-07
I0110 13:32:28.082206  4932 solver.cpp:240] Iteration 35920, loss = 0.0374336
I0110 13:32:28.082275  4932 solver.cpp:255]     Train net output #0: loss = 0.00223315 (* 1 = 0.00223315 loss)
I0110 13:32:28.082285  4932 solver.cpp:631] Iteration 35920, lr = 1e-07
I0110 13:32:43.953591  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2366 > 20) by scale factor 0.988306
I0110 13:32:50.613200  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9111 > 20) by scale factor 0.912778
I0110 13:33:12.473832  4932 solver.cpp:240] Iteration 35940, loss = 0.0630192
I0110 13:33:12.473894  4932 solver.cpp:255]     Train net output #0: loss = 0.00578871 (* 1 = 0.00578871 loss)
I0110 13:33:12.473904  4932 solver.cpp:631] Iteration 35940, lr = 1e-07
I0110 13:33:26.129506  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7236 > 20) by scale factor 0.696291
I0110 13:33:56.866189  4932 solver.cpp:240] Iteration 35960, loss = 0.0619801
I0110 13:33:56.866261  4932 solver.cpp:255]     Train net output #0: loss = 0.0232093 (* 1 = 0.0232093 loss)
I0110 13:33:56.866271  4932 solver.cpp:631] Iteration 35960, lr = 1e-07
I0110 13:34:17.182276  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0366 > 20) by scale factor 0.950723
I0110 13:34:23.842929  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1989 > 20) by scale factor 0.900947
I0110 13:34:41.258415  4932 solver.cpp:240] Iteration 35980, loss = 0.0867516
I0110 13:34:41.258502  4932 solver.cpp:255]     Train net output #0: loss = 0.0126255 (* 1 = 0.0126255 loss)
I0110 13:34:41.258515  4932 solver.cpp:631] Iteration 35980, lr = 1e-07
I0110 13:35:01.575134  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4369 > 20) by scale factor 0.786258
I0110 13:35:19.334275  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.8077 > 20) by scale factor 0.574586
I0110 13:35:23.780275  4932 solver.cpp:424] Iteration 36000, Testing net (#0)
I0110 13:36:12.786147  4932 solver.cpp:481]     Test net output #0: accuracy = 0.82
I0110 13:36:12.786228  4932 solver.cpp:481]     Test net output #1: loss = 0.895699 (* 1 = 0.895699 loss)
I0110 13:36:14.652786  4932 solver.cpp:240] Iteration 36000, loss = 0.0491597
I0110 13:36:14.652817  4932 solver.cpp:255]     Train net output #0: loss = 0.0159991 (* 1 = 0.0159991 loss)
I0110 13:36:14.652827  4932 solver.cpp:631] Iteration 36000, lr = 1e-07
I0110 13:36:59.025089  4932 solver.cpp:240] Iteration 36020, loss = 0.0454431
I0110 13:36:59.025174  4932 solver.cpp:255]     Train net output #0: loss = 0.263598 (* 1 = 0.263598 loss)
I0110 13:36:59.025187  4932 solver.cpp:631] Iteration 36020, lr = 1e-07
I0110 13:37:14.900053  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8536 > 20) by scale factor 0.959067
I0110 13:37:43.402349  4932 solver.cpp:240] Iteration 36040, loss = 0.0721747
I0110 13:37:43.402437  4932 solver.cpp:255]     Train net output #0: loss = 0.0578403 (* 1 = 0.0578403 loss)
I0110 13:37:43.402451  4932 solver.cpp:631] Iteration 36040, lr = 1e-07
I0110 13:37:45.959873  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0614 > 20) by scale factor 0.996941
I0110 13:37:48.182209  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9683 > 20) by scale factor 0.741613
I0110 13:38:27.786979  4932 solver.cpp:240] Iteration 36060, loss = 0.066932
I0110 13:38:27.787061  4932 solver.cpp:255]     Train net output #0: loss = 0.000134713 (* 1 = 0.000134713 loss)
I0110 13:38:27.787073  4932 solver.cpp:631] Iteration 36060, lr = 1e-07
I0110 13:39:12.156780  4932 solver.cpp:240] Iteration 36080, loss = 0.0467145
I0110 13:39:12.156860  4932 solver.cpp:255]     Train net output #0: loss = 0.133463 (* 1 = 0.133463 loss)
I0110 13:39:12.156872  4932 solver.cpp:631] Iteration 36080, lr = 1e-07
I0110 13:39:56.528937  4932 solver.cpp:240] Iteration 36100, loss = 0.0525088
I0110 13:39:56.529013  4932 solver.cpp:255]     Train net output #0: loss = 0.119132 (* 1 = 0.119132 loss)
I0110 13:39:56.529023  4932 solver.cpp:631] Iteration 36100, lr = 1e-07
I0110 13:40:40.911909  4932 solver.cpp:240] Iteration 36120, loss = 0.0341074
I0110 13:40:40.911990  4932 solver.cpp:255]     Train net output #0: loss = 0.0418741 (* 1 = 0.0418741 loss)
I0110 13:40:40.912001  4932 solver.cpp:631] Iteration 36120, lr = 1e-07
I0110 13:41:25.301744  4932 solver.cpp:240] Iteration 36140, loss = 0.0357257
I0110 13:41:25.301837  4932 solver.cpp:255]     Train net output #0: loss = 0.000420556 (* 1 = 0.000420556 loss)
I0110 13:41:25.301851  4932 solver.cpp:631] Iteration 36140, lr = 1e-07
I0110 13:41:38.970331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9088 > 20) by scale factor 0.836513
I0110 13:41:45.628728  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3335 > 20) by scale factor 0.937491
I0110 13:42:05.598531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7649 > 20) by scale factor 0.878547
I0110 13:42:09.697762  4932 solver.cpp:240] Iteration 36160, loss = 0.0686703
I0110 13:42:09.697806  4932 solver.cpp:255]     Train net output #0: loss = 0.0612282 (* 1 = 0.0612282 loss)
I0110 13:42:09.697818  4932 solver.cpp:631] Iteration 36160, lr = 1e-07
I0110 13:42:43.314823  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0211 > 20) by scale factor 0.832602
I0110 13:42:54.072448  4932 solver.cpp:240] Iteration 36180, loss = 0.074084
I0110 13:42:54.072487  4932 solver.cpp:255]     Train net output #0: loss = 0.0144182 (* 1 = 0.0144182 loss)
I0110 13:42:54.072497  4932 solver.cpp:631] Iteration 36180, lr = 1e-07
I0110 13:42:56.629714  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2023 > 20) by scale factor 0.900809
I0110 13:43:16.603672  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5437 > 20) by scale factor 0.849483
I0110 13:43:38.462134  4932 solver.cpp:240] Iteration 36200, loss = 0.0807284
I0110 13:43:38.462189  4932 solver.cpp:255]     Train net output #0: loss = 0.0753096 (* 1 = 0.0753096 loss)
I0110 13:43:38.462204  4932 solver.cpp:631] Iteration 36200, lr = 1e-07
I0110 13:44:22.858507  4932 solver.cpp:240] Iteration 36220, loss = 0.0766287
I0110 13:44:22.858600  4932 solver.cpp:255]     Train net output #0: loss = 0.0427551 (* 1 = 0.0427551 loss)
I0110 13:44:22.858613  4932 solver.cpp:631] Iteration 36220, lr = 1e-07
I0110 13:44:38.727167  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4747 > 20) by scale factor 0.656282
I0110 13:44:56.478936  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7308 > 20) by scale factor 0.842786
I0110 13:45:07.233147  4932 solver.cpp:240] Iteration 36240, loss = 0.0605206
I0110 13:45:07.233186  4932 solver.cpp:255]     Train net output #0: loss = 0.0975265 (* 1 = 0.0975265 loss)
I0110 13:45:07.233197  4932 solver.cpp:631] Iteration 36240, lr = 1e-07
I0110 13:45:16.451995  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1696 > 20) by scale factor 0.991591
I0110 13:45:51.635663  4932 solver.cpp:240] Iteration 36260, loss = 0.0690545
I0110 13:45:51.635731  4932 solver.cpp:255]     Train net output #0: loss = 0.0205826 (* 1 = 0.0205826 loss)
I0110 13:45:51.635741  4932 solver.cpp:631] Iteration 36260, lr = 1e-07
I0110 13:45:56.412753  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8852 > 20) by scale factor 0.803691
I0110 13:46:36.017912  4932 solver.cpp:240] Iteration 36280, loss = 0.0762262
I0110 13:46:36.017988  4932 solver.cpp:255]     Train net output #0: loss = 0.000315051 (* 1 = 0.000315051 loss)
I0110 13:46:36.017998  4932 solver.cpp:631] Iteration 36280, lr = 1e-07
I0110 13:46:51.889933  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3735 > 20) by scale factor 0.935739
I0110 13:46:54.110728  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6442 > 20) by scale factor 0.88323
I0110 13:46:56.331610  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7736 > 20) by scale factor 0.962758
I0110 13:46:58.552990  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2021 > 20) by scale factor 0.793584
I0110 13:47:20.405838  4932 solver.cpp:240] Iteration 36300, loss = 0.0573371
I0110 13:47:20.405920  4932 solver.cpp:255]     Train net output #0: loss = 0.020643 (* 1 = 0.020643 loss)
I0110 13:47:20.405930  4932 solver.cpp:631] Iteration 36300, lr = 1e-07
I0110 13:47:25.179654  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9711 > 20) by scale factor 0.870658
I0110 13:47:29.619243  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4268 > 20) by scale factor 0.891789
I0110 13:47:51.833227  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3827 > 20) by scale factor 0.820254
I0110 13:48:04.805244  4932 solver.cpp:240] Iteration 36320, loss = 0.0522552
I0110 13:48:04.805289  4932 solver.cpp:255]     Train net output #0: loss = 0.0111643 (* 1 = 0.0111643 loss)
I0110 13:48:04.805300  4932 solver.cpp:631] Iteration 36320, lr = 1e-07
I0110 13:48:27.337256  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.9953 > 20) by scale factor 0.625092
I0110 13:48:45.089741  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9792 > 20) by scale factor 0.909952
I0110 13:48:49.190165  4932 solver.cpp:240] Iteration 36340, loss = 0.0772981
I0110 13:48:49.190204  4932 solver.cpp:255]     Train net output #0: loss = 0.0850302 (* 1 = 0.0850302 loss)
I0110 13:48:49.190213  4932 solver.cpp:631] Iteration 36340, lr = 1e-07
I0110 13:49:09.502858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8264 > 20) by scale factor 0.960321
I0110 13:49:25.039533  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0018 > 20) by scale factor 0.83327
I0110 13:49:33.576320  4932 solver.cpp:240] Iteration 36360, loss = 0.0662097
I0110 13:49:33.576364  4932 solver.cpp:255]     Train net output #0: loss = 0.0100824 (* 1 = 0.0100824 loss)
I0110 13:49:33.576375  4932 solver.cpp:631] Iteration 36360, lr = 1e-07
I0110 13:50:17.971202  4932 solver.cpp:240] Iteration 36380, loss = 0.080846
I0110 13:50:17.971298  4932 solver.cpp:255]     Train net output #0: loss = 0.0157016 (* 1 = 0.0157016 loss)
I0110 13:50:17.971312  4932 solver.cpp:631] Iteration 36380, lr = 1e-07
I0110 13:50:22.749402  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6547 > 20) by scale factor 0.845497
I0110 13:51:00.476102  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4711 > 20) by scale factor 0.81729
I0110 13:51:02.359776  4932 solver.cpp:240] Iteration 36400, loss = 0.0548082
I0110 13:51:02.359827  4932 solver.cpp:255]     Train net output #0: loss = 0.0187785 (* 1 = 0.0187785 loss)
I0110 13:51:02.359843  4932 solver.cpp:631] Iteration 36400, lr = 1e-07
I0110 13:51:46.756702  4932 solver.cpp:240] Iteration 36420, loss = 0.0625438
I0110 13:51:46.756794  4932 solver.cpp:255]     Train net output #0: loss = 0.123027 (* 1 = 0.123027 loss)
I0110 13:51:46.756808  4932 solver.cpp:631] Iteration 36420, lr = 1e-07
I0110 13:51:49.315740  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5341 > 20) by scale factor 0.753748
I0110 13:52:02.633097  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4789 > 20) by scale factor 0.755318
I0110 13:52:31.137186  4932 solver.cpp:240] Iteration 36440, loss = 0.0597868
I0110 13:52:31.137264  4932 solver.cpp:255]     Train net output #0: loss = 0.011866 (* 1 = 0.011866 loss)
I0110 13:52:31.137274  4932 solver.cpp:631] Iteration 36440, lr = 1e-07
I0110 13:53:15.525032  4932 solver.cpp:240] Iteration 36460, loss = 0.0519731
I0110 13:53:15.525101  4932 solver.cpp:255]     Train net output #0: loss = 0.0559046 (* 1 = 0.0559046 loss)
I0110 13:53:15.525111  4932 solver.cpp:631] Iteration 36460, lr = 1e-07
I0110 13:53:46.938159  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5832 > 20) by scale factor 0.971664
I0110 13:53:59.915704  4932 solver.cpp:240] Iteration 36480, loss = 0.050474
I0110 13:53:59.915737  4932 solver.cpp:255]     Train net output #0: loss = 0.0432931 (* 1 = 0.0432931 loss)
I0110 13:53:59.915747  4932 solver.cpp:631] Iteration 36480, lr = 1e-07
I0110 13:54:44.309562  4932 solver.cpp:240] Iteration 36500, loss = 0.0553935
I0110 13:54:44.309638  4932 solver.cpp:255]     Train net output #0: loss = 0.00426516 (* 1 = 0.00426516 loss)
I0110 13:54:44.309649  4932 solver.cpp:631] Iteration 36500, lr = 1e-07
I0110 13:55:04.618368  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8097 > 20) by scale factor 0.876821
I0110 13:55:11.283015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8719 > 20) by scale factor 0.958224
I0110 13:55:28.697921  4932 solver.cpp:240] Iteration 36520, loss = 0.068453
I0110 13:55:28.698012  4932 solver.cpp:255]     Train net output #0: loss = 0.12313 (* 1 = 0.12313 loss)
I0110 13:55:28.698026  4932 solver.cpp:631] Iteration 36520, lr = 1e-07
I0110 13:55:33.477239  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3857 > 20) by scale factor 0.935205
I0110 13:55:35.700189  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6901 > 20) by scale factor 0.881443
I0110 13:55:57.890357  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6028 > 20) by scale factor 0.847359
I0110 13:56:13.094065  4932 solver.cpp:240] Iteration 36540, loss = 0.0781027
I0110 13:56:13.094179  4932 solver.cpp:255]     Train net output #0: loss = 0.000279543 (* 1 = 0.000279543 loss)
I0110 13:56:13.094198  4932 solver.cpp:631] Iteration 36540, lr = 1e-07
I0110 13:56:57.470093  4932 solver.cpp:240] Iteration 36560, loss = 0.055485
I0110 13:56:57.470173  4932 solver.cpp:255]     Train net output #0: loss = 0.182139 (* 1 = 0.182139 loss)
I0110 13:56:57.470185  4932 solver.cpp:631] Iteration 36560, lr = 1e-07
I0110 13:57:33.320283  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8258 > 20) by scale factor 0.876201
I0110 13:57:41.857813  4932 solver.cpp:240] Iteration 36580, loss = 0.0885775
I0110 13:57:41.857858  4932 solver.cpp:255]     Train net output #0: loss = 0.0856158 (* 1 = 0.0856158 loss)
I0110 13:57:41.857870  4932 solver.cpp:631] Iteration 36580, lr = 1e-07
I0110 13:58:08.828523  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0599 > 20) by scale factor 0.739101
I0110 13:58:26.240198  4932 solver.cpp:240] Iteration 36600, loss = 0.0581468
I0110 13:58:26.240239  4932 solver.cpp:255]     Train net output #0: loss = 0.256392 (* 1 = 0.256392 loss)
I0110 13:58:26.240249  4932 solver.cpp:631] Iteration 36600, lr = 1e-07
I0110 13:59:10.612367  4932 solver.cpp:240] Iteration 36620, loss = 0.0740568
I0110 13:59:10.612464  4932 solver.cpp:255]     Train net output #0: loss = 0.16579 (* 1 = 0.16579 loss)
I0110 13:59:10.612480  4932 solver.cpp:631] Iteration 36620, lr = 1e-07
I0110 13:59:10.953382  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8651 > 20) by scale factor 0.804342
I0110 13:59:55.009521  4932 solver.cpp:240] Iteration 36640, loss = 0.0594842
I0110 13:59:55.009591  4932 solver.cpp:255]     Train net output #0: loss = 0.0382025 (* 1 = 0.0382025 loss)
I0110 13:59:55.009601  4932 solver.cpp:631] Iteration 36640, lr = 1e-07
I0110 14:00:39.381034  4932 solver.cpp:240] Iteration 36660, loss = 0.0484627
I0110 14:00:39.381109  4932 solver.cpp:255]     Train net output #0: loss = 0.00284335 (* 1 = 0.00284335 loss)
I0110 14:00:39.381121  4932 solver.cpp:631] Iteration 36660, lr = 1e-07
I0110 14:00:50.819399  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2337 > 20) by scale factor 0.941898
I0110 14:01:21.880825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6179 > 20) by scale factor 0.970029
I0110 14:01:23.762778  4932 solver.cpp:240] Iteration 36680, loss = 0.0588898
I0110 14:01:23.762816  4932 solver.cpp:255]     Train net output #0: loss = 0.00428448 (* 1 = 0.00428448 loss)
I0110 14:01:23.762825  4932 solver.cpp:631] Iteration 36680, lr = 1e-07
I0110 14:01:26.319461  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1615 > 20) by scale factor 0.863502
I0110 14:02:08.149010  4932 solver.cpp:240] Iteration 36700, loss = 0.0613025
I0110 14:02:08.149094  4932 solver.cpp:255]     Train net output #0: loss = 0.0570603 (* 1 = 0.0570603 loss)
I0110 14:02:08.149107  4932 solver.cpp:631] Iteration 36700, lr = 1e-07
I0110 14:02:12.929841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3348 > 20) by scale factor 0.983537
I0110 14:02:50.656390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2892 > 20) by scale factor 0.985745
I0110 14:02:52.538338  4932 solver.cpp:240] Iteration 36720, loss = 0.0877356
I0110 14:02:52.538368  4932 solver.cpp:255]     Train net output #0: loss = 0.0216582 (* 1 = 0.0216582 loss)
I0110 14:02:52.538378  4932 solver.cpp:631] Iteration 36720, lr = 1e-07
I0110 14:03:17.288452  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9797 > 20) by scale factor 0.800649
I0110 14:03:28.398087  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.643 > 20) by scale factor 0.674696
I0110 14:03:36.934826  4932 solver.cpp:240] Iteration 36740, loss = 0.0568906
I0110 14:03:36.934857  4932 solver.cpp:255]     Train net output #0: loss = 0.0118664 (* 1 = 0.0118664 loss)
I0110 14:03:36.934867  4932 solver.cpp:631] Iteration 36740, lr = 1e-07
I0110 14:03:50.588861  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9712 > 20) by scale factor 0.953688
I0110 14:04:08.337950  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5534 > 20) by scale factor 0.973074
I0110 14:04:21.315878  4932 solver.cpp:240] Iteration 36760, loss = 0.0527079
I0110 14:04:21.315922  4932 solver.cpp:255]     Train net output #0: loss = 0.0110035 (* 1 = 0.0110035 loss)
I0110 14:04:21.315932  4932 solver.cpp:631] Iteration 36760, lr = 1e-07
I0110 14:04:59.389744  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2729 > 20) by scale factor 0.940165
I0110 14:05:05.707201  4932 solver.cpp:240] Iteration 36780, loss = 0.0522909
I0110 14:05:05.707240  4932 solver.cpp:255]     Train net output #0: loss = 0.0162353 (* 1 = 0.0162353 loss)
I0110 14:05:05.707250  4932 solver.cpp:631] Iteration 36780, lr = 1e-07
I0110 14:05:17.145509  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.7076 > 20) by scale factor 0.630764
I0110 14:05:28.247211  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3924 > 20) by scale factor 0.980759
I0110 14:05:50.104140  4932 solver.cpp:240] Iteration 36800, loss = 0.0555856
I0110 14:05:50.104216  4932 solver.cpp:255]     Train net output #0: loss = 0.0019821 (* 1 = 0.0019821 loss)
I0110 14:05:50.104226  4932 solver.cpp:631] Iteration 36800, lr = 1e-07
I0110 14:06:34.479936  4932 solver.cpp:240] Iteration 36820, loss = 0.0422945
I0110 14:06:34.480022  4932 solver.cpp:255]     Train net output #0: loss = 0.00614522 (* 1 = 0.00614522 loss)
I0110 14:06:34.480036  4932 solver.cpp:631] Iteration 36820, lr = 1e-07
I0110 14:07:18.861546  4932 solver.cpp:240] Iteration 36840, loss = 0.0743941
I0110 14:07:18.861618  4932 solver.cpp:255]     Train net output #0: loss = 0.193814 (* 1 = 0.193814 loss)
I0110 14:07:18.861629  4932 solver.cpp:631] Iteration 36840, lr = 1e-07
I0110 14:08:03.239027  4932 solver.cpp:240] Iteration 36860, loss = 0.0627723
I0110 14:08:03.239120  4932 solver.cpp:255]     Train net output #0: loss = 0.0491284 (* 1 = 0.0491284 loss)
I0110 14:08:03.239135  4932 solver.cpp:631] Iteration 36860, lr = 1e-07
I0110 14:08:16.900846  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8056 > 20) by scale factor 0.961279
I0110 14:08:47.749960  4932 solver.cpp:240] Iteration 36880, loss = 0.0828275
I0110 14:08:47.750063  4932 solver.cpp:255]     Train net output #0: loss = 0.00130479 (* 1 = 0.00130479 loss)
I0110 14:08:47.750079  4932 solver.cpp:631] Iteration 36880, lr = 1e-07
I0110 14:09:01.402554  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7756 > 20) by scale factor 0.918457
I0110 14:09:23.591982  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7616 > 20) by scale factor 0.695372
I0110 14:09:32.129710  4932 solver.cpp:240] Iteration 36900, loss = 0.0766585
I0110 14:09:32.129750  4932 solver.cpp:255]     Train net output #0: loss = 0.0621236 (* 1 = 0.0621236 loss)
I0110 14:09:32.129760  4932 solver.cpp:631] Iteration 36900, lr = 1e-07
I0110 14:10:16.511626  4932 solver.cpp:240] Iteration 36920, loss = 0.0942322
I0110 14:10:16.511739  4932 solver.cpp:255]     Train net output #0: loss = 0.0872791 (* 1 = 0.0872791 loss)
I0110 14:10:16.511754  4932 solver.cpp:631] Iteration 36920, lr = 1e-07
I0110 14:11:00.891707  4932 solver.cpp:240] Iteration 36940, loss = 0.0225528
I0110 14:11:00.891793  4932 solver.cpp:255]     Train net output #0: loss = 0.0102235 (* 1 = 0.0102235 loss)
I0110 14:11:00.891805  4932 solver.cpp:631] Iteration 36940, lr = 1e-07
I0110 14:11:07.889163  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.672 > 20) by scale factor 0.844881
I0110 14:11:36.736979  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1706 > 20) by scale factor 0.991544
I0110 14:11:45.278976  4932 solver.cpp:240] Iteration 36960, loss = 0.0842966
I0110 14:11:45.279016  4932 solver.cpp:255]     Train net output #0: loss = 0.392429 (* 1 = 0.392429 loss)
I0110 14:11:45.279026  4932 solver.cpp:631] Iteration 36960, lr = 1e-07
I0110 14:11:45.618317  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.7876 > 20) by scale factor 0.574917
I0110 14:12:10.030261  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4911 > 20) by scale factor 0.976035
I0110 14:12:29.666587  4932 solver.cpp:240] Iteration 36980, loss = 0.0737585
I0110 14:12:29.666632  4932 solver.cpp:255]     Train net output #0: loss = 0.0762656 (* 1 = 0.0762656 loss)
I0110 14:12:29.666645  4932 solver.cpp:631] Iteration 36980, lr = 1e-07
I0110 14:12:34.445659  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3088 > 20) by scale factor 0.790239
I0110 14:12:41.101270  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.013 > 20) by scale factor 0.999353
I0110 14:13:12.171226  4932 solver.cpp:424] Iteration 37000, Testing net (#0)
I0110 14:14:02.256783  4932 solver.cpp:481]     Test net output #0: accuracy = 0.82
I0110 14:14:02.256883  4932 solver.cpp:481]     Test net output #1: loss = 0.938852 (* 1 = 0.938852 loss)
I0110 14:14:04.124150  4932 solver.cpp:240] Iteration 37000, loss = 0.0736011
I0110 14:14:04.124189  4932 solver.cpp:255]     Train net output #0: loss = 0.0111322 (* 1 = 0.0111322 loss)
I0110 14:14:04.124198  4932 solver.cpp:631] Iteration 37000, lr = 1e-07
I0110 14:14:24.439085  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8745 > 20) by scale factor 0.914305
I0110 14:14:46.633904  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2392 > 20) by scale factor 0.988182
I0110 14:14:48.515630  4932 solver.cpp:240] Iteration 37020, loss = 0.0692464
I0110 14:14:48.515674  4932 solver.cpp:255]     Train net output #0: loss = 0.00530289 (* 1 = 0.00530289 loss)
I0110 14:14:48.515686  4932 solver.cpp:631] Iteration 37020, lr = 1e-07
I0110 14:14:53.296275  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4127 > 20) by scale factor 0.97978
I0110 14:15:32.910559  4932 solver.cpp:240] Iteration 37040, loss = 0.0590836
I0110 14:15:32.910676  4932 solver.cpp:255]     Train net output #0: loss = 0.0198485 (* 1 = 0.0198485 loss)
I0110 14:15:32.910694  4932 solver.cpp:631] Iteration 37040, lr = 1e-07
I0110 14:16:06.543397  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9315 > 20) by scale factor 0.91193
I0110 14:16:17.303098  4932 solver.cpp:240] Iteration 37060, loss = 0.0904812
I0110 14:16:17.303145  4932 solver.cpp:255]     Train net output #0: loss = 0.162839 (* 1 = 0.162839 loss)
I0110 14:16:17.303267  4932 solver.cpp:631] Iteration 37060, lr = 1e-07
I0110 14:16:17.642246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4752 > 20) by scale factor 0.976792
I0110 14:17:01.690438  4932 solver.cpp:240] Iteration 37080, loss = 0.0558383
I0110 14:17:01.690521  4932 solver.cpp:255]     Train net output #0: loss = 0.0423993 (* 1 = 0.0423993 loss)
I0110 14:17:01.690532  4932 solver.cpp:631] Iteration 37080, lr = 1e-07
I0110 14:17:46.080432  4932 solver.cpp:240] Iteration 37100, loss = 0.0500521
I0110 14:17:46.080520  4932 solver.cpp:255]     Train net output #0: loss = 0.103802 (* 1 = 0.103802 loss)
I0110 14:17:46.080534  4932 solver.cpp:631] Iteration 37100, lr = 1e-07
I0110 14:18:30.471802  4932 solver.cpp:240] Iteration 37120, loss = 0.0389958
I0110 14:18:30.471879  4932 solver.cpp:255]     Train net output #0: loss = 0.220459 (* 1 = 0.220459 loss)
I0110 14:18:30.471889  4932 solver.cpp:631] Iteration 37120, lr = 1e-07
I0110 14:18:30.810819  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9659 > 20) by scale factor 0.910503
I0110 14:18:46.350050  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2692 > 20) by scale factor 0.940327
I0110 14:19:14.868765  4932 solver.cpp:240] Iteration 37140, loss = 0.0687278
I0110 14:19:14.868842  4932 solver.cpp:255]     Train net output #0: loss = 0.00218486 (* 1 = 0.00218486 loss)
I0110 14:19:14.868854  4932 solver.cpp:631] Iteration 37140, lr = 1e-07
I0110 14:19:19.643662  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4052 > 20) by scale factor 0.980142
I0110 14:19:41.837395  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1522 > 20) by scale factor 0.992449
I0110 14:19:50.718580  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9885 > 20) by scale factor 0.869999
I0110 14:19:59.253198  4932 solver.cpp:240] Iteration 37160, loss = 0.084814
I0110 14:19:59.253244  4932 solver.cpp:255]     Train net output #0: loss = 0.00225627 (* 1 = 0.00225627 loss)
I0110 14:19:59.253255  4932 solver.cpp:631] Iteration 37160, lr = 1e-07
I0110 14:20:10.689594  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6809 > 20) by scale factor 0.778789
I0110 14:20:17.351486  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6776 > 20) by scale factor 0.922613
I0110 14:20:19.571368  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2453 > 20) by scale factor 0.899065
I0110 14:20:43.648880  4932 solver.cpp:240] Iteration 37180, loss = 0.0909241
I0110 14:20:43.648977  4932 solver.cpp:255]     Train net output #0: loss = 0.00755914 (* 1 = 0.00755914 loss)
I0110 14:20:43.648991  4932 solver.cpp:631] Iteration 37180, lr = 1e-07
I0110 14:21:01.750974  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4726 > 20) by scale factor 0.727999
I0110 14:21:17.281229  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.537 > 20) by scale factor 0.849727
I0110 14:21:28.040659  4932 solver.cpp:240] Iteration 37200, loss = 0.0845099
I0110 14:21:28.040699  4932 solver.cpp:255]     Train net output #0: loss = 0.11766 (* 1 = 0.11766 loss)
I0110 14:21:28.040707  4932 solver.cpp:631] Iteration 37200, lr = 1e-07
I0110 14:21:32.822597  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5948 > 20) by scale factor 0.926147
I0110 14:22:01.679134  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5128 > 20) by scale factor 0.850599
I0110 14:22:10.558727  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.6364 > 20) by scale factor 0.594594
I0110 14:22:12.439862  4932 solver.cpp:240] Iteration 37220, loss = 0.0829397
I0110 14:22:12.439903  4932 solver.cpp:255]     Train net output #0: loss = 0.00164677 (* 1 = 0.00164677 loss)
I0110 14:22:12.439911  4932 solver.cpp:631] Iteration 37220, lr = 1e-07
I0110 14:22:30.535750  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2327 > 20) by scale factor 0.792623
I0110 14:22:56.840001  4932 solver.cpp:240] Iteration 37240, loss = 0.071649
I0110 14:22:56.840071  4932 solver.cpp:255]     Train net output #0: loss = 0.0747703 (* 1 = 0.0747703 loss)
I0110 14:22:56.840082  4932 solver.cpp:631] Iteration 37240, lr = 1e-07
I0110 14:23:19.366153  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.813 > 20) by scale factor 0.960939
I0110 14:23:37.126322  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1266 > 20) by scale factor 0.79597
I0110 14:23:41.225831  4932 solver.cpp:240] Iteration 37260, loss = 0.0502597
I0110 14:23:41.225862  4932 solver.cpp:255]     Train net output #0: loss = 0.0530122 (* 1 = 0.0530122 loss)
I0110 14:23:41.225870  4932 solver.cpp:631] Iteration 37260, lr = 1e-07
I0110 14:23:43.784960  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7362 > 20) by scale factor 0.920126
I0110 14:24:25.610769  4932 solver.cpp:240] Iteration 37280, loss = 0.0495081
I0110 14:24:25.610867  4932 solver.cpp:255]     Train net output #0: loss = 0.230377 (* 1 = 0.230377 loss)
I0110 14:24:25.610882  4932 solver.cpp:631] Iteration 37280, lr = 1e-07
I0110 14:24:59.240818  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1887 > 20) by scale factor 0.90136
I0110 14:25:01.465911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8859 > 20) by scale factor 0.837315
I0110 14:25:10.005110  4932 solver.cpp:240] Iteration 37300, loss = 0.0672371
I0110 14:25:10.005157  4932 solver.cpp:255]     Train net output #0: loss = 0.206902 (* 1 = 0.206902 loss)
I0110 14:25:10.005167  4932 solver.cpp:631] Iteration 37300, lr = 1e-07
I0110 14:25:28.097630  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0441 > 20) by scale factor 0.831806
I0110 14:25:48.071007  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1159 > 20) by scale factor 0.737575
I0110 14:25:52.513754  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1115 > 20) by scale factor 0.994455
I0110 14:25:54.394950  4932 solver.cpp:240] Iteration 37320, loss = 0.0647916
I0110 14:25:54.394989  4932 solver.cpp:255]     Train net output #0: loss = 0.00839082 (* 1 = 0.00839082 loss)
I0110 14:25:54.394999  4932 solver.cpp:631] Iteration 37320, lr = 1e-07
I0110 14:25:59.170831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7848 > 20) by scale factor 0.96224
I0110 14:26:38.776968  4932 solver.cpp:240] Iteration 37340, loss = 0.0615913
I0110 14:26:38.777052  4932 solver.cpp:255]     Train net output #0: loss = 0.131161 (* 1 = 0.131161 loss)
I0110 14:26:38.777065  4932 solver.cpp:631] Iteration 37340, lr = 1e-07
I0110 14:27:23.158476  4932 solver.cpp:240] Iteration 37360, loss = 0.0647406
I0110 14:27:23.158550  4932 solver.cpp:255]     Train net output #0: loss = 0.0197111 (* 1 = 0.0197111 loss)
I0110 14:27:23.158560  4932 solver.cpp:631] Iteration 37360, lr = 1e-07
I0110 14:28:07.544404  4932 solver.cpp:240] Iteration 37380, loss = 0.0636606
I0110 14:28:07.544476  4932 solver.cpp:255]     Train net output #0: loss = 0.0506544 (* 1 = 0.0506544 loss)
I0110 14:28:07.544486  4932 solver.cpp:631] Iteration 37380, lr = 1e-07
I0110 14:28:47.831903  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8163 > 20) by scale factor 0.916745
I0110 14:28:51.934386  4932 solver.cpp:240] Iteration 37400, loss = 0.0834221
I0110 14:28:51.934429  4932 solver.cpp:255]     Train net output #0: loss = 0.22347 (* 1 = 0.22347 loss)
I0110 14:28:51.934440  4932 solver.cpp:631] Iteration 37400, lr = 1e-07
I0110 14:28:52.274708  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5447 > 20) by scale factor 0.849449
I0110 14:29:03.371889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6757 > 20) by scale factor 0.697453
I0110 14:29:27.782407  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 38.0887 > 20) by scale factor 0.52509
I0110 14:29:36.322639  4932 solver.cpp:240] Iteration 37420, loss = 0.0784851
I0110 14:29:36.322685  4932 solver.cpp:255]     Train net output #0: loss = 0.0074976 (* 1 = 0.0074976 loss)
I0110 14:29:36.322698  4932 solver.cpp:631] Iteration 37420, lr = 1e-07
I0110 14:30:20.700558  4932 solver.cpp:240] Iteration 37440, loss = 0.0443086
I0110 14:30:20.700634  4932 solver.cpp:255]     Train net output #0: loss = 0.0099074 (* 1 = 0.0099074 loss)
I0110 14:30:20.700644  4932 solver.cpp:631] Iteration 37440, lr = 1e-07
I0110 14:30:25.477013  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5376 > 20) by scale factor 0.70083
I0110 14:31:05.072583  4932 solver.cpp:240] Iteration 37460, loss = 0.0746519
I0110 14:31:05.072672  4932 solver.cpp:255]     Train net output #0: loss = 0.0125605 (* 1 = 0.0125605 loss)
I0110 14:31:05.072685  4932 solver.cpp:631] Iteration 37460, lr = 1e-07
I0110 14:31:23.168195  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0378 > 20) by scale factor 0.832022
I0110 14:31:25.388181  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1092 > 20) by scale factor 0.994571
I0110 14:31:32.044800  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7009 > 20) by scale factor 0.966142
I0110 14:31:36.487529  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1367 > 20) by scale factor 0.993214
I0110 14:31:49.468883  4932 solver.cpp:240] Iteration 37480, loss = 0.0981908
I0110 14:31:49.468935  4932 solver.cpp:255]     Train net output #0: loss = 0.322183 (* 1 = 0.322183 loss)
I0110 14:31:49.468946  4932 solver.cpp:631] Iteration 37480, lr = 1e-07
I0110 14:31:49.809217  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.566 > 20) by scale factor 0.614137
I0110 14:32:23.093624  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9318 > 20) by scale factor 0.742615
I0110 14:32:33.846926  4932 solver.cpp:240] Iteration 37500, loss = 0.0953547
I0110 14:32:33.846964  4932 solver.cpp:255]     Train net output #0: loss = 0.0354469 (* 1 = 0.0354469 loss)
I0110 14:32:33.846974  4932 solver.cpp:631] Iteration 37500, lr = 1e-07
I0110 14:32:56.371963  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5655 > 20) by scale factor 0.848698
I0110 14:33:14.133069  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3894 > 20) by scale factor 0.980903
I0110 14:33:18.235471  4932 solver.cpp:240] Iteration 37520, loss = 0.0662497
I0110 14:33:18.235512  4932 solver.cpp:255]     Train net output #0: loss = 0.000977019 (* 1 = 0.000977019 loss)
I0110 14:33:18.235520  4932 solver.cpp:631] Iteration 37520, lr = 1e-07
I0110 14:33:29.671603  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6951 > 20) by scale factor 0.696984
I0110 14:34:02.618468  4932 solver.cpp:240] Iteration 37540, loss = 0.0682248
I0110 14:34:02.618556  4932 solver.cpp:255]     Train net output #0: loss = 0.00558476 (* 1 = 0.00558476 loss)
I0110 14:34:02.618569  4932 solver.cpp:631] Iteration 37540, lr = 1e-07
I0110 14:34:07.397954  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4273 > 20) by scale factor 0.979083
I0110 14:34:09.619308  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0108 > 20) by scale factor 0.869159
I0110 14:34:14.055366  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6717 > 20) by scale factor 0.84489
I0110 14:34:47.058281  4932 solver.cpp:240] Iteration 37560, loss = 0.0702075
I0110 14:34:47.058377  4932 solver.cpp:255]     Train net output #0: loss = 0.00094889 (* 1 = 0.00094889 loss)
I0110 14:34:47.058390  4932 solver.cpp:631] Iteration 37560, lr = 1e-07
I0110 14:34:51.839612  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.1248 > 20) by scale factor 0.663905
I0110 14:35:31.439116  4932 solver.cpp:240] Iteration 37580, loss = 0.0576522
I0110 14:35:31.439210  4932 solver.cpp:255]     Train net output #0: loss = 0.154587 (* 1 = 0.154587 loss)
I0110 14:35:31.439224  4932 solver.cpp:631] Iteration 37580, lr = 1e-07
I0110 14:35:56.193465  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6917 > 20) by scale factor 0.966571
I0110 14:36:15.823611  4932 solver.cpp:240] Iteration 37600, loss = 0.0484823
I0110 14:36:15.823719  4932 solver.cpp:255]     Train net output #0: loss = 0.00595398 (* 1 = 0.00595398 loss)
I0110 14:36:15.823735  4932 solver.cpp:631] Iteration 37600, lr = 1e-07
I0110 14:36:42.786836  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9325 > 20) by scale factor 0.802166
I0110 14:37:00.194877  4932 solver.cpp:240] Iteration 37620, loss = 0.0662939
I0110 14:37:00.194964  4932 solver.cpp:255]     Train net output #0: loss = 0.0313245 (* 1 = 0.0313245 loss)
I0110 14:37:00.194978  4932 solver.cpp:631] Iteration 37620, lr = 1e-07
I0110 14:37:44.572994  4932 solver.cpp:240] Iteration 37640, loss = 0.0637734
I0110 14:37:44.573091  4932 solver.cpp:255]     Train net output #0: loss = 0.186303 (* 1 = 0.186303 loss)
I0110 14:37:44.573104  4932 solver.cpp:631] Iteration 37640, lr = 1e-07
I0110 14:38:28.957881  4932 solver.cpp:240] Iteration 37660, loss = 0.0374163
I0110 14:38:28.957955  4932 solver.cpp:255]     Train net output #0: loss = 0.0106773 (* 1 = 0.0106773 loss)
I0110 14:38:28.957965  4932 solver.cpp:631] Iteration 37660, lr = 1e-07
I0110 14:38:49.272279  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0257 > 20) by scale factor 0.832443
I0110 14:38:51.495676  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.4926 > 20) by scale factor 0.63507
I0110 14:39:13.346346  4932 solver.cpp:240] Iteration 37680, loss = 0.0880117
I0110 14:39:13.346441  4932 solver.cpp:255]     Train net output #0: loss = 0.0308227 (* 1 = 0.0308227 loss)
I0110 14:39:13.346451  4932 solver.cpp:631] Iteration 37680, lr = 1e-07
I0110 14:39:57.732635  4932 solver.cpp:240] Iteration 37700, loss = 0.0819247
I0110 14:39:57.732708  4932 solver.cpp:255]     Train net output #0: loss = 0.210813 (* 1 = 0.210813 loss)
I0110 14:39:57.732719  4932 solver.cpp:631] Iteration 37700, lr = 1e-07
I0110 14:40:11.392009  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9026 > 20) by scale factor 0.83673
I0110 14:40:15.833526  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4638 > 20) by scale factor 0.852378
I0110 14:40:42.427587  4932 solver.cpp:240] Iteration 37720, loss = 0.100712
I0110 14:40:42.427677  4932 solver.cpp:255]     Train net output #0: loss = 0.0271391 (* 1 = 0.0271391 loss)
I0110 14:40:42.427690  4932 solver.cpp:631] Iteration 37720, lr = 1e-07
I0110 14:41:26.821177  4932 solver.cpp:240] Iteration 37740, loss = 0.0399685
I0110 14:41:26.821280  4932 solver.cpp:255]     Train net output #0: loss = 0.0286263 (* 1 = 0.0286263 loss)
I0110 14:41:26.821295  4932 solver.cpp:631] Iteration 37740, lr = 1e-07
I0110 14:41:44.993654  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8963 > 20) by scale factor 0.873505
I0110 14:41:51.707185  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8545 > 20) by scale factor 0.875103
I0110 14:42:11.343997  4932 solver.cpp:240] Iteration 37760, loss = 0.0711774
I0110 14:42:11.344077  4932 solver.cpp:255]     Train net output #0: loss = 0.0862966 (* 1 = 0.0862966 loss)
I0110 14:42:11.344089  4932 solver.cpp:631] Iteration 37760, lr = 1e-07
I0110 14:42:38.318732  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.982 > 20) by scale factor 0.953196
I0110 14:42:55.900362  4932 solver.cpp:240] Iteration 37780, loss = 0.0725451
I0110 14:42:55.900473  4932 solver.cpp:255]     Train net output #0: loss = 0.0382798 (* 1 = 0.0382798 loss)
I0110 14:42:55.900488  4932 solver.cpp:631] Iteration 37780, lr = 1e-07
I0110 14:42:58.461189  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0683 > 20) by scale factor 0.797821
I0110 14:43:05.120906  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.734 > 20) by scale factor 0.748111
I0110 14:43:40.308014  4932 solver.cpp:240] Iteration 37800, loss = 0.0813173
I0110 14:43:40.308128  4932 solver.cpp:255]     Train net output #0: loss = 0.0818608 (* 1 = 0.0818608 loss)
I0110 14:43:40.308145  4932 solver.cpp:631] Iteration 37800, lr = 1e-07
I0110 14:43:47.309765  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7792 > 20) by scale factor 0.775818
I0110 14:44:24.713414  4932 solver.cpp:240] Iteration 37820, loss = 0.0645032
I0110 14:44:24.713527  4932 solver.cpp:255]     Train net output #0: loss = 0.129152 (* 1 = 0.129152 loss)
I0110 14:44:24.713542  4932 solver.cpp:631] Iteration 37820, lr = 1e-07
I0110 14:44:33.934355  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9726 > 20) by scale factor 0.834285
I0110 14:44:49.958055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0025 > 20) by scale factor 0.869469
I0110 14:44:54.402472  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7192 > 20) by scale factor 0.965286
I0110 14:45:09.608113  4932 solver.cpp:240] Iteration 37840, loss = 0.0995647
I0110 14:45:09.608206  4932 solver.cpp:255]     Train net output #0: loss = 0.0356705 (* 1 = 0.0356705 loss)
I0110 14:45:09.608219  4932 solver.cpp:631] Iteration 37840, lr = 1e-07
I0110 14:45:54.617522  4932 solver.cpp:240] Iteration 37860, loss = 0.0656532
I0110 14:45:54.617619  4932 solver.cpp:255]     Train net output #0: loss = 0.00225881 (* 1 = 0.00225881 loss)
I0110 14:45:54.617637  4932 solver.cpp:631] Iteration 37860, lr = 1e-07
I0110 14:46:39.020093  4932 solver.cpp:240] Iteration 37880, loss = 0.0543334
I0110 14:46:39.020192  4932 solver.cpp:255]     Train net output #0: loss = 0.00287487 (* 1 = 0.00287487 loss)
I0110 14:46:39.020205  4932 solver.cpp:631] Iteration 37880, lr = 1e-07
I0110 14:47:10.446945  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.71 > 20) by scale factor 0.965718
I0110 14:47:23.432248  4932 solver.cpp:240] Iteration 37900, loss = 0.0476079
I0110 14:47:23.432291  4932 solver.cpp:255]     Train net output #0: loss = 0.00496338 (* 1 = 0.00496338 loss)
I0110 14:47:23.432302  4932 solver.cpp:631] Iteration 37900, lr = 1e-07
I0110 14:48:01.518208  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0527 > 20) by scale factor 0.99737
I0110 14:48:07.843235  4932 solver.cpp:240] Iteration 37920, loss = 0.0402925
I0110 14:48:07.843279  4932 solver.cpp:255]     Train net output #0: loss = 0.0541139 (* 1 = 0.0541139 loss)
I0110 14:48:07.843291  4932 solver.cpp:631] Iteration 37920, lr = 1e-07
I0110 14:48:39.274463  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2778 > 20) by scale factor 0.7611
I0110 14:48:52.425968  4932 solver.cpp:240] Iteration 37940, loss = 0.0294153
I0110 14:48:52.426007  4932 solver.cpp:255]     Train net output #0: loss = 0.0671839 (* 1 = 0.0671839 loss)
I0110 14:48:52.426019  4932 solver.cpp:631] Iteration 37940, lr = 1e-07
I0110 14:49:21.632669  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.282 > 20) by scale factor 0.823657
I0110 14:49:33.424042  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6395 > 20) by scale factor 0.811705
I0110 14:49:37.527925  4932 solver.cpp:240] Iteration 37960, loss = 0.0637322
I0110 14:49:37.527966  4932 solver.cpp:255]     Train net output #0: loss = 0.00582058 (* 1 = 0.00582058 loss)
I0110 14:49:37.527977  4932 solver.cpp:631] Iteration 37960, lr = 1e-07
I0110 14:50:15.606180  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7265 > 20) by scale factor 0.842939
I0110 14:50:21.925284  4932 solver.cpp:240] Iteration 37980, loss = 0.0743811
I0110 14:50:21.925329  4932 solver.cpp:255]     Train net output #0: loss = 0.0668637 (* 1 = 0.0668637 loss)
I0110 14:50:21.925341  4932 solver.cpp:631] Iteration 37980, lr = 1e-07
I0110 14:50:55.954542  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9288 > 20) by scale factor 0.912043
I0110 14:51:04.845829  4932 solver.cpp:424] Iteration 38000, Testing net (#0)
I0110 14:51:53.642154  4932 solver.cpp:481]     Test net output #0: accuracy = 0.844211
I0110 14:51:53.642249  4932 solver.cpp:481]     Test net output #1: loss = 0.777427 (* 1 = 0.777427 loss)
I0110 14:51:55.509292  4932 solver.cpp:240] Iteration 38000, loss = 0.0464469
I0110 14:51:55.509332  4932 solver.cpp:255]     Train net output #0: loss = 0.000400718 (* 1 = 0.000400718 loss)
I0110 14:51:55.509341  4932 solver.cpp:631] Iteration 38000, lr = 1e-07
I0110 14:52:39.881821  4932 solver.cpp:240] Iteration 38020, loss = 0.0724124
I0110 14:52:39.881907  4932 solver.cpp:255]     Train net output #0: loss = 0.0228648 (* 1 = 0.0228648 loss)
I0110 14:52:39.881918  4932 solver.cpp:631] Iteration 38020, lr = 1e-07
I0110 14:52:42.437710  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.4788 > 20) by scale factor 0.597393
I0110 14:52:49.094787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7535 > 20) by scale factor 0.878986
I0110 14:53:24.891095  4932 solver.cpp:240] Iteration 38040, loss = 0.0844344
I0110 14:53:24.891209  4932 solver.cpp:255]     Train net output #0: loss = 0.0348445 (* 1 = 0.0348445 loss)
I0110 14:53:24.891225  4932 solver.cpp:631] Iteration 38040, lr = 1e-07
I0110 14:53:47.418269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0455 > 20) by scale factor 0.907214
I0110 14:54:08.275710  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6229 > 20) by scale factor 0.88406
I0110 14:54:10.157500  4932 solver.cpp:240] Iteration 38060, loss = 0.0480592
I0110 14:54:10.157529  4932 solver.cpp:255]     Train net output #0: loss = 0.00028652 (* 1 = 0.00028652 loss)
I0110 14:54:10.157538  4932 solver.cpp:631] Iteration 38060, lr = 1e-07
I0110 14:54:19.373914  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0005 > 20) by scale factor 0.869546
I0110 14:54:55.531466  4932 solver.cpp:240] Iteration 38080, loss = 0.0808571
I0110 14:54:55.531559  4932 solver.cpp:255]     Train net output #0: loss = 0.0592122 (* 1 = 0.0592122 loss)
I0110 14:54:55.531570  4932 solver.cpp:631] Iteration 38080, lr = 1e-07
I0110 14:54:58.089767  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0329 > 20) by scale factor 0.739838
I0110 14:55:39.910517  4932 solver.cpp:240] Iteration 38100, loss = 0.0533191
I0110 14:55:39.910604  4932 solver.cpp:255]     Train net output #0: loss = 0.0357043 (* 1 = 0.0357043 loss)
I0110 14:55:39.910616  4932 solver.cpp:631] Iteration 38100, lr = 1e-07
I0110 14:55:54.277592  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1788 > 20) by scale factor 0.763977
I0110 14:56:14.247922  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5369 > 20) by scale factor 0.928638
I0110 14:56:25.722254  4932 solver.cpp:240] Iteration 38120, loss = 0.080619
I0110 14:56:25.722293  4932 solver.cpp:255]     Train net output #0: loss = 0.0781063 (* 1 = 0.0781063 loss)
I0110 14:56:25.722302  4932 solver.cpp:631] Iteration 38120, lr = 1e-07
I0110 14:57:10.691684  4932 solver.cpp:240] Iteration 38140, loss = 0.064432
I0110 14:57:10.691777  4932 solver.cpp:255]     Train net output #0: loss = 0.00064459 (* 1 = 0.00064459 loss)
I0110 14:57:10.691789  4932 solver.cpp:631] Iteration 38140, lr = 1e-07
I0110 14:57:55.881568  4932 solver.cpp:240] Iteration 38160, loss = 0.0429194
I0110 14:57:55.881659  4932 solver.cpp:255]     Train net output #0: loss = 0.013567 (* 1 = 0.013567 loss)
I0110 14:57:55.881672  4932 solver.cpp:631] Iteration 38160, lr = 1e-07
I0110 14:58:07.310479  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9969 > 20) by scale factor 0.833441
I0110 14:58:40.248235  4932 solver.cpp:240] Iteration 38180, loss = 0.062476
I0110 14:58:40.248327  4932 solver.cpp:255]     Train net output #0: loss = 0.0301512 (* 1 = 0.0301512 loss)
I0110 14:58:40.248339  4932 solver.cpp:631] Iteration 38180, lr = 1e-07
I0110 14:58:56.716428  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4615 > 20) by scale factor 0.7855
I0110 14:59:10.033288  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6312 > 20) by scale factor 0.883737
I0110 14:59:25.225826  4932 solver.cpp:240] Iteration 38200, loss = 0.069542
I0110 14:59:25.225903  4932 solver.cpp:255]     Train net output #0: loss = 0.00160047 (* 1 = 0.00160047 loss)
I0110 14:59:25.225914  4932 solver.cpp:631] Iteration 38200, lr = 1e-07
I0110 14:59:32.219755  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1263 > 20) by scale factor 0.946689
I0110 14:59:36.658133  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3179 > 20) by scale factor 0.638612
I0110 15:00:09.912838  4932 solver.cpp:240] Iteration 38220, loss = 0.0597466
I0110 15:00:09.912928  4932 solver.cpp:255]     Train net output #0: loss = 0.00716531 (* 1 = 0.00716531 loss)
I0110 15:00:09.912941  4932 solver.cpp:631] Iteration 38220, lr = 1e-07
I0110 15:00:14.692347  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7662 > 20) by scale factor 0.776211
I0110 15:00:16.913231  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5638 > 20) by scale factor 0.972583
I0110 15:00:19.135525  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5565 > 20) by scale factor 0.97293
I0110 15:00:54.530490  4932 solver.cpp:240] Iteration 38240, loss = 0.0972522
I0110 15:00:54.530593  4932 solver.cpp:255]     Train net output #0: loss = 0.241694 (* 1 = 0.241694 loss)
I0110 15:00:54.530606  4932 solver.cpp:631] Iteration 38240, lr = 1e-07
I0110 15:01:38.888994  4932 solver.cpp:240] Iteration 38260, loss = 0.0653104
I0110 15:01:38.889091  4932 solver.cpp:255]     Train net output #0: loss = 0.0118016 (* 1 = 0.0118016 loss)
I0110 15:01:38.889103  4932 solver.cpp:631] Iteration 38260, lr = 1e-07
I0110 15:02:06.938246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7441 > 20) by scale factor 0.74783
I0110 15:02:11.377827  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.324 > 20) by scale factor 0.895897
I0110 15:02:24.353288  4932 solver.cpp:240] Iteration 38280, loss = 0.055208
I0110 15:02:24.353329  4932 solver.cpp:255]     Train net output #0: loss = 0.00271739 (* 1 = 0.00271739 loss)
I0110 15:02:24.353338  4932 solver.cpp:631] Iteration 38280, lr = 1e-07
I0110 15:02:53.536191  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.192 > 20) by scale factor 0.990493
I0110 15:02:57.974637  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1253 > 20) by scale factor 0.993772
I0110 15:03:00.195003  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5809 > 20) by scale factor 0.813639
I0110 15:03:09.775774  4932 solver.cpp:240] Iteration 38300, loss = 0.07321
I0110 15:03:09.775811  4932 solver.cpp:255]     Train net output #0: loss = 0.24327 (* 1 = 0.24327 loss)
I0110 15:03:09.775820  4932 solver.cpp:631] Iteration 38300, lr = 1e-07
I0110 15:03:10.114688  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3383 > 20) by scale factor 0.789318
I0110 15:03:46.368468  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9801 > 20) by scale factor 0.834025
I0110 15:03:54.901072  4932 solver.cpp:240] Iteration 38320, loss = 0.0553077
I0110 15:03:54.901104  4932 solver.cpp:255]     Train net output #0: loss = 0.0306012 (* 1 = 0.0306012 loss)
I0110 15:03:54.901114  4932 solver.cpp:631] Iteration 38320, lr = 1e-07
I0110 15:04:39.428987  4932 solver.cpp:240] Iteration 38340, loss = 0.0475378
I0110 15:04:39.429080  4932 solver.cpp:255]     Train net output #0: loss = 0.0245646 (* 1 = 0.0245646 loss)
I0110 15:04:39.429092  4932 solver.cpp:631] Iteration 38340, lr = 1e-07
I0110 15:05:15.260280  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7246 > 20) by scale factor 0.920614
I0110 15:05:24.591996  4932 solver.cpp:240] Iteration 38360, loss = 0.0481158
I0110 15:05:24.592033  4932 solver.cpp:255]     Train net output #0: loss = 0.0728809 (* 1 = 0.0728809 loss)
I0110 15:05:24.592042  4932 solver.cpp:631] Iteration 38360, lr = 1e-07
I0110 15:05:38.243206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5988 > 20) by scale factor 0.813047
I0110 15:06:01.114830  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.689 > 20) by scale factor 0.922126
I0110 15:06:09.651370  4932 solver.cpp:240] Iteration 38380, loss = 0.0721911
I0110 15:06:09.651408  4932 solver.cpp:255]     Train net output #0: loss = 0.00308128 (* 1 = 0.00308128 loss)
I0110 15:06:09.651418  4932 solver.cpp:631] Iteration 38380, lr = 1e-07
I0110 15:06:54.014503  4932 solver.cpp:240] Iteration 38400, loss = 0.0443879
I0110 15:06:54.014598  4932 solver.cpp:255]     Train net output #0: loss = 0.0548431 (* 1 = 0.0548431 loss)
I0110 15:06:54.014611  4932 solver.cpp:631] Iteration 38400, lr = 1e-07
I0110 15:07:03.553375  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1526 > 20) by scale factor 0.992426
I0110 15:07:39.700769  4932 solver.cpp:240] Iteration 38420, loss = 0.0658674
I0110 15:07:39.700865  4932 solver.cpp:255]     Train net output #0: loss = 0.00379167 (* 1 = 0.00379167 loss)
I0110 15:07:39.700877  4932 solver.cpp:631] Iteration 38420, lr = 1e-07
I0110 15:07:46.693568  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1583 > 20) by scale factor 0.945254
I0110 15:07:57.790863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8237 > 20) by scale factor 0.80568
I0110 15:08:18.778100  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.729 > 20) by scale factor 0.964832
I0110 15:08:25.096298  4932 solver.cpp:240] Iteration 38440, loss = 0.121137
I0110 15:08:25.096344  4932 solver.cpp:255]     Train net output #0: loss = 0.0147368 (* 1 = 0.0147368 loss)
I0110 15:08:25.096355  4932 solver.cpp:631] Iteration 38440, lr = 1e-07
I0110 15:08:32.091748  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0178 > 20) by scale factor 0.908355
I0110 15:09:10.584058  4932 solver.cpp:240] Iteration 38460, loss = 0.046026
I0110 15:09:10.584152  4932 solver.cpp:255]     Train net output #0: loss = 0.0100043 (* 1 = 0.0100043 loss)
I0110 15:09:10.584166  4932 solver.cpp:631] Iteration 38460, lr = 1e-07
I0110 15:09:22.016016  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5548 > 20) by scale factor 0.814506
I0110 15:09:56.043277  4932 solver.cpp:240] Iteration 38480, loss = 0.0583444
I0110 15:09:56.043382  4932 solver.cpp:255]     Train net output #0: loss = 0.0784248 (* 1 = 0.0784248 loss)
I0110 15:09:56.043400  4932 solver.cpp:631] Iteration 38480, lr = 1e-07
I0110 15:10:21.747717  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8035 > 20) by scale factor 0.917285
I0110 15:10:40.424813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6519 > 20) by scale factor 0.882928
I0110 15:10:42.306231  4932 solver.cpp:240] Iteration 38500, loss = 0.112433
I0110 15:10:42.306268  4932 solver.cpp:255]     Train net output #0: loss = 0.0388485 (* 1 = 0.0388485 loss)
I0110 15:10:42.306277  4932 solver.cpp:631] Iteration 38500, lr = 1e-07
I0110 15:11:18.140815  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1869 > 20) by scale factor 0.901432
I0110 15:11:27.144925  4932 solver.cpp:240] Iteration 38520, loss = 0.100684
I0110 15:11:27.144958  4932 solver.cpp:255]     Train net output #0: loss = 0.0881175 (* 1 = 0.0881175 loss)
I0110 15:11:27.144966  4932 solver.cpp:631] Iteration 38520, lr = 1e-07
I0110 15:11:38.577164  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 46.9094 > 20) by scale factor 0.426354
I0110 15:11:45.238904  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2704 > 20) by scale factor 0.791439
I0110 15:12:08.682047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1878 > 20) by scale factor 0.990698
I0110 15:12:12.780974  4932 solver.cpp:240] Iteration 38540, loss = 0.0692133
I0110 15:12:12.781013  4932 solver.cpp:255]     Train net output #0: loss = 0.0366761 (* 1 = 0.0366761 loss)
I0110 15:12:12.781023  4932 solver.cpp:631] Iteration 38540, lr = 1e-07
I0110 15:12:34.019385  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3753 > 20) by scale factor 0.981582
I0110 15:12:40.677862  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3703 > 20) by scale factor 0.98182
I0110 15:12:51.772001  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.0065 > 20) by scale factor 0.555456
I0110 15:12:58.090365  4932 solver.cpp:240] Iteration 38560, loss = 0.138204
I0110 15:12:58.090409  4932 solver.cpp:255]     Train net output #0: loss = 0.227284 (* 1 = 0.227284 loss)
I0110 15:12:58.090420  4932 solver.cpp:631] Iteration 38560, lr = 1e-07
I0110 15:13:00.649338  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4647 > 20) by scale factor 0.890287
I0110 15:13:26.064065  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9193 > 20) by scale factor 0.716351
I0110 15:13:30.507542  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5201 > 20) by scale factor 0.888096
I0110 15:13:43.479821  4932 solver.cpp:240] Iteration 38580, loss = 0.0602703
I0110 15:13:43.479854  4932 solver.cpp:255]     Train net output #0: loss = 0.0157995 (* 1 = 0.0157995 loss)
I0110 15:13:43.479871  4932 solver.cpp:631] Iteration 38580, lr = 1e-07
I0110 15:14:27.752195  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6336 > 20) by scale factor 0.883643
I0110 15:14:29.633175  4932 solver.cpp:240] Iteration 38600, loss = 0.0814177
I0110 15:14:29.633216  4932 solver.cpp:255]     Train net output #0: loss = 0.0233456 (* 1 = 0.0233456 loss)
I0110 15:14:29.633225  4932 solver.cpp:631] Iteration 38600, lr = 1e-07
I0110 15:14:36.629743  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7897 > 20) by scale factor 0.775503
I0110 15:15:14.798800  4932 solver.cpp:240] Iteration 38620, loss = 0.0661524
I0110 15:15:14.798913  4932 solver.cpp:255]     Train net output #0: loss = 0.00857176 (* 1 = 0.00857176 loss)
I0110 15:15:14.798928  4932 solver.cpp:631] Iteration 38620, lr = 1e-07
I0110 15:15:59.269081  4932 solver.cpp:240] Iteration 38640, loss = 0.0432365
I0110 15:15:59.269165  4932 solver.cpp:255]     Train net output #0: loss = 0.0187225 (* 1 = 0.0187225 loss)
I0110 15:15:59.269176  4932 solver.cpp:631] Iteration 38640, lr = 1e-07
I0110 15:16:10.703511  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.516 > 20) by scale factor 0.815795
I0110 15:16:22.720856  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3904 > 20) by scale factor 0.855052
I0110 15:16:44.575901  4932 solver.cpp:240] Iteration 38660, loss = 0.078927
I0110 15:16:44.575994  4932 solver.cpp:255]     Train net output #0: loss = 0.185828 (* 1 = 0.185828 loss)
I0110 15:16:44.576007  4932 solver.cpp:631] Iteration 38660, lr = 1e-07
I0110 15:17:05.917660  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3397 > 20) by scale factor 0.789275
I0110 15:17:29.981770  4932 solver.cpp:240] Iteration 38680, loss = 0.0606672
I0110 15:17:29.981860  4932 solver.cpp:255]     Train net output #0: loss = 0.0406781 (* 1 = 0.0406781 loss)
I0110 15:17:29.981873  4932 solver.cpp:631] Iteration 38680, lr = 1e-07
I0110 15:17:48.072196  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7413 > 20) by scale factor 0.842412
I0110 15:18:06.033540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3368 > 20) by scale factor 0.821799
I0110 15:18:08.254140  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.574 > 20) by scale factor 0.972099
I0110 15:18:12.693058  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9656 > 20) by scale factor 0.741685
I0110 15:18:14.574018  4932 solver.cpp:240] Iteration 38700, loss = 0.0969517
I0110 15:18:14.574054  4932 solver.cpp:255]     Train net output #0: loss = 0.08806 (* 1 = 0.08806 loss)
I0110 15:18:14.574062  4932 solver.cpp:631] Iteration 38700, lr = 1e-07
I0110 15:18:46.845603  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.69 > 20) by scale factor 0.922085
I0110 15:19:00.635756  4932 solver.cpp:240] Iteration 38720, loss = 0.0519266
I0110 15:19:00.635792  4932 solver.cpp:255]     Train net output #0: loss = 0.0157764 (* 1 = 0.0157764 loss)
I0110 15:19:00.635800  4932 solver.cpp:631] Iteration 38720, lr = 1e-07
I0110 15:19:12.073032  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4858 > 20) by scale factor 0.784751
I0110 15:19:16.512204  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0999 > 20) by scale factor 0.947873
I0110 15:19:34.261176  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6896 > 20) by scale factor 0.88146
I0110 15:19:39.612850  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4507 > 20) by scale factor 0.817972
I0110 15:19:45.929852  4932 solver.cpp:240] Iteration 38740, loss = 0.0880967
I0110 15:19:45.929890  4932 solver.cpp:255]     Train net output #0: loss = 0.0685003 (* 1 = 0.0685003 loss)
I0110 15:19:45.929899  4932 solver.cpp:631] Iteration 38740, lr = 1e-07
I0110 15:20:20.744555  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.688 > 20) by scale factor 0.81011
I0110 15:20:27.401552  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.6439 > 20) by scale factor 0.561106
I0110 15:20:31.502215  4932 solver.cpp:240] Iteration 38760, loss = 0.115543
I0110 15:20:31.502249  4932 solver.cpp:255]     Train net output #0: loss = 0.0226961 (* 1 = 0.0226961 loss)
I0110 15:20:31.502259  4932 solver.cpp:631] Iteration 38760, lr = 1e-07
I0110 15:21:16.755172  4932 solver.cpp:240] Iteration 38780, loss = 0.062927
I0110 15:21:16.755260  4932 solver.cpp:255]     Train net output #0: loss = 0.019186 (* 1 = 0.019186 loss)
I0110 15:21:16.755272  4932 solver.cpp:631] Iteration 38780, lr = 1e-07
I0110 15:21:58.455301  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3354 > 20) by scale factor 0.983509
I0110 15:22:03.543030  4932 solver.cpp:240] Iteration 38800, loss = 0.0746795
I0110 15:22:03.543059  4932 solver.cpp:255]     Train net output #0: loss = 0.42562 (* 1 = 0.42562 loss)
I0110 15:22:03.543067  4932 solver.cpp:631] Iteration 38800, lr = 1e-07
I0110 15:22:03.881774  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.0411 > 20) by scale factor 0.554922
I0110 15:22:37.156308  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5035 > 20) by scale factor 0.888751
I0110 15:22:49.219676  4932 solver.cpp:240] Iteration 38820, loss = 0.0682809
I0110 15:22:49.219727  4932 solver.cpp:255]     Train net output #0: loss = 0.282285 (* 1 = 0.282285 loss)
I0110 15:22:49.244036  4932 solver.cpp:631] Iteration 38820, lr = 1e-07
I0110 15:23:34.909972  4932 solver.cpp:240] Iteration 38840, loss = 0.0501618
I0110 15:23:34.910078  4932 solver.cpp:255]     Train net output #0: loss = 0.173519 (* 1 = 0.173519 loss)
I0110 15:23:34.910092  4932 solver.cpp:631] Iteration 38840, lr = 1e-07
I0110 15:23:46.344913  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9155 > 20) by scale factor 0.771739
I0110 15:24:19.292024  4932 solver.cpp:240] Iteration 38860, loss = 0.0715932
I0110 15:24:19.292124  4932 solver.cpp:255]     Train net output #0: loss = 0.0367956 (* 1 = 0.0367956 loss)
I0110 15:24:19.292138  4932 solver.cpp:631] Iteration 38860, lr = 1e-07
I0110 15:24:32.390182  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0808 > 20) by scale factor 0.995976
I0110 15:24:39.051059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5224 > 20) by scale factor 0.850253
I0110 15:24:52.367995  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7282 > 20) by scale factor 0.842879
I0110 15:25:06.831751  4932 solver.cpp:240] Iteration 38880, loss = 0.0899536
I0110 15:25:06.831791  4932 solver.cpp:255]     Train net output #0: loss = 0.136093 (* 1 = 0.136093 loss)
I0110 15:25:06.831801  4932 solver.cpp:631] Iteration 38880, lr = 1e-07
I0110 15:25:41.245232  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6374 > 20) by scale factor 0.780111
I0110 15:25:51.999223  4932 solver.cpp:240] Iteration 38900, loss = 0.0606293
I0110 15:25:51.999254  4932 solver.cpp:255]     Train net output #0: loss = 0.141612 (* 1 = 0.141612 loss)
I0110 15:25:51.999263  4932 solver.cpp:631] Iteration 38900, lr = 1e-07
I0110 15:26:37.592286  4932 solver.cpp:240] Iteration 38920, loss = 0.0478298
I0110 15:26:37.592381  4932 solver.cpp:255]     Train net output #0: loss = 0.0010929 (* 1 = 0.0010929 loss)
I0110 15:26:37.592394  4932 solver.cpp:631] Iteration 38920, lr = 1e-07
I0110 15:26:50.580396  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.389 > 20) by scale factor 0.787743
I0110 15:27:24.647900  4932 solver.cpp:240] Iteration 38940, loss = 0.0652508
I0110 15:27:24.647994  4932 solver.cpp:255]     Train net output #0: loss = 0.106027 (* 1 = 0.106027 loss)
I0110 15:27:24.648005  4932 solver.cpp:631] Iteration 38940, lr = 1e-07
I0110 15:27:38.304055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.2573 > 20) by scale factor 0.683591
I0110 15:28:10.311508  4932 solver.cpp:240] Iteration 38960, loss = 0.065676
I0110 15:28:10.311633  4932 solver.cpp:255]     Train net output #0: loss = 0.0240899 (* 1 = 0.0240899 loss)
I0110 15:28:10.311661  4932 solver.cpp:631] Iteration 38960, lr = 1e-07
I0110 15:28:21.744200  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4416 > 20) by scale factor 0.853182
I0110 15:28:26.186369  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6816 > 20) by scale factor 0.967042
I0110 15:28:56.022001  4932 solver.cpp:240] Iteration 38980, loss = 0.0682384
I0110 15:28:56.022096  4932 solver.cpp:255]     Train net output #0: loss = 0.000142334 (* 1 = 0.000142334 loss)
I0110 15:28:56.022109  4932 solver.cpp:631] Iteration 38980, lr = 1e-07
I0110 15:29:40.006332  4932 solver.cpp:424] Iteration 39000, Testing net (#0)
I0110 15:30:31.131108  4932 solver.cpp:481]     Test net output #0: accuracy = 0.842105
I0110 15:30:31.131193  4932 solver.cpp:481]     Test net output #1: loss = 0.759033 (* 1 = 0.759033 loss)
I0110 15:30:32.998502  4932 solver.cpp:240] Iteration 39000, loss = 0.0450193
I0110 15:30:32.998539  4932 solver.cpp:255]     Train net output #0: loss = 0.0229343 (* 1 = 0.0229343 loss)
I0110 15:30:32.998549  4932 solver.cpp:631] Iteration 39000, lr = 1e-07
I0110 15:30:44.430989  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7068 > 20) by scale factor 0.921369
I0110 15:31:10.471333  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6403 > 20) by scale factor 0.883382
I0110 15:31:12.693120  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.167 > 20) by scale factor 0.827574
I0110 15:31:19.016830  4932 solver.cpp:240] Iteration 39020, loss = 0.0906795
I0110 15:31:19.016877  4932 solver.cpp:255]     Train net output #0: loss = 0.26653 (* 1 = 0.26653 loss)
I0110 15:31:19.016890  4932 solver.cpp:631] Iteration 39020, lr = 1e-07
I0110 15:32:03.399636  4932 solver.cpp:240] Iteration 39040, loss = 0.0418587
I0110 15:32:03.399746  4932 solver.cpp:255]     Train net output #0: loss = 0.0332877 (* 1 = 0.0332877 loss)
I0110 15:32:03.399762  4932 solver.cpp:631] Iteration 39040, lr = 1e-07
I0110 15:32:10.397094  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9828 > 20) by scale factor 0.953162
I0110 15:32:29.263504  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8782 > 20) by scale factor 0.957939
I0110 15:32:35.918596  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0842 > 20) by scale factor 0.948578
I0110 15:32:48.897826  4932 solver.cpp:240] Iteration 39060, loss = 0.0779324
I0110 15:32:48.897867  4932 solver.cpp:255]     Train net output #0: loss = 0.0499015 (* 1 = 0.0499015 loss)
I0110 15:32:48.897876  4932 solver.cpp:631] Iteration 39060, lr = 1e-07
I0110 15:33:15.141280  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3363 > 20) by scale factor 0.857035
I0110 15:33:19.579468  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3476 > 20) by scale factor 0.982916
I0110 15:33:34.771394  4932 solver.cpp:240] Iteration 39080, loss = 0.0985057
I0110 15:33:34.771445  4932 solver.cpp:255]     Train net output #0: loss = 0.0781379 (* 1 = 0.0781379 loss)
I0110 15:33:34.771574  4932 solver.cpp:631] Iteration 39080, lr = 1e-07
I0110 15:34:15.660701  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8385 > 20) by scale factor 0.745198
I0110 15:34:19.764125  4932 solver.cpp:240] Iteration 39100, loss = 0.0563736
I0110 15:34:19.764170  4932 solver.cpp:255]     Train net output #0: loss = 0.0309924 (* 1 = 0.0309924 loss)
I0110 15:34:19.764183  4932 solver.cpp:631] Iteration 39100, lr = 1e-07
I0110 15:34:26.769282  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6803 > 20) by scale factor 0.922496
I0110 15:34:49.025249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.882 > 20) by scale factor 0.803795
I0110 15:35:04.229944  4932 solver.cpp:240] Iteration 39120, loss = 0.0674123
I0110 15:35:04.229991  4932 solver.cpp:255]     Train net output #0: loss = 0.139578 (* 1 = 0.139578 loss)
I0110 15:35:04.230003  4932 solver.cpp:631] Iteration 39120, lr = 1e-07
I0110 15:35:06.789947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6192 > 20) by scale factor 0.846767
I0110 15:35:29.056537  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2248 > 20) by scale factor 0.942292
I0110 15:35:49.486637  4932 solver.cpp:240] Iteration 39140, loss = 0.071264
I0110 15:35:49.486673  4932 solver.cpp:255]     Train net output #0: loss = 0.00185785 (* 1 = 0.00185785 loss)
I0110 15:35:49.486683  4932 solver.cpp:631] Iteration 39140, lr = 1e-07
I0110 15:35:54.260058  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5673 > 20) by scale factor 0.78225
I0110 15:36:16.447289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.86 > 20) by scale factor 0.838224
I0110 15:36:33.514214  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8334 > 20) by scale factor 0.916027
I0110 15:36:35.397595  4932 solver.cpp:240] Iteration 39160, loss = 0.0681226
I0110 15:36:35.397833  4932 solver.cpp:255]     Train net output #0: loss = 0.0106525 (* 1 = 0.0106525 loss)
I0110 15:36:35.397850  4932 solver.cpp:631] Iteration 39160, lr = 1e-07
I0110 15:36:37.958828  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4854 > 20) by scale factor 0.930864
I0110 15:36:49.095572  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6103 > 20) by scale factor 0.75159
I0110 15:36:53.543560  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7695 > 20) by scale factor 0.962951
I0110 15:37:19.833487  4932 solver.cpp:240] Iteration 39180, loss = 0.0731866
I0110 15:37:19.833588  4932 solver.cpp:255]     Train net output #0: loss = 0.0124536 (* 1 = 0.0124536 loss)
I0110 15:37:19.833603  4932 solver.cpp:631] Iteration 39180, lr = 1e-07
I0110 15:38:05.977341  4932 solver.cpp:240] Iteration 39200, loss = 0.0530348
I0110 15:38:05.977421  4932 solver.cpp:255]     Train net output #0: loss = 0.0965615 (* 1 = 0.0965615 loss)
I0110 15:38:05.977430  4932 solver.cpp:631] Iteration 39200, lr = 1e-07
I0110 15:38:10.752358  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.7421 > 20) by scale factor 0.610834
I0110 15:38:12.974318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2857 > 20) by scale factor 0.897438
I0110 15:38:40.444473  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7226 > 20) by scale factor 0.96513
I0110 15:38:44.885555  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1031 > 20) by scale factor 0.947728
I0110 15:38:51.203451  4932 solver.cpp:240] Iteration 39220, loss = 0.0916607
I0110 15:38:51.203486  4932 solver.cpp:255]     Train net output #0: loss = 0.142007 (* 1 = 0.142007 loss)
I0110 15:38:51.203495  4932 solver.cpp:631] Iteration 39220, lr = 1e-07
I0110 15:39:00.417866  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8337 > 20) by scale factor 0.774182
I0110 15:39:23.746322  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8385 > 20) by scale factor 0.745197
I0110 15:39:36.721520  4932 solver.cpp:240] Iteration 39240, loss = 0.0764339
I0110 15:39:36.721554  4932 solver.cpp:255]     Train net output #0: loss = 0.0786209 (* 1 = 0.0786209 loss)
I0110 15:39:36.721565  4932 solver.cpp:631] Iteration 39240, lr = 1e-07
I0110 15:39:39.278406  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9316 > 20) by scale factor 0.87216
I0110 15:40:23.277858  4932 solver.cpp:240] Iteration 39260, loss = 0.0767435
I0110 15:40:23.277972  4932 solver.cpp:255]     Train net output #0: loss = 0.000157843 (* 1 = 0.000157843 loss)
I0110 15:40:23.277987  4932 solver.cpp:631] Iteration 39260, lr = 1e-07
I0110 15:40:39.154820  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2625 > 20) by scale factor 0.987046
I0110 15:41:09.014048  4932 solver.cpp:240] Iteration 39280, loss = 0.0721349
I0110 15:41:09.014138  4932 solver.cpp:255]     Train net output #0: loss = 0.000874323 (* 1 = 0.000874323 loss)
I0110 15:41:09.014152  4932 solver.cpp:631] Iteration 39280, lr = 1e-07
I0110 15:41:24.892385  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4277 > 20) by scale factor 0.891756
I0110 15:41:31.989850  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1571 > 20) by scale factor 0.736456
I0110 15:41:53.854197  4932 solver.cpp:240] Iteration 39300, loss = 0.0920821
I0110 15:41:53.854295  4932 solver.cpp:255]     Train net output #0: loss = 0.0387352 (* 1 = 0.0387352 loss)
I0110 15:41:53.854308  4932 solver.cpp:631] Iteration 39300, lr = 1e-07
I0110 15:42:06.585196  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1322 > 20) by scale factor 0.946423
I0110 15:42:24.346390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9375 > 20) by scale factor 0.802005
I0110 15:42:41.193500  4932 solver.cpp:240] Iteration 39320, loss = 0.076685
I0110 15:42:41.193538  4932 solver.cpp:255]     Train net output #0: loss = 0.000820396 (* 1 = 0.000820396 loss)
I0110 15:42:41.193547  4932 solver.cpp:631] Iteration 39320, lr = 1e-07
I0110 15:42:43.750516  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7293 > 20) by scale factor 0.721259
I0110 15:42:54.848225  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6779 > 20) by scale factor 0.673901
I0110 15:43:08.178685  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2699 > 20) by scale factor 0.761328
I0110 15:43:26.729151  4932 solver.cpp:240] Iteration 39340, loss = 0.0802083
I0110 15:43:26.729223  4932 solver.cpp:255]     Train net output #0: loss = 0.0010565 (* 1 = 0.0010565 loss)
I0110 15:43:26.729235  4932 solver.cpp:631] Iteration 39340, lr = 1e-07
I0110 15:44:12.149924  4932 solver.cpp:240] Iteration 39360, loss = 0.0330484
I0110 15:44:12.150017  4932 solver.cpp:255]     Train net output #0: loss = 0.00350664 (* 1 = 0.00350664 loss)
I0110 15:44:12.150032  4932 solver.cpp:631] Iteration 39360, lr = 1e-07
I0110 15:44:35.570111  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4976 > 20) by scale factor 0.701814
I0110 15:44:57.430104  4932 solver.cpp:240] Iteration 39380, loss = 0.0705681
I0110 15:44:57.430202  4932 solver.cpp:255]     Train net output #0: loss = 0.000943319 (* 1 = 0.000943319 loss)
I0110 15:44:57.430217  4932 solver.cpp:631] Iteration 39380, lr = 1e-07
I0110 15:45:44.183450  4932 solver.cpp:240] Iteration 39400, loss = 0.0488306
I0110 15:45:44.183540  4932 solver.cpp:255]     Train net output #0: loss = 0.00174376 (* 1 = 0.00174376 loss)
I0110 15:45:44.183553  4932 solver.cpp:631] Iteration 39400, lr = 1e-07
I0110 15:46:28.748905  4932 solver.cpp:240] Iteration 39420, loss = 0.0398
I0110 15:46:28.749017  4932 solver.cpp:255]     Train net output #0: loss = 0.00133824 (* 1 = 0.00133824 loss)
I0110 15:46:28.749034  4932 solver.cpp:631] Iteration 39420, lr = 1e-07
I0110 15:46:55.718909  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3969 > 20) by scale factor 0.73001
I0110 15:47:05.814699  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0461 > 20) by scale factor 0.907192
I0110 15:47:14.348906  4932 solver.cpp:240] Iteration 39440, loss = 0.0544687
I0110 15:47:14.348943  4932 solver.cpp:255]     Train net output #0: loss = 0.00395836 (* 1 = 0.00395836 loss)
I0110 15:47:14.348953  4932 solver.cpp:631] Iteration 39440, lr = 1e-07
I0110 15:47:59.685297  4932 solver.cpp:240] Iteration 39460, loss = 0.0332559
I0110 15:47:59.685411  4932 solver.cpp:255]     Train net output #0: loss = 0.190537 (* 1 = 0.190537 loss)
I0110 15:47:59.685428  4932 solver.cpp:631] Iteration 39460, lr = 1e-07
I0110 15:48:00.026011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9808 > 20) by scale factor 0.909884
I0110 15:48:44.418848  4932 solver.cpp:240] Iteration 39480, loss = 0.0379744
I0110 15:48:44.418929  4932 solver.cpp:255]     Train net output #0: loss = 0.00306245 (* 1 = 0.00306245 loss)
I0110 15:48:44.418941  4932 solver.cpp:631] Iteration 39480, lr = 1e-07
I0110 15:49:04.791374  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2521 > 20) by scale factor 0.792013
I0110 15:49:28.881778  4932 solver.cpp:240] Iteration 39500, loss = 0.0806915
I0110 15:49:28.881878  4932 solver.cpp:255]     Train net output #0: loss = 0.163085 (* 1 = 0.163085 loss)
I0110 15:49:28.881891  4932 solver.cpp:631] Iteration 39500, lr = 1e-07
I0110 15:50:14.189942  4932 solver.cpp:240] Iteration 39520, loss = 0.03475
I0110 15:50:14.190009  4932 solver.cpp:255]     Train net output #0: loss = 0.0911025 (* 1 = 0.0911025 loss)
I0110 15:50:14.190022  4932 solver.cpp:631] Iteration 39520, lr = 1e-07
I0110 15:50:36.716174  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8296 > 20) by scale factor 0.805491
I0110 15:50:59.466370  4932 solver.cpp:240] Iteration 39540, loss = 0.0848785
I0110 15:50:59.466475  4932 solver.cpp:255]     Train net output #0: loss = 0.0377502 (* 1 = 0.0377502 loss)
I0110 15:50:59.466491  4932 solver.cpp:631] Iteration 39540, lr = 1e-07
I0110 15:51:06.465122  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5584 > 20) by scale factor 0.814387
I0110 15:51:45.412386  4932 solver.cpp:240] Iteration 39560, loss = 0.0851087
I0110 15:51:45.412466  4932 solver.cpp:255]     Train net output #0: loss = 0.00409385 (* 1 = 0.00409385 loss)
I0110 15:51:45.412477  4932 solver.cpp:631] Iteration 39560, lr = 1e-07
I0110 15:52:31.090548  4932 solver.cpp:240] Iteration 39580, loss = 0.0566372
I0110 15:52:31.090627  4932 solver.cpp:255]     Train net output #0: loss = 0.0164736 (* 1 = 0.0164736 loss)
I0110 15:52:31.090638  4932 solver.cpp:631] Iteration 39580, lr = 1e-07
I0110 15:52:59.723088  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9373 > 20) by scale factor 0.77109
I0110 15:53:08.601419  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4034 > 20) by scale factor 0.980227
I0110 15:53:17.145754  4932 solver.cpp:240] Iteration 39600, loss = 0.0964295
I0110 15:53:17.145789  4932 solver.cpp:255]     Train net output #0: loss = 0.149355 (* 1 = 0.149355 loss)
I0110 15:53:17.145799  4932 solver.cpp:631] Iteration 39600, lr = 1e-07
I0110 15:53:37.747668  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0581 > 20) by scale factor 0.739152
I0110 15:54:21.808974  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0114 > 20) by scale factor 0.799634
I0110 15:54:46.522186  4932 solver.cpp:240] Iteration 39620, loss = 0.0745793
I0110 15:54:46.522222  4932 solver.cpp:255]     Train net output #0: loss = 0.0812998 (* 1 = 0.0812998 loss)
I0110 15:54:46.522231  4932 solver.cpp:631] Iteration 39620, lr = 1e-07
I0110 15:55:32.123036  4932 solver.cpp:240] Iteration 39640, loss = 0.0492057
I0110 15:55:32.123127  4932 solver.cpp:255]     Train net output #0: loss = 0.240711 (* 1 = 0.240711 loss)
I0110 15:55:32.123142  4932 solver.cpp:631] Iteration 39640, lr = 1e-07
I0110 15:55:32.463620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0269 > 20) by scale factor 0.768437
I0110 15:56:11.366720  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3436 > 20) by scale factor 0.983112
I0110 15:56:17.684383  4932 solver.cpp:240] Iteration 39660, loss = 0.0658617
I0110 15:56:17.684424  4932 solver.cpp:255]     Train net output #0: loss = 0.0506857 (* 1 = 0.0506857 loss)
I0110 15:56:17.684434  4932 solver.cpp:631] Iteration 39660, lr = 1e-07
I0110 15:56:22.463765  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8968 > 20) by scale factor 0.957083
I0110 15:56:58.014547  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2336 > 20) by scale factor 0.941903
I0110 15:57:04.333717  4932 solver.cpp:240] Iteration 39680, loss = 0.0842013
I0110 15:57:04.333756  4932 solver.cpp:255]     Train net output #0: loss = 0.0421931 (* 1 = 0.0421931 loss)
I0110 15:57:04.333766  4932 solver.cpp:631] Iteration 39680, lr = 1e-07
I0110 15:57:09.110069  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7579 > 20) by scale factor 0.963487
I0110 15:57:49.615051  4932 solver.cpp:240] Iteration 39700, loss = 0.0715992
I0110 15:57:49.615144  4932 solver.cpp:255]     Train net output #0: loss = 0.177354 (* 1 = 0.177354 loss)
I0110 15:57:49.615155  4932 solver.cpp:631] Iteration 39700, lr = 1e-07
I0110 15:58:35.714017  4932 solver.cpp:240] Iteration 39720, loss = 0.0532476
I0110 15:58:35.714110  4932 solver.cpp:255]     Train net output #0: loss = 0.00179208 (* 1 = 0.00179208 loss)
I0110 15:58:35.714123  4932 solver.cpp:631] Iteration 39720, lr = 1e-07
I0110 15:58:54.322907  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6599 > 20) by scale factor 0.923365
I0110 15:59:20.616117  4932 solver.cpp:240] Iteration 39740, loss = 0.0585573
I0110 15:59:20.616209  4932 solver.cpp:255]     Train net output #0: loss = 0.000495688 (* 1 = 0.000495688 loss)
I0110 15:59:20.616222  4932 solver.cpp:631] Iteration 39740, lr = 1e-07
I0110 15:59:27.609889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.019 > 20) by scale factor 0.740221
I0110 16:00:07.793205  4932 solver.cpp:240] Iteration 39760, loss = 0.0712431
I0110 16:00:07.793298  4932 solver.cpp:255]     Train net output #0: loss = 0.0186663 (* 1 = 0.0186663 loss)
I0110 16:00:07.793310  4932 solver.cpp:631] Iteration 39760, lr = 1e-07
I0110 16:00:10.351351  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4155 > 20) by scale factor 0.75713
I0110 16:00:19.227749  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3618 > 20) by scale factor 0.936249
I0110 16:00:28.105501  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8553 > 20) by scale factor 0.91511
I0110 16:00:41.423136  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5244 > 20) by scale factor 0.754022
I0110 16:00:50.303669  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2183 > 20) by scale factor 0.900158
I0110 16:00:52.186436  4932 solver.cpp:240] Iteration 39780, loss = 0.113986
I0110 16:00:52.186476  4932 solver.cpp:255]     Train net output #0: loss = 0.027866 (* 1 = 0.027866 loss)
I0110 16:00:52.186488  4932 solver.cpp:631] Iteration 39780, lr = 1e-07
I0110 16:01:37.997810  4932 solver.cpp:240] Iteration 39800, loss = 0.0741913
I0110 16:01:37.997915  4932 solver.cpp:255]     Train net output #0: loss = 0.214533 (* 1 = 0.214533 loss)
I0110 16:01:37.997927  4932 solver.cpp:631] Iteration 39800, lr = 1e-07
I0110 16:02:17.552191  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9216 > 20) by scale factor 0.872538
I0110 16:02:21.992182  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3413 > 20) by scale factor 0.85685
I0110 16:02:23.874861  4932 solver.cpp:240] Iteration 39820, loss = 0.0618326
I0110 16:02:23.874898  4932 solver.cpp:255]     Train net output #0: loss = 0.0567785 (* 1 = 0.0567785 loss)
I0110 16:02:23.874908  4932 solver.cpp:631] Iteration 39820, lr = 1e-07
I0110 16:02:26.433161  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2653 > 20) by scale factor 0.85965
I0110 16:02:54.177553  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.493 > 20) by scale factor 0.930538
I0110 16:03:09.369470  4932 solver.cpp:240] Iteration 39840, loss = 0.0689479
I0110 16:03:09.369509  4932 solver.cpp:255]     Train net output #0: loss = 0.0121282 (* 1 = 0.0121282 loss)
I0110 16:03:09.369519  4932 solver.cpp:631] Iteration 39840, lr = 1e-07
I0110 16:03:33.059535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9327 > 20) by scale factor 0.911881
I0110 16:03:46.372786  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1147 > 20) by scale factor 0.796347
I0110 16:03:54.914014  4932 solver.cpp:240] Iteration 39860, loss = 0.0718206
I0110 16:03:54.914050  4932 solver.cpp:255]     Train net output #0: loss = 0.0496653 (* 1 = 0.0496653 loss)
I0110 16:03:54.914060  4932 solver.cpp:631] Iteration 39860, lr = 1e-07
I0110 16:04:16.682312  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8868 > 20) by scale factor 0.913793
I0110 16:04:18.901738  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2772 > 20) by scale factor 0.897778
I0110 16:04:32.218230  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6609 > 20) by scale factor 0.811
I0110 16:04:40.756569  4932 solver.cpp:240] Iteration 39880, loss = 0.0764076
I0110 16:04:40.756614  4932 solver.cpp:255]     Train net output #0: loss = 0.0964721 (* 1 = 0.0964721 loss)
I0110 16:04:40.756626  4932 solver.cpp:631] Iteration 39880, lr = 1e-07
I0110 16:05:04.661540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3733 > 20) by scale factor 0.855677
I0110 16:05:11.322638  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.2366 > 20) by scale factor 0.620413
I0110 16:05:26.514101  4932 solver.cpp:240] Iteration 39900, loss = 0.082595
I0110 16:05:26.514145  4932 solver.cpp:255]     Train net output #0: loss = 0.08571 (* 1 = 0.08571 loss)
I0110 16:05:26.514156  4932 solver.cpp:631] Iteration 39900, lr = 1e-07
I0110 16:06:13.209385  4932 solver.cpp:240] Iteration 39920, loss = 0.0273003
I0110 16:06:13.209478  4932 solver.cpp:255]     Train net output #0: loss = 0.0186132 (* 1 = 0.0186132 loss)
I0110 16:06:13.209493  4932 solver.cpp:631] Iteration 39920, lr = 1e-07
I0110 16:06:42.400207  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6292 > 20) by scale factor 0.924676
I0110 16:06:48.044571  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.2914 > 20) by scale factor 0.682795
I0110 16:06:58.829660  4932 solver.cpp:240] Iteration 39940, loss = 0.0681728
I0110 16:06:58.829716  4932 solver.cpp:255]     Train net output #0: loss = 0.0208088 (* 1 = 0.0208088 loss)
I0110 16:06:58.829735  4932 solver.cpp:631] Iteration 39940, lr = 1e-07
I0110 16:07:03.612807  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.03 > 20) by scale factor 0.951021
I0110 16:07:40.604534  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.851 > 20) by scale factor 0.838541
I0110 16:07:44.702790  4932 solver.cpp:240] Iteration 39960, loss = 0.0634339
I0110 16:07:44.702829  4932 solver.cpp:255]     Train net output #0: loss = 0.0160583 (* 1 = 0.0160583 loss)
I0110 16:07:44.702839  4932 solver.cpp:631] Iteration 39960, lr = 1e-07
I0110 16:07:58.354746  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6651 > 20) by scale factor 0.750043
I0110 16:08:30.410164  4932 solver.cpp:240] Iteration 39980, loss = 0.0832471
I0110 16:08:30.410253  4932 solver.cpp:255]     Train net output #0: loss = 0.405783 (* 1 = 0.405783 loss)
I0110 16:08:30.410264  4932 solver.cpp:631] Iteration 39980, lr = 1e-07
I0110 16:08:30.750773  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6262 > 20) by scale factor 0.812142
I0110 16:08:50.023651  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5517 > 20) by scale factor 0.782727
I0110 16:09:15.690326  4932 solver.cpp:424] Iteration 40000, Testing net (#0)
I0110 16:10:15.616598  4932 solver.cpp:481]     Test net output #0: accuracy = 0.824211
I0110 16:10:15.616694  4932 solver.cpp:481]     Test net output #1: loss = 0.875966 (* 1 = 0.875966 loss)
I0110 16:10:17.484225  4932 solver.cpp:240] Iteration 40000, loss = 0.0623805
I0110 16:10:17.484264  4932 solver.cpp:255]     Train net output #0: loss = 0.178515 (* 1 = 0.178515 loss)
I0110 16:10:17.484282  4932 solver.cpp:631] Iteration 40000, lr = 1e-07
I0110 16:10:17.823194  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3818 > 20) by scale factor 0.787967
I0110 16:10:28.922992  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7555 > 20) by scale factor 0.776533
I0110 16:11:03.489118  4932 solver.cpp:240] Iteration 40020, loss = 0.0424076
I0110 16:11:03.489224  4932 solver.cpp:255]     Train net output #0: loss = 0.00581719 (* 1 = 0.00581719 loss)
I0110 16:11:03.489238  4932 solver.cpp:631] Iteration 40020, lr = 1e-07
I0110 16:11:50.800199  4932 solver.cpp:240] Iteration 40040, loss = 0.0528707
I0110 16:11:50.800276  4932 solver.cpp:255]     Train net output #0: loss = 0.0883023 (* 1 = 0.0883023 loss)
I0110 16:11:50.800287  4932 solver.cpp:631] Iteration 40040, lr = 1e-07
I0110 16:11:51.139214  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8964 > 20) by scale factor 0.913392
I0110 16:12:36.610326  4932 solver.cpp:240] Iteration 40060, loss = 0.0560029
I0110 16:12:36.610422  4932 solver.cpp:255]     Train net output #0: loss = 0.00609854 (* 1 = 0.00609854 loss)
I0110 16:12:36.610437  4932 solver.cpp:631] Iteration 40060, lr = 1e-07
I0110 16:12:52.493336  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7136 > 20) by scale factor 0.921083
I0110 16:13:22.294602  4932 solver.cpp:240] Iteration 40080, loss = 0.03978
I0110 16:13:22.294683  4932 solver.cpp:255]     Train net output #0: loss = 0.0289903 (* 1 = 0.0289903 loss)
I0110 16:13:22.294694  4932 solver.cpp:631] Iteration 40080, lr = 1e-07
I0110 16:13:57.442505  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7207 > 20) by scale factor 0.809038
I0110 16:14:08.202190  4932 solver.cpp:240] Iteration 40100, loss = 0.0424685
I0110 16:14:08.202231  4932 solver.cpp:255]     Train net output #0: loss = 0.0638705 (* 1 = 0.0638705 loss)
I0110 16:14:08.202242  4932 solver.cpp:631] Iteration 40100, lr = 1e-07
I0110 16:14:45.284660  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7706 > 20) by scale factor 0.878325
I0110 16:14:54.098884  4932 solver.cpp:240] Iteration 40120, loss = 0.0406726
I0110 16:14:54.098922  4932 solver.cpp:255]     Train net output #0: loss = 0.0222959 (* 1 = 0.0222959 loss)
I0110 16:14:54.098930  4932 solver.cpp:631] Iteration 40120, lr = 1e-07
I0110 16:15:03.314793  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6882 > 20) by scale factor 0.749396
I0110 16:15:12.197373  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8811 > 20) by scale factor 0.803823
I0110 16:15:23.294811  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5732 > 20) by scale factor 0.752637
I0110 16:15:40.140493  4932 solver.cpp:240] Iteration 40140, loss = 0.0944829
I0110 16:15:40.140533  4932 solver.cpp:255]     Train net output #0: loss = 0.0846095 (* 1 = 0.0846095 loss)
I0110 16:15:40.140545  4932 solver.cpp:631] Iteration 40140, lr = 1e-07
I0110 16:15:44.924175  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0061 > 20) by scale factor 0.799805
I0110 16:16:19.746762  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1418 > 20) by scale factor 0.6863
I0110 16:16:26.063755  4932 solver.cpp:240] Iteration 40160, loss = 0.0832747
I0110 16:16:26.063791  4932 solver.cpp:255]     Train net output #0: loss = 0.0113167 (* 1 = 0.0113167 loss)
I0110 16:16:26.063799  4932 solver.cpp:631] Iteration 40160, lr = 1e-07
I0110 16:17:11.994154  4932 solver.cpp:240] Iteration 40180, loss = 0.0712003
I0110 16:17:11.994242  4932 solver.cpp:255]     Train net output #0: loss = 0.0401923 (* 1 = 0.0401923 loss)
I0110 16:17:11.994254  4932 solver.cpp:631] Iteration 40180, lr = 1e-07
I0110 16:17:35.110523  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1699 > 20) by scale factor 0.863189
I0110 16:17:56.963583  4932 solver.cpp:240] Iteration 40200, loss = 0.0515413
I0110 16:17:56.963701  4932 solver.cpp:255]     Train net output #0: loss = 0.0153087 (* 1 = 0.0153087 loss)
I0110 16:17:56.963714  4932 solver.cpp:631] Iteration 40200, lr = 1e-07
I0110 16:18:21.110224  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8915 > 20) by scale factor 0.772455
I0110 16:18:44.097157  4932 solver.cpp:240] Iteration 40220, loss = 0.0720494
I0110 16:18:44.097249  4932 solver.cpp:255]     Train net output #0: loss = 0.00805057 (* 1 = 0.00805057 loss)
I0110 16:18:44.097261  4932 solver.cpp:631] Iteration 40220, lr = 1e-07
I0110 16:19:28.175947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5429 > 20) by scale factor 0.887198
I0110 16:19:30.059239  4932 solver.cpp:240] Iteration 40240, loss = 0.0585991
I0110 16:19:30.059284  4932 solver.cpp:255]     Train net output #0: loss = 0.00191026 (* 1 = 0.00191026 loss)
I0110 16:19:30.059296  4932 solver.cpp:631] Iteration 40240, lr = 1e-07
I0110 16:19:45.940943  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.138 > 20) by scale factor 0.993148
I0110 16:20:05.388896  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4893 > 20) by scale factor 0.784644
I0110 16:20:16.152796  4932 solver.cpp:240] Iteration 40260, loss = 0.0792242
I0110 16:20:16.152838  4932 solver.cpp:255]     Train net output #0: loss = 0.0595571 (* 1 = 0.0595571 loss)
I0110 16:20:16.152850  4932 solver.cpp:631] Iteration 40260, lr = 1e-07
I0110 16:21:02.295176  4932 solver.cpp:240] Iteration 40280, loss = 0.0634682
I0110 16:21:02.295251  4932 solver.cpp:255]     Train net output #0: loss = 0.0486208 (* 1 = 0.0486208 loss)
I0110 16:21:02.295261  4932 solver.cpp:631] Iteration 40280, lr = 1e-07
I0110 16:21:07.070972  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0236 > 20) by scale factor 0.998824
I0110 16:21:13.729849  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0466 > 20) by scale factor 0.997674
I0110 16:21:48.469733  4932 solver.cpp:240] Iteration 40300, loss = 0.0685478
I0110 16:21:48.469815  4932 solver.cpp:255]     Train net output #0: loss = 0.153763 (* 1 = 0.153763 loss)
I0110 16:21:48.469826  4932 solver.cpp:631] Iteration 40300, lr = 1e-07
I0110 16:22:02.127154  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8409 > 20) by scale factor 0.875623
I0110 16:22:08.797994  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9851 > 20) by scale factor 0.769671
I0110 16:22:30.291802  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.513 > 20) by scale factor 0.974989
I0110 16:22:34.392776  4932 solver.cpp:240] Iteration 40320, loss = 0.100924
I0110 16:22:34.392807  4932 solver.cpp:255]     Train net output #0: loss = 0.0460063 (* 1 = 0.0460063 loss)
I0110 16:22:34.392815  4932 solver.cpp:631] Iteration 40320, lr = 1e-07
I0110 16:23:20.711047  4932 solver.cpp:240] Iteration 40340, loss = 0.0623793
I0110 16:23:20.711132  4932 solver.cpp:255]     Train net output #0: loss = 0.161315 (* 1 = 0.161315 loss)
I0110 16:23:20.711143  4932 solver.cpp:631] Iteration 40340, lr = 1e-07
I0110 16:23:32.141439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3969 > 20) by scale factor 0.980543
I0110 16:23:36.584095  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.5029 > 20) by scale factor 0.655675
I0110 16:24:00.484639  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0949 > 20) by scale factor 0.995277
I0110 16:24:02.705647  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9077 > 20) by scale factor 0.873068
I0110 16:24:06.808954  4932 solver.cpp:240] Iteration 40360, loss = 0.111598
I0110 16:24:06.808989  4932 solver.cpp:255]     Train net output #0: loss = 0.0543196 (* 1 = 0.0543196 loss)
I0110 16:24:06.808998  4932 solver.cpp:631] Iteration 40360, lr = 1e-07
I0110 16:24:11.586277  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2128 > 20) by scale factor 0.826009
I0110 16:24:27.123076  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.81 > 20) by scale factor 0.961076
I0110 16:24:29.345233  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4231 > 20) by scale factor 0.933574
I0110 16:24:35.436290  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1253 > 20) by scale factor 0.946734
I0110 16:24:52.853135  4932 solver.cpp:240] Iteration 40380, loss = 0.0834838
I0110 16:24:52.853184  4932 solver.cpp:255]     Train net output #0: loss = 0.118415 (* 1 = 0.118415 loss)
I0110 16:24:52.853199  4932 solver.cpp:631] Iteration 40380, lr = 1e-07
I0110 16:25:38.794119  4932 solver.cpp:240] Iteration 40400, loss = 0.0680756
I0110 16:25:38.794217  4932 solver.cpp:255]     Train net output #0: loss = 0.0156584 (* 1 = 0.0156584 loss)
I0110 16:25:38.794231  4932 solver.cpp:631] Iteration 40400, lr = 1e-07
I0110 16:25:51.609493  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.617 > 20) by scale factor 0.88429
I0110 16:26:11.590562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2682 > 20) by scale factor 0.986766
I0110 16:26:25.626503  4932 solver.cpp:240] Iteration 40420, loss = 0.107229
I0110 16:26:25.626540  4932 solver.cpp:255]     Train net output #0: loss = 0.213831 (* 1 = 0.213831 loss)
I0110 16:26:25.626550  4932 solver.cpp:631] Iteration 40420, lr = 1e-07
I0110 16:26:41.502394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.04 > 20) by scale factor 0.907439
I0110 16:27:01.767489  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5962 > 20) by scale factor 0.926088
I0110 16:27:10.301277  4932 solver.cpp:240] Iteration 40440, loss = 0.0980123
I0110 16:27:10.301314  4932 solver.cpp:255]     Train net output #0: loss = 0.018113 (* 1 = 0.018113 loss)
I0110 16:27:10.301323  4932 solver.cpp:631] Iteration 40440, lr = 1e-07
I0110 16:27:19.523061  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.193 > 20) by scale factor 0.990441
I0110 16:27:56.366911  4932 solver.cpp:240] Iteration 40460, loss = 0.056821
I0110 16:27:56.367004  4932 solver.cpp:255]     Train net output #0: loss = 0.00524486 (* 1 = 0.00524486 loss)
I0110 16:27:56.367018  4932 solver.cpp:631] Iteration 40460, lr = 1e-07
I0110 16:28:11.667122  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2619 > 20) by scale factor 0.987075
I0110 16:28:13.889916  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1576 > 20) by scale factor 0.764595
I0110 16:28:33.857995  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2089 > 20) by scale factor 0.942999
I0110 16:28:40.515964  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2504 > 20) by scale factor 0.987637
I0110 16:28:42.399358  4932 solver.cpp:240] Iteration 40480, loss = 0.102909
I0110 16:28:42.399405  4932 solver.cpp:255]     Train net output #0: loss = 0.0682908 (* 1 = 0.0682908 loss)
I0110 16:28:42.399417  4932 solver.cpp:631] Iteration 40480, lr = 1e-07
I0110 16:29:26.789324  4932 solver.cpp:240] Iteration 40500, loss = 0.0483844
I0110 16:29:26.789405  4932 solver.cpp:255]     Train net output #0: loss = 0.00454929 (* 1 = 0.00454929 loss)
I0110 16:29:26.789417  4932 solver.cpp:631] Iteration 40500, lr = 1e-07
I0110 16:29:36.002379  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1872 > 20) by scale factor 0.990729
I0110 16:29:42.664129  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7801 > 20) by scale factor 0.8071
I0110 16:30:11.174757  4932 solver.cpp:240] Iteration 40520, loss = 0.0848721
I0110 16:30:11.174856  4932 solver.cpp:255]     Train net output #0: loss = 0.0385225 (* 1 = 0.0385225 loss)
I0110 16:30:11.174871  4932 solver.cpp:631] Iteration 40520, lr = 1e-07
I0110 16:30:22.610406  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2215 > 20) by scale factor 0.861269
I0110 16:30:24.829892  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2796 > 20) by scale factor 0.986214
I0110 16:30:29.270771  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0542 > 20) by scale factor 0.739255
I0110 16:30:56.586926  4932 solver.cpp:240] Iteration 40540, loss = 0.0407529
I0110 16:30:56.587030  4932 solver.cpp:255]     Train net output #0: loss = 0.143782 (* 1 = 0.143782 loss)
I0110 16:30:56.587044  4932 solver.cpp:631] Iteration 40540, lr = 1e-07
I0110 16:31:42.549893  4932 solver.cpp:240] Iteration 40560, loss = 0.0304098
I0110 16:31:42.549981  4932 solver.cpp:255]     Train net output #0: loss = 0.244939 (* 1 = 0.244939 loss)
I0110 16:31:42.549991  4932 solver.cpp:631] Iteration 40560, lr = 1e-07
I0110 16:31:49.544013  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1753 > 20) by scale factor 0.901906
I0110 16:32:00.644048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3371 > 20) by scale factor 0.789357
I0110 16:32:07.308358  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.186 > 20) by scale factor 0.944018
I0110 16:32:26.946795  4932 solver.cpp:240] Iteration 40580, loss = 0.0946208
I0110 16:32:26.946879  4932 solver.cpp:255]     Train net output #0: loss = 0.00940067 (* 1 = 0.00940067 loss)
I0110 16:32:26.946892  4932 solver.cpp:631] Iteration 40580, lr = 1e-07
I0110 16:32:36.162483  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3133 > 20) by scale factor 0.760071
I0110 16:32:40.603058  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4806 > 20) by scale factor 0.755269
I0110 16:32:59.729642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3939 > 20) by scale factor 0.980684
I0110 16:33:01.954473  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9558 > 20) by scale factor 0.910921
I0110 16:33:10.836478  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6618 > 20) by scale factor 0.779369
I0110 16:33:12.717177  4932 solver.cpp:240] Iteration 40600, loss = 0.0832407
I0110 16:33:12.717214  4932 solver.cpp:255]     Train net output #0: loss = 0.0112235 (* 1 = 0.0112235 loss)
I0110 16:33:12.717223  4932 solver.cpp:631] Iteration 40600, lr = 1e-07
I0110 16:33:33.996521  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9746 > 20) by scale factor 0.741438
I0110 16:33:49.735249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7489 > 20) by scale factor 0.879162
I0110 16:33:58.279356  4932 solver.cpp:240] Iteration 40620, loss = 0.0677491
I0110 16:33:58.279402  4932 solver.cpp:255]     Train net output #0: loss = 0.00550261 (* 1 = 0.00550261 loss)
I0110 16:33:58.279413  4932 solver.cpp:631] Iteration 40620, lr = 1e-07
I0110 16:34:37.690754  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6178 > 20) by scale factor 0.970036
I0110 16:34:39.912042  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.4521 > 20) by scale factor 0.635887
I0110 16:34:44.010915  4932 solver.cpp:240] Iteration 40640, loss = 0.0680701
I0110 16:34:44.010954  4932 solver.cpp:255]     Train net output #0: loss = 0.00034857 (* 1 = 0.00034857 loss)
I0110 16:34:44.010964  4932 solver.cpp:631] Iteration 40640, lr = 1e-07
I0110 16:35:27.485954  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9734 > 20) by scale factor 0.870571
I0110 16:35:29.368005  4932 solver.cpp:240] Iteration 40660, loss = 0.0553408
I0110 16:35:29.368047  4932 solver.cpp:255]     Train net output #0: loss = 0.0617306 (* 1 = 0.0617306 loss)
I0110 16:35:29.368180  4932 solver.cpp:631] Iteration 40660, lr = 1e-07
I0110 16:35:57.208783  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7893 > 20) by scale factor 0.840715
I0110 16:36:06.088145  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4174 > 20) by scale factor 0.703793
I0110 16:36:15.938297  4932 solver.cpp:240] Iteration 40680, loss = 0.0805038
I0110 16:36:15.938341  4932 solver.cpp:255]     Train net output #0: loss = 0.138638 (* 1 = 0.138638 loss)
I0110 16:36:15.938354  4932 solver.cpp:631] Iteration 40680, lr = 1e-07
I0110 16:36:16.278071  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1204 > 20) by scale factor 0.994015
I0110 16:36:25.153962  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6222 > 20) by scale factor 0.924976
I0110 16:36:45.125876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.018 > 20) by scale factor 0.951565
I0110 16:37:01.969277  4932 solver.cpp:240] Iteration 40700, loss = 0.0798619
I0110 16:37:01.969311  4932 solver.cpp:255]     Train net output #0: loss = 0.108504 (* 1 = 0.108504 loss)
I0110 16:37:01.969319  4932 solver.cpp:631] Iteration 40700, lr = 1e-07
I0110 16:37:04.528205  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6284 > 20) by scale factor 0.924711
I0110 16:37:33.884187  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8408 > 20) by scale factor 0.875627
I0110 16:37:46.879462  4932 solver.cpp:240] Iteration 40720, loss = 0.102704
I0110 16:37:46.879504  4932 solver.cpp:255]     Train net output #0: loss = 0.0929846 (* 1 = 0.0929846 loss)
I0110 16:37:46.879514  4932 solver.cpp:631] Iteration 40720, lr = 1e-07
I0110 16:37:49.439007  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5662 > 20) by scale factor 0.848674
I0110 16:38:33.254400  4932 solver.cpp:240] Iteration 40740, loss = 0.0803702
I0110 16:38:33.254483  4932 solver.cpp:255]     Train net output #0: loss = 0.42022 (* 1 = 0.42022 loss)
I0110 16:38:33.254494  4932 solver.cpp:631] Iteration 40740, lr = 1e-07
I0110 16:38:33.593369  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8726 > 20) by scale factor 0.914388
I0110 16:39:17.762728  4932 solver.cpp:240] Iteration 40760, loss = 0.0630897
I0110 16:39:17.762815  4932 solver.cpp:255]     Train net output #0: loss = 0.0316012 (* 1 = 0.0316012 loss)
I0110 16:39:17.762826  4932 solver.cpp:631] Iteration 40760, lr = 1e-07
I0110 16:39:43.940562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6928 > 20) by scale factor 0.844139
I0110 16:40:03.573256  4932 solver.cpp:240] Iteration 40780, loss = 0.0778276
I0110 16:40:03.573467  4932 solver.cpp:255]     Train net output #0: loss = 0.00833196 (* 1 = 0.00833196 loss)
I0110 16:40:03.573483  4932 solver.cpp:631] Iteration 40780, lr = 1e-07
I0110 16:40:32.261732  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0456 > 20) by scale factor 0.907212
I0110 16:40:43.561189  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9063 > 20) by scale factor 0.803009
I0110 16:40:49.880183  4932 solver.cpp:240] Iteration 40800, loss = 0.073975
I0110 16:40:49.880228  4932 solver.cpp:255]     Train net output #0: loss = 0.0039749 (* 1 = 0.0039749 loss)
I0110 16:40:49.880240  4932 solver.cpp:631] Iteration 40800, lr = 1e-07
I0110 16:41:32.382825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0377 > 20) by scale factor 0.998118
I0110 16:41:34.264847  4932 solver.cpp:240] Iteration 40820, loss = 0.0447726
I0110 16:41:34.264902  4932 solver.cpp:255]     Train net output #0: loss = 0.181918 (* 1 = 0.181918 loss)
I0110 16:41:34.269155  4932 solver.cpp:631] Iteration 40820, lr = 1e-07
I0110 16:41:47.927024  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.7731 > 20) by scale factor 0.629463
I0110 16:42:06.270174  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6519 > 20) by scale factor 0.882927
I0110 16:42:19.246589  4932 solver.cpp:240] Iteration 40840, loss = 0.0696964
I0110 16:42:19.246629  4932 solver.cpp:255]     Train net output #0: loss = 0.0198261 (* 1 = 0.0198261 loss)
I0110 16:42:19.246639  4932 solver.cpp:631] Iteration 40840, lr = 1e-07
I0110 16:42:21.804157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0843 > 20) by scale factor 0.664798
I0110 16:42:26.522737  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2894 > 20) by scale factor 0.897286
I0110 16:42:50.932085  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7593 > 20) by scale factor 0.695428
I0110 16:42:59.807252  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1101 > 20) by scale factor 0.829526
I0110 16:43:04.922200  4932 solver.cpp:240] Iteration 40860, loss = 0.101415
I0110 16:43:04.922247  4932 solver.cpp:255]     Train net output #0: loss = 0.211537 (* 1 = 0.211537 loss)
I0110 16:43:04.922260  4932 solver.cpp:631] Iteration 40860, lr = 1e-07
I0110 16:43:47.085311  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2206 > 20) by scale factor 0.734737
I0110 16:43:49.309322  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6088 > 20) by scale factor 0.884612
I0110 16:43:51.190793  4932 solver.cpp:240] Iteration 40880, loss = 0.0671331
I0110 16:43:51.190831  4932 solver.cpp:255]     Train net output #0: loss = 0.114994 (* 1 = 0.114994 loss)
I0110 16:43:51.190841  4932 solver.cpp:631] Iteration 40880, lr = 1e-07
I0110 16:43:53.749285  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5274 > 20) by scale factor 0.850072
I0110 16:44:24.019274  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3622 > 20) by scale factor 0.856085
I0110 16:44:36.999146  4932 solver.cpp:240] Iteration 40900, loss = 0.0605891
I0110 16:44:36.999186  4932 solver.cpp:255]     Train net output #0: loss = 0.0288369 (* 1 = 0.0288369 loss)
I0110 16:44:36.999197  4932 solver.cpp:631] Iteration 40900, lr = 1e-07
I0110 16:45:03.294503  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0116 > 20) by scale factor 0.768887
I0110 16:45:22.936470  4932 solver.cpp:240] Iteration 40920, loss = 0.062289
I0110 16:45:22.936509  4932 solver.cpp:255]     Train net output #0: loss = 0.0224335 (* 1 = 0.0224335 loss)
I0110 16:45:22.936522  4932 solver.cpp:631] Iteration 40920, lr = 1e-07
I0110 16:46:01.288733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5897 > 20) by scale factor 0.847829
I0110 16:46:09.148403  4932 solver.cpp:240] Iteration 40940, loss = 0.0591502
I0110 16:46:09.148442  4932 solver.cpp:255]     Train net output #0: loss = 0.0502772 (* 1 = 0.0502772 loss)
I0110 16:46:09.148452  4932 solver.cpp:631] Iteration 40940, lr = 1e-07
I0110 16:46:22.800463  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3238 > 20) by scale factor 0.78977
I0110 16:46:27.237659  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0013 > 20) by scale factor 0.799959
I0110 16:46:40.558363  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7501 > 20) by scale factor 0.879117
I0110 16:46:54.660122  4932 solver.cpp:240] Iteration 40960, loss = 0.0755126
I0110 16:46:54.660156  4932 solver.cpp:255]     Train net output #0: loss = 0.00171725 (* 1 = 0.00171725 loss)
I0110 16:46:54.660166  4932 solver.cpp:631] Iteration 40960, lr = 1e-07
I0110 16:47:01.655808  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.1992 > 20) by scale factor 0.621133
I0110 16:47:40.280828  4932 solver.cpp:240] Iteration 40980, loss = 0.0973309
I0110 16:47:40.280927  4932 solver.cpp:255]     Train net output #0: loss = 0.00794291 (* 1 = 0.00794291 loss)
I0110 16:47:40.280941  4932 solver.cpp:631] Iteration 40980, lr = 1e-07
I0110 16:48:22.035908  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2317 > 20) by scale factor 0.899617
I0110 16:48:24.266362  4932 solver.cpp:424] Iteration 41000, Testing net (#0)
I0110 16:49:28.716473  4932 solver.cpp:481]     Test net output #0: accuracy = 0.810526
I0110 16:49:28.716554  4932 solver.cpp:481]     Test net output #1: loss = 0.951363 (* 1 = 0.951363 loss)
I0110 16:49:30.582327  4932 solver.cpp:240] Iteration 41000, loss = 0.0711538
I0110 16:49:30.582368  4932 solver.cpp:255]     Train net output #0: loss = 0.0224957 (* 1 = 0.0224957 loss)
I0110 16:49:30.582379  4932 solver.cpp:631] Iteration 41000, lr = 1e-07
I0110 16:50:05.841653  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.189 > 20) by scale factor 0.943888
I0110 16:50:08.074661  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1677 > 20) by scale factor 0.902215
I0110 16:50:16.613320  4932 solver.cpp:240] Iteration 41020, loss = 0.0881241
I0110 16:50:16.613366  4932 solver.cpp:255]     Train net output #0: loss = 0.0819482 (* 1 = 0.0819482 loss)
I0110 16:50:16.613378  4932 solver.cpp:631] Iteration 41020, lr = 1e-07
I0110 16:50:52.762390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1087 > 20) by scale factor 0.904623
I0110 16:51:01.302434  4932 solver.cpp:240] Iteration 41040, loss = 0.0699034
I0110 16:51:01.302484  4932 solver.cpp:255]     Train net output #0: loss = 0.249162 (* 1 = 0.249162 loss)
I0110 16:51:01.302496  4932 solver.cpp:631] Iteration 41040, lr = 1e-07
I0110 16:51:12.741981  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2353 > 20) by scale factor 0.899472
I0110 16:51:45.691272  4932 solver.cpp:240] Iteration 41060, loss = 0.0520321
I0110 16:51:45.691359  4932 solver.cpp:255]     Train net output #0: loss = 0.00909345 (* 1 = 0.00909345 loss)
I0110 16:51:45.691372  4932 solver.cpp:631] Iteration 41060, lr = 1e-07
I0110 16:51:57.129454  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6471 > 20) by scale factor 0.968658
I0110 16:52:03.788413  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0751 > 20) by scale factor 0.797604
I0110 16:52:30.354354  4932 solver.cpp:240] Iteration 41080, loss = 0.0838543
I0110 16:52:30.354446  4932 solver.cpp:255]     Train net output #0: loss = 0.0359809 (* 1 = 0.0359809 loss)
I0110 16:52:30.354460  4932 solver.cpp:631] Iteration 41080, lr = 1e-07
I0110 16:53:42.726402  4932 solver.cpp:240] Iteration 41100, loss = 0.0431224
I0110 16:53:42.726490  4932 solver.cpp:255]     Train net output #0: loss = 0.121113 (* 1 = 0.121113 loss)
I0110 16:53:42.726501  4932 solver.cpp:631] Iteration 41100, lr = 1e-07
I0110 16:54:28.541223  4932 solver.cpp:240] Iteration 41120, loss = 0.0379459
I0110 16:54:28.541318  4932 solver.cpp:255]     Train net output #0: loss = 0.114265 (* 1 = 0.114265 loss)
I0110 16:54:28.541330  4932 solver.cpp:631] Iteration 41120, lr = 1e-07
I0110 16:54:42.199223  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9686 > 20) by scale factor 0.834424
I0110 16:55:13.303640  4932 solver.cpp:240] Iteration 41140, loss = 0.0594601
I0110 16:55:13.303733  4932 solver.cpp:255]     Train net output #0: loss = 0.219249 (* 1 = 0.219249 loss)
I0110 16:55:13.303747  4932 solver.cpp:631] Iteration 41140, lr = 1e-07
I0110 16:55:26.960043  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5317 > 20) by scale factor 0.726435
I0110 16:55:58.021270  4932 solver.cpp:240] Iteration 41160, loss = 0.0441597
I0110 16:55:58.021376  4932 solver.cpp:255]     Train net output #0: loss = 0.107362 (* 1 = 0.107362 loss)
I0110 16:55:58.021392  4932 solver.cpp:631] Iteration 41160, lr = 1e-07
I0110 16:56:11.679003  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0283 > 20) by scale factor 0.907922
I0110 16:56:20.628769  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4941 > 20) by scale factor 0.889123
I0110 16:56:42.764518  4932 solver.cpp:240] Iteration 41180, loss = 0.0544297
I0110 16:56:42.764590  4932 solver.cpp:255]     Train net output #0: loss = 0.317242 (* 1 = 0.317242 loss)
I0110 16:56:42.764601  4932 solver.cpp:631] Iteration 41180, lr = 1e-07
I0110 16:56:43.103924  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5417 > 20) by scale factor 0.887244
I0110 16:57:27.264524  4932 solver.cpp:240] Iteration 41200, loss = 0.0694244
I0110 16:57:27.264641  4932 solver.cpp:255]     Train net output #0: loss = 0.100053 (* 1 = 0.100053 loss)
I0110 16:57:27.264657  4932 solver.cpp:631] Iteration 41200, lr = 1e-07
I0110 16:58:12.048640  4932 solver.cpp:240] Iteration 41220, loss = 0.055837
I0110 16:58:12.048724  4932 solver.cpp:255]     Train net output #0: loss = 0.101253 (* 1 = 0.101253 loss)
I0110 16:58:12.048737  4932 solver.cpp:631] Iteration 41220, lr = 1e-07
I0110 16:58:21.262651  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0338 > 20) by scale factor 0.768233
I0110 16:58:57.386857  4932 solver.cpp:240] Iteration 41240, loss = 0.0531301
I0110 16:58:57.386940  4932 solver.cpp:255]     Train net output #0: loss = 0.0800137 (* 1 = 0.0800137 loss)
I0110 16:58:57.386950  4932 solver.cpp:631] Iteration 41240, lr = 1e-07
I0110 16:59:28.793787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5048 > 20) by scale factor 0.816168
I0110 16:59:41.773646  4932 solver.cpp:240] Iteration 41260, loss = 0.0669393
I0110 16:59:41.773687  4932 solver.cpp:255]     Train net output #0: loss = 0.00365947 (* 1 = 0.00365947 loss)
I0110 16:59:41.773697  4932 solver.cpp:631] Iteration 41260, lr = 1e-07
I0110 16:59:44.334164  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.638 > 20) by scale factor 0.9243
I0110 16:59:46.558729  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2454 > 20) by scale factor 0.899063
I0110 16:59:59.878240  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2496 > 20) by scale factor 0.707974
I0110 17:00:24.770189  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5727 > 20) by scale factor 0.927099
I0110 17:00:26.652662  4932 solver.cpp:240] Iteration 41280, loss = 0.108119
I0110 17:00:26.652706  4932 solver.cpp:255]     Train net output #0: loss = 0.0022012 (* 1 = 0.0022012 loss)
I0110 17:00:26.652717  4932 solver.cpp:631] Iteration 41280, lr = 1e-07
I0110 17:00:49.558121  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7629 > 20) by scale factor 0.963256
I0110 17:00:56.224527  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1787 > 20) by scale factor 0.901767
I0110 17:01:11.629886  4932 solver.cpp:240] Iteration 41300, loss = 0.0440098
I0110 17:01:11.629935  4932 solver.cpp:255]     Train net output #0: loss = 0.00146512 (* 1 = 0.00146512 loss)
I0110 17:01:11.629946  4932 solver.cpp:631] Iteration 41300, lr = 1e-07
I0110 17:01:14.191347  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6918 > 20) by scale factor 0.922008
I0110 17:01:20.849228  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1068 > 20) by scale factor 0.687124
I0110 17:01:56.210664  4932 solver.cpp:240] Iteration 41320, loss = 0.0646191
I0110 17:01:56.210769  4932 solver.cpp:255]     Train net output #0: loss = 0.0154792 (* 1 = 0.0154792 loss)
I0110 17:01:56.210784  4932 solver.cpp:631] Iteration 41320, lr = 1e-07
I0110 17:02:23.646661  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2485 > 20) by scale factor 0.708001
I0110 17:02:41.067819  4932 solver.cpp:240] Iteration 41340, loss = 0.0723459
I0110 17:02:41.067914  4932 solver.cpp:255]     Train net output #0: loss = 0.00931882 (* 1 = 0.00931882 loss)
I0110 17:02:41.067927  4932 solver.cpp:631] Iteration 41340, lr = 1e-07
I0110 17:03:26.218317  4932 solver.cpp:240] Iteration 41360, loss = 0.0747961
I0110 17:03:26.218394  4932 solver.cpp:255]     Train net output #0: loss = 0.0288063 (* 1 = 0.0288063 loss)
I0110 17:03:26.218405  4932 solver.cpp:631] Iteration 41360, lr = 1e-07
I0110 17:03:28.775432  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0583 > 20) by scale factor 0.831314
I0110 17:03:42.098268  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3166 > 20) by scale factor 0.896193
I0110 17:03:50.977887  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6615 > 20) by scale factor 0.6978
I0110 17:03:55.635879  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1931 > 20) by scale factor 0.990438
I0110 17:04:10.840705  4932 solver.cpp:240] Iteration 41380, loss = 0.0801662
I0110 17:04:10.840817  4932 solver.cpp:255]     Train net output #0: loss = 0.112812 (* 1 = 0.112812 loss)
I0110 17:04:10.840832  4932 solver.cpp:631] Iteration 41380, lr = 1e-07
I0110 17:04:31.242878  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4458 > 20) by scale factor 0.978197
I0110 17:04:44.569314  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8801 > 20) by scale factor 0.874121
I0110 17:04:55.537772  4932 solver.cpp:240] Iteration 41400, loss = 0.0826859
I0110 17:04:55.537819  4932 solver.cpp:255]     Train net output #0: loss = 0.0521903 (* 1 = 0.0521903 loss)
I0110 17:04:55.537830  4932 solver.cpp:631] Iteration 41400, lr = 1e-07
I0110 17:05:00.372910  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6124 > 20) by scale factor 0.884469
I0110 17:05:02.593785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4209 > 20) by scale factor 0.979388
I0110 17:05:25.085652  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4854 > 20) by scale factor 0.889466
I0110 17:05:31.749164  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.209 > 20) by scale factor 0.763096
I0110 17:05:40.286110  4932 solver.cpp:240] Iteration 41420, loss = 0.0839315
I0110 17:05:40.286157  4932 solver.cpp:255]     Train net output #0: loss = 0.105807 (* 1 = 0.105807 loss)
I0110 17:05:40.286171  4932 solver.cpp:631] Iteration 41420, lr = 1e-07
I0110 17:06:25.171630  4932 solver.cpp:240] Iteration 41440, loss = 0.0535906
I0110 17:06:25.171730  4932 solver.cpp:255]     Train net output #0: loss = 0.00164065 (* 1 = 0.00164065 loss)
I0110 17:06:25.171742  4932 solver.cpp:631] Iteration 41440, lr = 1e-07
I0110 17:06:27.731845  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7285 > 20) by scale factor 0.672755
I0110 17:06:52.147750  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7188 > 20) by scale factor 0.809101
I0110 17:07:03.248172  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6924 > 20) by scale factor 0.809965
I0110 17:07:09.571236  4932 solver.cpp:240] Iteration 41460, loss = 0.0676916
I0110 17:07:09.571276  4932 solver.cpp:255]     Train net output #0: loss = 0.00945626 (* 1 = 0.00945626 loss)
I0110 17:07:09.571287  4932 solver.cpp:631] Iteration 41460, lr = 1e-07
I0110 17:07:43.452778  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0899 > 20) by scale factor 0.995525
I0110 17:07:54.207965  4932 solver.cpp:240] Iteration 41480, loss = 0.0498634
I0110 17:07:54.207998  4932 solver.cpp:255]     Train net output #0: loss = 0.179536 (* 1 = 0.179536 loss)
I0110 17:07:54.208006  4932 solver.cpp:631] Iteration 41480, lr = 1e-07
I0110 17:08:10.078860  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.223 > 20) by scale factor 0.825662
I0110 17:08:39.448894  4932 solver.cpp:240] Iteration 41500, loss = 0.0671735
I0110 17:08:39.448989  4932 solver.cpp:255]     Train net output #0: loss = 0.0835005 (* 1 = 0.0835005 loss)
I0110 17:08:39.449002  4932 solver.cpp:631] Iteration 41500, lr = 1e-07
I0110 17:09:24.080552  4932 solver.cpp:240] Iteration 41520, loss = 0.0696818
I0110 17:09:24.080646  4932 solver.cpp:255]     Train net output #0: loss = 0.0104364 (* 1 = 0.0104364 loss)
I0110 17:09:24.080660  4932 solver.cpp:631] Iteration 41520, lr = 1e-07
I0110 17:10:02.175700  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6672 > 20) by scale factor 0.845051
I0110 17:10:08.498507  4932 solver.cpp:240] Iteration 41540, loss = 0.0501797
I0110 17:10:08.498553  4932 solver.cpp:255]     Train net output #0: loss = 0.0194658 (* 1 = 0.0194658 loss)
I0110 17:10:08.498565  4932 solver.cpp:631] Iteration 41540, lr = 1e-07
I0110 17:10:28.992153  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1487 > 20) by scale factor 0.992618
I0110 17:10:51.194763  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2787 > 20) by scale factor 0.733172
I0110 17:10:53.079166  4932 solver.cpp:240] Iteration 41560, loss = 0.11242
I0110 17:10:53.079212  4932 solver.cpp:255]     Train net output #0: loss = 0.127381 (* 1 = 0.127381 loss)
I0110 17:10:53.079226  4932 solver.cpp:631] Iteration 41560, lr = 1e-07
I0110 17:11:04.515326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7837 > 20) by scale factor 0.840913
I0110 17:11:36.083036  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6457 > 20) by scale factor 0.923971
I0110 17:11:37.964340  4932 solver.cpp:240] Iteration 41580, loss = 0.0740713
I0110 17:11:37.964375  4932 solver.cpp:255]     Train net output #0: loss = 0.0263329 (* 1 = 0.0263329 loss)
I0110 17:11:37.964383  4932 solver.cpp:631] Iteration 41580, lr = 1e-07
I0110 17:11:42.747297  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.91 > 20) by scale factor 0.956481
I0110 17:11:48.179710  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.632 > 20) by scale factor 0.924554
I0110 17:11:54.837990  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4044 > 20) by scale factor 0.934389
I0110 17:12:05.943203  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.348 > 20) by scale factor 0.856606
I0110 17:12:23.626605  4932 solver.cpp:240] Iteration 41600, loss = 0.0998299
I0110 17:12:23.626705  4932 solver.cpp:255]     Train net output #0: loss = 0.132534 (* 1 = 0.132534 loss)
I0110 17:12:23.626719  4932 solver.cpp:631] Iteration 41600, lr = 1e-07
I0110 17:12:41.744300  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5579 > 20) by scale factor 0.848973
I0110 17:12:50.801967  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5064 > 20) by scale factor 0.975305
I0110 17:13:08.225215  4932 solver.cpp:240] Iteration 41620, loss = 0.0590459
I0110 17:13:08.225308  4932 solver.cpp:255]     Train net output #0: loss = 0.0726668 (* 1 = 0.0726668 loss)
I0110 17:13:08.225322  4932 solver.cpp:631] Iteration 41620, lr = 1e-07
I0110 17:13:22.082664  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4281 > 20) by scale factor 0.679623
I0110 17:13:28.741547  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8197 > 20) by scale factor 0.839639
I0110 17:13:53.160259  4932 solver.cpp:240] Iteration 41640, loss = 0.0835713
I0110 17:13:53.160367  4932 solver.cpp:255]     Train net output #0: loss = 0.00254808 (* 1 = 0.00254808 loss)
I0110 17:13:53.160383  4932 solver.cpp:631] Iteration 41640, lr = 1e-07
I0110 17:14:00.177837  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.153 > 20) by scale factor 0.764731
I0110 17:14:37.744493  4932 solver.cpp:240] Iteration 41660, loss = 0.0829103
I0110 17:14:37.744616  4932 solver.cpp:255]     Train net output #0: loss = 0.00102777 (* 1 = 0.00102777 loss)
I0110 17:14:37.744633  4932 solver.cpp:631] Iteration 41660, lr = 1e-07
I0110 17:15:23.808632  4932 solver.cpp:240] Iteration 41680, loss = 0.0660313
I0110 17:15:23.808714  4932 solver.cpp:255]     Train net output #0: loss = 0.0238032 (* 1 = 0.0238032 loss)
I0110 17:15:23.808727  4932 solver.cpp:631] Iteration 41680, lr = 1e-07
I0110 17:15:28.585968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.797 > 20) by scale factor 0.746353
I0110 17:15:46.349652  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5474 > 20) by scale factor 0.849352
I0110 17:16:01.907475  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.928 > 20) by scale factor 0.955657
I0110 17:16:08.227370  4932 solver.cpp:240] Iteration 41700, loss = 0.0824271
I0110 17:16:08.227404  4932 solver.cpp:255]     Train net output #0: loss = 0.00162902 (* 1 = 0.00162902 loss)
I0110 17:16:08.227422  4932 solver.cpp:631] Iteration 41700, lr = 1e-07
I0110 17:16:53.797261  4932 solver.cpp:240] Iteration 41720, loss = 0.0573916
I0110 17:16:53.797374  4932 solver.cpp:255]     Train net output #0: loss = 0.00880656 (* 1 = 0.00880656 loss)
I0110 17:16:53.797387  4932 solver.cpp:631] Iteration 41720, lr = 1e-07
I0110 17:17:39.356096  4932 solver.cpp:240] Iteration 41740, loss = 0.0450822
I0110 17:17:39.356185  4932 solver.cpp:255]     Train net output #0: loss = 0.00780435 (* 1 = 0.00780435 loss)
I0110 17:17:39.356197  4932 solver.cpp:631] Iteration 41740, lr = 1e-07
I0110 17:18:25.127326  4932 solver.cpp:240] Iteration 41760, loss = 0.0428769
I0110 17:18:25.127427  4932 solver.cpp:255]     Train net output #0: loss = 0.15326 (* 1 = 0.15326 loss)
I0110 17:18:25.127442  4932 solver.cpp:631] Iteration 41760, lr = 1e-07
I0110 17:18:25.468669  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0615 > 20) by scale factor 0.996937
I0110 17:18:41.586879  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0955 > 20) by scale factor 0.995247
I0110 17:19:10.122156  4932 solver.cpp:240] Iteration 41780, loss = 0.0752094
I0110 17:19:10.122236  4932 solver.cpp:255]     Train net output #0: loss = 0.236167 (* 1 = 0.236167 loss)
I0110 17:19:10.122247  4932 solver.cpp:631] Iteration 41780, lr = 1e-07
I0110 17:19:12.681613  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5676 > 20) by scale factor 0.700093
I0110 17:19:48.388650  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9174 > 20) by scale factor 0.912517
I0110 17:19:54.840482  4932 solver.cpp:240] Iteration 41800, loss = 0.0748694
I0110 17:19:54.840523  4932 solver.cpp:255]     Train net output #0: loss = 0.00120404 (* 1 = 0.00120404 loss)
I0110 17:19:54.840533  4932 solver.cpp:631] Iteration 41800, lr = 1e-07
I0110 17:20:39.544287  4932 solver.cpp:240] Iteration 41820, loss = 0.0453191
I0110 17:20:39.544376  4932 solver.cpp:255]     Train net output #0: loss = 0.0195153 (* 1 = 0.0195153 loss)
I0110 17:20:39.544389  4932 solver.cpp:631] Iteration 41820, lr = 1e-07
I0110 17:21:04.299749  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7719 > 20) by scale factor 0.878275
I0110 17:21:19.027878  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7976 > 20) by scale factor 0.961651
I0110 17:21:25.355341  4932 solver.cpp:240] Iteration 41840, loss = 0.0547955
I0110 17:21:25.355392  4932 solver.cpp:255]     Train net output #0: loss = 0.00663967 (* 1 = 0.00663967 loss)
I0110 17:21:25.355406  4932 solver.cpp:631] Iteration 41840, lr = 1e-07
I0110 17:22:10.032084  4932 solver.cpp:240] Iteration 41860, loss = 0.0527195
I0110 17:22:10.032188  4932 solver.cpp:255]     Train net output #0: loss = 0.0718037 (* 1 = 0.0718037 loss)
I0110 17:22:10.032203  4932 solver.cpp:631] Iteration 41860, lr = 1e-07
I0110 17:22:40.933364  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1272 > 20) by scale factor 0.864784
I0110 17:22:54.614547  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7593 > 20) by scale factor 0.776418
I0110 17:22:56.497908  4932 solver.cpp:240] Iteration 41880, loss = 0.0632079
I0110 17:22:56.497952  4932 solver.cpp:255]     Train net output #0: loss = 0.0171772 (* 1 = 0.0171772 loss)
I0110 17:22:56.497963  4932 solver.cpp:631] Iteration 41880, lr = 1e-07
I0110 17:23:07.934964  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1277 > 20) by scale factor 0.795934
I0110 17:23:41.738790  4932 solver.cpp:240] Iteration 41900, loss = 0.0455059
I0110 17:23:41.738898  4932 solver.cpp:255]     Train net output #0: loss = 0.0344641 (* 1 = 0.0344641 loss)
I0110 17:23:41.738914  4932 solver.cpp:631] Iteration 41900, lr = 1e-07
I0110 17:23:48.757963  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9704 > 20) by scale factor 0.800947
I0110 17:23:53.197088  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3803 > 20) by scale factor 0.704714
I0110 17:24:20.329979  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3558 > 20) by scale factor 0.705322
I0110 17:24:26.651546  4932 solver.cpp:240] Iteration 41920, loss = 0.102769
I0110 17:24:26.651595  4932 solver.cpp:255]     Train net output #0: loss = 0.145559 (* 1 = 0.145559 loss)
I0110 17:24:26.651609  4932 solver.cpp:631] Iteration 41920, lr = 1e-07
I0110 17:24:46.530727  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7115 > 20) by scale factor 0.921172
I0110 17:24:55.410044  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8175 > 20) by scale factor 0.745781
I0110 17:25:13.242931  4932 solver.cpp:240] Iteration 41940, loss = 0.0875521
I0110 17:25:13.242977  4932 solver.cpp:255]     Train net output #0: loss = 0.00405362 (* 1 = 0.00405362 loss)
I0110 17:25:13.243141  4932 solver.cpp:631] Iteration 41940, lr = 1e-07
I0110 17:25:58.834520  4932 solver.cpp:240] Iteration 41960, loss = 0.0774717
I0110 17:25:58.834620  4932 solver.cpp:255]     Train net output #0: loss = 0.114655 (* 1 = 0.114655 loss)
I0110 17:25:58.834635  4932 solver.cpp:631] Iteration 41960, lr = 1e-07
I0110 17:26:14.707322  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9301 > 20) by scale factor 0.668224
I0110 17:26:44.168467  4932 solver.cpp:240] Iteration 41980, loss = 0.0988793
I0110 17:26:44.168565  4932 solver.cpp:255]     Train net output #0: loss = 0.136172 (* 1 = 0.136172 loss)
I0110 17:26:44.168579  4932 solver.cpp:631] Iteration 41980, lr = 1e-07
I0110 17:27:10.207733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7506 > 20) by scale factor 0.695639
I0110 17:27:27.964787  4932 solver.cpp:424] Iteration 42000, Testing net (#0)
I0110 17:28:29.907101  4932 solver.cpp:481]     Test net output #0: accuracy = 0.847368
I0110 17:28:29.907181  4932 solver.cpp:481]     Test net output #1: loss = 0.761119 (* 1 = 0.761119 loss)
I0110 17:28:31.773530  4932 solver.cpp:240] Iteration 42000, loss = 0.0803012
I0110 17:28:31.773562  4932 solver.cpp:255]     Train net output #0: loss = 0.0041869 (* 1 = 0.0041869 loss)
I0110 17:28:31.773571  4932 solver.cpp:631] Iteration 42000, lr = 1e-07
I0110 17:29:16.915731  4932 solver.cpp:240] Iteration 42020, loss = 0.0582138
I0110 17:29:16.915827  4932 solver.cpp:255]     Train net output #0: loss = 0.156155 (* 1 = 0.156155 loss)
I0110 17:29:16.915838  4932 solver.cpp:631] Iteration 42020, lr = 1e-07
I0110 17:29:21.690860  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6579 > 20) by scale factor 0.968153
I0110 17:29:44.550475  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1666 > 20) by scale factor 0.991739
I0110 17:29:57.901350  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.8858 > 20) by scale factor 0.590218
I0110 17:30:02.000113  4932 solver.cpp:240] Iteration 42040, loss = 0.079254
I0110 17:30:02.000147  4932 solver.cpp:255]     Train net output #0: loss = 0.000539125 (* 1 = 0.000539125 loss)
I0110 17:30:02.000156  4932 solver.cpp:631] Iteration 42040, lr = 1e-07
I0110 17:30:13.431694  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1594 > 20) by scale factor 0.992094
I0110 17:30:33.469111  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2755 > 20) by scale factor 0.940048
I0110 17:30:46.478227  4932 solver.cpp:240] Iteration 42060, loss = 0.0816632
I0110 17:30:46.478277  4932 solver.cpp:255]     Train net output #0: loss = 0.181726 (* 1 = 0.181726 loss)
I0110 17:30:46.478289  4932 solver.cpp:631] Iteration 42060, lr = 1e-07
I0110 17:30:57.911671  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4053 > 20) by scale factor 0.980137
I0110 17:31:32.963685  4932 solver.cpp:240] Iteration 42080, loss = 0.0593642
I0110 17:31:32.988987  4932 solver.cpp:255]     Train net output #0: loss = 0.113196 (* 1 = 0.113196 loss)
I0110 17:31:32.988999  4932 solver.cpp:631] Iteration 42080, lr = 1e-07
I0110 17:31:53.278574  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2383 > 20) by scale factor 0.762244
I0110 17:32:11.259284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8518 > 20) by scale factor 0.80477
I0110 17:32:17.580771  4932 solver.cpp:240] Iteration 42100, loss = 0.0795669
I0110 17:32:17.580811  4932 solver.cpp:255]     Train net output #0: loss = 0.0415928 (* 1 = 0.0415928 loss)
I0110 17:32:17.580821  4932 solver.cpp:631] Iteration 42100, lr = 1e-07
I0110 17:32:45.797173  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.1713 > 20) by scale factor 0.662881
I0110 17:33:03.213317  4932 solver.cpp:240] Iteration 42120, loss = 0.0381099
I0110 17:33:03.213351  4932 solver.cpp:255]     Train net output #0: loss = 0.0042136 (* 1 = 0.0042136 loss)
I0110 17:33:03.213359  4932 solver.cpp:631] Iteration 42120, lr = 1e-07
I0110 17:33:49.606057  4932 solver.cpp:240] Iteration 42140, loss = 0.0682992
I0110 17:33:49.606148  4932 solver.cpp:255]     Train net output #0: loss = 0.0546789 (* 1 = 0.0546789 loss)
I0110 17:33:49.606160  4932 solver.cpp:631] Iteration 42140, lr = 1e-07
I0110 17:34:33.982640  4932 solver.cpp:240] Iteration 42160, loss = 0.037718
I0110 17:34:33.982739  4932 solver.cpp:255]     Train net output #0: loss = 0.0354012 (* 1 = 0.0354012 loss)
I0110 17:34:33.982753  4932 solver.cpp:631] Iteration 42160, lr = 1e-07
I0110 17:34:45.458299  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6461 > 20) by scale factor 0.723429
I0110 17:34:52.135133  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5505 > 20) by scale factor 0.814648
I0110 17:34:56.573911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.692 > 20) by scale factor 0.778454
I0110 17:35:18.422431  4932 solver.cpp:240] Iteration 42180, loss = 0.0788889
I0110 17:35:18.422541  4932 solver.cpp:255]     Train net output #0: loss = 0.0179761 (* 1 = 0.0179761 loss)
I0110 17:35:18.422557  4932 solver.cpp:631] Iteration 42180, lr = 1e-07
I0110 17:35:57.933559  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6568 > 20) by scale factor 0.882739
I0110 17:36:05.289912  4932 solver.cpp:240] Iteration 42200, loss = 0.0539424
I0110 17:36:05.289953  4932 solver.cpp:255]     Train net output #0: loss = 0.105036 (* 1 = 0.105036 loss)
I0110 17:36:05.289963  4932 solver.cpp:631] Iteration 42200, lr = 1e-07
I0110 17:36:10.069203  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2805 > 20) by scale factor 0.897646
I0110 17:36:27.827054  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0575 > 20) by scale factor 0.949779
I0110 17:36:51.180402  4932 solver.cpp:240] Iteration 42220, loss = 0.0742069
I0110 17:36:51.180500  4932 solver.cpp:255]     Train net output #0: loss = 0.0574483 (* 1 = 0.0574483 loss)
I0110 17:36:51.180513  4932 solver.cpp:631] Iteration 42220, lr = 1e-07
I0110 17:37:35.767496  4932 solver.cpp:240] Iteration 42240, loss = 0.0601418
I0110 17:37:35.767586  4932 solver.cpp:255]     Train net output #0: loss = 0.0273015 (* 1 = 0.0273015 loss)
I0110 17:37:35.767601  4932 solver.cpp:631] Iteration 42240, lr = 1e-07
I0110 17:38:12.661209  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.851 > 20) by scale factor 0.804796
I0110 17:38:21.199846  4932 solver.cpp:240] Iteration 42260, loss = 0.0509732
I0110 17:38:21.199895  4932 solver.cpp:255]     Train net output #0: loss = 0.0604252 (* 1 = 0.0604252 loss)
I0110 17:38:21.199909  4932 solver.cpp:631] Iteration 42260, lr = 1e-07
I0110 17:39:08.946342  4932 solver.cpp:240] Iteration 42280, loss = 0.0432143
I0110 17:39:08.946424  4932 solver.cpp:255]     Train net output #0: loss = 0.00846435 (* 1 = 0.00846435 loss)
I0110 17:39:08.946436  4932 solver.cpp:631] Iteration 42280, lr = 1e-07
I0110 17:39:54.326591  4932 solver.cpp:240] Iteration 42300, loss = 0.0464414
I0110 17:39:54.326721  4932 solver.cpp:255]     Train net output #0: loss = 0.0571467 (* 1 = 0.0571467 loss)
I0110 17:39:54.326743  4932 solver.cpp:631] Iteration 42300, lr = 1e-07
I0110 17:40:03.542745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7983 > 20) by scale factor 0.775245
I0110 17:40:26.589381  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6481 > 20) by scale factor 0.750521
I0110 17:40:31.031636  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8857 > 20) by scale factor 0.717214
I0110 17:40:39.570471  4932 solver.cpp:240] Iteration 42320, loss = 0.131395
I0110 17:40:39.570502  4932 solver.cpp:255]     Train net output #0: loss = 0.119578 (* 1 = 0.119578 loss)
I0110 17:40:39.570513  4932 solver.cpp:631] Iteration 42320, lr = 1e-07
I0110 17:40:42.126863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3347 > 20) by scale factor 0.821872
I0110 17:41:25.434655  4932 solver.cpp:240] Iteration 42340, loss = 0.0407765
I0110 17:41:25.434751  4932 solver.cpp:255]     Train net output #0: loss = 0.00258999 (* 1 = 0.00258999 loss)
I0110 17:41:25.434765  4932 solver.cpp:631] Iteration 42340, lr = 1e-07
I0110 17:41:45.738224  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0951 > 20) by scale factor 0.99527
I0110 17:42:10.726354  4932 solver.cpp:240] Iteration 42360, loss = 0.10025
I0110 17:42:10.726442  4932 solver.cpp:255]     Train net output #0: loss = 0.0459266 (* 1 = 0.0459266 loss)
I0110 17:42:10.726456  4932 solver.cpp:631] Iteration 42360, lr = 1e-07
I0110 17:42:41.800282  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.547 > 20) by scale factor 0.887037
I0110 17:42:57.003150  4932 solver.cpp:240] Iteration 42380, loss = 0.049067
I0110 17:42:57.003195  4932 solver.cpp:255]     Train net output #0: loss = 0.0206334 (* 1 = 0.0206334 loss)
I0110 17:42:57.003206  4932 solver.cpp:631] Iteration 42380, lr = 1e-07
I0110 17:43:12.054488  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.0952 > 20) by scale factor 0.55409
I0110 17:43:43.010395  4932 solver.cpp:240] Iteration 42400, loss = 0.0607501
I0110 17:43:43.010479  4932 solver.cpp:255]     Train net output #0: loss = 0.0426363 (* 1 = 0.0426363 loss)
I0110 17:43:43.010493  4932 solver.cpp:631] Iteration 42400, lr = 1e-07
I0110 17:44:27.573189  4932 solver.cpp:240] Iteration 42420, loss = 0.0375432
I0110 17:44:27.573279  4932 solver.cpp:255]     Train net output #0: loss = 0.0471929 (* 1 = 0.0471929 loss)
I0110 17:44:27.573293  4932 solver.cpp:631] Iteration 42420, lr = 1e-07
I0110 17:45:13.403640  4932 solver.cpp:240] Iteration 42440, loss = 0.054743
I0110 17:45:13.403728  4932 solver.cpp:255]     Train net output #0: loss = 0.0784433 (* 1 = 0.0784433 loss)
I0110 17:45:13.403741  4932 solver.cpp:631] Iteration 42440, lr = 1e-07
I0110 17:45:15.962849  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3835 > 20) by scale factor 0.704634
I0110 17:45:59.710186  4932 solver.cpp:240] Iteration 42460, loss = 0.0571905
I0110 17:45:59.710269  4932 solver.cpp:255]     Train net output #0: loss = 0.0491862 (* 1 = 0.0491862 loss)
I0110 17:45:59.710280  4932 solver.cpp:631] Iteration 42460, lr = 1e-07
I0110 17:46:44.581207  4932 solver.cpp:240] Iteration 42480, loss = 0.0335091
I0110 17:46:44.581295  4932 solver.cpp:255]     Train net output #0: loss = 0.0179534 (* 1 = 0.0179534 loss)
I0110 17:46:44.581306  4932 solver.cpp:631] Iteration 42480, lr = 1e-07
I0110 17:47:02.670298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3784 > 20) by scale factor 0.855492
I0110 17:47:29.395174  4932 solver.cpp:240] Iteration 42500, loss = 0.0752575
I0110 17:47:29.395272  4932 solver.cpp:255]     Train net output #0: loss = 0.0023034 (* 1 = 0.0023034 loss)
I0110 17:47:29.395287  4932 solver.cpp:631] Iteration 42500, lr = 1e-07
I0110 17:48:14.038112  4932 solver.cpp:240] Iteration 42520, loss = 0.0468734
I0110 17:48:14.038185  4932 solver.cpp:255]     Train net output #0: loss = 0.0254356 (* 1 = 0.0254356 loss)
I0110 17:48:14.038203  4932 solver.cpp:631] Iteration 42520, lr = 1e-07
I0110 17:48:52.049548  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.747 > 20) by scale factor 0.747748
I0110 17:49:00.590101  4932 solver.cpp:240] Iteration 42540, loss = 0.0529211
I0110 17:49:00.590143  4932 solver.cpp:255]     Train net output #0: loss = 0.029252 (* 1 = 0.029252 loss)
I0110 17:49:00.590158  4932 solver.cpp:631] Iteration 42540, lr = 1e-07
I0110 17:49:16.456506  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4991 > 20) by scale factor 0.816355
I0110 17:49:45.008173  4932 solver.cpp:240] Iteration 42560, loss = 0.0532377
I0110 17:49:45.008291  4932 solver.cpp:255]     Train net output #0: loss = 0.0424482 (* 1 = 0.0424482 loss)
I0110 17:49:45.008307  4932 solver.cpp:631] Iteration 42560, lr = 1e-07
I0110 17:50:20.897946  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5392 > 20) by scale factor 0.973747
I0110 17:50:29.433934  4932 solver.cpp:240] Iteration 42580, loss = 0.0587238
I0110 17:50:29.433972  4932 solver.cpp:255]     Train net output #0: loss = 0.0113666 (* 1 = 0.0113666 loss)
I0110 17:50:29.433981  4932 solver.cpp:631] Iteration 42580, lr = 1e-07
I0110 17:51:13.990582  4932 solver.cpp:240] Iteration 42600, loss = 0.0514332
I0110 17:51:13.990663  4932 solver.cpp:255]     Train net output #0: loss = 0.00866933 (* 1 = 0.00866933 loss)
I0110 17:51:13.990674  4932 solver.cpp:631] Iteration 42600, lr = 1e-07
I0110 17:51:40.952313  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4663 > 20) by scale factor 0.785353
I0110 17:51:59.410558  4932 solver.cpp:240] Iteration 42620, loss = 0.0722257
I0110 17:51:59.410658  4932 solver.cpp:255]     Train net output #0: loss = 0.16172 (* 1 = 0.16172 loss)
I0110 17:51:59.410672  4932 solver.cpp:631] Iteration 42620, lr = 1e-07
I0110 17:52:15.281488  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5989 > 20) by scale factor 0.970925
I0110 17:52:26.373661  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5452 > 20) by scale factor 0.973462
I0110 17:52:45.410568  4932 solver.cpp:240] Iteration 42640, loss = 0.05851
I0110 17:52:45.410660  4932 solver.cpp:255]     Train net output #0: loss = 0.00423735 (* 1 = 0.00423735 loss)
I0110 17:52:45.410675  4932 solver.cpp:631] Iteration 42640, lr = 1e-07
I0110 17:53:25.401222  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7669 > 20) by scale factor 0.720282
I0110 17:53:31.717871  4932 solver.cpp:240] Iteration 42660, loss = 0.0576067
I0110 17:53:31.717908  4932 solver.cpp:255]     Train net output #0: loss = 0.00898114 (* 1 = 0.00898114 loss)
I0110 17:53:31.717918  4932 solver.cpp:631] Iteration 42660, lr = 1e-07
I0110 17:53:51.229120  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4516 > 20) by scale factor 0.817941
I0110 17:54:17.518251  4932 solver.cpp:240] Iteration 42680, loss = 0.0850665
I0110 17:54:17.518344  4932 solver.cpp:255]     Train net output #0: loss = 0.0745193 (* 1 = 0.0745193 loss)
I0110 17:54:17.518357  4932 solver.cpp:631] Iteration 42680, lr = 1e-07
I0110 17:54:22.293735  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9711 > 20) by scale factor 0.870659
I0110 17:54:53.367980  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0373 > 20) by scale factor 0.798807
I0110 17:55:01.959302  4932 solver.cpp:240] Iteration 42700, loss = 0.0636413
I0110 17:55:01.959338  4932 solver.cpp:255]     Train net output #0: loss = 0.162611 (* 1 = 0.162611 loss)
I0110 17:55:01.959347  4932 solver.cpp:631] Iteration 42700, lr = 1e-07
I0110 17:55:06.736346  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8274 > 20) by scale factor 0.774371
I0110 17:55:42.235483  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.148 > 20) by scale factor 0.764876
I0110 17:55:47.541290  4932 solver.cpp:240] Iteration 42720, loss = 0.131098
I0110 17:55:47.541333  4932 solver.cpp:255]     Train net output #0: loss = 0.0200016 (* 1 = 0.0200016 loss)
I0110 17:55:47.541342  4932 solver.cpp:631] Iteration 42720, lr = 1e-07
I0110 17:56:33.338542  4932 solver.cpp:240] Iteration 42740, loss = 0.0777026
I0110 17:56:33.338639  4932 solver.cpp:255]     Train net output #0: loss = 0.0197717 (* 1 = 0.0197717 loss)
I0110 17:56:33.338652  4932 solver.cpp:631] Iteration 42740, lr = 1e-07
I0110 17:56:40.331674  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0371 > 20) by scale factor 0.868166
I0110 17:56:42.551576  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7138 > 20) by scale factor 0.843389
I0110 17:56:46.994323  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2652 > 20) by scale factor 0.824224
I0110 17:57:15.315343  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9614 > 20) by scale factor 0.871028
I0110 17:57:19.413854  4932 solver.cpp:240] Iteration 42760, loss = 0.100477
I0110 17:57:19.413895  4932 solver.cpp:255]     Train net output #0: loss = 0.062999 (* 1 = 0.062999 loss)
I0110 17:57:19.413904  4932 solver.cpp:631] Iteration 42760, lr = 1e-07
I0110 17:58:03.993163  4932 solver.cpp:240] Iteration 42780, loss = 0.0439801
I0110 17:58:03.993261  4932 solver.cpp:255]     Train net output #0: loss = 0.0620402 (* 1 = 0.0620402 loss)
I0110 17:58:03.993274  4932 solver.cpp:631] Iteration 42780, lr = 1e-07
I0110 17:58:50.070173  4932 solver.cpp:240] Iteration 42800, loss = 0.0457175
I0110 17:58:50.070266  4932 solver.cpp:255]     Train net output #0: loss = 0.0480566 (* 1 = 0.0480566 loss)
I0110 17:58:50.070278  4932 solver.cpp:631] Iteration 42800, lr = 1e-07
I0110 17:59:35.874485  4932 solver.cpp:240] Iteration 42820, loss = 0.0518301
I0110 17:59:35.874569  4932 solver.cpp:255]     Train net output #0: loss = 0.16496 (* 1 = 0.16496 loss)
I0110 17:59:35.874581  4932 solver.cpp:631] Iteration 42820, lr = 1e-07
I0110 18:00:07.278410  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9483 > 20) by scale factor 0.954734
I0110 18:00:21.799693  4932 solver.cpp:240] Iteration 42840, loss = 0.0612404
I0110 18:00:21.799739  4932 solver.cpp:255]     Train net output #0: loss = 0.239159 (* 1 = 0.239159 loss)
I0110 18:00:21.799752  4932 solver.cpp:631] Iteration 42840, lr = 1e-07
I0110 18:00:46.547680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8959 > 20) by scale factor 0.957124
I0110 18:01:07.916118  4932 solver.cpp:240] Iteration 42860, loss = 0.0585593
I0110 18:01:07.916167  4932 solver.cpp:255]     Train net output #0: loss = 0.035136 (* 1 = 0.035136 loss)
I0110 18:01:07.916178  4932 solver.cpp:631] Iteration 42860, lr = 1e-07
I0110 18:01:17.141357  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0395 > 20) by scale factor 0.99803
I0110 18:01:19.364009  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0769 > 20) by scale factor 0.71233
I0110 18:01:31.591995  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7671 > 20) by scale factor 0.918819
I0110 18:01:38.253504  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.257 > 20) by scale factor 0.761703
I0110 18:01:40.476783  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0314 > 20) by scale factor 0.950959
I0110 18:01:47.141685  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7494 > 20) by scale factor 0.8081
I0110 18:01:53.464804  4932 solver.cpp:240] Iteration 42880, loss = 0.107622
I0110 18:01:53.464848  4932 solver.cpp:255]     Train net output #0: loss = 0.00562211 (* 1 = 0.00562211 loss)
I0110 18:01:53.464859  4932 solver.cpp:631] Iteration 42880, lr = 1e-07
I0110 18:02:33.362064  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5915 > 20) by scale factor 0.81329
I0110 18:02:37.801182  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.154 > 20) by scale factor 0.863783
I0110 18:02:39.682343  4932 solver.cpp:240] Iteration 42900, loss = 0.0994911
I0110 18:02:39.682381  4932 solver.cpp:255]     Train net output #0: loss = 0.0921762 (* 1 = 0.0921762 loss)
I0110 18:02:39.682390  4932 solver.cpp:631] Iteration 42900, lr = 1e-07
I0110 18:03:02.205140  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4575 > 20) by scale factor 0.656653
I0110 18:03:25.876054  4932 solver.cpp:240] Iteration 42920, loss = 0.0482442
I0110 18:03:25.876138  4932 solver.cpp:255]     Train net output #0: loss = 0.038598 (* 1 = 0.038598 loss)
I0110 18:03:25.876149  4932 solver.cpp:631] Iteration 42920, lr = 1e-07
I0110 18:03:52.834136  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 41.4952 > 20) by scale factor 0.481984
I0110 18:03:59.491646  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3027 > 20) by scale factor 0.98509
I0110 18:04:10.243531  4932 solver.cpp:240] Iteration 42940, loss = 0.0820515
I0110 18:04:10.243571  4932 solver.cpp:255]     Train net output #0: loss = 0.151798 (* 1 = 0.151798 loss)
I0110 18:04:10.243583  4932 solver.cpp:631] Iteration 42940, lr = 1e-07
I0110 18:04:57.598700  4932 solver.cpp:240] Iteration 42960, loss = 0.026535
I0110 18:04:57.598781  4932 solver.cpp:255]     Train net output #0: loss = 0.0557548 (* 1 = 0.0557548 loss)
I0110 18:04:57.598793  4932 solver.cpp:631] Iteration 42960, lr = 1e-07
I0110 18:05:24.571599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0697 > 20) by scale factor 0.906221
I0110 18:05:29.944527  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1532 > 20) by scale factor 0.86381
I0110 18:05:42.918972  4932 solver.cpp:240] Iteration 42980, loss = 0.047857
I0110 18:05:42.919013  4932 solver.cpp:255]     Train net output #0: loss = 0.00515376 (* 1 = 0.00515376 loss)
I0110 18:05:42.919023  4932 solver.cpp:631] Iteration 42980, lr = 1e-07
I0110 18:05:47.695262  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3865 > 20) by scale factor 0.757964
I0110 18:06:26.861380  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7147 > 20) by scale factor 0.921033
I0110 18:06:26.874353  4932 solver.cpp:424] Iteration 43000, Testing net (#0)
I0110 18:07:28.725636  4932 solver.cpp:481]     Test net output #0: accuracy = 0.845263
I0110 18:07:28.725692  4932 solver.cpp:481]     Test net output #1: loss = 0.754135 (* 1 = 0.754135 loss)
I0110 18:07:30.591240  4932 solver.cpp:240] Iteration 43000, loss = 0.0949536
I0110 18:07:30.591276  4932 solver.cpp:255]     Train net output #0: loss = 0.00620393 (* 1 = 0.00620393 loss)
I0110 18:07:30.591285  4932 solver.cpp:631] Iteration 43000, lr = 1e-07
I0110 18:07:37.875880  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7817 > 20) by scale factor 0.962384
I0110 18:08:15.374461  4932 solver.cpp:240] Iteration 43020, loss = 0.0837622
I0110 18:08:15.374552  4932 solver.cpp:255]     Train net output #0: loss = 0.0945617 (* 1 = 0.0945617 loss)
I0110 18:08:15.374567  4932 solver.cpp:631] Iteration 43020, lr = 1e-07
I0110 18:08:35.835206  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3844 > 20) by scale factor 0.981143
I0110 18:09:00.265024  4932 solver.cpp:240] Iteration 43040, loss = 0.0536327
I0110 18:09:00.265106  4932 solver.cpp:255]     Train net output #0: loss = 0.178151 (* 1 = 0.178151 loss)
I0110 18:09:00.265117  4932 solver.cpp:631] Iteration 43040, lr = 1e-07
I0110 18:09:16.143234  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3201 > 20) by scale factor 0.896055
I0110 18:09:29.526087  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5667 > 20) by scale factor 0.848657
I0110 18:09:44.726891  4932 solver.cpp:240] Iteration 43060, loss = 0.0632307
I0110 18:09:44.726971  4932 solver.cpp:255]     Train net output #0: loss = 0.0444111 (* 1 = 0.0444111 loss)
I0110 18:09:44.726984  4932 solver.cpp:631] Iteration 43060, lr = 1e-07
I0110 18:09:53.943387  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0648 > 20) by scale factor 0.867123
I0110 18:10:11.697875  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.8022 > 20) by scale factor 0.671091
I0110 18:10:29.116958  4932 solver.cpp:240] Iteration 43080, loss = 0.0922432
I0110 18:10:29.117072  4932 solver.cpp:255]     Train net output #0: loss = 0.000760309 (* 1 = 0.000760309 loss)
I0110 18:10:29.117089  4932 solver.cpp:631] Iteration 43080, lr = 1e-07
I0110 18:11:05.172621  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5496 > 20) by scale factor 0.849272
I0110 18:11:13.881500  4932 solver.cpp:240] Iteration 43100, loss = 0.0438765
I0110 18:11:13.881536  4932 solver.cpp:255]     Train net output #0: loss = 0.0485204 (* 1 = 0.0485204 loss)
I0110 18:11:13.881546  4932 solver.cpp:631] Iteration 43100, lr = 1e-07
I0110 18:11:34.351209  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7677 > 20) by scale factor 0.963033
I0110 18:11:52.109472  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1659 > 20) by scale factor 0.902285
I0110 18:11:58.427438  4932 solver.cpp:240] Iteration 43120, loss = 0.0773104
I0110 18:11:58.427474  4932 solver.cpp:255]     Train net output #0: loss = 0.116203 (* 1 = 0.116203 loss)
I0110 18:11:58.427484  4932 solver.cpp:631] Iteration 43120, lr = 1e-07
I0110 18:12:09.858691  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1557 > 20) by scale factor 0.94537
I0110 18:12:27.619639  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8277 > 20) by scale factor 0.960262
I0110 18:12:40.935739  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.7964 > 20) by scale factor 0.609823
I0110 18:12:42.817114  4932 solver.cpp:240] Iteration 43140, loss = 0.068216
I0110 18:12:42.817155  4932 solver.cpp:255]     Train net output #0: loss = 0.000788155 (* 1 = 0.000788155 loss)
I0110 18:12:42.817165  4932 solver.cpp:631] Iteration 43140, lr = 1e-07
I0110 18:13:19.409606  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5338 > 20) by scale factor 0.974004
I0110 18:13:27.946820  4932 solver.cpp:240] Iteration 43160, loss = 0.070915
I0110 18:13:27.946866  4932 solver.cpp:255]     Train net output #0: loss = 0.0535461 (* 1 = 0.0535461 loss)
I0110 18:13:27.946877  4932 solver.cpp:631] Iteration 43160, lr = 1e-07
I0110 18:13:41.920867  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.943 > 20) by scale factor 0.835318
I0110 18:13:55.235630  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5356 > 20) by scale factor 0.97392
I0110 18:14:18.014257  4932 solver.cpp:240] Iteration 43180, loss = 0.09092
I0110 18:14:18.014302  4932 solver.cpp:255]     Train net output #0: loss = 0.0067072 (* 1 = 0.0067072 loss)
I0110 18:14:18.014317  4932 solver.cpp:631] Iteration 43180, lr = 1e-07
I0110 18:14:33.883793  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3196 > 20) by scale factor 0.857646
I0110 18:15:02.595023  4932 solver.cpp:240] Iteration 43200, loss = 0.0623818
I0110 18:15:02.595067  4932 solver.cpp:255]     Train net output #0: loss = 0.0432079 (* 1 = 0.0432079 loss)
I0110 18:15:02.595077  4932 solver.cpp:631] Iteration 43200, lr = 1e-07
I0110 18:15:09.593781  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5815 > 20) by scale factor 0.971748
I0110 18:15:20.697619  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5739 > 20) by scale factor 0.752619
I0110 18:15:29.574334  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.813 > 20) by scale factor 0.528919
I0110 18:15:46.998291  4932 solver.cpp:240] Iteration 43220, loss = 0.113311
I0110 18:15:46.998376  4932 solver.cpp:255]     Train net output #0: loss = 0.0424157 (* 1 = 0.0424157 loss)
I0110 18:15:46.998390  4932 solver.cpp:631] Iteration 43220, lr = 1e-07
I0110 18:16:31.536891  4932 solver.cpp:240] Iteration 43240, loss = 0.0817799
I0110 18:16:31.537003  4932 solver.cpp:255]     Train net output #0: loss = 0.112014 (* 1 = 0.112014 loss)
I0110 18:16:31.537019  4932 solver.cpp:631] Iteration 43240, lr = 1e-07
I0110 18:16:47.417227  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5262 > 20) by scale factor 0.974365
I0110 18:17:15.936415  4932 solver.cpp:240] Iteration 43260, loss = 0.0784425
I0110 18:17:15.936503  4932 solver.cpp:255]     Train net output #0: loss = 0.00520187 (* 1 = 0.00520187 loss)
I0110 18:17:15.936516  4932 solver.cpp:631] Iteration 43260, lr = 1e-07
I0110 18:18:00.792881  4932 solver.cpp:240] Iteration 43280, loss = 0.0488502
I0110 18:18:00.792954  4932 solver.cpp:255]     Train net output #0: loss = 0.0123344 (* 1 = 0.0123344 loss)
I0110 18:18:00.792966  4932 solver.cpp:631] Iteration 43280, lr = 1e-07
I0110 18:18:45.436250  4932 solver.cpp:240] Iteration 43300, loss = 0.0556666
I0110 18:18:45.436348  4932 solver.cpp:255]     Train net output #0: loss = 0.0836577 (* 1 = 0.0836577 loss)
I0110 18:18:45.436362  4932 solver.cpp:631] Iteration 43300, lr = 1e-07
I0110 18:19:31.531997  4932 solver.cpp:240] Iteration 43320, loss = 0.0448499
I0110 18:19:31.532093  4932 solver.cpp:255]     Train net output #0: loss = 0.00134489 (* 1 = 0.00134489 loss)
I0110 18:19:31.532104  4932 solver.cpp:631] Iteration 43320, lr = 1e-07
I0110 18:19:57.420409  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.032 > 20) by scale factor 0.868357
I0110 18:20:10.735777  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9889 > 20) by scale factor 0.869985
I0110 18:20:17.054388  4932 solver.cpp:240] Iteration 43340, loss = 0.0868779
I0110 18:20:17.054419  4932 solver.cpp:255]     Train net output #0: loss = 0.0646847 (* 1 = 0.0646847 loss)
I0110 18:20:17.054430  4932 solver.cpp:631] Iteration 43340, lr = 1e-07
I0110 18:20:42.566156  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2347 > 20) by scale factor 0.825262
I0110 18:21:02.201786  4932 solver.cpp:240] Iteration 43360, loss = 0.0628165
I0110 18:21:02.201843  4932 solver.cpp:255]     Train net output #0: loss = 0.00518316 (* 1 = 0.00518316 loss)
I0110 18:21:02.201864  4932 solver.cpp:631] Iteration 43360, lr = 1e-07
I0110 18:21:26.961426  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3436 > 20) by scale factor 0.93705
I0110 18:21:48.401737  4932 solver.cpp:240] Iteration 43380, loss = 0.059421
I0110 18:21:48.401787  4932 solver.cpp:255]     Train net output #0: loss = 0.0242891 (* 1 = 0.0242891 loss)
I0110 18:21:48.401801  4932 solver.cpp:631] Iteration 43380, lr = 1e-07
I0110 18:22:18.477840  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2763 > 20) by scale factor 0.791256
I0110 18:22:33.671097  4932 solver.cpp:240] Iteration 43400, loss = 0.0487434
I0110 18:22:33.671141  4932 solver.cpp:255]     Train net output #0: loss = 0.037025 (* 1 = 0.037025 loss)
I0110 18:22:33.671154  4932 solver.cpp:631] Iteration 43400, lr = 1e-07
I0110 18:22:40.879887  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3332 > 20) by scale factor 0.705885
I0110 18:22:43.105936  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.17 > 20) by scale factor 0.863186
I0110 18:23:14.173548  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.851 > 20) by scale factor 0.669994
I0110 18:23:18.272811  4932 solver.cpp:240] Iteration 43420, loss = 0.109453
I0110 18:23:18.272853  4932 solver.cpp:255]     Train net output #0: loss = 0.174429 (* 1 = 0.174429 loss)
I0110 18:23:18.272984  4932 solver.cpp:631] Iteration 43420, lr = 1e-07
I0110 18:23:29.760888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.672 > 20) by scale factor 0.882144
I0110 18:24:03.429224  4932 solver.cpp:240] Iteration 43440, loss = 0.0850904
I0110 18:24:03.429338  4932 solver.cpp:255]     Train net output #0: loss = 0.0565456 (* 1 = 0.0565456 loss)
I0110 18:24:03.429353  4932 solver.cpp:631] Iteration 43440, lr = 1e-07
I0110 18:24:25.984300  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6413 > 20) by scale factor 0.92416
I0110 18:24:49.016043  4932 solver.cpp:240] Iteration 43460, loss = 0.0476795
I0110 18:24:49.016170  4932 solver.cpp:255]     Train net output #0: loss = 0.00666163 (* 1 = 0.00666163 loss)
I0110 18:24:49.016186  4932 solver.cpp:631] Iteration 43460, lr = 1e-07
I0110 18:24:58.233222  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7082 > 20) by scale factor 0.921311
I0110 18:25:29.308259  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7146 > 20) by scale factor 0.809239
I0110 18:25:33.410694  4932 solver.cpp:240] Iteration 43480, loss = 0.0756259
I0110 18:25:33.410744  4932 solver.cpp:255]     Train net output #0: loss = 0.00469218 (* 1 = 0.00469218 loss)
I0110 18:25:33.410758  4932 solver.cpp:631] Iteration 43480, lr = 1e-07
I0110 18:25:41.542713  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5587 > 20) by scale factor 0.927698
I0110 18:26:20.350262  4932 solver.cpp:240] Iteration 43500, loss = 0.0989591
I0110 18:26:20.350347  4932 solver.cpp:255]     Train net output #0: loss = 0.0916703 (* 1 = 0.0916703 loss)
I0110 18:26:20.350358  4932 solver.cpp:631] Iteration 43500, lr = 1e-07
I0110 18:27:04.896560  4932 solver.cpp:240] Iteration 43520, loss = 0.0458264
I0110 18:27:04.896659  4932 solver.cpp:255]     Train net output #0: loss = 0.0128875 (* 1 = 0.0128875 loss)
I0110 18:27:04.896672  4932 solver.cpp:631] Iteration 43520, lr = 1e-07
I0110 18:27:44.545084  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2482 > 20) by scale factor 0.987742
I0110 18:27:46.768679  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1964 > 20) by scale factor 0.763462
I0110 18:27:50.873258  4932 solver.cpp:240] Iteration 43540, loss = 0.0587326
I0110 18:27:50.873298  4932 solver.cpp:255]     Train net output #0: loss = 0.00182949 (* 1 = 0.00182949 loss)
I0110 18:27:50.873308  4932 solver.cpp:631] Iteration 43540, lr = 1e-07
I0110 18:28:05.877863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.4477 > 20) by scale factor 0.616376
I0110 18:28:37.761708  4932 solver.cpp:240] Iteration 43560, loss = 0.0596788
I0110 18:28:37.761798  4932 solver.cpp:255]     Train net output #0: loss = 0.0568546 (* 1 = 0.0568546 loss)
I0110 18:28:37.761811  4932 solver.cpp:631] Iteration 43560, lr = 1e-07
I0110 18:29:16.129284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.037 > 20) by scale factor 0.998155
I0110 18:29:22.453137  4932 solver.cpp:240] Iteration 43580, loss = 0.0650878
I0110 18:29:22.453182  4932 solver.cpp:255]     Train net output #0: loss = 0.0846294 (* 1 = 0.0846294 loss)
I0110 18:29:22.453193  4932 solver.cpp:631] Iteration 43580, lr = 1e-07
I0110 18:29:27.235244  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5114 > 20) by scale factor 0.975066
I0110 18:30:02.994385  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0045 > 20) by scale factor 0.908906
I0110 18:30:07.467882  4932 solver.cpp:240] Iteration 43600, loss = 0.081523
I0110 18:30:07.467931  4932 solver.cpp:255]     Train net output #0: loss = 0.135837 (* 1 = 0.135837 loss)
I0110 18:30:07.467944  4932 solver.cpp:631] Iteration 43600, lr = 1e-07
I0110 18:30:25.565531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2705 > 20) by scale factor 0.791436
I0110 18:30:51.964530  4932 solver.cpp:240] Iteration 43620, loss = 0.048183
I0110 18:30:51.964628  4932 solver.cpp:255]     Train net output #0: loss = 0.0089679 (* 1 = 0.0089679 loss)
I0110 18:30:51.964642  4932 solver.cpp:631] Iteration 43620, lr = 1e-07
I0110 18:31:16.720825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1156 > 20) by scale factor 0.947169
I0110 18:31:31.621541  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9616 > 20) by scale factor 0.871021
I0110 18:31:37.941540  4932 solver.cpp:240] Iteration 43640, loss = 0.075178
I0110 18:31:37.941576  4932 solver.cpp:255]     Train net output #0: loss = 0.0974296 (* 1 = 0.0974296 loss)
I0110 18:31:37.941583  4932 solver.cpp:631] Iteration 43640, lr = 1e-07
I0110 18:31:58.267098  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1919 > 20) by scale factor 0.990494
I0110 18:32:22.341367  4932 solver.cpp:240] Iteration 43660, loss = 0.0579191
I0110 18:32:22.341473  4932 solver.cpp:255]     Train net output #0: loss = 0.0394138 (* 1 = 0.0394138 loss)
I0110 18:32:22.341490  4932 solver.cpp:631] Iteration 43660, lr = 1e-07
I0110 18:32:41.756165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6655 > 20) by scale factor 0.923125
I0110 18:33:08.053225  4932 solver.cpp:240] Iteration 43680, loss = 0.0407484
I0110 18:33:08.053309  4932 solver.cpp:255]     Train net output #0: loss = 0.0665667 (* 1 = 0.0665667 loss)
I0110 18:33:08.053321  4932 solver.cpp:631] Iteration 43680, lr = 1e-07
I0110 18:33:53.946493  4932 solver.cpp:240] Iteration 43700, loss = 0.049825
I0110 18:33:53.946588  4932 solver.cpp:255]     Train net output #0: loss = 0.269203 (* 1 = 0.269203 loss)
I0110 18:33:53.946600  4932 solver.cpp:631] Iteration 43700, lr = 1e-07
I0110 18:33:54.285961  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6561 > 20) by scale factor 0.674397
I0110 18:34:38.364759  4932 solver.cpp:240] Iteration 43720, loss = 0.0560211
I0110 18:34:38.364872  4932 solver.cpp:255]     Train net output #0: loss = 0.193277 (* 1 = 0.193277 loss)
I0110 18:34:38.364887  4932 solver.cpp:631] Iteration 43720, lr = 1e-07
I0110 18:34:56.463968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4039 > 20) by scale factor 0.980205
I0110 18:35:22.760434  4932 solver.cpp:240] Iteration 43740, loss = 0.0749933
I0110 18:35:22.760535  4932 solver.cpp:255]     Train net output #0: loss = 0.147473 (* 1 = 0.147473 loss)
I0110 18:35:22.760550  4932 solver.cpp:631] Iteration 43740, lr = 1e-07
I0110 18:35:27.544829  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.605 > 20) by scale factor 0.751738
I0110 18:35:31.987499  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9254 > 20) by scale factor 0.912183
I0110 18:35:34.208250  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1959 > 20) by scale factor 0.990299
I0110 18:36:07.213897  4932 solver.cpp:240] Iteration 43760, loss = 0.0575013
I0110 18:36:07.213990  4932 solver.cpp:255]     Train net output #0: loss = 0.0974289 (* 1 = 0.0974289 loss)
I0110 18:36:07.214004  4932 solver.cpp:631] Iteration 43760, lr = 1e-07
I0110 18:36:29.787811  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.929 > 20) by scale factor 0.955611
I0110 18:36:38.669386  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5111 > 20) by scale factor 0.929755
I0110 18:36:40.892839  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2371 > 20) by scale factor 0.988286
I0110 18:36:53.115717  4932 solver.cpp:240] Iteration 43780, loss = 0.0562675
I0110 18:36:53.115754  4932 solver.cpp:255]     Train net output #0: loss = 0.0163123 (* 1 = 0.0163123 loss)
I0110 18:36:53.115764  4932 solver.cpp:631] Iteration 43780, lr = 1e-07
I0110 18:37:04.542704  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6414 > 20) by scale factor 0.750712
I0110 18:37:35.614040  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.7182 > 20) by scale factor 0.630553
I0110 18:37:37.496464  4932 solver.cpp:240] Iteration 43800, loss = 0.0982189
I0110 18:37:37.496496  4932 solver.cpp:255]     Train net output #0: loss = 0.01171 (* 1 = 0.01171 loss)
I0110 18:37:37.496506  4932 solver.cpp:631] Iteration 43800, lr = 1e-07
I0110 18:38:21.955925  4932 solver.cpp:240] Iteration 43820, loss = 0.0572599
I0110 18:38:21.956056  4932 solver.cpp:255]     Train net output #0: loss = 0.0127848 (* 1 = 0.0127848 loss)
I0110 18:38:21.956077  4932 solver.cpp:631] Iteration 43820, lr = 1e-07
I0110 18:38:38.922847  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.838 > 20) by scale factor 0.805217
I0110 18:38:43.367555  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7217 > 20) by scale factor 0.809007
I0110 18:39:05.568482  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2017 > 20) by scale factor 0.90083
I0110 18:39:07.450633  4932 solver.cpp:240] Iteration 43840, loss = 0.0763098
I0110 18:39:07.450670  4932 solver.cpp:255]     Train net output #0: loss = 0.303124 (* 1 = 0.303124 loss)
I0110 18:39:07.450678  4932 solver.cpp:631] Iteration 43840, lr = 1e-07
I0110 18:39:07.789757  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.335 > 20) by scale factor 0.821863
I0110 18:39:37.634304  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0304 > 20) by scale factor 0.907836
I0110 18:39:53.955818  4932 solver.cpp:240] Iteration 43860, loss = 0.0437098
I0110 18:39:53.955860  4932 solver.cpp:255]     Train net output #0: loss = 0.0245282 (* 1 = 0.0245282 loss)
I0110 18:39:53.955871  4932 solver.cpp:631] Iteration 43860, lr = 1e-07
I0110 18:40:18.708997  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.53 > 20) by scale factor 0.928937
I0110 18:40:38.580025  4932 solver.cpp:240] Iteration 43880, loss = 0.0752929
I0110 18:40:38.580063  4932 solver.cpp:255]     Train net output #0: loss = 0.0827328 (* 1 = 0.0827328 loss)
I0110 18:40:38.580073  4932 solver.cpp:631] Iteration 43880, lr = 1e-07
I0110 18:41:23.202550  4932 solver.cpp:240] Iteration 43900, loss = 0.0864223
I0110 18:41:23.202623  4932 solver.cpp:255]     Train net output #0: loss = 0.111864 (* 1 = 0.111864 loss)
I0110 18:41:23.202633  4932 solver.cpp:631] Iteration 43900, lr = 1e-07
I0110 18:41:27.983911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3331 > 20) by scale factor 0.7595
I0110 18:42:08.146222  4932 solver.cpp:240] Iteration 43920, loss = 0.050617
I0110 18:42:08.146311  4932 solver.cpp:255]     Train net output #0: loss = 0.016719 (* 1 = 0.016719 loss)
I0110 18:42:08.146323  4932 solver.cpp:631] Iteration 43920, lr = 1e-07
I0110 18:42:54.413738  4932 solver.cpp:240] Iteration 43940, loss = 0.0344229
I0110 18:42:54.413818  4932 solver.cpp:255]     Train net output #0: loss = 0.0312023 (* 1 = 0.0312023 loss)
I0110 18:42:54.413830  4932 solver.cpp:631] Iteration 43940, lr = 1e-07
I0110 18:43:08.068392  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5263 > 20) by scale factor 0.887853
I0110 18:43:41.018852  4932 solver.cpp:240] Iteration 43960, loss = 0.0781624
I0110 18:43:41.018929  4932 solver.cpp:255]     Train net output #0: loss = 0.0025331 (* 1 = 0.0025331 loss)
I0110 18:43:41.018939  4932 solver.cpp:631] Iteration 43960, lr = 1e-07
I0110 18:43:43.576527  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0225 > 20) by scale factor 0.868715
I0110 18:44:23.312047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2434 > 20) by scale factor 0.987978
I0110 18:44:27.413604  4932 solver.cpp:240] Iteration 43980, loss = 0.0947965
I0110 18:44:27.413645  4932 solver.cpp:255]     Train net output #0: loss = 0.069168 (* 1 = 0.069168 loss)
I0110 18:44:27.413655  4932 solver.cpp:631] Iteration 43980, lr = 1e-07
I0110 18:44:43.282289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6951 > 20) by scale factor 0.749201
I0110 18:45:10.053406  4932 solver.cpp:424] Iteration 44000, Testing net (#0)
I0110 18:46:00.907678  4932 solver.cpp:481]     Test net output #0: accuracy = 0.818947
I0110 18:46:00.907773  4932 solver.cpp:481]     Test net output #1: loss = 0.891865 (* 1 = 0.891865 loss)
I0110 18:46:02.775315  4932 solver.cpp:240] Iteration 44000, loss = 0.0618349
I0110 18:46:02.775346  4932 solver.cpp:255]     Train net output #0: loss = 0.053168 (* 1 = 0.053168 loss)
I0110 18:46:02.775360  4932 solver.cpp:631] Iteration 44000, lr = 1e-07
I0110 18:46:11.995331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3036 > 20) by scale factor 0.938807
I0110 18:46:29.756572  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4585 > 20) by scale factor 0.93203
I0110 18:46:48.583441  4932 solver.cpp:240] Iteration 44020, loss = 0.0726728
I0110 18:46:48.583533  4932 solver.cpp:255]     Train net output #0: loss = 0.0196406 (* 1 = 0.0196406 loss)
I0110 18:46:48.583544  4932 solver.cpp:631] Iteration 44020, lr = 1e-07
I0110 18:46:55.578189  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2043 > 20) by scale factor 0.989889
I0110 18:47:15.560735  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7353 > 20) by scale factor 0.920161
I0110 18:47:32.981014  4932 solver.cpp:240] Iteration 44040, loss = 0.0667382
I0110 18:47:32.981114  4932 solver.cpp:255]     Train net output #0: loss = 0.0263979 (* 1 = 0.0263979 loss)
I0110 18:47:32.981127  4932 solver.cpp:631] Iteration 44040, lr = 1e-07
I0110 18:48:06.975755  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5784 > 20) by scale factor 0.848232
I0110 18:48:17.736399  4932 solver.cpp:240] Iteration 44060, loss = 0.0460148
I0110 18:48:17.736449  4932 solver.cpp:255]     Train net output #0: loss = 0.227442 (* 1 = 0.227442 loss)
I0110 18:48:17.736464  4932 solver.cpp:631] Iteration 44060, lr = 1e-07
I0110 18:48:18.076982  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 38.085 > 20) by scale factor 0.525142
I0110 18:48:39.474040  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4424 > 20) by scale factor 0.853153
I0110 18:48:46.133314  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 40.3898 > 20) by scale factor 0.495174
I0110 18:48:50.647438  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.1205 > 20) by scale factor 0.642663
I0110 18:49:03.661754  4932 solver.cpp:240] Iteration 44080, loss = 0.101383
I0110 18:49:03.661797  4932 solver.cpp:255]     Train net output #0: loss = 0.0142792 (* 1 = 0.0142792 loss)
I0110 18:49:03.661809  4932 solver.cpp:631] Iteration 44080, lr = 1e-07
I0110 18:49:49.121747  4932 solver.cpp:240] Iteration 44100, loss = 0.054412
I0110 18:49:49.121830  4932 solver.cpp:255]     Train net output #0: loss = 0.128349 (* 1 = 0.128349 loss)
I0110 18:49:49.121841  4932 solver.cpp:631] Iteration 44100, lr = 1e-07
I0110 18:50:34.090919  4932 solver.cpp:240] Iteration 44120, loss = 0.0463016
I0110 18:50:34.091006  4932 solver.cpp:255]     Train net output #0: loss = 0.0636285 (* 1 = 0.0636285 loss)
I0110 18:50:34.091018  4932 solver.cpp:631] Iteration 44120, lr = 1e-07
I0110 18:50:57.289165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2734 > 20) by scale factor 0.986512
I0110 18:51:01.727265  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6112 > 20) by scale factor 0.925446
I0110 18:51:19.148641  4932 solver.cpp:240] Iteration 44140, loss = 0.0741228
I0110 18:51:19.148720  4932 solver.cpp:255]     Train net output #0: loss = 0.054825 (* 1 = 0.054825 loss)
I0110 18:51:19.148731  4932 solver.cpp:631] Iteration 44140, lr = 1e-07
I0110 18:52:00.946673  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4247 > 20) by scale factor 0.891875
I0110 18:52:05.049067  4932 solver.cpp:240] Iteration 44160, loss = 0.0541415
I0110 18:52:05.813735  4932 solver.cpp:255]     Train net output #0: loss = 0.0238476 (* 1 = 0.0238476 loss)
I0110 18:52:05.813763  4932 solver.cpp:631] Iteration 44160, lr = 1e-07
I0110 18:52:29.119931  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5336 > 20) by scale factor 0.726384
I0110 18:52:52.444646  4932 solver.cpp:240] Iteration 44180, loss = 0.0922598
I0110 18:52:52.444771  4932 solver.cpp:255]     Train net output #0: loss = 0.0188327 (* 1 = 0.0188327 loss)
I0110 18:52:52.444785  4932 solver.cpp:631] Iteration 44180, lr = 1e-07
I0110 18:53:34.105113  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6759 > 20) by scale factor 0.84474
I0110 18:53:38.204552  4932 solver.cpp:240] Iteration 44200, loss = 0.0770847
I0110 18:53:38.204591  4932 solver.cpp:255]     Train net output #0: loss = 0.0829616 (* 1 = 0.0829616 loss)
I0110 18:53:38.204602  4932 solver.cpp:631] Iteration 44200, lr = 1e-07
I0110 18:54:02.071064  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7113 > 20) by scale factor 0.880619
I0110 18:54:17.605716  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.81 > 20) by scale factor 0.917012
I0110 18:54:22.045819  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6809 > 20) by scale factor 0.844562
I0110 18:54:23.927968  4932 solver.cpp:240] Iteration 44220, loss = 0.0919725
I0110 18:54:23.928004  4932 solver.cpp:255]     Train net output #0: loss = 0.23229 (* 1 = 0.23229 loss)
I0110 18:54:23.928014  4932 solver.cpp:631] Iteration 44220, lr = 1e-07
I0110 18:54:24.267019  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4923 > 20) by scale factor 0.975978
I0110 18:54:28.705603  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3191 > 20) by scale factor 0.857665
I0110 18:54:35.366989  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0324 > 20) by scale factor 0.950913
I0110 18:55:08.338838  4932 solver.cpp:240] Iteration 44240, loss = 0.101965
I0110 18:55:08.338943  4932 solver.cpp:255]     Train net output #0: loss = 0.100285 (* 1 = 0.100285 loss)
I0110 18:55:08.338956  4932 solver.cpp:631] Iteration 44240, lr = 1e-07
I0110 18:55:17.554287  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7244 > 20) by scale factor 0.843014
I0110 18:55:28.650768  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9572 > 20) by scale factor 0.910863
I0110 18:55:54.367344  4932 solver.cpp:240] Iteration 44260, loss = 0.0558047
I0110 18:55:54.367475  4932 solver.cpp:255]     Train net output #0: loss = 0.00155048 (* 1 = 0.00155048 loss)
I0110 18:55:54.367494  4932 solver.cpp:631] Iteration 44260, lr = 1e-07
I0110 18:56:10.264207  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6187 > 20) by scale factor 0.812391
I0110 18:56:28.021523  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0969 > 20) by scale factor 0.99518
I0110 18:56:38.787812  4932 solver.cpp:240] Iteration 44280, loss = 0.0377213
I0110 18:56:38.787852  4932 solver.cpp:255]     Train net output #0: loss = 0.0252817 (* 1 = 0.0252817 loss)
I0110 18:56:38.787863  4932 solver.cpp:631] Iteration 44280, lr = 1e-07
I0110 18:56:41.346050  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 41.8178 > 20) by scale factor 0.478266
I0110 18:57:23.265797  4932 solver.cpp:240] Iteration 44300, loss = 0.077136
I0110 18:57:23.265885  4932 solver.cpp:255]     Train net output #0: loss = 0.000459936 (* 1 = 0.000459936 loss)
I0110 18:57:23.265897  4932 solver.cpp:631] Iteration 44300, lr = 1e-07
I0110 18:58:10.455273  4932 solver.cpp:240] Iteration 44320, loss = 0.0599179
I0110 18:58:10.455353  4932 solver.cpp:255]     Train net output #0: loss = 0.127949 (* 1 = 0.127949 loss)
I0110 18:58:10.455363  4932 solver.cpp:631] Iteration 44320, lr = 1e-07
I0110 18:58:37.421632  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0707 > 20) by scale factor 0.830885
I0110 18:58:54.239447  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8907 > 20) by scale factor 0.837147
I0110 18:58:56.122545  4932 solver.cpp:240] Iteration 44340, loss = 0.0701358
I0110 18:58:56.122589  4932 solver.cpp:255]     Train net output #0: loss = 0.0404631 (* 1 = 0.0404631 loss)
I0110 18:58:56.122601  4932 solver.cpp:631] Iteration 44340, lr = 1e-07
I0110 18:59:40.512718  4932 solver.cpp:240] Iteration 44360, loss = 0.0651253
I0110 18:59:40.512840  4932 solver.cpp:255]     Train net output #0: loss = 0.0498868 (* 1 = 0.0498868 loss)
I0110 18:59:40.512861  4932 solver.cpp:631] Iteration 44360, lr = 1e-07
I0110 19:00:27.568169  4932 solver.cpp:240] Iteration 44380, loss = 0.0388235
I0110 19:00:27.568264  4932 solver.cpp:255]     Train net output #0: loss = 2.60766e-05 (* 1 = 2.60766e-05 loss)
I0110 19:00:27.568276  4932 solver.cpp:631] Iteration 44380, lr = 1e-07
I0110 19:01:12.713201  4932 solver.cpp:240] Iteration 44400, loss = 0.0535067
I0110 19:01:12.713284  4932 solver.cpp:255]     Train net output #0: loss = 0.0174778 (* 1 = 0.0174778 loss)
I0110 19:01:12.713295  4932 solver.cpp:631] Iteration 44400, lr = 1e-07
I0110 19:01:57.163605  4932 solver.cpp:240] Iteration 44420, loss = 0.0615896
I0110 19:01:57.163697  4932 solver.cpp:255]     Train net output #0: loss = 0.141005 (* 1 = 0.141005 loss)
I0110 19:01:57.163709  4932 solver.cpp:631] Iteration 44420, lr = 1e-07
I0110 19:01:57.503146  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8103 > 20) by scale factor 0.961063
I0110 19:02:14.320477  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3895 > 20) by scale factor 0.820026
I0110 19:02:42.827157  4932 solver.cpp:240] Iteration 44440, loss = 0.066274
I0110 19:02:42.827255  4932 solver.cpp:255]     Train net output #0: loss = 0.209327 (* 1 = 0.209327 loss)
I0110 19:02:42.827266  4932 solver.cpp:631] Iteration 44440, lr = 1e-07
I0110 19:03:17.180742  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.0929 > 20) by scale factor 0.623192
I0110 19:03:28.325114  4932 solver.cpp:240] Iteration 44460, loss = 0.0611015
I0110 19:03:28.325158  4932 solver.cpp:255]     Train net output #0: loss = 0.0977663 (* 1 = 0.0977663 loss)
I0110 19:03:28.325168  4932 solver.cpp:631] Iteration 44460, lr = 1e-07
I0110 19:04:12.728766  4932 solver.cpp:240] Iteration 44480, loss = 0.0790078
I0110 19:04:12.728863  4932 solver.cpp:255]     Train net output #0: loss = 0.0714387 (* 1 = 0.0714387 loss)
I0110 19:04:12.728876  4932 solver.cpp:631] Iteration 44480, lr = 1e-07
I0110 19:04:39.793426  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8172 > 20) by scale factor 0.774677
I0110 19:04:57.220052  4932 solver.cpp:240] Iteration 44500, loss = 0.0520391
I0110 19:04:57.220149  4932 solver.cpp:255]     Train net output #0: loss = 0.0632542 (* 1 = 0.0632542 loss)
I0110 19:04:57.220162  4932 solver.cpp:631] Iteration 44500, lr = 1e-07
I0110 19:05:11.358914  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9538 > 20) by scale factor 0.801483
I0110 19:05:42.660804  4932 solver.cpp:240] Iteration 44520, loss = 0.0881603
I0110 19:05:42.660910  4932 solver.cpp:255]     Train net output #0: loss = 0.00494123 (* 1 = 0.00494123 loss)
I0110 19:05:42.660924  4932 solver.cpp:631] Iteration 44520, lr = 1e-07
I0110 19:06:00.766394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6689 > 20) by scale factor 0.749936
I0110 19:06:16.299854  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8651 > 20) by scale factor 0.874694
I0110 19:06:19.702556  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0519 > 20) by scale factor 0.831535
I0110 19:06:24.141916  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1693 > 20) by scale factor 0.944763
I0110 19:06:28.242241  4932 solver.cpp:240] Iteration 44540, loss = 0.0682317
I0110 19:06:28.242280  4932 solver.cpp:255]     Train net output #0: loss = 0.0310316 (* 1 = 0.0310316 loss)
I0110 19:06:28.242290  4932 solver.cpp:631] Iteration 44540, lr = 1e-07
I0110 19:07:11.586033  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7877 > 20) by scale factor 0.962105
I0110 19:07:13.468969  4932 solver.cpp:240] Iteration 44560, loss = 0.0848328
I0110 19:07:13.469003  4932 solver.cpp:255]     Train net output #0: loss = 0.0584809 (* 1 = 0.0584809 loss)
I0110 19:07:13.469012  4932 solver.cpp:631] Iteration 44560, lr = 1e-07
I0110 19:07:36.243274  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7589 > 20) by scale factor 0.878776
I0110 19:07:58.092469  4932 solver.cpp:240] Iteration 44580, loss = 0.0747945
I0110 19:07:58.092595  4932 solver.cpp:255]     Train net output #0: loss = 0.0629967 (* 1 = 0.0629967 loss)
I0110 19:07:58.092609  4932 solver.cpp:631] Iteration 44580, lr = 1e-07
I0110 19:08:24.357913  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5363 > 20) by scale factor 0.849752
I0110 19:08:26.578701  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1427 > 20) by scale factor 0.992917
I0110 19:08:43.992007  4932 solver.cpp:240] Iteration 44600, loss = 0.0953824
I0110 19:08:43.992089  4932 solver.cpp:255]     Train net output #0: loss = 0.000526675 (* 1 = 0.000526675 loss)
I0110 19:08:43.992100  4932 solver.cpp:631] Iteration 44600, lr = 1e-07
I0110 19:09:28.444468  4932 solver.cpp:240] Iteration 44620, loss = 0.0546553
I0110 19:09:28.444567  4932 solver.cpp:255]     Train net output #0: loss = 0.0976122 (* 1 = 0.0976122 loss)
I0110 19:09:28.444581  4932 solver.cpp:631] Iteration 44620, lr = 1e-07
I0110 19:09:56.183717  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2343 > 20) by scale factor 0.792571
I0110 19:10:13.594434  4932 solver.cpp:240] Iteration 44640, loss = 0.0646669
I0110 19:10:13.594529  4932 solver.cpp:255]     Train net output #0: loss = 0.0333241 (* 1 = 0.0333241 loss)
I0110 19:10:13.594542  4932 solver.cpp:631] Iteration 44640, lr = 1e-07
I0110 19:10:57.970903  4932 solver.cpp:240] Iteration 44660, loss = 0.0475695
I0110 19:10:57.970993  4932 solver.cpp:255]     Train net output #0: loss = 0.013055 (* 1 = 0.013055 loss)
I0110 19:10:57.971004  4932 solver.cpp:631] Iteration 44660, lr = 1e-07
I0110 19:11:23.818439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4317 > 20) by scale factor 0.978873
I0110 19:11:44.661681  4932 solver.cpp:240] Iteration 44680, loss = 0.0636488
I0110 19:11:44.661765  4932 solver.cpp:255]     Train net output #0: loss = 0.16421 (* 1 = 0.16421 loss)
I0110 19:11:44.661777  4932 solver.cpp:631] Iteration 44680, lr = 1e-07
I0110 19:12:30.550473  4932 solver.cpp:240] Iteration 44700, loss = 0.0522938
I0110 19:12:30.550572  4932 solver.cpp:255]     Train net output #0: loss = 0.0500975 (* 1 = 0.0500975 loss)
I0110 19:12:30.550586  4932 solver.cpp:631] Iteration 44700, lr = 1e-07
I0110 19:13:16.373623  4932 solver.cpp:240] Iteration 44720, loss = 0.0231112
I0110 19:13:16.373704  4932 solver.cpp:255]     Train net output #0: loss = 0.0325317 (* 1 = 0.0325317 loss)
I0110 19:13:16.373715  4932 solver.cpp:631] Iteration 44720, lr = 1e-07
I0110 19:13:18.933269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3223 > 20) by scale factor 0.937986
I0110 19:13:53.649158  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.314 > 20) by scale factor 0.857853
I0110 19:14:02.185782  4932 solver.cpp:240] Iteration 44740, loss = 0.0594849
I0110 19:14:02.185811  4932 solver.cpp:255]     Train net output #0: loss = 0.0751489 (* 1 = 0.0751489 loss)
I0110 19:14:02.185820  4932 solver.cpp:631] Iteration 44740, lr = 1e-07
I0110 19:14:48.887702  4932 solver.cpp:240] Iteration 44760, loss = 0.0709132
I0110 19:14:48.887796  4932 solver.cpp:255]     Train net output #0: loss = 0.0605545 (* 1 = 0.0605545 loss)
I0110 19:14:48.887809  4932 solver.cpp:631] Iteration 44760, lr = 1e-07
I0110 19:15:20.639323  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5808 > 20) by scale factor 0.885709
I0110 19:15:33.614591  4932 solver.cpp:240] Iteration 44780, loss = 0.0550852
I0110 19:15:33.614631  4932 solver.cpp:255]     Train net output #0: loss = 0.00916922 (* 1 = 0.00916922 loss)
I0110 19:15:33.614641  4932 solver.cpp:631] Iteration 44780, lr = 1e-07
I0110 19:16:19.151638  4932 solver.cpp:240] Iteration 44800, loss = 0.072648
I0110 19:16:19.151770  4932 solver.cpp:255]     Train net output #0: loss = 0.0271407 (* 1 = 0.0271407 loss)
I0110 19:16:19.151790  4932 solver.cpp:631] Iteration 44800, lr = 1e-07
I0110 19:16:28.370118  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9359 > 20) by scale factor 0.771133
I0110 19:16:58.351954  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6179 > 20) by scale factor 0.884254
I0110 19:17:04.669462  4932 solver.cpp:240] Iteration 44820, loss = 0.0763112
I0110 19:17:04.669499  4932 solver.cpp:255]     Train net output #0: loss = 0.0329605 (* 1 = 0.0329605 loss)
I0110 19:17:04.669510  4932 solver.cpp:631] Iteration 44820, lr = 1e-07
I0110 19:17:39.642065  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0108 > 20) by scale factor 0.76891
I0110 19:17:46.301673  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2058 > 20) by scale factor 0.989813
I0110 19:17:48.521812  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2127 > 20) by scale factor 0.793251
I0110 19:17:50.403527  4932 solver.cpp:240] Iteration 44840, loss = 0.0916496
I0110 19:17:50.403560  4932 solver.cpp:255]     Train net output #0: loss = 0.205321 (* 1 = 0.205321 loss)
I0110 19:17:50.403569  4932 solver.cpp:631] Iteration 44840, lr = 1e-07
I0110 19:17:50.742704  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8377 > 20) by scale factor 0.959801
I0110 19:17:55.182261  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9107 > 20) by scale factor 0.956448
I0110 19:18:15.150830  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7282 > 20) by scale factor 0.964869
I0110 19:18:19.592248  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6128 > 20) by scale factor 0.925377
I0110 19:18:34.921279  4932 solver.cpp:240] Iteration 44860, loss = 0.0808376
I0110 19:18:34.921322  4932 solver.cpp:255]     Train net output #0: loss = 0.00669015 (* 1 = 0.00669015 loss)
I0110 19:18:34.921334  4932 solver.cpp:631] Iteration 44860, lr = 1e-07
I0110 19:18:46.681620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1015 > 20) by scale factor 0.904916
I0110 19:19:19.623457  4932 solver.cpp:240] Iteration 44880, loss = 0.0780401
I0110 19:19:19.623550  4932 solver.cpp:255]     Train net output #0: loss = 0.12689 (* 1 = 0.12689 loss)
I0110 19:19:19.623564  4932 solver.cpp:631] Iteration 44880, lr = 1e-07
I0110 19:19:22.180119  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7518 > 20) by scale factor 0.879052
I0110 19:20:04.201812  4932 solver.cpp:240] Iteration 44900, loss = 0.0909296
I0110 19:20:04.201908  4932 solver.cpp:255]     Train net output #0: loss = 0.024494 (* 1 = 0.024494 loss)
I0110 19:20:04.201921  4932 solver.cpp:631] Iteration 44900, lr = 1e-07
I0110 19:20:24.509060  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.527 > 20) by scale factor 0.887825
I0110 19:20:28.945741  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4935 > 20) by scale factor 0.930513
I0110 19:20:48.575258  4932 solver.cpp:240] Iteration 44920, loss = 0.0907058
I0110 19:20:48.575352  4932 solver.cpp:255]     Train net output #0: loss = 0.061033 (* 1 = 0.061033 loss)
I0110 19:20:48.575364  4932 solver.cpp:631] Iteration 44920, lr = 1e-07
I0110 19:21:08.886468  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6754 > 20) by scale factor 0.844757
I0110 19:21:33.226342  4932 solver.cpp:240] Iteration 44940, loss = 0.06983
I0110 19:21:33.226420  4932 solver.cpp:255]     Train net output #0: loss = 0.0411007 (* 1 = 0.0411007 loss)
I0110 19:21:33.226431  4932 solver.cpp:631] Iteration 44940, lr = 1e-07
I0110 19:22:18.732025  4932 solver.cpp:240] Iteration 44960, loss = 0.0646538
I0110 19:22:18.732112  4932 solver.cpp:255]     Train net output #0: loss = 0.0444653 (* 1 = 0.0444653 loss)
I0110 19:22:18.732126  4932 solver.cpp:631] Iteration 44960, lr = 1e-07
I0110 19:23:03.161309  4932 solver.cpp:240] Iteration 44980, loss = 0.0527242
I0110 19:23:03.161432  4932 solver.cpp:255]     Train net output #0: loss = 0.0148562 (* 1 = 0.0148562 loss)
I0110 19:23:03.161444  4932 solver.cpp:631] Iteration 44980, lr = 1e-07
I0110 19:23:47.033550  4932 solver.cpp:424] Iteration 45000, Testing net (#0)
I0110 19:24:38.001523  4932 solver.cpp:481]     Test net output #0: accuracy = 0.813684
I0110 19:24:38.001631  4932 solver.cpp:481]     Test net output #1: loss = 0.963391 (* 1 = 0.963391 loss)
I0110 19:24:39.869053  4932 solver.cpp:240] Iteration 45000, loss = 0.0605297
I0110 19:24:39.869087  4932 solver.cpp:255]     Train net output #0: loss = 0.138992 (* 1 = 0.138992 loss)
I0110 19:24:39.869096  4932 solver.cpp:631] Iteration 45000, lr = 1e-07
I0110 19:24:46.862905  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0134 > 20) by scale factor 0.86906
I0110 19:24:53.520493  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9231 > 20) by scale factor 0.771514
I0110 19:25:20.145648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0767 > 20) by scale factor 0.905931
I0110 19:25:25.617399  4932 solver.cpp:240] Iteration 45020, loss = 0.0748331
I0110 19:25:25.617439  4932 solver.cpp:255]     Train net output #0: loss = 0.0110079 (* 1 = 0.0110079 loss)
I0110 19:25:25.617449  4932 solver.cpp:631] Iteration 45020, lr = 1e-07
I0110 19:25:28.174578  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.677 > 20) by scale factor 0.967256
I0110 19:26:10.977716  4932 solver.cpp:240] Iteration 45040, loss = 0.0521257
I0110 19:26:10.977798  4932 solver.cpp:255]     Train net output #0: loss = 0.0078064 (* 1 = 0.0078064 loss)
I0110 19:26:10.977810  4932 solver.cpp:631] Iteration 45040, lr = 1e-07
I0110 19:26:56.844123  4932 solver.cpp:240] Iteration 45060, loss = 0.0746083
I0110 19:26:56.844210  4932 solver.cpp:255]     Train net output #0: loss = 0.000453618 (* 1 = 0.000453618 loss)
I0110 19:26:56.844221  4932 solver.cpp:631] Iteration 45060, lr = 1e-07
I0110 19:27:33.875712  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5549 > 20) by scale factor 0.814501
I0110 19:27:42.413935  4932 solver.cpp:240] Iteration 45080, loss = 0.0551308
I0110 19:27:42.413969  4932 solver.cpp:255]     Train net output #0: loss = 0.0310968 (* 1 = 0.0310968 loss)
I0110 19:27:42.413977  4932 solver.cpp:631] Iteration 45080, lr = 1e-07
I0110 19:28:34.621330  4932 solver.cpp:240] Iteration 45100, loss = 0.0569304
I0110 19:28:34.621419  4932 solver.cpp:255]     Train net output #0: loss = 0.122366 (* 1 = 0.122366 loss)
I0110 19:28:34.621430  4932 solver.cpp:631] Iteration 45100, lr = 1e-07
I0110 19:29:20.486285  4932 solver.cpp:240] Iteration 45120, loss = 0.0611854
I0110 19:29:20.486379  4932 solver.cpp:255]     Train net output #0: loss = 0.00539103 (* 1 = 0.00539103 loss)
I0110 19:29:20.486392  4932 solver.cpp:631] Iteration 45120, lr = 1e-07
I0110 19:30:04.891800  4932 solver.cpp:240] Iteration 45140, loss = 0.0241816
I0110 19:30:04.891850  4932 solver.cpp:255]     Train net output #0: loss = 0.00219945 (* 1 = 0.00219945 loss)
I0110 19:30:04.891860  4932 solver.cpp:631] Iteration 45140, lr = 1e-07
I0110 19:30:07.449726  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0322 > 20) by scale factor 0.998391
I0110 19:30:18.571848  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8524 > 20) by scale factor 0.959124
I0110 19:30:38.543208  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9226 > 20) by scale factor 0.716267
I0110 19:30:49.533550  4932 solver.cpp:240] Iteration 45160, loss = 0.0830791
I0110 19:30:49.533596  4932 solver.cpp:255]     Train net output #0: loss = 0.02555 (* 1 = 0.02555 loss)
I0110 19:30:49.533608  4932 solver.cpp:631] Iteration 45160, lr = 1e-07
I0110 19:31:35.065155  4932 solver.cpp:240] Iteration 45180, loss = 0.041418
I0110 19:31:35.065227  4932 solver.cpp:255]     Train net output #0: loss = 0.0231342 (* 1 = 0.0231342 loss)
I0110 19:31:35.065237  4932 solver.cpp:631] Iteration 45180, lr = 1e-07
I0110 19:31:53.153182  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8569 > 20) by scale factor 0.804607
I0110 19:32:19.546972  4932 solver.cpp:240] Iteration 45200, loss = 0.062934
I0110 19:32:19.547080  4932 solver.cpp:255]     Train net output #0: loss = 0.12887 (* 1 = 0.12887 loss)
I0110 19:32:19.547093  4932 solver.cpp:631] Iteration 45200, lr = 1e-07
I0110 19:32:39.852870  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2676 > 20) by scale factor 0.761395
I0110 19:33:05.306432  4932 solver.cpp:240] Iteration 45220, loss = 0.0909167
I0110 19:33:05.306529  4932 solver.cpp:255]     Train net output #0: loss = 0.0869443 (* 1 = 0.0869443 loss)
I0110 19:33:05.306543  4932 solver.cpp:631] Iteration 45220, lr = 1e-07
I0110 19:33:49.686342  4932 solver.cpp:240] Iteration 45240, loss = 0.0534255
I0110 19:33:49.686441  4932 solver.cpp:255]     Train net output #0: loss = 0.00404548 (* 1 = 0.00404548 loss)
I0110 19:33:49.686455  4932 solver.cpp:631] Iteration 45240, lr = 1e-07
I0110 19:34:09.990263  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4902 > 20) by scale factor 0.930658
I0110 19:34:34.076810  4932 solver.cpp:240] Iteration 45260, loss = 0.0448421
I0110 19:34:34.076905  4932 solver.cpp:255]     Train net output #0: loss = 0.0973196 (* 1 = 0.0973196 loss)
I0110 19:34:34.076920  4932 solver.cpp:631] Iteration 45260, lr = 1e-07
I0110 19:35:18.448074  4932 solver.cpp:240] Iteration 45280, loss = 0.0510349
I0110 19:35:18.448163  4932 solver.cpp:255]     Train net output #0: loss = 0.0241119 (* 1 = 0.0241119 loss)
I0110 19:35:18.448173  4932 solver.cpp:631] Iteration 45280, lr = 1e-07
I0110 19:36:04.596916  4932 solver.cpp:240] Iteration 45300, loss = 0.069879
I0110 19:36:04.597007  4932 solver.cpp:255]     Train net output #0: loss = 0.144376 (* 1 = 0.144376 loss)
I0110 19:36:04.597018  4932 solver.cpp:631] Iteration 45300, lr = 1e-07
I0110 19:36:42.094848  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2283 > 20) by scale factor 0.861017
I0110 19:36:50.629467  4932 solver.cpp:240] Iteration 45320, loss = 0.0571629
I0110 19:36:50.629498  4932 solver.cpp:255]     Train net output #0: loss = 0.00356702 (* 1 = 0.00356702 loss)
I0110 19:36:50.629506  4932 solver.cpp:631] Iteration 45320, lr = 1e-07
I0110 19:37:15.397378  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4993 > 20) by scale factor 0.975645
I0110 19:37:34.338068  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4104 > 20) by scale factor 0.854322
I0110 19:37:36.218572  4932 solver.cpp:240] Iteration 45340, loss = 0.0704315
I0110 19:37:36.218612  4932 solver.cpp:255]     Train net output #0: loss = 0.0844713 (* 1 = 0.0844713 loss)
I0110 19:37:36.218622  4932 solver.cpp:631] Iteration 45340, lr = 1e-07
I0110 19:38:21.982748  4932 solver.cpp:240] Iteration 45360, loss = 0.0900918
I0110 19:38:21.982846  4932 solver.cpp:255]     Train net output #0: loss = 0.0278192 (* 1 = 0.0278192 loss)
I0110 19:38:21.982861  4932 solver.cpp:631] Iteration 45360, lr = 1e-07
I0110 19:38:35.629983  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9476 > 20) by scale factor 0.742182
I0110 19:39:00.305666  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1603 > 20) by scale factor 0.992046
I0110 19:39:06.629220  4932 solver.cpp:240] Iteration 45380, loss = 0.0854245
I0110 19:39:06.629253  4932 solver.cpp:255]     Train net output #0: loss = 0.00535089 (* 1 = 0.00535089 loss)
I0110 19:39:06.629263  4932 solver.cpp:631] Iteration 45380, lr = 1e-07
I0110 19:39:13.623227  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1965 > 20) by scale factor 0.901043
I0110 19:39:50.999943  4932 solver.cpp:240] Iteration 45400, loss = 0.0826782
I0110 19:39:51.000031  4932 solver.cpp:255]     Train net output #0: loss = 0.155743 (* 1 = 0.155743 loss)
I0110 19:39:51.000043  4932 solver.cpp:631] Iteration 45400, lr = 1e-07
I0110 19:40:22.762285  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5477 > 20) by scale factor 0.928174
I0110 19:40:35.737628  4932 solver.cpp:240] Iteration 45420, loss = 0.0694927
I0110 19:40:35.737673  4932 solver.cpp:255]     Train net output #0: loss = 0.0753483 (* 1 = 0.0753483 loss)
I0110 19:40:35.737685  4932 solver.cpp:631] Iteration 45420, lr = 1e-07
I0110 19:40:58.268124  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7598 > 20) by scale factor 0.963401
I0110 19:41:20.120333  4932 solver.cpp:240] Iteration 45440, loss = 0.0534494
I0110 19:41:20.120373  4932 solver.cpp:255]     Train net output #0: loss = 0.0619845 (* 1 = 0.0619845 loss)
I0110 19:41:20.120381  4932 solver.cpp:631] Iteration 45440, lr = 1e-07
I0110 19:42:04.499061  4932 solver.cpp:240] Iteration 45460, loss = 0.0642246
I0110 19:42:04.499173  4932 solver.cpp:255]     Train net output #0: loss = 0.135417 (* 1 = 0.135417 loss)
I0110 19:42:04.499189  4932 solver.cpp:631] Iteration 45460, lr = 1e-07
I0110 19:42:07.059202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0245 > 20) by scale factor 0.95127
I0110 19:42:49.153050  4932 solver.cpp:240] Iteration 45480, loss = 0.0602612
I0110 19:42:49.153142  4932 solver.cpp:255]     Train net output #0: loss = 0.168948 (* 1 = 0.168948 loss)
I0110 19:42:49.153156  4932 solver.cpp:631] Iteration 45480, lr = 1e-07
I0110 19:43:29.421360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0049 > 20) by scale factor 0.999754
I0110 19:43:33.522765  4932 solver.cpp:240] Iteration 45500, loss = 0.0433364
I0110 19:43:33.522802  4932 solver.cpp:255]     Train net output #0: loss = 0.0521349 (* 1 = 0.0521349 loss)
I0110 19:43:33.522811  4932 solver.cpp:631] Iteration 45500, lr = 1e-07
I0110 19:44:02.848592  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0503 > 20) by scale factor 0.907018
I0110 19:44:18.314613  4932 solver.cpp:240] Iteration 45520, loss = 0.0522353
I0110 19:44:18.314654  4932 solver.cpp:255]     Train net output #0: loss = 0.0392057 (* 1 = 0.0392057 loss)
I0110 19:44:18.314664  4932 solver.cpp:631] Iteration 45520, lr = 1e-07
I0110 19:45:02.841830  4932 solver.cpp:240] Iteration 45540, loss = 0.0693309
I0110 19:45:02.841928  4932 solver.cpp:255]     Train net output #0: loss = 0.000754351 (* 1 = 0.000754351 loss)
I0110 19:45:02.841941  4932 solver.cpp:631] Iteration 45540, lr = 1e-07
I0110 19:45:16.489446  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7771 > 20) by scale factor 0.9626
I0110 19:45:47.218722  4932 solver.cpp:240] Iteration 45560, loss = 0.0565488
I0110 19:45:47.218806  4932 solver.cpp:255]     Train net output #0: loss = 0.101145 (* 1 = 0.101145 loss)
I0110 19:45:47.218816  4932 solver.cpp:631] Iteration 45560, lr = 1e-07
I0110 19:46:31.728538  4932 solver.cpp:240] Iteration 45580, loss = 0.0595707
I0110 19:46:31.728624  4932 solver.cpp:255]     Train net output #0: loss = 0.0201574 (* 1 = 0.0201574 loss)
I0110 19:46:31.728637  4932 solver.cpp:631] Iteration 45580, lr = 1e-07
I0110 19:47:03.129155  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0602 > 20) by scale factor 0.949659
I0110 19:47:16.105100  4932 solver.cpp:240] Iteration 45600, loss = 0.0466945
I0110 19:47:16.105132  4932 solver.cpp:255]     Train net output #0: loss = 0.131282 (* 1 = 0.131282 loss)
I0110 19:47:16.105141  4932 solver.cpp:631] Iteration 45600, lr = 1e-07
I0110 19:48:00.800053  4932 solver.cpp:240] Iteration 45620, loss = 0.0447233
I0110 19:48:00.800155  4932 solver.cpp:255]     Train net output #0: loss = 0.10244 (* 1 = 0.10244 loss)
I0110 19:48:00.800169  4932 solver.cpp:631] Iteration 45620, lr = 1e-07
I0110 19:48:45.262904  4932 solver.cpp:240] Iteration 45640, loss = 0.0506878
I0110 19:48:45.262990  4932 solver.cpp:255]     Train net output #0: loss = 0.289684 (* 1 = 0.289684 loss)
I0110 19:48:45.263002  4932 solver.cpp:631] Iteration 45640, lr = 1e-07
I0110 19:48:45.602524  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6995 > 20) by scale factor 0.966209
I0110 19:49:29.821554  4932 solver.cpp:240] Iteration 45660, loss = 0.0725381
I0110 19:49:29.821662  4932 solver.cpp:255]     Train net output #0: loss = 0.268309 (* 1 = 0.268309 loss)
I0110 19:49:29.821676  4932 solver.cpp:631] Iteration 45660, lr = 1e-07
I0110 19:49:43.476342  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8079 > 20) by scale factor 0.961174
I0110 19:49:52.358247  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.3003 > 20) by scale factor 0.55096
I0110 19:50:14.207793  4932 solver.cpp:240] Iteration 45680, loss = 0.0838247
I0110 19:50:14.207887  4932 solver.cpp:255]     Train net output #0: loss = 0.164333 (* 1 = 0.164333 loss)
I0110 19:50:14.207900  4932 solver.cpp:631] Iteration 45680, lr = 1e-07
I0110 19:50:21.202970  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7226 > 20) by scale factor 0.96513
I0110 19:50:59.011893  4932 solver.cpp:240] Iteration 45700, loss = 0.0620078
I0110 19:50:59.011981  4932 solver.cpp:255]     Train net output #0: loss = 0.0631418 (* 1 = 0.0631418 loss)
I0110 19:50:59.011994  4932 solver.cpp:631] Iteration 45700, lr = 1e-07
I0110 19:51:06.093924  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8891 > 20) by scale factor 0.957436
I0110 19:51:43.496176  4932 solver.cpp:240] Iteration 45720, loss = 0.057698
I0110 19:51:43.496268  4932 solver.cpp:255]     Train net output #0: loss = 0.00472193 (* 1 = 0.00472193 loss)
I0110 19:51:43.496280  4932 solver.cpp:631] Iteration 45720, lr = 1e-07
I0110 19:52:27.875463  4932 solver.cpp:240] Iteration 45740, loss = 0.0416366
I0110 19:52:27.875543  4932 solver.cpp:255]     Train net output #0: loss = 0.146374 (* 1 = 0.146374 loss)
I0110 19:52:27.875553  4932 solver.cpp:631] Iteration 45740, lr = 1e-07
I0110 19:53:12.249356  4932 solver.cpp:240] Iteration 45760, loss = 0.0422228
I0110 19:53:12.249440  4932 solver.cpp:255]     Train net output #0: loss = 0.000746826 (* 1 = 0.000746826 loss)
I0110 19:53:12.249452  4932 solver.cpp:631] Iteration 45760, lr = 1e-07
I0110 19:53:57.276739  4932 solver.cpp:240] Iteration 45780, loss = 0.0282424
I0110 19:53:57.276839  4932 solver.cpp:255]     Train net output #0: loss = 0.0243999 (* 1 = 0.0243999 loss)
I0110 19:53:57.276852  4932 solver.cpp:631] Iteration 45780, lr = 1e-07
I0110 19:54:37.563776  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3475 > 20) by scale factor 0.681489
I0110 19:54:41.665923  4932 solver.cpp:240] Iteration 45800, loss = 0.0780559
I0110 19:54:41.665961  4932 solver.cpp:255]     Train net output #0: loss = 0.103447 (* 1 = 0.103447 loss)
I0110 19:54:41.665971  4932 solver.cpp:631] Iteration 45800, lr = 1e-07
I0110 19:55:10.029498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.318 > 20) by scale factor 0.896139
I0110 19:55:27.441221  4932 solver.cpp:240] Iteration 45820, loss = 0.0419693
I0110 19:55:27.441267  4932 solver.cpp:255]     Train net output #0: loss = 0.00176606 (* 1 = 0.00176606 loss)
I0110 19:55:27.441280  4932 solver.cpp:631] Iteration 45820, lr = 1e-07
I0110 19:55:48.992074  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5884 > 20) by scale factor 0.847874
I0110 19:55:53.434222  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9672 > 20) by scale factor 0.910447
I0110 19:56:00.090831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0575 > 20) by scale factor 0.831342
I0110 19:56:14.497380  4932 solver.cpp:240] Iteration 45840, loss = 0.0594888
I0110 19:56:14.497419  4932 solver.cpp:255]     Train net output #0: loss = 0.000578128 (* 1 = 0.000578128 loss)
I0110 19:56:14.497428  4932 solver.cpp:631] Iteration 45840, lr = 1e-07
I0110 19:56:25.931525  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4931 > 20) by scale factor 0.889161
I0110 19:56:55.793591  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1103 > 20) by scale factor 0.947405
I0110 19:56:59.896775  4932 solver.cpp:240] Iteration 45860, loss = 0.0701408
I0110 19:56:59.896886  4932 solver.cpp:255]     Train net output #0: loss = 0.0091906 (* 1 = 0.0091906 loss)
I0110 19:56:59.896903  4932 solver.cpp:631] Iteration 45860, lr = 1e-07
I0110 19:57:09.113301  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8161 > 20) by scale factor 0.916754
I0110 19:57:15.774781  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0541 > 20) by scale factor 0.90686
I0110 19:57:45.057319  4932 solver.cpp:240] Iteration 45880, loss = 0.0593198
I0110 19:57:45.057410  4932 solver.cpp:255]     Train net output #0: loss = 0.00518848 (* 1 = 0.00518848 loss)
I0110 19:57:45.057421  4932 solver.cpp:631] Iteration 45880, lr = 1e-07
I0110 19:57:58.709256  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.3526 > 20) by scale factor 0.658923
I0110 19:58:12.305377  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1833 > 20) by scale factor 0.90158
I0110 19:58:29.713176  4932 solver.cpp:240] Iteration 45900, loss = 0.0758992
I0110 19:58:29.713287  4932 solver.cpp:255]     Train net output #0: loss = 0.108952 (* 1 = 0.108952 loss)
I0110 19:58:29.713304  4932 solver.cpp:631] Iteration 45900, lr = 1e-07
I0110 19:59:16.409637  4932 solver.cpp:240] Iteration 45920, loss = 0.045087
I0110 19:59:16.409729  4932 solver.cpp:255]     Train net output #0: loss = 0.0609877 (* 1 = 0.0609877 loss)
I0110 19:59:16.409741  4932 solver.cpp:631] Iteration 45920, lr = 1e-07
I0110 19:59:36.719995  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.699 > 20) by scale factor 0.673424
I0110 19:59:38.939574  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9335 > 20) by scale factor 0.802133
I0110 19:59:55.616616  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1104 > 20) by scale factor 0.994511
I0110 20:00:01.932621  4932 solver.cpp:240] Iteration 45940, loss = 0.110113
I0110 20:00:01.932658  4932 solver.cpp:255]     Train net output #0: loss = 0.2217 (* 1 = 0.2217 loss)
I0110 20:00:01.932667  4932 solver.cpp:631] Iteration 45940, lr = 1e-07
I0110 20:00:02.271721  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4632 > 20) by scale factor 0.93183
I0110 20:00:11.150763  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5178 > 20) by scale factor 0.888186
I0110 20:00:13.372548  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1232 > 20) by scale factor 0.829078
I0110 20:00:36.791177  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6353 > 20) by scale factor 0.674871
I0110 20:00:47.546358  4932 solver.cpp:240] Iteration 45960, loss = 0.0761646
I0110 20:00:47.546396  4932 solver.cpp:255]     Train net output #0: loss = 0.00285548 (* 1 = 0.00285548 loss)
I0110 20:00:47.546406  4932 solver.cpp:631] Iteration 45960, lr = 1e-07
I0110 20:01:27.963074  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.923 > 20) by scale factor 0.836014
I0110 20:01:32.063832  4932 solver.cpp:240] Iteration 45980, loss = 0.0657402
I0110 20:01:32.063871  4932 solver.cpp:255]     Train net output #0: loss = 0.000967763 (* 1 = 0.000967763 loss)
I0110 20:01:32.063880  4932 solver.cpp:631] Iteration 45980, lr = 1e-07
I0110 20:02:15.778235  4932 solver.cpp:424] Iteration 46000, Testing net (#0)
I0110 20:03:06.754328  4932 solver.cpp:481]     Test net output #0: accuracy = 0.847368
I0110 20:03:06.754427  4932 solver.cpp:481]     Test net output #1: loss = 0.744235 (* 1 = 0.744235 loss)
I0110 20:03:08.622637  4932 solver.cpp:240] Iteration 46000, loss = 0.0638334
I0110 20:03:08.622668  4932 solver.cpp:255]     Train net output #0: loss = 0.0877298 (* 1 = 0.0877298 loss)
I0110 20:03:08.622676  4932 solver.cpp:631] Iteration 46000, lr = 1e-07
I0110 20:03:51.287811  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.7112 > 20) by scale factor 0.611412
I0110 20:03:53.171075  4932 solver.cpp:240] Iteration 46020, loss = 0.0500562
I0110 20:03:53.171123  4932 solver.cpp:255]     Train net output #0: loss = 0.0575775 (* 1 = 0.0575775 loss)
I0110 20:03:53.171135  4932 solver.cpp:631] Iteration 46020, lr = 1e-07
I0110 20:04:02.393934  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7114 > 20) by scale factor 0.777866
I0110 20:04:21.834687  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0027 > 20) by scale factor 0.999863
I0110 20:04:39.259172  4932 solver.cpp:240] Iteration 46040, loss = 0.0533402
I0110 20:04:39.259204  4932 solver.cpp:255]     Train net output #0: loss = 0.0107493 (* 1 = 0.0107493 loss)
I0110 20:04:39.259214  4932 solver.cpp:631] Iteration 46040, lr = 1e-07
I0110 20:04:55.864053  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5562 > 20) by scale factor 0.972942
I0110 20:05:25.249812  4932 solver.cpp:240] Iteration 46060, loss = 0.0609097
I0110 20:05:25.249856  4932 solver.cpp:255]     Train net output #0: loss = 0.0319707 (* 1 = 0.0319707 loss)
I0110 20:05:25.249868  4932 solver.cpp:631] Iteration 46060, lr = 1e-07
I0110 20:06:09.642037  4932 solver.cpp:240] Iteration 46080, loss = 0.0795542
I0110 20:06:09.642127  4932 solver.cpp:255]     Train net output #0: loss = 0.194034 (* 1 = 0.194034 loss)
I0110 20:06:09.642139  4932 solver.cpp:631] Iteration 46080, lr = 1e-07
I0110 20:06:09.981269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.001 > 20) by scale factor 0.952334
I0110 20:06:25.872932  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0634 > 20) by scale factor 0.867177
I0110 20:06:54.623873  4932 solver.cpp:240] Iteration 46100, loss = 0.0421573
I0110 20:06:54.623952  4932 solver.cpp:255]     Train net output #0: loss = 0.0669493 (* 1 = 0.0669493 loss)
I0110 20:06:54.623963  4932 solver.cpp:631] Iteration 46100, lr = 1e-07
I0110 20:07:06.222822  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7125 > 20) by scale factor 0.92113
I0110 20:07:39.170671  4932 solver.cpp:240] Iteration 46120, loss = 0.0607444
I0110 20:07:39.170765  4932 solver.cpp:255]     Train net output #0: loss = 0.0433161 (* 1 = 0.0433161 loss)
I0110 20:07:39.170778  4932 solver.cpp:631] Iteration 46120, lr = 1e-07
I0110 20:08:12.795897  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6702 > 20) by scale factor 0.674076
I0110 20:08:15.017135  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4217 > 20) by scale factor 0.933631
I0110 20:08:23.555294  4932 solver.cpp:240] Iteration 46140, loss = 0.0647746
I0110 20:08:23.555331  4932 solver.cpp:255]     Train net output #0: loss = 0.0707234 (* 1 = 0.0707234 loss)
I0110 20:08:23.555341  4932 solver.cpp:631] Iteration 46140, lr = 1e-07
I0110 20:08:37.209787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2859 > 20) by scale factor 0.985906
I0110 20:08:43.870229  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3256 > 20) by scale factor 0.983981
I0110 20:08:50.534406  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.5727 > 20) by scale factor 0.614011
I0110 20:09:08.784405  4932 solver.cpp:240] Iteration 46160, loss = 0.0836334
I0110 20:09:08.784446  4932 solver.cpp:255]     Train net output #0: loss = 0.000534123 (* 1 = 0.000534123 loss)
I0110 20:09:08.784456  4932 solver.cpp:631] Iteration 46160, lr = 1e-07
I0110 20:09:44.632949  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1577 > 20) by scale factor 0.863642
I0110 20:09:53.171747  4932 solver.cpp:240] Iteration 46180, loss = 0.0865884
I0110 20:09:53.171792  4932 solver.cpp:255]     Train net output #0: loss = 0.0346271 (* 1 = 0.0346271 loss)
I0110 20:09:53.171803  4932 solver.cpp:631] Iteration 46180, lr = 1e-07
I0110 20:10:37.657196  4932 solver.cpp:240] Iteration 46200, loss = 0.0753796
I0110 20:10:37.657301  4932 solver.cpp:255]     Train net output #0: loss = 0.193014 (* 1 = 0.193014 loss)
I0110 20:10:37.657321  4932 solver.cpp:631] Iteration 46200, lr = 1e-07
I0110 20:11:22.281240  4932 solver.cpp:240] Iteration 46220, loss = 0.0399876
I0110 20:11:22.281329  4932 solver.cpp:255]     Train net output #0: loss = 0.0277276 (* 1 = 0.0277276 loss)
I0110 20:11:22.281342  4932 solver.cpp:631] Iteration 46220, lr = 1e-07
I0110 20:11:36.184037  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3042 > 20) by scale factor 0.985018
I0110 20:12:06.918340  4932 solver.cpp:240] Iteration 46240, loss = 0.0795212
I0110 20:12:06.918419  4932 solver.cpp:255]     Train net output #0: loss = 0.00534192 (* 1 = 0.00534192 loss)
I0110 20:12:06.918431  4932 solver.cpp:631] Iteration 46240, lr = 1e-07
I0110 20:12:27.464272  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2071 > 20) by scale factor 0.861804
I0110 20:12:51.603965  4932 solver.cpp:240] Iteration 46260, loss = 0.0466419
I0110 20:12:51.604074  4932 solver.cpp:255]     Train net output #0: loss = 0.0623136 (* 1 = 0.0623136 loss)
I0110 20:12:51.604090  4932 solver.cpp:631] Iteration 46260, lr = 1e-07
I0110 20:13:21.267325  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3702 > 20) by scale factor 0.981825
I0110 20:13:25.709398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.6357 > 20) by scale factor 0.652833
I0110 20:13:36.698899  4932 solver.cpp:240] Iteration 46280, loss = 0.0904169
I0110 20:13:36.698935  4932 solver.cpp:255]     Train net output #0: loss = 0.281122 (* 1 = 0.281122 loss)
I0110 20:13:36.698943  4932 solver.cpp:631] Iteration 46280, lr = 1e-07
I0110 20:13:41.479815  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.305 > 20) by scale factor 0.896662
I0110 20:14:17.778883  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2765 > 20) by scale factor 0.897806
I0110 20:14:21.882510  4932 solver.cpp:240] Iteration 46300, loss = 0.0715842
I0110 20:14:21.882558  4932 solver.cpp:255]     Train net output #0: loss = 0.0587914 (* 1 = 0.0587914 loss)
I0110 20:14:21.882695  4932 solver.cpp:631] Iteration 46300, lr = 1e-07
I0110 20:15:06.562136  4932 solver.cpp:240] Iteration 46320, loss = 0.0529339
I0110 20:15:06.562228  4932 solver.cpp:255]     Train net output #0: loss = 0.0323856 (* 1 = 0.0323856 loss)
I0110 20:15:06.562240  4932 solver.cpp:631] Iteration 46320, lr = 1e-07
I0110 20:15:31.670202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.9673 > 20) by scale factor 0.588802
I0110 20:15:51.298513  4932 solver.cpp:240] Iteration 46340, loss = 0.0736604
I0110 20:15:51.298610  4932 solver.cpp:255]     Train net output #0: loss = 0.165844 (* 1 = 0.165844 loss)
I0110 20:15:51.298622  4932 solver.cpp:631] Iteration 46340, lr = 1e-07
I0110 20:16:35.675858  4932 solver.cpp:240] Iteration 46360, loss = 0.0882481
I0110 20:16:35.675951  4932 solver.cpp:255]     Train net output #0: loss = 0.00895921 (* 1 = 0.00895921 loss)
I0110 20:16:35.675963  4932 solver.cpp:631] Iteration 46360, lr = 1e-07
I0110 20:17:22.158954  4932 solver.cpp:240] Iteration 46380, loss = 0.0753249
I0110 20:17:22.159045  4932 solver.cpp:255]     Train net output #0: loss = 0.280961 (* 1 = 0.280961 loss)
I0110 20:17:22.159060  4932 solver.cpp:631] Iteration 46380, lr = 1e-07
I0110 20:17:22.500457  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.849 > 20) by scale factor 0.804862
I0110 20:18:06.568506  4932 solver.cpp:240] Iteration 46400, loss = 0.042325
I0110 20:18:06.568610  4932 solver.cpp:255]     Train net output #0: loss = 0.00119132 (* 1 = 0.00119132 loss)
I0110 20:18:06.568626  4932 solver.cpp:631] Iteration 46400, lr = 1e-07
I0110 20:18:51.406178  4932 solver.cpp:240] Iteration 46420, loss = 0.0323641
I0110 20:18:51.406244  4932 solver.cpp:255]     Train net output #0: loss = 0.0389996 (* 1 = 0.0389996 loss)
I0110 20:18:51.406253  4932 solver.cpp:631] Iteration 46420, lr = 1e-07
I0110 20:18:55.008314  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2232 > 20) by scale factor 0.942367
I0110 20:19:08.318171  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9954 > 20) by scale factor 0.769366
I0110 20:19:36.826203  4932 solver.cpp:240] Iteration 46440, loss = 0.085765
I0110 20:19:36.826308  4932 solver.cpp:255]     Train net output #0: loss = 0.039808 (* 1 = 0.039808 loss)
I0110 20:19:36.826320  4932 solver.cpp:631] Iteration 46440, lr = 1e-07
I0110 20:19:48.253948  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.612 > 20) by scale factor 0.780884
I0110 20:19:58.281560  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9244 > 20) by scale factor 0.95582
I0110 20:20:22.347100  4932 solver.cpp:240] Iteration 46460, loss = 0.0713604
I0110 20:20:22.347200  4932 solver.cpp:255]     Train net output #0: loss = 0.00366342 (* 1 = 0.00366342 loss)
I0110 20:20:22.347214  4932 solver.cpp:631] Iteration 46460, lr = 1e-07
I0110 20:21:07.941740  4932 solver.cpp:240] Iteration 46480, loss = 0.081839
I0110 20:21:07.941825  4932 solver.cpp:255]     Train net output #0: loss = 0.0365169 (* 1 = 0.0365169 loss)
I0110 20:21:07.941836  4932 solver.cpp:631] Iteration 46480, lr = 1e-07
I0110 20:21:54.296313  4932 solver.cpp:240] Iteration 46500, loss = 0.0386985
I0110 20:21:54.296411  4932 solver.cpp:255]     Train net output #0: loss = 0.0824608 (* 1 = 0.0824608 loss)
I0110 20:21:54.296423  4932 solver.cpp:631] Iteration 46500, lr = 1e-07
I0110 20:22:03.511499  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0328 > 20) by scale factor 0.832195
I0110 20:22:34.583372  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2204 > 20) by scale factor 0.942491
I0110 20:22:38.687217  4932 solver.cpp:240] Iteration 46520, loss = 0.0718286
I0110 20:22:38.687258  4932 solver.cpp:255]     Train net output #0: loss = 0.139003 (* 1 = 0.139003 loss)
I0110 20:22:38.687269  4932 solver.cpp:631] Iteration 46520, lr = 1e-07
I0110 20:23:19.180481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.346 > 20) by scale factor 0.759129
I0110 20:23:23.281946  4932 solver.cpp:240] Iteration 46540, loss = 0.0371168
I0110 20:23:23.281998  4932 solver.cpp:255]     Train net output #0: loss = 0.00891037 (* 1 = 0.00891037 loss)
I0110 20:23:23.282014  4932 solver.cpp:631] Iteration 46540, lr = 1e-07
I0110 20:23:43.629611  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7597 > 20) by scale factor 0.807763
I0110 20:23:50.289494  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8393 > 20) by scale factor 0.959727
I0110 20:24:07.702925  4932 solver.cpp:240] Iteration 46560, loss = 0.0757559
I0110 20:24:07.702966  4932 solver.cpp:255]     Train net output #0: loss = 0.00451875 (* 1 = 0.00451875 loss)
I0110 20:24:07.702977  4932 solver.cpp:631] Iteration 46560, lr = 1e-07
I0110 20:24:35.881873  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3444 > 20) by scale factor 0.856738
I0110 20:24:54.162330  4932 solver.cpp:240] Iteration 46580, loss = 0.0685216
I0110 20:24:54.162371  4932 solver.cpp:255]     Train net output #0: loss = 0.0825553 (* 1 = 0.0825553 loss)
I0110 20:24:54.162380  4932 solver.cpp:631] Iteration 46580, lr = 1e-07
I0110 20:25:10.032117  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3013 > 20) by scale factor 0.985157
I0110 20:25:38.544668  4932 solver.cpp:240] Iteration 46600, loss = 0.0637103
I0110 20:25:38.544710  4932 solver.cpp:255]     Train net output #0: loss = 0.0148514 (* 1 = 0.0148514 loss)
I0110 20:25:38.544720  4932 solver.cpp:631] Iteration 46600, lr = 1e-07
I0110 20:25:45.539728  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0204 > 20) by scale factor 0.998981
I0110 20:26:23.932572  4932 solver.cpp:240] Iteration 46620, loss = 0.0683692
I0110 20:26:23.932665  4932 solver.cpp:255]     Train net output #0: loss = 0.090583 (* 1 = 0.090583 loss)
I0110 20:26:23.932679  4932 solver.cpp:631] Iteration 46620, lr = 1e-07
I0110 20:27:09.336809  4932 solver.cpp:240] Iteration 46640, loss = 0.0227165
I0110 20:27:09.336921  4932 solver.cpp:255]     Train net output #0: loss = 0.00443146 (* 1 = 0.00443146 loss)
I0110 20:27:09.336935  4932 solver.cpp:631] Iteration 46640, lr = 1e-07
I0110 20:27:29.661011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9914 > 20) by scale factor 0.95277
I0110 20:27:35.259342  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7623 > 20) by scale factor 0.963286
I0110 20:27:54.905485  4932 solver.cpp:240] Iteration 46660, loss = 0.0819183
I0110 20:27:54.905571  4932 solver.cpp:255]     Train net output #0: loss = 0.0215549 (* 1 = 0.0215549 loss)
I0110 20:27:54.905585  4932 solver.cpp:631] Iteration 46660, lr = 1e-07
I0110 20:27:59.687296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6627 > 20) by scale factor 0.845213
I0110 20:28:04.131960  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7706 > 20) by scale factor 0.776077
I0110 20:28:40.216678  4932 solver.cpp:240] Iteration 46680, loss = 0.0903736
I0110 20:28:40.216789  4932 solver.cpp:255]     Train net output #0: loss = 0.0933337 (* 1 = 0.0933337 loss)
I0110 20:28:40.216806  4932 solver.cpp:631] Iteration 46680, lr = 1e-07
I0110 20:28:40.557097  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6718 > 20) by scale factor 0.967503
I0110 20:29:00.963528  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.1985 > 20) by scale factor 0.662284
I0110 20:29:14.286495  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1153 > 20) by scale factor 0.994266
I0110 20:29:22.249351  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3219 > 20) by scale factor 0.984161
I0110 20:29:26.350350  4932 solver.cpp:240] Iteration 46700, loss = 0.0677858
I0110 20:29:26.350388  4932 solver.cpp:255]     Train net output #0: loss = 0.000155484 (* 1 = 0.000155484 loss)
I0110 20:29:26.350396  4932 solver.cpp:631] Iteration 46700, lr = 1e-07
I0110 20:29:49.083802  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.567 > 20) by scale factor 0.814101
I0110 20:30:06.833091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9632 > 20) by scale factor 0.770323
I0110 20:30:11.195206  4932 solver.cpp:240] Iteration 46720, loss = 0.0744228
I0110 20:30:11.195245  4932 solver.cpp:255]     Train net output #0: loss = 0.091465 (* 1 = 0.091465 loss)
I0110 20:30:11.195255  4932 solver.cpp:631] Iteration 46720, lr = 1e-07
I0110 20:30:15.975932  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1456 > 20) by scale factor 0.903112
I0110 20:30:20.415194  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5607 > 20) by scale factor 0.814308
I0110 20:30:51.487828  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6675 > 20) by scale factor 0.779195
I0110 20:30:55.847280  4932 solver.cpp:240] Iteration 46740, loss = 0.0782334
I0110 20:30:55.847319  4932 solver.cpp:255]     Train net output #0: loss = 0.114933 (* 1 = 0.114933 loss)
I0110 20:30:55.847331  4932 solver.cpp:631] Iteration 46740, lr = 1e-07
I0110 20:31:40.377540  4932 solver.cpp:240] Iteration 46760, loss = 0.0614978
I0110 20:31:40.377626  4932 solver.cpp:255]     Train net output #0: loss = 0.00821111 (* 1 = 0.00821111 loss)
I0110 20:31:40.377640  4932 solver.cpp:631] Iteration 46760, lr = 1e-07
I0110 20:32:26.195885  4932 solver.cpp:240] Iteration 46780, loss = 0.0993877
I0110 20:32:26.195977  4932 solver.cpp:255]     Train net output #0: loss = 0.00292173 (* 1 = 0.00292173 loss)
I0110 20:32:26.195991  4932 solver.cpp:631] Iteration 46780, lr = 1e-07
I0110 20:33:11.805006  4932 solver.cpp:240] Iteration 46800, loss = 0.0646521
I0110 20:33:11.805088  4932 solver.cpp:255]     Train net output #0: loss = 0.0719469 (* 1 = 0.0719469 loss)
I0110 20:33:11.805099  4932 solver.cpp:631] Iteration 46800, lr = 1e-07
I0110 20:33:21.020918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0005 > 20) by scale factor 0.769215
I0110 20:33:34.335805  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7638 > 20) by scale factor 0.841616
I0110 20:33:38.780210  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4173 > 20) by scale factor 0.819092
I0110 20:33:56.775739  4932 solver.cpp:240] Iteration 46820, loss = 0.124654
I0110 20:33:56.775848  4932 solver.cpp:255]     Train net output #0: loss = 0.0291744 (* 1 = 0.0291744 loss)
I0110 20:33:56.775862  4932 solver.cpp:631] Iteration 46820, lr = 1e-07
I0110 20:34:41.225941  4932 solver.cpp:240] Iteration 46840, loss = 0.0487669
I0110 20:34:41.226045  4932 solver.cpp:255]     Train net output #0: loss = 0.0284045 (* 1 = 0.0284045 loss)
I0110 20:34:41.226058  4932 solver.cpp:631] Iteration 46840, lr = 1e-07
I0110 20:35:05.126756  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9568 > 20) by scale factor 0.871202
I0110 20:35:26.982074  4932 solver.cpp:240] Iteration 46860, loss = 0.0649732
I0110 20:35:26.982174  4932 solver.cpp:255]     Train net output #0: loss = 0.141923 (* 1 = 0.141923 loss)
I0110 20:35:26.982187  4932 solver.cpp:631] Iteration 46860, lr = 1e-07
I0110 20:35:27.321095  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4545 > 20) by scale factor 0.932203
I0110 20:35:42.853005  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6391 > 20) by scale factor 0.924253
I0110 20:35:56.182865  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.421 > 20) by scale factor 0.933662
I0110 20:36:11.378214  4932 solver.cpp:240] Iteration 46880, loss = 0.106047
I0110 20:36:11.378312  4932 solver.cpp:255]     Train net output #0: loss = 0.121224 (* 1 = 0.121224 loss)
I0110 20:36:11.378325  4932 solver.cpp:631] Iteration 46880, lr = 1e-07
I0110 20:36:55.796314  4932 solver.cpp:240] Iteration 46900, loss = 0.037858
I0110 20:36:55.796402  4932 solver.cpp:255]     Train net output #0: loss = 0.0399351 (* 1 = 0.0399351 loss)
I0110 20:36:55.796414  4932 solver.cpp:631] Iteration 46900, lr = 1e-07
I0110 20:37:05.014983  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5863 > 20) by scale factor 0.84795
I0110 20:37:24.984710  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8174 > 20) by scale factor 0.805886
I0110 20:37:33.979060  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2798 > 20) by scale factor 0.859113
I0110 20:37:40.300130  4932 solver.cpp:240] Iteration 46920, loss = 0.0627754
I0110 20:37:40.300171  4932 solver.cpp:255]     Train net output #0: loss = 0.0300154 (* 1 = 0.0300154 loss)
I0110 20:37:40.300180  4932 solver.cpp:631] Iteration 46920, lr = 1e-07
I0110 20:37:45.075819  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2346 > 20) by scale factor 0.899499
I0110 20:38:24.919675  4932 solver.cpp:240] Iteration 46940, loss = 0.0476478
I0110 20:38:24.919775  4932 solver.cpp:255]     Train net output #0: loss = 0.0115993 (* 1 = 0.0115993 loss)
I0110 20:38:24.919790  4932 solver.cpp:631] Iteration 46940, lr = 1e-07
I0110 20:38:31.914379  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1504 > 20) by scale factor 0.795217
I0110 20:38:51.885527  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9279 > 20) by scale factor 0.646666
I0110 20:38:54.106531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5093 > 20) by scale factor 0.677751
I0110 20:38:58.551688  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1681 > 20) by scale factor 0.991665
I0110 20:39:09.309974  4932 solver.cpp:240] Iteration 46960, loss = 0.0627521
I0110 20:39:09.310011  4932 solver.cpp:255]     Train net output #0: loss = 0.0901552 (* 1 = 0.0901552 loss)
I0110 20:39:09.310021  4932 solver.cpp:631] Iteration 46960, lr = 1e-07
I0110 20:39:53.906292  4932 solver.cpp:240] Iteration 46980, loss = 0.0450844
I0110 20:39:53.906410  4932 solver.cpp:255]     Train net output #0: loss = 0.00240333 (* 1 = 0.00240333 loss)
I0110 20:39:53.906424  4932 solver.cpp:631] Iteration 46980, lr = 1e-07
I0110 20:40:36.407032  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0987 > 20) by scale factor 0.766321
I0110 20:40:36.416007  4932 solver.cpp:424] Iteration 47000, Testing net (#0)
I0110 20:41:26.580807  4932 solver.cpp:481]     Test net output #0: accuracy = 0.841053
I0110 20:41:26.580916  4932 solver.cpp:481]     Test net output #1: loss = 0.759274 (* 1 = 0.759274 loss)
I0110 20:41:28.448988  4932 solver.cpp:240] Iteration 47000, loss = 0.0771697
I0110 20:41:28.449030  4932 solver.cpp:255]     Train net output #0: loss = 0.0819178 (* 1 = 0.0819178 loss)
I0110 20:41:28.449041  4932 solver.cpp:631] Iteration 47000, lr = 1e-07
I0110 20:42:12.829160  4932 solver.cpp:240] Iteration 47020, loss = 0.0676702
I0110 20:42:12.829267  4932 solver.cpp:255]     Train net output #0: loss = 0.0411989 (* 1 = 0.0411989 loss)
I0110 20:42:12.829282  4932 solver.cpp:631] Iteration 47020, lr = 1e-07
I0110 20:42:22.051869  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1992 > 20) by scale factor 0.990138
I0110 20:42:57.511714  4932 solver.cpp:240] Iteration 47040, loss = 0.0520916
I0110 20:42:57.511775  4932 solver.cpp:255]     Train net output #0: loss = 0.00828021 (* 1 = 0.00828021 loss)
I0110 20:42:57.511786  4932 solver.cpp:631] Iteration 47040, lr = 1e-07
I0110 20:43:17.835252  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8757 > 20) by scale factor 0.958053
I0110 20:43:35.596204  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9056 > 20) by scale factor 0.913008
I0110 20:43:41.919337  4932 solver.cpp:240] Iteration 47060, loss = 0.0603573
I0110 20:43:41.919378  4932 solver.cpp:255]     Train net output #0: loss = 0.232931 (* 1 = 0.232931 loss)
I0110 20:43:41.919387  4932 solver.cpp:631] Iteration 47060, lr = 1e-07
I0110 20:43:42.258987  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5534 > 20) by scale factor 0.973076
I0110 20:44:26.424445  4932 solver.cpp:240] Iteration 47080, loss = 0.0620225
I0110 20:44:26.424556  4932 solver.cpp:255]     Train net output #0: loss = 0.199294 (* 1 = 0.199294 loss)
I0110 20:44:26.424572  4932 solver.cpp:631] Iteration 47080, lr = 1e-07
I0110 20:44:57.880123  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3959 > 20) by scale factor 0.787527
I0110 20:45:10.853406  4932 solver.cpp:240] Iteration 47100, loss = 0.081335
I0110 20:45:10.853444  4932 solver.cpp:255]     Train net output #0: loss = 0.00206015 (* 1 = 0.00206015 loss)
I0110 20:45:10.853454  4932 solver.cpp:631] Iteration 47100, lr = 1e-07
I0110 20:45:17.848757  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5838 > 20) by scale factor 0.848039
I0110 20:45:28.945775  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5105 > 20) by scale factor 0.975112
I0110 20:45:55.802011  4932 solver.cpp:240] Iteration 47120, loss = 0.0814458
I0110 20:45:55.802044  4932 solver.cpp:255]     Train net output #0: loss = 0.0178053 (* 1 = 0.0178053 loss)
I0110 20:45:55.802053  4932 solver.cpp:631] Iteration 47120, lr = 1e-07
I0110 20:46:05.014422  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.133 > 20) by scale factor 0.993392
I0110 20:46:40.244621  4932 solver.cpp:240] Iteration 47140, loss = 0.0461506
I0110 20:46:40.244709  4932 solver.cpp:255]     Train net output #0: loss = 0.010066 (* 1 = 0.010066 loss)
I0110 20:46:40.244721  4932 solver.cpp:631] Iteration 47140, lr = 1e-07
I0110 20:46:53.899775  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1541 > 20) by scale factor 0.68601
I0110 20:47:00.563030  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7208 > 20) by scale factor 0.965212
I0110 20:47:25.351483  4932 solver.cpp:240] Iteration 47160, loss = 0.082808
I0110 20:47:25.351598  4932 solver.cpp:255]     Train net output #0: loss = 0.031669 (* 1 = 0.031669 loss)
I0110 20:47:25.351610  4932 solver.cpp:631] Iteration 47160, lr = 1e-07
I0110 20:47:56.769151  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3449 > 20) by scale factor 0.983046
I0110 20:48:09.750247  4932 solver.cpp:240] Iteration 47180, loss = 0.059943
I0110 20:48:09.750293  4932 solver.cpp:255]     Train net output #0: loss = 0.15565 (* 1 = 0.15565 loss)
I0110 20:48:09.750304  4932 solver.cpp:631] Iteration 47180, lr = 1e-07
I0110 20:48:25.624116  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.278 > 20) by scale factor 0.93994
I0110 20:48:27.845896  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6583 > 20) by scale factor 0.882679
I0110 20:48:41.231498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2458 > 20) by scale factor 0.98786
I0110 20:48:54.477763  4932 solver.cpp:240] Iteration 47200, loss = 0.0670583
I0110 20:48:54.477815  4932 solver.cpp:255]     Train net output #0: loss = 0.0064469 (* 1 = 0.0064469 loss)
I0110 20:48:54.477829  4932 solver.cpp:631] Iteration 47200, lr = 1e-07
I0110 20:49:03.942128  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5342 > 20) by scale factor 0.928756
I0110 20:49:32.797520  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2004 > 20) by scale factor 0.862053
I0110 20:49:39.116160  4932 solver.cpp:240] Iteration 47220, loss = 0.0477341
I0110 20:49:39.116261  4932 solver.cpp:255]     Train net output #0: loss = 0.00683841 (* 1 = 0.00683841 loss)
I0110 20:49:39.116273  4932 solver.cpp:631] Iteration 47220, lr = 1e-07
I0110 20:50:24.900288  4932 solver.cpp:240] Iteration 47240, loss = 0.0607444
I0110 20:50:24.900372  4932 solver.cpp:255]     Train net output #0: loss = 0.00977003 (* 1 = 0.00977003 loss)
I0110 20:50:24.900383  4932 solver.cpp:631] Iteration 47240, lr = 1e-07
I0110 20:51:08.107326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3166 > 20) by scale factor 0.984418
I0110 20:51:09.989586  4932 solver.cpp:240] Iteration 47260, loss = 0.0491797
I0110 20:51:09.989632  4932 solver.cpp:255]     Train net output #0: loss = 0.00314368 (* 1 = 0.00314368 loss)
I0110 20:51:09.989646  4932 solver.cpp:631] Iteration 47260, lr = 1e-07
I0110 20:51:23.801687  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4114 > 20) by scale factor 0.819289
I0110 20:51:54.585698  4932 solver.cpp:240] Iteration 47280, loss = 0.05694
I0110 20:51:54.585778  4932 solver.cpp:255]     Train net output #0: loss = 0.00337911 (* 1 = 0.00337911 loss)
I0110 20:51:54.585790  4932 solver.cpp:631] Iteration 47280, lr = 1e-07
I0110 20:52:03.808789  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0522 > 20) by scale factor 0.831526
I0110 20:52:40.333415  4932 solver.cpp:240] Iteration 47300, loss = 0.0673226
I0110 20:52:40.333513  4932 solver.cpp:255]     Train net output #0: loss = 0.012986 (* 1 = 0.012986 loss)
I0110 20:52:40.333528  4932 solver.cpp:631] Iteration 47300, lr = 1e-07
I0110 20:53:03.344296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2134 > 20) by scale factor 0.793228
I0110 20:53:10.001950  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0902 > 20) by scale factor 0.948307
I0110 20:53:25.202277  4932 solver.cpp:240] Iteration 47320, loss = 0.0498321
I0110 20:53:25.202373  4932 solver.cpp:255]     Train net output #0: loss = 0.00257058 (* 1 = 0.00257058 loss)
I0110 20:53:25.202386  4932 solver.cpp:631] Iteration 47320, lr = 1e-07
I0110 20:54:09.586982  4932 solver.cpp:240] Iteration 47340, loss = 0.0376129
I0110 20:54:09.587071  4932 solver.cpp:255]     Train net output #0: loss = 0.0566925 (* 1 = 0.0566925 loss)
I0110 20:54:09.587085  4932 solver.cpp:631] Iteration 47340, lr = 1e-07
I0110 20:54:18.804246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5653 > 20) by scale factor 0.886315
I0110 20:54:21.027940  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5187 > 20) by scale factor 0.754185
I0110 20:54:55.070691  4932 solver.cpp:240] Iteration 47360, loss = 0.0751821
I0110 20:54:55.070792  4932 solver.cpp:255]     Train net output #0: loss = 0.00284826 (* 1 = 0.00284826 loss)
I0110 20:54:55.070804  4932 solver.cpp:631] Iteration 47360, lr = 1e-07
I0110 20:55:19.885382  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2847 > 20) by scale factor 0.985965
I0110 20:55:30.987795  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3644 > 20) by scale factor 0.856004
I0110 20:55:39.526556  4932 solver.cpp:240] Iteration 47380, loss = 0.0724935
I0110 20:55:39.526595  4932 solver.cpp:255]     Train net output #0: loss = 0.0183342 (* 1 = 0.0183342 loss)
I0110 20:55:39.526608  4932 solver.cpp:631] Iteration 47380, lr = 1e-07
I0110 20:55:50.967803  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3325 > 20) by scale factor 0.983646
I0110 20:55:53.188895  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0013 > 20) by scale factor 0.909039
I0110 20:56:24.188623  4932 solver.cpp:240] Iteration 47400, loss = 0.0801565
I0110 20:56:24.188724  4932 solver.cpp:255]     Train net output #0: loss = 0.0736509 (* 1 = 0.0736509 loss)
I0110 20:56:24.188737  4932 solver.cpp:631] Iteration 47400, lr = 1e-07
I0110 20:57:08.571954  4932 solver.cpp:240] Iteration 47420, loss = 0.0351552
I0110 20:57:08.572049  4932 solver.cpp:255]     Train net output #0: loss = 0.0309073 (* 1 = 0.0309073 loss)
I0110 20:57:08.572064  4932 solver.cpp:631] Iteration 47420, lr = 1e-07
I0110 20:57:54.270663  4932 solver.cpp:240] Iteration 47440, loss = 0.0747011
I0110 20:57:54.270745  4932 solver.cpp:255]     Train net output #0: loss = 0.00663384 (* 1 = 0.00663384 loss)
I0110 20:57:54.270757  4932 solver.cpp:631] Iteration 47440, lr = 1e-07
I0110 20:58:39.718447  4932 solver.cpp:240] Iteration 47460, loss = 0.040805
I0110 20:58:39.718535  4932 solver.cpp:255]     Train net output #0: loss = 0.00217054 (* 1 = 0.00217054 loss)
I0110 20:58:39.718549  4932 solver.cpp:631] Iteration 47460, lr = 1e-07
I0110 20:58:51.650406  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2919 > 20) by scale factor 0.939323
I0110 20:59:25.063658  4932 solver.cpp:240] Iteration 47480, loss = 0.0687093
I0110 20:59:25.063733  4932 solver.cpp:255]     Train net output #0: loss = 0.128064 (* 1 = 0.128064 loss)
I0110 20:59:25.063745  4932 solver.cpp:631] Iteration 47480, lr = 1e-07
I0110 20:59:39.130012  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8746 > 20) by scale factor 0.914302
I0110 21:00:10.212093  4932 solver.cpp:240] Iteration 47500, loss = 0.0472996
I0110 21:00:10.212188  4932 solver.cpp:255]     Train net output #0: loss = 0.00400841 (* 1 = 0.00400841 loss)
I0110 21:00:10.212199  4932 solver.cpp:631] Iteration 47500, lr = 1e-07
I0110 21:00:46.446260  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4701 > 20) by scale factor 0.728064
I0110 21:00:53.111507  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.515 > 20) by scale factor 0.929583
I0110 21:00:54.994146  4932 solver.cpp:240] Iteration 47520, loss = 0.0454043
I0110 21:00:54.994182  4932 solver.cpp:255]     Train net output #0: loss = 0.0988433 (* 1 = 0.0988433 loss)
I0110 21:00:54.994191  4932 solver.cpp:631] Iteration 47520, lr = 1e-07
I0110 21:00:59.770472  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2915 > 20) by scale factor 0.985636
I0110 21:01:39.569903  4932 solver.cpp:240] Iteration 47540, loss = 0.0540063
I0110 21:01:39.570013  4932 solver.cpp:255]     Train net output #0: loss = 0.142449 (* 1 = 0.142449 loss)
I0110 21:01:39.570029  4932 solver.cpp:631] Iteration 47540, lr = 1e-07
I0110 21:02:25.011684  4932 solver.cpp:240] Iteration 47560, loss = 0.0765563
I0110 21:02:25.011833  4932 solver.cpp:255]     Train net output #0: loss = 0.0261333 (* 1 = 0.0261333 loss)
I0110 21:02:25.011858  4932 solver.cpp:631] Iteration 47560, lr = 1e-07
I0110 21:02:38.671936  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2795 > 20) by scale factor 0.897685
I0110 21:02:49.771042  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5352 > 20) by scale factor 0.973936
I0110 21:03:09.408180  4932 solver.cpp:240] Iteration 47580, loss = 0.0773969
I0110 21:03:09.408274  4932 solver.cpp:255]     Train net output #0: loss = 0.00564765 (* 1 = 0.00564765 loss)
I0110 21:03:09.408288  4932 solver.cpp:631] Iteration 47580, lr = 1e-07
I0110 21:03:53.899077  4932 solver.cpp:240] Iteration 47600, loss = 0.0401425
I0110 21:03:53.899178  4932 solver.cpp:255]     Train net output #0: loss = 0.0498155 (* 1 = 0.0498155 loss)
I0110 21:03:53.899191  4932 solver.cpp:631] Iteration 47600, lr = 1e-07
I0110 21:03:56.457528  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2941 > 20) by scale factor 0.985506
I0110 21:03:58.678163  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.8819 > 20) by scale factor 0.608237
I0110 21:04:20.871934  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0864 > 20) by scale factor 0.948479
I0110 21:04:25.313271  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4707 > 20) by scale factor 0.931501
I0110 21:04:27.534636  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6067 > 20) by scale factor 0.925639
I0110 21:04:38.299046  4932 solver.cpp:240] Iteration 47620, loss = 0.0917393
I0110 21:04:38.299091  4932 solver.cpp:255]     Train net output #0: loss = 0.0123839 (* 1 = 0.0123839 loss)
I0110 21:04:38.299103  4932 solver.cpp:631] Iteration 47620, lr = 1e-07
I0110 21:04:47.512398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5612 > 20) by scale factor 0.725658
I0110 21:05:05.464254  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4932 > 20) by scale factor 0.784524
I0110 21:05:12.228534  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8593 > 20) by scale factor 0.958805
I0110 21:05:22.991485  4932 solver.cpp:240] Iteration 47640, loss = 0.0920332
I0110 21:05:22.991529  4932 solver.cpp:255]     Train net output #0: loss = 0.0138452 (* 1 = 0.0138452 loss)
I0110 21:05:22.991541  4932 solver.cpp:631] Iteration 47640, lr = 1e-07
I0110 21:05:41.211196  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7153 > 20) by scale factor 0.721624
I0110 21:06:08.059061  4932 solver.cpp:240] Iteration 47660, loss = 0.0661578
I0110 21:06:08.059109  4932 solver.cpp:255]     Train net output #0: loss = 0.0209391 (* 1 = 0.0209391 loss)
I0110 21:06:08.059123  4932 solver.cpp:631] Iteration 47660, lr = 1e-07
I0110 21:06:12.840298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4384 > 20) by scale factor 0.978549
I0110 21:06:26.153149  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1153 > 20) by scale factor 0.737591
I0110 21:06:52.448074  4932 solver.cpp:240] Iteration 47680, loss = 0.0572887
I0110 21:06:52.448170  4932 solver.cpp:255]     Train net output #0: loss = 0.015133 (* 1 = 0.015133 loss)
I0110 21:06:52.448184  4932 solver.cpp:631] Iteration 47680, lr = 1e-07
I0110 21:07:42.869418  4932 solver.cpp:240] Iteration 47700, loss = 0.0366757
I0110 21:07:42.869503  4932 solver.cpp:255]     Train net output #0: loss = 0.00132313 (* 1 = 0.00132313 loss)
I0110 21:07:42.869515  4932 solver.cpp:631] Iteration 47700, lr = 1e-07
I0110 21:08:28.715136  4932 solver.cpp:240] Iteration 47720, loss = 0.0449215
I0110 21:08:28.715224  4932 solver.cpp:255]     Train net output #0: loss = 0.238346 (* 1 = 0.238346 loss)
I0110 21:08:28.715234  4932 solver.cpp:631] Iteration 47720, lr = 1e-07
I0110 21:08:29.054766  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5854 > 20) by scale factor 0.97156
I0110 21:08:49.024312  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2459 > 20) by scale factor 0.987852
I0110 21:08:56.418226  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.1704 > 20) by scale factor 0.662902
I0110 21:09:13.822376  4932 solver.cpp:240] Iteration 47740, loss = 0.0854023
I0110 21:09:13.822477  4932 solver.cpp:255]     Train net output #0: loss = 0.133073 (* 1 = 0.133073 loss)
I0110 21:09:13.822489  4932 solver.cpp:631] Iteration 47740, lr = 1e-07
I0110 21:09:58.374800  4932 solver.cpp:240] Iteration 47760, loss = 0.0363313
I0110 21:09:58.374897  4932 solver.cpp:255]     Train net output #0: loss = 0.00139659 (* 1 = 0.00139659 loss)
I0110 21:09:58.374910  4932 solver.cpp:631] Iteration 47760, lr = 1e-07
I0110 21:10:09.829040  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0349 > 20) by scale factor 0.768199
I0110 21:10:12.049816  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1012 > 20) by scale factor 0.865758
I0110 21:10:16.489076  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5635 > 20) by scale factor 0.676509
I0110 21:10:37.532867  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5327 > 20) by scale factor 0.887597
I0110 21:10:43.854329  4932 solver.cpp:240] Iteration 47780, loss = 0.0912997
I0110 21:10:43.854364  4932 solver.cpp:255]     Train net output #0: loss = 0.0245542 (* 1 = 0.0245542 loss)
I0110 21:10:43.854372  4932 solver.cpp:631] Iteration 47780, lr = 1e-07
I0110 21:11:22.983111  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6899 > 20) by scale factor 0.749347
I0110 21:11:29.304738  4932 solver.cpp:240] Iteration 47800, loss = 0.105849
I0110 21:11:29.304780  4932 solver.cpp:255]     Train net output #0: loss = 0.0901282 (* 1 = 0.0901282 loss)
I0110 21:11:29.304788  4932 solver.cpp:631] Iteration 47800, lr = 1e-07
I0110 21:11:31.861781  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0674 > 20) by scale factor 0.949332
I0110 21:11:38.518457  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6399 > 20) by scale factor 0.750753
I0110 21:12:14.767885  4932 solver.cpp:240] Iteration 47820, loss = 0.0593843
I0110 21:12:14.767984  4932 solver.cpp:255]     Train net output #0: loss = 0.0364704 (* 1 = 0.0364704 loss)
I0110 21:12:14.767997  4932 solver.cpp:631] Iteration 47820, lr = 1e-07
I0110 21:12:17.326457  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7179 > 20) by scale factor 0.777667
I0110 21:12:31.520030  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8448 > 20) by scale factor 0.773851
I0110 21:13:00.846063  4932 solver.cpp:240] Iteration 47840, loss = 0.0721814
I0110 21:13:00.846158  4932 solver.cpp:255]     Train net output #0: loss = 0.0605854 (* 1 = 0.0605854 loss)
I0110 21:13:00.846170  4932 solver.cpp:631] Iteration 47840, lr = 1e-07
I0110 21:13:03.404278  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9391 > 20) by scale factor 0.771037
I0110 21:13:46.126266  4932 solver.cpp:240] Iteration 47860, loss = 0.0819408
I0110 21:13:46.126350  4932 solver.cpp:255]     Train net output #0: loss = 0.0215374 (* 1 = 0.0215374 loss)
I0110 21:13:46.126363  4932 solver.cpp:631] Iteration 47860, lr = 1e-07
I0110 21:14:30.661753  4932 solver.cpp:240] Iteration 47880, loss = 0.0428106
I0110 21:14:30.661854  4932 solver.cpp:255]     Train net output #0: loss = 0.0170825 (* 1 = 0.0170825 loss)
I0110 21:14:30.661866  4932 solver.cpp:631] Iteration 47880, lr = 1e-07
I0110 21:15:15.949692  4932 solver.cpp:240] Iteration 47900, loss = 0.0592262
I0110 21:15:15.949774  4932 solver.cpp:255]     Train net output #0: loss = 0.00331955 (* 1 = 0.00331955 loss)
I0110 21:15:15.949786  4932 solver.cpp:631] Iteration 47900, lr = 1e-07
I0110 21:15:29.606019  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0677 > 20) by scale factor 0.996627
I0110 21:16:01.104609  4932 solver.cpp:240] Iteration 47920, loss = 0.0444808
I0110 21:16:01.104742  4932 solver.cpp:255]     Train net output #0: loss = 0.0836296 (* 1 = 0.0836296 loss)
I0110 21:16:01.104760  4932 solver.cpp:631] Iteration 47920, lr = 1e-07
I0110 21:16:40.741857  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.6822 > 20) by scale factor 0.576665
I0110 21:16:47.059638  4932 solver.cpp:240] Iteration 47940, loss = 0.0739153
I0110 21:16:47.059684  4932 solver.cpp:255]     Train net output #0: loss = 0.00329328 (* 1 = 0.00329328 loss)
I0110 21:16:47.059696  4932 solver.cpp:631] Iteration 47940, lr = 1e-07
I0110 21:17:25.590270  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.318 > 20) by scale factor 0.896138
I0110 21:17:31.910128  4932 solver.cpp:240] Iteration 47960, loss = 0.0715551
I0110 21:17:31.910177  4932 solver.cpp:255]     Train net output #0: loss = 0.0200781 (* 1 = 0.0200781 loss)
I0110 21:17:31.910190  4932 solver.cpp:631] Iteration 47960, lr = 1e-07
I0110 21:17:36.694064  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.591 > 20) by scale factor 0.971298
I0110 21:18:18.233747  4932 solver.cpp:240] Iteration 47980, loss = 0.0562333
I0110 21:18:18.233809  4932 solver.cpp:255]     Train net output #0: loss = 0.0155078 (* 1 = 0.0155078 loss)
I0110 21:18:18.233819  4932 solver.cpp:631] Iteration 47980, lr = 1e-07
I0110 21:18:49.746609  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5323 > 20) by scale factor 0.928838
I0110 21:19:00.853932  4932 solver.cpp:424] Iteration 48000, Testing net (#0)
I0110 21:19:53.456756  4932 solver.cpp:481]     Test net output #0: accuracy = 0.824211
I0110 21:19:53.456836  4932 solver.cpp:481]     Test net output #1: loss = 0.89481 (* 1 = 0.89481 loss)
I0110 21:19:55.323854  4932 solver.cpp:240] Iteration 48000, loss = 0.0726337
I0110 21:19:55.323891  4932 solver.cpp:255]     Train net output #0: loss = 0.000262282 (* 1 = 0.000262282 loss)
I0110 21:19:55.323900  4932 solver.cpp:631] Iteration 48000, lr = 1e-07
I0110 21:20:22.539299  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.722 > 20) by scale factor 0.965159
I0110 21:20:39.952752  4932 solver.cpp:240] Iteration 48020, loss = 0.049157
I0110 21:20:39.952834  4932 solver.cpp:255]     Train net output #0: loss = 0.00488513 (* 1 = 0.00488513 loss)
I0110 21:20:39.952847  4932 solver.cpp:631] Iteration 48020, lr = 1e-07
I0110 21:21:25.252830  4932 solver.cpp:240] Iteration 48040, loss = 0.039814
I0110 21:21:25.252929  4932 solver.cpp:255]     Train net output #0: loss = 0.0569404 (* 1 = 0.0569404 loss)
I0110 21:21:25.252943  4932 solver.cpp:631] Iteration 48040, lr = 1e-07
I0110 21:22:10.842392  4932 solver.cpp:240] Iteration 48060, loss = 0.0477625
I0110 21:22:10.842484  4932 solver.cpp:255]     Train net output #0: loss = 0.0466125 (* 1 = 0.0466125 loss)
I0110 21:22:10.842497  4932 solver.cpp:631] Iteration 48060, lr = 1e-07
I0110 21:22:15.625041  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1346 > 20) by scale factor 0.993316
I0110 21:22:22.309617  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5458 > 20) by scale factor 0.973437
I0110 21:22:33.468331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1854 > 20) by scale factor 0.826945
I0110 21:22:55.823695  4932 solver.cpp:240] Iteration 48080, loss = 0.0580175
I0110 21:22:55.823799  4932 solver.cpp:255]     Train net output #0: loss = 0.0420618 (* 1 = 0.0420618 loss)
I0110 21:22:55.823817  4932 solver.cpp:631] Iteration 48080, lr = 1e-07
I0110 21:23:25.537019  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9664 > 20) by scale factor 0.91048
I0110 21:23:34.419296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3026 > 20) by scale factor 0.790431
I0110 21:23:36.643281  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.318 > 20) by scale factor 0.938173
I0110 21:23:40.746616  4932 solver.cpp:240] Iteration 48100, loss = 0.126357
I0110 21:23:40.746670  4932 solver.cpp:255]     Train net output #0: loss = 0.0785411 (* 1 = 0.0785411 loss)
I0110 21:23:40.746681  4932 solver.cpp:631] Iteration 48100, lr = 1e-07
I0110 21:24:06.457401  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.684 > 20) by scale factor 0.966933
I0110 21:24:13.120520  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.1272 > 20) by scale factor 0.622526
I0110 21:24:26.104931  4932 solver.cpp:240] Iteration 48120, loss = 0.0698354
I0110 21:24:26.104981  4932 solver.cpp:255]     Train net output #0: loss = 0.230972 (* 1 = 0.230972 loss)
I0110 21:24:26.105109  4932 solver.cpp:631] Iteration 48120, lr = 1e-07
I0110 21:25:11.509816  4932 solver.cpp:240] Iteration 48140, loss = 0.077648
I0110 21:25:11.509898  4932 solver.cpp:255]     Train net output #0: loss = 0.250254 (* 1 = 0.250254 loss)
I0110 21:25:11.509909  4932 solver.cpp:631] Iteration 48140, lr = 1e-07
I0110 21:25:28.292516  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8372 > 20) by scale factor 0.718464
I0110 21:25:37.172507  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6253 > 20) by scale factor 0.969685
I0110 21:25:57.851336  4932 solver.cpp:240] Iteration 48160, loss = 0.0585397
I0110 21:25:57.851418  4932 solver.cpp:255]     Train net output #0: loss = 0.0564993 (* 1 = 0.0564993 loss)
I0110 21:25:57.851428  4932 solver.cpp:631] Iteration 48160, lr = 1e-07
I0110 21:26:20.391923  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2574 > 20) by scale factor 0.898578
I0110 21:26:40.636929  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.5224 > 20) by scale factor 0.579334
I0110 21:26:46.965463  4932 solver.cpp:240] Iteration 48180, loss = 0.0867927
I0110 21:26:46.965509  4932 solver.cpp:255]     Train net output #0: loss = 0.325904 (* 1 = 0.325904 loss)
I0110 21:26:46.965523  4932 solver.cpp:631] Iteration 48180, lr = 1e-07
I0110 21:26:49.527142  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9694 > 20) by scale factor 0.953772
I0110 21:26:56.185498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4008 > 20) by scale factor 0.854671
I0110 21:27:00.625978  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5437 > 20) by scale factor 0.849484
I0110 21:27:08.572360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7514 > 20) by scale factor 0.879068
I0110 21:27:10.792976  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4042 > 20) by scale factor 0.934396
I0110 21:27:32.652817  4932 solver.cpp:240] Iteration 48200, loss = 0.0968696
I0110 21:27:32.652865  4932 solver.cpp:255]     Train net output #0: loss = 0.00110982 (* 1 = 0.00110982 loss)
I0110 21:27:32.652878  4932 solver.cpp:631] Iteration 48200, lr = 1e-07
I0110 21:28:04.343466  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5428 > 20) by scale factor 0.753501
I0110 21:28:17.936360  4932 solver.cpp:240] Iteration 48220, loss = 0.0814376
I0110 21:28:17.936403  4932 solver.cpp:255]     Train net output #0: loss = 0.000543011 (* 1 = 0.000543011 loss)
I0110 21:28:17.936413  4932 solver.cpp:631] Iteration 48220, lr = 1e-07
I0110 21:28:27.147284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6303 > 20) by scale factor 0.92463
I0110 21:29:01.212365  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7019 > 20) by scale factor 0.880983
I0110 21:29:03.094931  4932 solver.cpp:240] Iteration 48240, loss = 0.0766428
I0110 21:29:03.094966  4932 solver.cpp:255]     Train net output #0: loss = 0.142629 (* 1 = 0.142629 loss)
I0110 21:29:03.094975  4932 solver.cpp:631] Iteration 48240, lr = 1e-07
I0110 21:29:10.093658  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4419 > 20) by scale factor 0.818267
I0110 21:29:23.410975  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1304 > 20) by scale factor 0.795848
I0110 21:29:48.152380  4932 solver.cpp:240] Iteration 48260, loss = 0.0890127
I0110 21:29:48.152499  4932 solver.cpp:255]     Train net output #0: loss = 0.00101832 (* 1 = 0.00101832 loss)
I0110 21:29:48.152513  4932 solver.cpp:631] Iteration 48260, lr = 1e-07
I0110 21:29:52.931730  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4138 > 20) by scale factor 0.892306
I0110 21:30:33.471496  4932 solver.cpp:240] Iteration 48280, loss = 0.0605303
I0110 21:30:33.471590  4932 solver.cpp:255]     Train net output #0: loss = 0.249862 (* 1 = 0.249862 loss)
I0110 21:30:33.471602  4932 solver.cpp:631] Iteration 48280, lr = 1e-07
I0110 21:30:43.784783  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9954 > 20) by scale factor 0.869738
I0110 21:30:57.106205  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.439 > 20) by scale factor 0.756459
I0110 21:31:19.028074  4932 solver.cpp:240] Iteration 48300, loss = 0.0624114
I0110 21:31:19.028177  4932 solver.cpp:255]     Train net output #0: loss = 0.142234 (* 1 = 0.142234 loss)
I0110 21:31:19.028192  4932 solver.cpp:631] Iteration 48300, lr = 1e-07
I0110 21:31:32.687599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3523 > 20) by scale factor 0.7312
I0110 21:32:03.418311  4932 solver.cpp:240] Iteration 48320, loss = 0.0449767
I0110 21:32:03.418401  4932 solver.cpp:255]     Train net output #0: loss = 0.00107223 (* 1 = 0.00107223 loss)
I0110 21:32:03.418414  4932 solver.cpp:631] Iteration 48320, lr = 1e-07
I0110 21:32:49.960667  4932 solver.cpp:240] Iteration 48340, loss = 0.063094
I0110 21:32:49.960762  4932 solver.cpp:255]     Train net output #0: loss = 0.0872369 (* 1 = 0.0872369 loss)
I0110 21:32:49.960774  4932 solver.cpp:631] Iteration 48340, lr = 1e-07
I0110 21:33:16.934481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.977 > 20) by scale factor 0.953426
I0110 21:33:19.155598  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2131 > 20) by scale factor 0.734941
I0110 21:33:35.249917  4932 solver.cpp:240] Iteration 48360, loss = 0.07075
I0110 21:33:35.249996  4932 solver.cpp:255]     Train net output #0: loss = 0.113873 (* 1 = 0.113873 loss)
I0110 21:33:35.250007  4932 solver.cpp:631] Iteration 48360, lr = 1e-07
I0110 21:34:07.685279  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3086 > 20) by scale factor 0.938588
I0110 21:34:20.663053  4932 solver.cpp:240] Iteration 48380, loss = 0.0548049
I0110 21:34:20.663090  4932 solver.cpp:255]     Train net output #0: loss = 0.110477 (* 1 = 0.110477 loss)
I0110 21:34:20.663100  4932 solver.cpp:631] Iteration 48380, lr = 1e-07
I0110 21:34:41.091214  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4219 > 20) by scale factor 0.756949
I0110 21:35:05.310704  4932 solver.cpp:240] Iteration 48400, loss = 0.0710971
I0110 21:35:05.310741  4932 solver.cpp:255]     Train net output #0: loss = 0.0315283 (* 1 = 0.0315283 loss)
I0110 21:35:05.310751  4932 solver.cpp:631] Iteration 48400, lr = 1e-07
I0110 21:35:21.186694  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2784 > 20) by scale factor 0.986271
I0110 21:35:50.861208  4932 solver.cpp:240] Iteration 48420, loss = 0.0690357
I0110 21:35:50.861253  4932 solver.cpp:255]     Train net output #0: loss = 0.00651211 (* 1 = 0.00651211 loss)
I0110 21:35:50.861265  4932 solver.cpp:631] Iteration 48420, lr = 1e-07
I0110 21:36:15.982455  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8896 > 20) by scale factor 0.803549
I0110 21:36:35.711670  4932 solver.cpp:240] Iteration 48440, loss = 0.0666283
I0110 21:36:35.711711  4932 solver.cpp:255]     Train net output #0: loss = 0.0271109 (* 1 = 0.0271109 loss)
I0110 21:36:35.711721  4932 solver.cpp:631] Iteration 48440, lr = 1e-07
I0110 21:36:40.488641  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0197 > 20) by scale factor 0.908278
I0110 21:37:20.292589  4932 solver.cpp:240] Iteration 48460, loss = 0.0614779
I0110 21:37:20.292701  4932 solver.cpp:255]     Train net output #0: loss = 0.293403 (* 1 = 0.293403 loss)
I0110 21:37:20.292714  4932 solver.cpp:631] Iteration 48460, lr = 1e-07
I0110 21:37:20.633095  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4168 > 20) by scale factor 0.892186
I0110 21:38:06.012584  4932 solver.cpp:240] Iteration 48480, loss = 0.0764769
I0110 21:38:06.012679  4932 solver.cpp:255]     Train net output #0: loss = 0.42587 (* 1 = 0.42587 loss)
I0110 21:38:06.012696  4932 solver.cpp:631] Iteration 48480, lr = 1e-07
I0110 21:38:06.353495  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3911 > 20) by scale factor 0.980819
I0110 21:38:17.454737  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9305 > 20) by scale factor 0.691312
I0110 21:38:52.173517  4932 solver.cpp:240] Iteration 48500, loss = 0.045825
I0110 21:38:52.173604  4932 solver.cpp:255]     Train net output #0: loss = 0.129367 (* 1 = 0.129367 loss)
I0110 21:38:52.173617  4932 solver.cpp:631] Iteration 48500, lr = 1e-07
I0110 21:39:31.190762  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0865 > 20) by scale factor 0.905532
I0110 21:39:37.510470  4932 solver.cpp:240] Iteration 48520, loss = 0.0851573
I0110 21:39:37.510515  4932 solver.cpp:255]     Train net output #0: loss = 0.0607867 (* 1 = 0.0607867 loss)
I0110 21:39:37.510526  4932 solver.cpp:631] Iteration 48520, lr = 1e-07
I0110 21:39:40.069999  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.815 > 20) by scale factor 0.719037
I0110 21:39:48.945286  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3402 > 20) by scale factor 0.856891
I0110 21:40:15.924510  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2513 > 20) by scale factor 0.987592
I0110 21:40:20.391289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1963 > 20) by scale factor 0.943561
I0110 21:40:22.284188  4932 solver.cpp:240] Iteration 48540, loss = 0.0817408
I0110 21:40:22.284241  4932 solver.cpp:255]     Train net output #0: loss = 0.112064 (* 1 = 0.112064 loss)
I0110 21:40:22.313887  4932 solver.cpp:631] Iteration 48540, lr = 1e-07
I0110 21:40:45.409973  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5053 > 20) by scale factor 0.88868
I0110 21:40:52.074601  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8458 > 20) by scale factor 0.804965
I0110 21:41:07.278956  4932 solver.cpp:240] Iteration 48560, loss = 0.0710452
I0110 21:41:07.279000  4932 solver.cpp:255]     Train net output #0: loss = 0.0250144 (* 1 = 0.0250144 loss)
I0110 21:41:07.279011  4932 solver.cpp:631] Iteration 48560, lr = 1e-07
I0110 21:41:32.919841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4245 > 20) by scale factor 0.979217
I0110 21:41:52.781458  4932 solver.cpp:240] Iteration 48580, loss = 0.0384291
I0110 21:41:52.781503  4932 solver.cpp:255]     Train net output #0: loss = 0.109581 (* 1 = 0.109581 loss)
I0110 21:41:52.781517  4932 solver.cpp:631] Iteration 48580, lr = 1e-07
I0110 21:42:02.005321  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6977 > 20) by scale factor 0.921758
I0110 21:42:17.549623  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4296 > 20) by scale factor 0.853619
I0110 21:42:38.323120  4932 solver.cpp:240] Iteration 48600, loss = 0.0739621
I0110 21:42:38.323161  4932 solver.cpp:255]     Train net output #0: loss = 0.00394313 (* 1 = 0.00394313 loss)
I0110 21:42:38.323171  4932 solver.cpp:631] Iteration 48600, lr = 1e-07
I0110 21:43:22.697129  4932 solver.cpp:240] Iteration 48620, loss = 0.0428086
I0110 21:43:22.697233  4932 solver.cpp:255]     Train net output #0: loss = 0.090283 (* 1 = 0.090283 loss)
I0110 21:43:22.697247  4932 solver.cpp:631] Iteration 48620, lr = 1e-07
I0110 21:43:36.357198  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8188 > 20) by scale factor 0.839671
I0110 21:43:38.576759  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0056 > 20) by scale factor 0.714143
I0110 21:43:47.453785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0842 > 20) by scale factor 0.866392
I0110 21:44:07.914196  4932 solver.cpp:240] Iteration 48640, loss = 0.0603593
I0110 21:44:07.914320  4932 solver.cpp:255]     Train net output #0: loss = 0.0216021 (* 1 = 0.0216021 loss)
I0110 21:44:07.914335  4932 solver.cpp:631] Iteration 48640, lr = 1e-07
I0110 21:44:21.599910  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0358 > 20) by scale factor 0.998215
I0110 21:44:42.300115  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5679 > 20) by scale factor 0.972388
I0110 21:44:46.742547  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.546 > 20) by scale factor 0.8494
I0110 21:44:53.087996  4932 solver.cpp:240] Iteration 48660, loss = 0.0692001
I0110 21:44:53.088035  4932 solver.cpp:255]     Train net output #0: loss = 0.00144185 (* 1 = 0.00144185 loss)
I0110 21:44:53.088045  4932 solver.cpp:631] Iteration 48660, lr = 1e-07
I0110 21:45:37.974123  4932 solver.cpp:240] Iteration 48680, loss = 0.0680834
I0110 21:45:37.974232  4932 solver.cpp:255]     Train net output #0: loss = 0.122234 (* 1 = 0.122234 loss)
I0110 21:45:37.974249  4932 solver.cpp:631] Iteration 48680, lr = 1e-07
I0110 21:46:14.725389  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4949 > 20) by scale factor 0.727406
I0110 21:46:24.166204  4932 solver.cpp:240] Iteration 48700, loss = 0.0509211
I0110 21:46:24.166244  4932 solver.cpp:255]     Train net output #0: loss = 0.0170969 (* 1 = 0.0170969 loss)
I0110 21:46:24.166254  4932 solver.cpp:631] Iteration 48700, lr = 1e-07
I0110 21:46:58.944751  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.855 > 20) by scale factor 0.648192
I0110 21:47:09.702186  4932 solver.cpp:240] Iteration 48720, loss = 0.0650015
I0110 21:47:09.702227  4932 solver.cpp:255]     Train net output #0: loss = 0.0100963 (* 1 = 0.0100963 loss)
I0110 21:47:09.702237  4932 solver.cpp:631] Iteration 48720, lr = 1e-07
I0110 21:47:14.477880  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6209 > 20) by scale factor 0.925029
I0110 21:47:37.171067  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6977 > 20) by scale factor 0.966293
I0110 21:47:54.584328  4932 solver.cpp:240] Iteration 48740, loss = 0.0603208
I0110 21:47:54.584372  4932 solver.cpp:255]     Train net output #0: loss = 0.038013 (* 1 = 0.038013 loss)
I0110 21:47:54.584385  4932 solver.cpp:631] Iteration 48740, lr = 1e-07
I0110 21:48:39.791873  4932 solver.cpp:240] Iteration 48760, loss = 0.0365763
I0110 21:48:39.791970  4932 solver.cpp:255]     Train net output #0: loss = 0.0095582 (* 1 = 0.0095582 loss)
I0110 21:48:39.791985  4932 solver.cpp:631] Iteration 48760, lr = 1e-07
I0110 21:49:01.345088  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1093 > 20) by scale factor 0.687066
I0110 21:49:08.139714  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5542 > 20) by scale factor 0.849107
I0110 21:49:19.244859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.411 > 20) by scale factor 0.787062
I0110 21:49:21.468237  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4828 > 20) by scale factor 0.678361
I0110 21:49:25.595597  4932 solver.cpp:240] Iteration 48780, loss = 0.0899211
I0110 21:49:25.595660  4932 solver.cpp:255]     Train net output #0: loss = 0.0275956 (* 1 = 0.0275956 loss)
I0110 21:49:25.595677  4932 solver.cpp:631] Iteration 48780, lr = 1e-07
I0110 21:49:37.039505  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.2753 > 20) by scale factor 0.639481
I0110 21:50:10.166420  4932 solver.cpp:240] Iteration 48800, loss = 0.0720437
I0110 21:50:10.166537  4932 solver.cpp:255]     Train net output #0: loss = 0.041042 (* 1 = 0.041042 loss)
I0110 21:50:10.166550  4932 solver.cpp:631] Iteration 48800, lr = 1e-07
I0110 21:50:44.868417  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7074 > 20) by scale factor 0.843619
I0110 21:50:56.560596  4932 solver.cpp:240] Iteration 48820, loss = 0.0773169
I0110 21:50:56.560633  4932 solver.cpp:255]     Train net output #0: loss = 0.00773437 (* 1 = 0.00773437 loss)
I0110 21:50:56.560642  4932 solver.cpp:631] Iteration 48820, lr = 1e-07
I0110 21:51:10.215250  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4193 > 20) by scale factor 0.729412
I0110 21:51:16.869863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8751 > 20) by scale factor 0.804015
I0110 21:51:33.656188  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.2777 > 20) by scale factor 0.583469
I0110 21:51:38.094197  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3607 > 20) by scale factor 0.982286
I0110 21:51:42.197386  4932 solver.cpp:240] Iteration 48840, loss = 0.124418
I0110 21:51:42.197432  4932 solver.cpp:255]     Train net output #0: loss = 0.068538 (* 1 = 0.068538 loss)
I0110 21:51:42.197444  4932 solver.cpp:631] Iteration 48840, lr = 1e-07
I0110 21:51:53.914294  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4743 > 20) by scale factor 0.931345
I0110 21:52:11.671411  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.818 > 20) by scale factor 0.839701
I0110 21:52:26.868350  4932 solver.cpp:240] Iteration 48860, loss = 0.0482499
I0110 21:52:26.868451  4932 solver.cpp:255]     Train net output #0: loss = 0.00559902 (* 1 = 0.00559902 loss)
I0110 21:52:26.868468  4932 solver.cpp:631] Iteration 48860, lr = 1e-07
I0110 21:53:13.293612  4932 solver.cpp:240] Iteration 48880, loss = 0.0619159
I0110 21:53:13.293695  4932 solver.cpp:255]     Train net output #0: loss = 0.0160822 (* 1 = 0.0160822 loss)
I0110 21:53:13.293707  4932 solver.cpp:631] Iteration 48880, lr = 1e-07
I0110 21:53:45.956895  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9665 > 20) by scale factor 0.870834
I0110 21:53:58.935207  4932 solver.cpp:240] Iteration 48900, loss = 0.0736613
I0110 21:53:58.935246  4932 solver.cpp:255]     Train net output #0: loss = 0.018058 (* 1 = 0.018058 loss)
I0110 21:53:58.935256  4932 solver.cpp:631] Iteration 48900, lr = 1e-07
I0110 21:54:41.846137  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2028 > 20) by scale factor 0.94327
I0110 21:54:43.741884  4932 solver.cpp:240] Iteration 48920, loss = 0.0594388
I0110 21:54:43.741928  4932 solver.cpp:255]     Train net output #0: loss = 0.07397 (* 1 = 0.07397 loss)
I0110 21:54:43.741943  4932 solver.cpp:631] Iteration 48920, lr = 1e-07
I0110 21:54:47.290289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0527 > 20) by scale factor 0.867579
I0110 21:55:09.597700  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4851 > 20) by scale factor 0.976318
I0110 21:55:25.134037  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1703 > 20) by scale factor 0.902107
I0110 21:55:29.239461  4932 solver.cpp:240] Iteration 48940, loss = 0.0902817
I0110 21:55:29.239498  4932 solver.cpp:255]     Train net output #0: loss = 0.000813992 (* 1 = 0.000813992 loss)
I0110 21:55:29.239511  4932 solver.cpp:631] Iteration 48940, lr = 1e-07
I0110 21:55:53.993011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7351 > 20) by scale factor 0.777148
I0110 21:55:58.456446  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9072 > 20) by scale factor 0.956609
I0110 21:56:13.783723  4932 solver.cpp:240] Iteration 48960, loss = 0.0691152
I0110 21:56:13.783772  4932 solver.cpp:255]     Train net output #0: loss = 0.00202132 (* 1 = 0.00202132 loss)
I0110 21:56:13.783794  4932 solver.cpp:631] Iteration 48960, lr = 1e-07
I0110 21:56:51.858322  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1815 > 20) by scale factor 0.991007
I0110 21:56:58.708685  4932 solver.cpp:240] Iteration 48980, loss = 0.0597679
I0110 21:56:58.708725  4932 solver.cpp:255]     Train net output #0: loss = 0.0317067 (* 1 = 0.0317067 loss)
I0110 21:56:58.708734  4932 solver.cpp:631] Iteration 48980, lr = 1e-07
I0110 21:57:37.086099  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0119 > 20) by scale factor 0.799618
I0110 21:57:41.539085  4932 solver.cpp:424] Iteration 49000, Testing net (#0)
I0110 21:58:36.136028  4932 solver.cpp:481]     Test net output #0: accuracy = 0.814737
I0110 21:58:36.136104  4932 solver.cpp:481]     Test net output #1: loss = 0.961203 (* 1 = 0.961203 loss)
I0110 21:58:38.003546  4932 solver.cpp:240] Iteration 49000, loss = 0.0877408
I0110 21:58:38.003584  4932 solver.cpp:255]     Train net output #0: loss = 0.0101081 (* 1 = 0.0101081 loss)
I0110 21:58:38.003592  4932 solver.cpp:631] Iteration 49000, lr = 1e-07
I0110 21:59:23.312741  4932 solver.cpp:240] Iteration 49020, loss = 0.0532198
I0110 21:59:23.312835  4932 solver.cpp:255]     Train net output #0: loss = 0.0278597 (* 1 = 0.0278597 loss)
I0110 21:59:23.312849  4932 solver.cpp:631] Iteration 49020, lr = 1e-07
I0110 21:59:43.652264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.1503 > 20) by scale factor 0.642049
I0110 22:00:07.746417  4932 solver.cpp:240] Iteration 49040, loss = 0.056813
I0110 22:00:07.746503  4932 solver.cpp:255]     Train net output #0: loss = 0.0526282 (* 1 = 0.0526282 loss)
I0110 22:00:07.746516  4932 solver.cpp:631] Iteration 49040, lr = 1e-07
I0110 22:00:53.568119  4932 solver.cpp:240] Iteration 49060, loss = 0.0238905
I0110 22:00:53.568203  4932 solver.cpp:255]     Train net output #0: loss = 0.0120525 (* 1 = 0.0120525 loss)
I0110 22:00:53.568217  4932 solver.cpp:631] Iteration 49060, lr = 1e-07
I0110 22:01:18.314209  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0905 > 20) by scale factor 0.948293
I0110 22:01:39.018607  4932 solver.cpp:240] Iteration 49080, loss = 0.0474813
I0110 22:01:39.018713  4932 solver.cpp:255]     Train net output #0: loss = 0.0336335 (* 1 = 0.0336335 loss)
I0110 22:01:39.018729  4932 solver.cpp:631] Iteration 49080, lr = 1e-07
I0110 22:02:23.934017  4932 solver.cpp:240] Iteration 49100, loss = 0.0502411
I0110 22:02:23.934067  4932 solver.cpp:255]     Train net output #0: loss = 0.059249 (* 1 = 0.059249 loss)
I0110 22:02:23.934077  4932 solver.cpp:631] Iteration 49100, lr = 1e-07
I0110 22:02:56.275053  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1449 > 20) by scale factor 0.864121
I0110 22:03:09.255354  4932 solver.cpp:240] Iteration 49120, loss = 0.0493665
I0110 22:03:09.255394  4932 solver.cpp:255]     Train net output #0: loss = 0.134845 (* 1 = 0.134845 loss)
I0110 22:03:09.255404  4932 solver.cpp:631] Iteration 49120, lr = 1e-07
I0110 22:03:55.453658  4932 solver.cpp:240] Iteration 49140, loss = 0.0597182
I0110 22:03:55.453754  4932 solver.cpp:255]     Train net output #0: loss = 0.276912 (* 1 = 0.276912 loss)
I0110 22:03:55.453768  4932 solver.cpp:631] Iteration 49140, lr = 1e-07
I0110 22:04:40.684994  4932 solver.cpp:240] Iteration 49160, loss = 0.0713842
I0110 22:04:40.685091  4932 solver.cpp:255]     Train net output #0: loss = 0.0186532 (* 1 = 0.0186532 loss)
I0110 22:04:40.685106  4932 solver.cpp:631] Iteration 49160, lr = 1e-07
I0110 22:05:03.208325  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1849 > 20) by scale factor 0.794127
I0110 22:05:25.057126  4932 solver.cpp:240] Iteration 49180, loss = 0.0866458
I0110 22:05:25.057240  4932 solver.cpp:255]     Train net output #0: loss = 0.12574 (* 1 = 0.12574 loss)
I0110 22:05:25.057255  4932 solver.cpp:631] Iteration 49180, lr = 1e-07
I0110 22:05:40.931063  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3751 > 20) by scale factor 0.935668
I0110 22:06:10.599452  4932 solver.cpp:240] Iteration 49200, loss = 0.0517616
I0110 22:06:10.599563  4932 solver.cpp:255]     Train net output #0: loss = 0.0906403 (* 1 = 0.0906403 loss)
I0110 22:06:10.599575  4932 solver.cpp:631] Iteration 49200, lr = 1e-07
I0110 22:06:40.139166  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7846 > 20) by scale factor 0.877787
I0110 22:06:55.334802  4932 solver.cpp:240] Iteration 49220, loss = 0.0529066
I0110 22:06:55.334902  4932 solver.cpp:255]     Train net output #0: loss = 0.00335777 (* 1 = 0.00335777 loss)
I0110 22:06:55.334915  4932 solver.cpp:631] Iteration 49220, lr = 1e-07
I0110 22:07:40.597596  4932 solver.cpp:240] Iteration 49240, loss = 0.0596663
I0110 22:07:40.597684  4932 solver.cpp:255]     Train net output #0: loss = 0.00852709 (* 1 = 0.00852709 loss)
I0110 22:07:40.597697  4932 solver.cpp:631] Iteration 49240, lr = 1e-07
I0110 22:08:26.898241  4932 solver.cpp:240] Iteration 49260, loss = 0.0284104
I0110 22:08:26.898332  4932 solver.cpp:255]     Train net output #0: loss = 0.0030173 (* 1 = 0.0030173 loss)
I0110 22:08:26.898345  4932 solver.cpp:631] Iteration 49260, lr = 1e-07
I0110 22:08:36.115291  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6978 > 20) by scale factor 0.843961
I0110 22:09:12.229496  4932 solver.cpp:240] Iteration 49280, loss = 0.0937527
I0110 22:09:12.229574  4932 solver.cpp:255]     Train net output #0: loss = 0.261484 (* 1 = 0.261484 loss)
I0110 22:09:12.229585  4932 solver.cpp:631] Iteration 49280, lr = 1e-07
I0110 22:09:53.670629  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8496 > 20) by scale factor 0.959251
I0110 22:09:57.774152  4932 solver.cpp:240] Iteration 49300, loss = 0.0548384
I0110 22:09:57.774193  4932 solver.cpp:255]     Train net output #0: loss = 0.0524085 (* 1 = 0.0524085 loss)
I0110 22:09:57.774202  4932 solver.cpp:631] Iteration 49300, lr = 1e-07
I0110 22:10:43.125959  4932 solver.cpp:240] Iteration 49320, loss = 0.0624898
I0110 22:10:43.126066  4932 solver.cpp:255]     Train net output #0: loss = 0.0373943 (* 1 = 0.0373943 loss)
I0110 22:10:43.126082  4932 solver.cpp:631] Iteration 49320, lr = 1e-07
I0110 22:11:27.513769  4932 solver.cpp:240] Iteration 49340, loss = 0.0692927
I0110 22:11:27.513861  4932 solver.cpp:255]     Train net output #0: loss = 0.00147375 (* 1 = 0.00147375 loss)
I0110 22:11:27.513875  4932 solver.cpp:631] Iteration 49340, lr = 1e-07
I0110 22:12:12.992281  4932 solver.cpp:240] Iteration 49360, loss = 0.0624199
I0110 22:12:12.992374  4932 solver.cpp:255]     Train net output #0: loss = 0.0814652 (* 1 = 0.0814652 loss)
I0110 22:12:12.992386  4932 solver.cpp:631] Iteration 49360, lr = 1e-07
I0110 22:12:51.663501  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2266 > 20) by scale factor 0.861083
I0110 22:12:57.982364  4932 solver.cpp:240] Iteration 49380, loss = 0.0265556
I0110 22:12:57.982403  4932 solver.cpp:255]     Train net output #0: loss = 0.0412596 (* 1 = 0.0412596 loss)
I0110 22:12:57.982414  4932 solver.cpp:631] Iteration 49380, lr = 1e-07
I0110 22:13:04.976899  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7342 > 20) by scale factor 0.696036
I0110 22:13:42.924618  4932 solver.cpp:240] Iteration 49400, loss = 0.0631633
I0110 22:13:42.924713  4932 solver.cpp:255]     Train net output #0: loss = 0.222433 (* 1 = 0.222433 loss)
I0110 22:13:42.924727  4932 solver.cpp:631] Iteration 49400, lr = 1e-07
I0110 22:14:08.673357  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9936 > 20) by scale factor 0.740915
I0110 22:14:28.305045  4932 solver.cpp:240] Iteration 49420, loss = 0.0314609
I0110 22:14:28.305136  4932 solver.cpp:255]     Train net output #0: loss = 0.0243818 (* 1 = 0.0243818 loss)
I0110 22:14:28.305150  4932 solver.cpp:631] Iteration 49420, lr = 1e-07
I0110 22:15:13.210000  4932 solver.cpp:240] Iteration 49440, loss = 0.0536683
I0110 22:15:13.210115  4932 solver.cpp:255]     Train net output #0: loss = 0.106189 (* 1 = 0.106189 loss)
I0110 22:15:13.210132  4932 solver.cpp:631] Iteration 49440, lr = 1e-07
I0110 22:15:20.206125  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1311 > 20) by scale factor 0.993489
I0110 22:15:40.183157  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5391 > 20) by scale factor 0.700794
I0110 22:15:42.404018  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0222 > 20) by scale factor 0.868728
I0110 22:15:47.876024  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6145 > 20) by scale factor 0.970192
I0110 22:15:50.099869  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1414 > 20) by scale factor 0.992978
I0110 22:15:58.642926  4932 solver.cpp:240] Iteration 49460, loss = 0.0921475
I0110 22:15:58.642966  4932 solver.cpp:255]     Train net output #0: loss = 0.0402688 (* 1 = 0.0402688 loss)
I0110 22:15:58.642976  4932 solver.cpp:631] Iteration 49460, lr = 1e-07
I0110 22:16:15.006683  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8164 > 20) by scale factor 0.876563
I0110 22:16:43.527859  4932 solver.cpp:240] Iteration 49480, loss = 0.0820596
I0110 22:16:43.527952  4932 solver.cpp:255]     Train net output #0: loss = 0.100621 (* 1 = 0.100621 loss)
I0110 22:16:43.527966  4932 solver.cpp:631] Iteration 49480, lr = 1e-07
I0110 22:17:17.256269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1673 > 20) by scale factor 0.991707
I0110 22:17:19.477963  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1762 > 20) by scale factor 0.944455
I0110 22:17:23.918382  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9936 > 20) by scale factor 0.952672
I0110 22:17:28.021663  4932 solver.cpp:240] Iteration 49500, loss = 0.0525637
I0110 22:17:28.021713  4932 solver.cpp:255]     Train net output #0: loss = 0.00702273 (* 1 = 0.00702273 loss)
I0110 22:17:28.021726  4932 solver.cpp:631] Iteration 49500, lr = 1e-07
I0110 22:18:12.406126  4932 solver.cpp:240] Iteration 49520, loss = 0.048015
I0110 22:18:12.406214  4932 solver.cpp:255]     Train net output #0: loss = 0.129551 (* 1 = 0.129551 loss)
I0110 22:18:12.406226  4932 solver.cpp:631] Iteration 49520, lr = 1e-07
I0110 22:18:12.745491  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8409 > 20) by scale factor 0.915715
I0110 22:18:17.185722  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5244 > 20) by scale factor 0.929177
I0110 22:18:26.063987  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4217 > 20) by scale factor 0.979349
I0110 22:18:37.272946  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4884 > 20) by scale factor 0.727579
I0110 22:18:56.917929  4932 solver.cpp:240] Iteration 49540, loss = 0.0780176
I0110 22:18:56.918023  4932 solver.cpp:255]     Train net output #0: loss = 0.00248349 (* 1 = 0.00248349 loss)
I0110 22:18:56.918036  4932 solver.cpp:631] Iteration 49540, lr = 1e-07
I0110 22:19:26.329871  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8933 > 20) by scale factor 0.7724
I0110 22:19:41.522389  4932 solver.cpp:240] Iteration 49560, loss = 0.0919061
I0110 22:19:41.522500  4932 solver.cpp:255]     Train net output #0: loss = 0.0272869 (* 1 = 0.0272869 loss)
I0110 22:19:41.522516  4932 solver.cpp:631] Iteration 49560, lr = 1e-07
I0110 22:20:01.949265  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.227 > 20) by scale factor 0.861067
I0110 22:20:04.170684  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5306 > 20) by scale factor 0.928909
I0110 22:20:26.032471  4932 solver.cpp:240] Iteration 49580, loss = 0.0749056
I0110 22:20:26.032577  4932 solver.cpp:255]     Train net output #0: loss = 0.288994 (* 1 = 0.288994 loss)
I0110 22:20:26.032593  4932 solver.cpp:631] Iteration 49580, lr = 1e-07
I0110 22:20:26.372972  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4154 > 20) by scale factor 0.703845
I0110 22:21:03.047888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2116 > 20) by scale factor 0.793287
I0110 22:21:11.587107  4932 solver.cpp:240] Iteration 49600, loss = 0.0683806
I0110 22:21:11.587143  4932 solver.cpp:255]     Train net output #0: loss = 0.00631074 (* 1 = 0.00631074 loss)
I0110 22:21:11.587153  4932 solver.cpp:631] Iteration 49600, lr = 1e-07
I0110 22:21:57.703727  4932 solver.cpp:240] Iteration 49620, loss = 0.0336444
I0110 22:21:57.703819  4932 solver.cpp:255]     Train net output #0: loss = 0.00579629 (* 1 = 0.00579629 loss)
I0110 22:21:57.703830  4932 solver.cpp:631] Iteration 49620, lr = 1e-07
I0110 22:22:29.117244  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8053 > 20) by scale factor 0.91721
I0110 22:22:38.757431  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0454 > 20) by scale factor 0.831759
I0110 22:22:40.979764  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2589 > 20) by scale factor 0.940783
I0110 22:22:42.863137  4932 solver.cpp:240] Iteration 49640, loss = 0.109074
I0110 22:22:42.863183  4932 solver.cpp:255]     Train net output #0: loss = 0.00259514 (* 1 = 0.00259514 loss)
I0110 22:22:42.863193  4932 solver.cpp:631] Iteration 49640, lr = 1e-07
I0110 22:23:27.893767  4932 solver.cpp:240] Iteration 49660, loss = 0.0376643
I0110 22:23:27.893857  4932 solver.cpp:255]     Train net output #0: loss = 0.0114143 (* 1 = 0.0114143 loss)
I0110 22:23:27.893870  4932 solver.cpp:631] Iteration 49660, lr = 1e-07
I0110 22:23:32.673918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5773 > 20) by scale factor 0.725233
I0110 22:23:41.554618  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6077 > 20) by scale factor 0.884653
I0110 22:24:13.306313  4932 solver.cpp:240] Iteration 49680, loss = 0.0548237
I0110 22:24:13.306408  4932 solver.cpp:255]     Train net output #0: loss = 0.0951105 (* 1 = 0.0951105 loss)
I0110 22:24:13.306421  4932 solver.cpp:631] Iteration 49680, lr = 1e-07
I0110 22:24:59.316066  4932 solver.cpp:240] Iteration 49700, loss = 0.0508287
I0110 22:24:59.316148  4932 solver.cpp:255]     Train net output #0: loss = 0.0283452 (* 1 = 0.0283452 loss)
I0110 22:24:59.316159  4932 solver.cpp:631] Iteration 49700, lr = 1e-07
I0110 22:25:44.467464  4932 solver.cpp:240] Iteration 49720, loss = 0.0498325
I0110 22:25:44.467573  4932 solver.cpp:255]     Train net output #0: loss = 0.00226057 (* 1 = 0.00226057 loss)
I0110 22:25:44.467587  4932 solver.cpp:631] Iteration 49720, lr = 1e-07
I0110 22:26:18.105028  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8354 > 20) by scale factor 0.875834
I0110 22:26:28.856648  4932 solver.cpp:240] Iteration 49740, loss = 0.0758056
I0110 22:26:28.856688  4932 solver.cpp:255]     Train net output #0: loss = 0.0183098 (* 1 = 0.0183098 loss)
I0110 22:26:28.856696  4932 solver.cpp:631] Iteration 49740, lr = 1e-07
I0110 22:26:49.178477  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2134 > 20) by scale factor 0.900356
I0110 22:27:13.797343  4932 solver.cpp:240] Iteration 49760, loss = 0.0933533
I0110 22:27:13.797375  4932 solver.cpp:255]     Train net output #0: loss = 0.0877008 (* 1 = 0.0877008 loss)
I0110 22:27:13.797385  4932 solver.cpp:631] Iteration 49760, lr = 1e-07
I0110 22:27:25.232141  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5117 > 20) by scale factor 0.975055
I0110 22:27:31.892073  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0677 > 20) by scale factor 0.94932
I0110 22:27:48.077993  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5838 > 20) by scale factor 0.885592
I0110 22:27:58.843119  4932 solver.cpp:240] Iteration 49780, loss = 0.0637595
I0110 22:27:58.843230  4932 solver.cpp:255]     Train net output #0: loss = 0.0554075 (* 1 = 0.0554075 loss)
I0110 22:27:58.843242  4932 solver.cpp:631] Iteration 49780, lr = 1e-07
I0110 22:28:14.716958  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.992 > 20) by scale factor 0.833612
I0110 22:28:44.391396  4932 solver.cpp:240] Iteration 49800, loss = 0.0630658
I0110 22:28:44.391501  4932 solver.cpp:255]     Train net output #0: loss = 0.0207144 (* 1 = 0.0207144 loss)
I0110 22:28:44.391515  4932 solver.cpp:631] Iteration 49800, lr = 1e-07
I0110 22:28:49.170994  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9737 > 20) by scale factor 0.770008
I0110 22:29:21.063733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2857 > 20) by scale factor 0.985917
I0110 22:29:30.501688  4932 solver.cpp:240] Iteration 49820, loss = 0.0716613
I0110 22:29:30.501734  4932 solver.cpp:255]     Train net output #0: loss = 0.0939852 (* 1 = 0.0939852 loss)
I0110 22:29:30.501746  4932 solver.cpp:631] Iteration 49820, lr = 1e-07
I0110 22:30:01.912317  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8099 > 20) by scale factor 0.917014
I0110 22:30:15.582206  4932 solver.cpp:240] Iteration 49840, loss = 0.0863433
I0110 22:30:15.582247  4932 solver.cpp:255]     Train net output #0: loss = 0.265161 (* 1 = 0.265161 loss)
I0110 22:30:15.582257  4932 solver.cpp:631] Iteration 49840, lr = 1e-07
I0110 22:31:00.802601  4932 solver.cpp:240] Iteration 49860, loss = 0.0576804
I0110 22:31:00.802700  4932 solver.cpp:255]     Train net output #0: loss = 0.0254241 (* 1 = 0.0254241 loss)
I0110 22:31:00.802713  4932 solver.cpp:631] Iteration 49860, lr = 1e-07
I0110 22:31:38.868533  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6423 > 20) by scale factor 0.845942
I0110 22:31:45.206248  4932 solver.cpp:240] Iteration 49880, loss = 0.06022
I0110 22:31:45.206295  4932 solver.cpp:255]     Train net output #0: loss = 0.0501501 (* 1 = 0.0501501 loss)
I0110 22:31:45.206306  4932 solver.cpp:631] Iteration 49880, lr = 1e-07
I0110 22:31:52.200963  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.361 > 20) by scale factor 0.98227
I0110 22:31:58.858978  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2821 > 20) by scale factor 0.89758
I0110 22:32:01.081776  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2214 > 20) by scale factor 0.825717
I0110 22:32:16.622999  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9901 > 20) by scale factor 0.952832
I0110 22:32:31.215934  4932 solver.cpp:240] Iteration 49900, loss = 0.0970859
I0110 22:32:31.215972  4932 solver.cpp:255]     Train net output #0: loss = 0.0396059 (* 1 = 0.0396059 loss)
I0110 22:32:31.215981  4932 solver.cpp:631] Iteration 49900, lr = 1e-07
I0110 22:32:40.432801  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.77 > 20) by scale factor 0.878349
I0110 22:32:58.796164  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6466 > 20) by scale factor 0.698162
I0110 22:33:16.214324  4932 solver.cpp:240] Iteration 49920, loss = 0.0895622
I0110 22:33:16.214364  4932 solver.cpp:255]     Train net output #0: loss = 0.0875333 (* 1 = 0.0875333 loss)
I0110 22:33:16.214372  4932 solver.cpp:631] Iteration 49920, lr = 1e-07
I0110 22:33:59.544912  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9252 > 20) by scale factor 0.668332
I0110 22:34:01.427793  4932 solver.cpp:240] Iteration 49940, loss = 0.044601
I0110 22:34:01.427834  4932 solver.cpp:255]     Train net output #0: loss = 0.00936458 (* 1 = 0.00936458 loss)
I0110 22:34:01.427845  4932 solver.cpp:631] Iteration 49940, lr = 1e-07
I0110 22:34:47.555645  4932 solver.cpp:240] Iteration 49960, loss = 0.0393441
I0110 22:34:47.555739  4932 solver.cpp:255]     Train net output #0: loss = 4.97954e-05 (* 1 = 4.97954e-05 loss)
I0110 22:34:47.555752  4932 solver.cpp:631] Iteration 49960, lr = 1e-07
I0110 22:34:50.115238  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0706 > 20) by scale factor 0.906181
I0110 22:34:52.338296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2856 > 20) by scale factor 0.985923
I0110 22:35:25.622483  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3464 > 20) by scale factor 0.936926
I0110 22:35:31.943189  4932 solver.cpp:240] Iteration 49980, loss = 0.0753209
I0110 22:35:31.943236  4932 solver.cpp:255]     Train net output #0: loss = 0.135867 (* 1 = 0.135867 loss)
I0110 22:35:31.943248  4932 solver.cpp:631] Iteration 49980, lr = 1e-07
I0110 22:36:15.617240  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9657 > 20) by scale factor 0.953938
I0110 22:36:15.626430  4932 solver.cpp:424] Iteration 50000, Testing net (#0)
I0110 22:37:07.994851  4932 solver.cpp:481]     Test net output #0: accuracy = 0.850526
I0110 22:37:07.994930  4932 solver.cpp:481]     Test net output #1: loss = 0.746772 (* 1 = 0.746772 loss)
I0110 22:37:09.862901  4932 solver.cpp:240] Iteration 50000, loss = 0.0524532
I0110 22:37:09.862942  4932 solver.cpp:255]     Train net output #0: loss = 0.0247509 (* 1 = 0.0247509 loss)
I0110 22:37:09.862951  4932 solver.cpp:565] MultiStep Status: Iteration 50000, step = 4
I0110 22:37:09.862962  4932 solver.cpp:631] Iteration 50000, lr = 1e-08
I0110 22:37:14.642262  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7897 > 20) by scale factor 0.806788
I0110 22:37:27.968572  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6564 > 20) by scale factor 0.845438
I0110 22:37:55.601519  4932 solver.cpp:240] Iteration 50020, loss = 0.079362
I0110 22:37:55.601613  4932 solver.cpp:255]     Train net output #0: loss = 0.251795 (* 1 = 0.251795 loss)
I0110 22:37:55.601625  4932 solver.cpp:631] Iteration 50020, lr = 1e-08
I0110 22:38:20.420119  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6694 > 20) by scale factor 0.674094
I0110 22:38:40.055147  4932 solver.cpp:240] Iteration 50040, loss = 0.0680512
I0110 22:38:40.055248  4932 solver.cpp:255]     Train net output #0: loss = 0.0148499 (* 1 = 0.0148499 loss)
I0110 22:38:40.055263  4932 solver.cpp:631] Iteration 50040, lr = 1e-08
I0110 22:38:53.712625  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4366 > 20) by scale factor 0.818443
I0110 22:39:25.324489  4932 solver.cpp:240] Iteration 50060, loss = 0.0694558
I0110 22:39:25.324587  4932 solver.cpp:255]     Train net output #0: loss = 0.2283 (* 1 = 0.2283 loss)
I0110 22:39:25.324600  4932 solver.cpp:631] Iteration 50060, lr = 1e-08
I0110 22:40:11.778815  4932 solver.cpp:240] Iteration 50080, loss = 0.0423931
I0110 22:40:11.778905  4932 solver.cpp:255]     Train net output #0: loss = 0.0501236 (* 1 = 0.0501236 loss)
I0110 22:40:11.778919  4932 solver.cpp:631] Iteration 50080, lr = 1e-08
I0110 22:40:30.146850  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7501 > 20) by scale factor 0.842101
I0110 22:40:54.564178  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.3194 > 20) by scale factor 0.659644
I0110 22:40:56.446259  4932 solver.cpp:240] Iteration 50100, loss = 0.0710508
I0110 22:40:56.446297  4932 solver.cpp:255]     Train net output #0: loss = 0.0189802 (* 1 = 0.0189802 loss)
I0110 22:40:56.446305  4932 solver.cpp:631] Iteration 50100, lr = 1e-08
I0110 22:41:41.794185  4932 solver.cpp:240] Iteration 50120, loss = 0.0441787
I0110 22:41:41.794275  4932 solver.cpp:255]     Train net output #0: loss = 0.150305 (* 1 = 0.150305 loss)
I0110 22:41:41.794287  4932 solver.cpp:631] Iteration 50120, lr = 1e-08
I0110 22:41:55.444586  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.726 > 20) by scale factor 0.777425
I0110 22:42:04.331393  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8244 > 20) by scale factor 0.916407
I0110 22:42:08.771841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9868 > 20) by scale factor 0.909636
I0110 22:42:26.186259  4932 solver.cpp:240] Iteration 50140, loss = 0.0881233
I0110 22:42:26.186365  4932 solver.cpp:255]     Train net output #0: loss = 0.000388238 (* 1 = 0.000388238 loss)
I0110 22:42:26.186377  4932 solver.cpp:631] Iteration 50140, lr = 1e-08
I0110 22:43:10.560468  4932 solver.cpp:240] Iteration 50160, loss = 0.0431602
I0110 22:43:10.560554  4932 solver.cpp:255]     Train net output #0: loss = 0.00735982 (* 1 = 0.00735982 loss)
I0110 22:43:10.560566  4932 solver.cpp:631] Iteration 50160, lr = 1e-08
I0110 22:43:17.559376  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6608 > 20) by scale factor 0.882582
I0110 22:43:55.933401  4932 solver.cpp:240] Iteration 50180, loss = 0.0620249
I0110 22:43:55.933490  4932 solver.cpp:255]     Train net output #0: loss = 0.037431 (* 1 = 0.037431 loss)
I0110 22:43:55.933501  4932 solver.cpp:631] Iteration 50180, lr = 1e-08
I0110 22:44:34.074630  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0084 > 20) by scale factor 0.952001
I0110 22:44:40.396361  4932 solver.cpp:240] Iteration 50200, loss = 0.0468544
I0110 22:44:40.396395  4932 solver.cpp:255]     Train net output #0: loss = 0.00191536 (* 1 = 0.00191536 loss)
I0110 22:44:40.396404  4932 solver.cpp:631] Iteration 50200, lr = 1e-08
I0110 22:45:16.997519  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7673 > 20) by scale factor 0.776179
I0110 22:45:26.461966  4932 solver.cpp:240] Iteration 50220, loss = 0.110064
I0110 22:45:26.462007  4932 solver.cpp:255]     Train net output #0: loss = 0.111184 (* 1 = 0.111184 loss)
I0110 22:45:26.462016  4932 solver.cpp:631] Iteration 50220, lr = 1e-08
I0110 22:45:58.880062  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.344 > 20) by scale factor 0.983089
I0110 22:46:11.854328  4932 solver.cpp:240] Iteration 50240, loss = 0.0518773
I0110 22:46:11.854374  4932 solver.cpp:255]     Train net output #0: loss = 0.0491263 (* 1 = 0.0491263 loss)
I0110 22:46:11.854393  4932 solver.cpp:631] Iteration 50240, lr = 1e-08
I0110 22:46:35.235038  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1122 > 20) by scale factor 0.796426
I0110 22:46:57.085897  4932 solver.cpp:240] Iteration 50260, loss = 0.0360281
I0110 22:46:57.085947  4932 solver.cpp:255]     Train net output #0: loss = 0.0101627 (* 1 = 0.0101627 loss)
I0110 22:46:57.085959  4932 solver.cpp:631] Iteration 50260, lr = 1e-08
I0110 22:47:01.868834  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2705 > 20) by scale factor 0.824046
I0110 22:47:42.126966  4932 solver.cpp:240] Iteration 50280, loss = 0.0572351
I0110 22:47:42.127056  4932 solver.cpp:255]     Train net output #0: loss = 0.00658789 (* 1 = 0.00658789 loss)
I0110 22:47:42.127069  4932 solver.cpp:631] Iteration 50280, lr = 1e-08
I0110 22:47:54.035944  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7595 > 20) by scale factor 0.776414
I0110 22:48:07.356622  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.242 > 20) by scale factor 0.762137
I0110 22:48:14.014211  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5643 > 20) by scale factor 0.927457
I0110 22:48:26.990525  4932 solver.cpp:240] Iteration 50300, loss = 0.07811
I0110 22:48:26.990559  4932 solver.cpp:255]     Train net output #0: loss = 0.0532796 (* 1 = 0.0532796 loss)
I0110 22:48:26.990569  4932 solver.cpp:631] Iteration 50300, lr = 1e-08
I0110 22:48:42.867383  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9296 > 20) by scale factor 0.835784
I0110 22:48:47.307552  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2868 > 20) by scale factor 0.823493
I0110 22:49:08.208904  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8687 > 20) by scale factor 0.837918
I0110 22:49:12.308737  4932 solver.cpp:240] Iteration 50320, loss = 0.0659748
I0110 22:49:12.308782  4932 solver.cpp:255]     Train net output #0: loss = 0.0485378 (* 1 = 0.0485378 loss)
I0110 22:49:12.308794  4932 solver.cpp:631] Iteration 50320, lr = 1e-08
I0110 22:49:32.622303  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0686 > 20) by scale factor 0.94928
I0110 22:49:57.869850  4932 solver.cpp:240] Iteration 50340, loss = 0.069921
I0110 22:49:57.869901  4932 solver.cpp:255]     Train net output #0: loss = 0.0429451 (* 1 = 0.0429451 loss)
I0110 22:49:57.869915  4932 solver.cpp:631] Iteration 50340, lr = 1e-08
I0110 22:50:32.367811  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2563 > 20) by scale factor 0.987348
I0110 22:50:36.811965  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8554 > 20) by scale factor 0.875065
I0110 22:50:43.130307  4932 solver.cpp:240] Iteration 50360, loss = 0.0649361
I0110 22:50:43.130342  4932 solver.cpp:255]     Train net output #0: loss = 0.0108127 (* 1 = 0.0108127 loss)
I0110 22:50:43.130352  4932 solver.cpp:631] Iteration 50360, lr = 1e-08
I0110 22:50:45.688484  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0491 > 20) by scale factor 0.997552
I0110 22:50:53.217815  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9991 > 20) by scale factor 0.95242
I0110 22:51:15.404753  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4505 > 20) by scale factor 0.785839
I0110 22:51:28.935041  4932 solver.cpp:240] Iteration 50380, loss = 0.0935623
I0110 22:51:28.935089  4932 solver.cpp:255]     Train net output #0: loss = 0.0455093 (* 1 = 0.0455093 loss)
I0110 22:51:28.935101  4932 solver.cpp:631] Iteration 50380, lr = 1e-08
I0110 22:52:03.547489  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1589 > 20) by scale factor 0.992118
I0110 22:52:14.305734  4932 solver.cpp:240] Iteration 50400, loss = 0.0635043
I0110 22:52:14.305774  4932 solver.cpp:255]     Train net output #0: loss = 0.0317062 (* 1 = 0.0317062 loss)
I0110 22:52:14.305784  4932 solver.cpp:631] Iteration 50400, lr = 1e-08
I0110 22:52:19.082238  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21 > 20) by scale factor 0.952383
I0110 22:52:59.497664  4932 solver.cpp:240] Iteration 50420, loss = 0.0689986
I0110 22:52:59.497756  4932 solver.cpp:255]     Train net output #0: loss = 0.0978577 (* 1 = 0.0978577 loss)
I0110 22:52:59.497769  4932 solver.cpp:631] Iteration 50420, lr = 1e-08
I0110 22:53:04.277091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.873 > 20) by scale factor 0.692688
I0110 22:53:22.034301  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2425 > 20) by scale factor 0.860493
I0110 22:53:26.472548  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4643 > 20) by scale factor 0.97731
I0110 22:53:37.586969  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1915 > 20) by scale factor 0.943777
I0110 22:53:43.901995  4932 solver.cpp:240] Iteration 50440, loss = 0.107553
I0110 22:53:43.902027  4932 solver.cpp:255]     Train net output #0: loss = 0.0967117 (* 1 = 0.0967117 loss)
I0110 22:53:43.902035  4932 solver.cpp:631] Iteration 50440, lr = 1e-08
I0110 22:54:11.434231  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4245 > 20) by scale factor 0.818849
I0110 22:54:28.847456  4932 solver.cpp:240] Iteration 50460, loss = 0.0775977
I0110 22:54:28.847494  4932 solver.cpp:255]     Train net output #0: loss = 0.0720787 (* 1 = 0.0720787 loss)
I0110 22:54:28.847508  4932 solver.cpp:631] Iteration 50460, lr = 1e-08
I0110 22:54:31.655804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3556 > 20) by scale factor 0.894629
I0110 22:55:14.378518  4932 solver.cpp:240] Iteration 50480, loss = 0.0672402
I0110 22:55:14.378607  4932 solver.cpp:255]     Train net output #0: loss = 0.134887 (* 1 = 0.134887 loss)
I0110 22:55:14.378618  4932 solver.cpp:631] Iteration 50480, lr = 1e-08
I0110 22:55:59.364735  4932 solver.cpp:240] Iteration 50500, loss = 0.0660699
I0110 22:55:59.364820  4932 solver.cpp:255]     Train net output #0: loss = 0.029633 (* 1 = 0.029633 loss)
I0110 22:55:59.364833  4932 solver.cpp:631] Iteration 50500, lr = 1e-08
I0110 22:56:36.004078  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9387 > 20) by scale factor 0.955169
I0110 22:56:44.547358  4932 solver.cpp:240] Iteration 50520, loss = 0.0699804
I0110 22:56:44.547400  4932 solver.cpp:255]     Train net output #0: loss = 0.114374 (* 1 = 0.114374 loss)
I0110 22:56:44.547412  4932 solver.cpp:631] Iteration 50520, lr = 1e-08
I0110 22:57:09.959625  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3616 > 20) by scale factor 0.894392
I0110 22:57:29.601132  4932 solver.cpp:240] Iteration 50540, loss = 0.0597497
I0110 22:57:29.601171  4932 solver.cpp:255]     Train net output #0: loss = 0.0220418 (* 1 = 0.0220418 loss)
I0110 22:57:29.601179  4932 solver.cpp:631] Iteration 50540, lr = 1e-08
I0110 22:57:41.036680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6289 > 20) by scale factor 0.846422
I0110 22:57:43.258229  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3483 > 20) by scale factor 0.936842
I0110 22:58:14.838151  4932 solver.cpp:240] Iteration 50560, loss = 0.0755472
I0110 22:58:14.838234  4932 solver.cpp:255]     Train net output #0: loss = 0.204435 (* 1 = 0.204435 loss)
I0110 22:58:14.838245  4932 solver.cpp:631] Iteration 50560, lr = 1e-08
I0110 22:58:24.055363  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9492 > 20) by scale factor 0.95469
I0110 22:58:28.499968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5952 > 20) by scale factor 0.885145
I0110 22:58:59.938282  4932 solver.cpp:240] Iteration 50580, loss = 0.0698932
I0110 22:58:59.938374  4932 solver.cpp:255]     Train net output #0: loss = 0.0110424 (* 1 = 0.0110424 loss)
I0110 22:58:59.938385  4932 solver.cpp:631] Iteration 50580, lr = 1e-08
I0110 22:59:04.718045  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5611 > 20) by scale factor 0.75298
I0110 22:59:09.321439  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7686 > 20) by scale factor 0.807475
I0110 22:59:40.395946  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9046 > 20) by scale factor 0.873186
I0110 22:59:45.077807  4932 solver.cpp:240] Iteration 50600, loss = 0.0877808
I0110 22:59:45.077847  4932 solver.cpp:255]     Train net output #0: loss = 0.151186 (* 1 = 0.151186 loss)
I0110 22:59:45.077857  4932 solver.cpp:631] Iteration 50600, lr = 1e-08
I0110 22:59:45.416918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7849 > 20) by scale factor 0.962239
I0110 23:00:00.953040  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3049 > 20) by scale factor 0.760315
I0110 23:00:29.463588  4932 solver.cpp:240] Iteration 50620, loss = 0.0937914
I0110 23:00:29.463682  4932 solver.cpp:255]     Train net output #0: loss = 0.0984617 (* 1 = 0.0984617 loss)
I0110 23:00:29.463696  4932 solver.cpp:631] Iteration 50620, lr = 1e-08
I0110 23:00:45.563772  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3394 > 20) by scale factor 0.75932
I0110 23:00:52.222501  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2832 > 20) by scale factor 0.93971
I0110 23:01:14.215409  4932 solver.cpp:240] Iteration 50640, loss = 0.0803372
I0110 23:01:14.215519  4932 solver.cpp:255]     Train net output #0: loss = 0.0207193 (* 1 = 0.0207193 loss)
I0110 23:01:14.215535  4932 solver.cpp:631] Iteration 50640, lr = 1e-08
I0110 23:01:54.501489  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1981 > 20) by scale factor 0.990191
I0110 23:01:56.722782  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5473 > 20) by scale factor 0.92819
I0110 23:01:58.605067  4932 solver.cpp:240] Iteration 50660, loss = 0.0683517
I0110 23:01:58.605118  4932 solver.cpp:255]     Train net output #0: loss = 0.120183 (* 1 = 0.120183 loss)
I0110 23:01:58.605146  4932 solver.cpp:631] Iteration 50660, lr = 1e-08
I0110 23:02:19.858772  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1972 > 20) by scale factor 0.862175
I0110 23:02:44.070994  4932 solver.cpp:240] Iteration 50680, loss = 0.0662474
I0110 23:02:44.071095  4932 solver.cpp:255]     Train net output #0: loss = 0.00715425 (* 1 = 0.00715425 loss)
I0110 23:02:44.071107  4932 solver.cpp:631] Iteration 50680, lr = 1e-08
I0110 23:03:15.481873  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7614 > 20) by scale factor 0.87868
I0110 23:03:28.462529  4932 solver.cpp:240] Iteration 50700, loss = 0.0919441
I0110 23:03:28.462576  4932 solver.cpp:255]     Train net output #0: loss = 0.309373 (* 1 = 0.309373 loss)
I0110 23:03:28.462589  4932 solver.cpp:631] Iteration 50700, lr = 1e-08
I0110 23:03:33.241124  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2563 > 20) by scale factor 0.987345
I0110 23:03:58.420902  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2287 > 20) by scale factor 0.942122
I0110 23:04:12.014926  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4925 > 20) by scale factor 0.754931
I0110 23:04:13.898308  4932 solver.cpp:240] Iteration 50720, loss = 0.0776516
I0110 23:04:13.898352  4932 solver.cpp:255]     Train net output #0: loss = 0.0694428 (* 1 = 0.0694428 loss)
I0110 23:04:13.898365  4932 solver.cpp:631] Iteration 50720, lr = 1e-08
I0110 23:04:25.338150  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0166 > 20) by scale factor 0.95163
I0110 23:04:31.995914  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.0202 > 20) by scale factor 0.587886
I0110 23:04:34.219131  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0528 > 20) by scale factor 0.767671
I0110 23:04:38.659246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1509 > 20) by scale factor 0.863899
I0110 23:04:58.869572  4932 solver.cpp:240] Iteration 50740, loss = 0.1125
I0110 23:04:58.869616  4932 solver.cpp:255]     Train net output #0: loss = 0.0085771 (* 1 = 0.0085771 loss)
I0110 23:04:58.869626  4932 solver.cpp:631] Iteration 50740, lr = 1e-08
I0110 23:05:43.995503  4932 solver.cpp:240] Iteration 50760, loss = 0.0652519
I0110 23:05:43.995601  4932 solver.cpp:255]     Train net output #0: loss = 0.0141967 (* 1 = 0.0141967 loss)
I0110 23:05:43.995615  4932 solver.cpp:631] Iteration 50760, lr = 1e-08
I0110 23:05:55.436203  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9858 > 20) by scale factor 0.953025
I0110 23:06:18.683377  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2746 > 20) by scale factor 0.940089
I0110 23:06:29.439791  4932 solver.cpp:240] Iteration 50780, loss = 0.0582244
I0110 23:06:29.439836  4932 solver.cpp:255]     Train net output #0: loss = 0.0267246 (* 1 = 0.0267246 loss)
I0110 23:06:29.439848  4932 solver.cpp:631] Iteration 50780, lr = 1e-08
I0110 23:06:36.434706  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4685 > 20) by scale factor 0.728107
I0110 23:06:38.655859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1239 > 20) by scale factor 0.71114
I0110 23:06:59.312760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5034 > 20) by scale factor 0.888756
I0110 23:07:14.515357  4932 solver.cpp:240] Iteration 50800, loss = 0.0756879
I0110 23:07:14.515403  4932 solver.cpp:255]     Train net output #0: loss = 0.0293385 (* 1 = 0.0293385 loss)
I0110 23:07:14.515414  4932 solver.cpp:631] Iteration 50800, lr = 1e-08
I0110 23:07:40.485741  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5392 > 20) by scale factor 0.973749
I0110 23:08:00.119405  4932 solver.cpp:240] Iteration 50820, loss = 0.056926
I0110 23:08:00.119451  4932 solver.cpp:255]     Train net output #0: loss = 0.0611626 (* 1 = 0.0611626 loss)
I0110 23:08:00.119469  4932 solver.cpp:631] Iteration 50820, lr = 1e-08
I0110 23:08:09.334862  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5255 > 20) by scale factor 0.974398
I0110 23:08:19.301172  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0377 > 20) by scale factor 0.998119
I0110 23:08:28.175640  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4431 > 20) by scale factor 0.978325
I0110 23:08:34.836449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.3264 > 20) by scale factor 0.706055
I0110 23:08:41.495091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.997 > 20) by scale factor 0.769318
I0110 23:08:45.594959  4932 solver.cpp:240] Iteration 50840, loss = 0.0886143
I0110 23:08:45.595006  4932 solver.cpp:255]     Train net output #0: loss = 0.0619315 (* 1 = 0.0619315 loss)
I0110 23:08:45.595018  4932 solver.cpp:631] Iteration 50840, lr = 1e-08
I0110 23:09:31.450254  4932 solver.cpp:240] Iteration 50860, loss = 0.0385846
I0110 23:09:31.450347  4932 solver.cpp:255]     Train net output #0: loss = 0.0586651 (* 1 = 0.0586651 loss)
I0110 23:09:31.450359  4932 solver.cpp:631] Iteration 50860, lr = 1e-08
I0110 23:10:15.838865  4932 solver.cpp:240] Iteration 50880, loss = 0.0623771
I0110 23:10:15.838951  4932 solver.cpp:255]     Train net output #0: loss = 0.101736 (* 1 = 0.101736 loss)
I0110 23:10:15.838963  4932 solver.cpp:631] Iteration 50880, lr = 1e-08
I0110 23:10:18.395138  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0768 > 20) by scale factor 0.830674
I0110 23:10:29.490298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0834 > 20) by scale factor 0.866425
I0110 23:11:00.233464  4932 solver.cpp:240] Iteration 50900, loss = 0.0783776
I0110 23:11:00.233551  4932 solver.cpp:255]     Train net output #0: loss = 0.0104571 (* 1 = 0.0104571 loss)
I0110 23:11:00.233562  4932 solver.cpp:631] Iteration 50900, lr = 1e-08
I0110 23:11:34.931378  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3984 > 20) by scale factor 0.980471
I0110 23:11:45.687016  4932 solver.cpp:240] Iteration 50920, loss = 0.0555914
I0110 23:11:45.687055  4932 solver.cpp:255]     Train net output #0: loss = 0.00587166 (* 1 = 0.00587166 loss)
I0110 23:11:45.687064  4932 solver.cpp:631] Iteration 50920, lr = 1e-08
I0110 23:12:06.243983  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9214 > 20) by scale factor 0.872546
I0110 23:12:30.767431  4932 solver.cpp:240] Iteration 50940, loss = 0.0491411
I0110 23:12:30.767474  4932 solver.cpp:255]     Train net output #0: loss = 0.000367605 (* 1 = 0.000367605 loss)
I0110 23:12:30.767483  4932 solver.cpp:631] Iteration 50940, lr = 1e-08
I0110 23:13:02.171663  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1872 > 20) by scale factor 0.943967
I0110 23:13:04.392326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9678 > 20) by scale factor 0.770183
I0110 23:13:15.151188  4932 solver.cpp:240] Iteration 50960, loss = 0.107008
I0110 23:13:15.151228  4932 solver.cpp:255]     Train net output #0: loss = 0.0936756 (* 1 = 0.0936756 loss)
I0110 23:13:15.151237  4932 solver.cpp:631] Iteration 50960, lr = 1e-08
I0110 23:13:28.813587  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2181 > 20) by scale factor 0.989212
I0110 23:13:56.072648  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4392 > 20) by scale factor 0.978511
I0110 23:14:00.177716  4932 solver.cpp:240] Iteration 50980, loss = 0.0556407
I0110 23:14:00.177759  4932 solver.cpp:255]     Train net output #0: loss = 0.00992708 (* 1 = 0.00992708 loss)
I0110 23:14:00.177770  4932 solver.cpp:631] Iteration 50980, lr = 1e-08
I0110 23:14:43.320742  4932 solver.cpp:424] Iteration 51000, Testing net (#0)
I0110 23:15:36.770874  4932 solver.cpp:481]     Test net output #0: accuracy = 0.84
I0110 23:15:36.770957  4932 solver.cpp:481]     Test net output #1: loss = 0.760506 (* 1 = 0.760506 loss)
I0110 23:15:38.637331  4932 solver.cpp:240] Iteration 51000, loss = 0.043196
I0110 23:15:38.637368  4932 solver.cpp:255]     Train net output #0: loss = 0.0206232 (* 1 = 0.0206232 loss)
I0110 23:15:38.637377  4932 solver.cpp:631] Iteration 51000, lr = 1e-08
I0110 23:16:14.476936  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.211 > 20) by scale factor 0.66201
I0110 23:16:23.563060  4932 solver.cpp:240] Iteration 51020, loss = 0.0735759
I0110 23:16:23.563102  4932 solver.cpp:255]     Train net output #0: loss = 0.00325304 (* 1 = 0.00325304 loss)
I0110 23:16:23.563112  4932 solver.cpp:631] Iteration 51020, lr = 1e-08
I0110 23:17:06.633170  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7914 > 20) by scale factor 0.877523
I0110 23:17:08.514571  4932 solver.cpp:240] Iteration 51040, loss = 0.0712062
I0110 23:17:08.514611  4932 solver.cpp:255]     Train net output #0: loss = 0.00363702 (* 1 = 0.00363702 loss)
I0110 23:17:08.514621  4932 solver.cpp:631] Iteration 51040, lr = 1e-08
I0110 23:17:19.949834  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6748 > 20) by scale factor 0.844781
I0110 23:17:53.785626  4932 solver.cpp:240] Iteration 51060, loss = 0.0655171
I0110 23:17:53.785714  4932 solver.cpp:255]     Train net output #0: loss = 0.0029544 (* 1 = 0.0029544 loss)
I0110 23:17:53.785727  4932 solver.cpp:631] Iteration 51060, lr = 1e-08
I0110 23:18:39.281205  4932 solver.cpp:240] Iteration 51080, loss = 0.0392318
I0110 23:18:39.281289  4932 solver.cpp:255]     Train net output #0: loss = 0.0615679 (* 1 = 0.0615679 loss)
I0110 23:18:39.281303  4932 solver.cpp:631] Iteration 51080, lr = 1e-08
I0110 23:18:55.745059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2774 > 20) by scale factor 0.859202
I0110 23:19:22.372931  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9285 > 20) by scale factor 0.912054
I0110 23:19:24.255156  4932 solver.cpp:240] Iteration 51100, loss = 0.0659864
I0110 23:19:24.255203  4932 solver.cpp:255]     Train net output #0: loss = 0.0115911 (* 1 = 0.0115911 loss)
I0110 23:19:24.255214  4932 solver.cpp:631] Iteration 51100, lr = 1e-08
I0110 23:19:42.352313  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8729 > 20) by scale factor 0.914374
I0110 23:19:56.243036  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6654 > 20) by scale factor 0.810852
I0110 23:20:09.217774  4932 solver.cpp:240] Iteration 51120, loss = 0.0617494
I0110 23:20:09.217818  4932 solver.cpp:255]     Train net output #0: loss = 0.00486043 (* 1 = 0.00486043 loss)
I0110 23:20:09.217828  4932 solver.cpp:631] Iteration 51120, lr = 1e-08
I0110 23:20:54.315495  4932 solver.cpp:240] Iteration 51140, loss = 0.0644971
I0110 23:20:54.315570  4932 solver.cpp:255]     Train net output #0: loss = 0.0686819 (* 1 = 0.0686819 loss)
I0110 23:20:54.315582  4932 solver.cpp:631] Iteration 51140, lr = 1e-08
I0110 23:21:03.530993  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0017 > 20) by scale factor 0.76918
I0110 23:21:05.752874  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7592 > 20) by scale factor 0.84178
I0110 23:21:39.254292  4932 solver.cpp:240] Iteration 51160, loss = 0.0814677
I0110 23:21:39.254390  4932 solver.cpp:255]     Train net output #0: loss = 0.0393892 (* 1 = 0.0393892 loss)
I0110 23:21:39.254402  4932 solver.cpp:631] Iteration 51160, lr = 1e-08
I0110 23:21:53.655724  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1836 > 20) by scale factor 0.901568
I0110 23:21:55.876272  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6302 > 20) by scale factor 0.846376
I0110 23:22:20.888034  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3985 > 20) by scale factor 0.854757
I0110 23:22:23.109612  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.162 > 20) by scale factor 0.863484
I0110 23:22:24.991292  4932 solver.cpp:240] Iteration 51180, loss = 0.0629136
I0110 23:22:24.991334  4932 solver.cpp:255]     Train net output #0: loss = 0.00810505 (* 1 = 0.00810505 loss)
I0110 23:22:24.991343  4932 solver.cpp:631] Iteration 51180, lr = 1e-08
I0110 23:23:01.202584  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3508 > 20) by scale factor 0.821327
I0110 23:23:09.738327  4932 solver.cpp:240] Iteration 51200, loss = 0.0712386
I0110 23:23:09.738366  4932 solver.cpp:255]     Train net output #0: loss = 0.00226518 (* 1 = 0.00226518 loss)
I0110 23:23:09.738375  4932 solver.cpp:631] Iteration 51200, lr = 1e-08
I0110 23:23:44.126248  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0142 > 20) by scale factor 0.832841
I0110 23:23:46.346544  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5734 > 20) by scale factor 0.813888
I0110 23:23:54.892506  4932 solver.cpp:240] Iteration 51220, loss = 0.0682409
I0110 23:23:54.892554  4932 solver.cpp:255]     Train net output #0: loss = 0.00975988 (* 1 = 0.00975988 loss)
I0110 23:23:54.892565  4932 solver.cpp:631] Iteration 51220, lr = 1e-08
I0110 23:24:20.518759  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8615 > 20) by scale factor 0.838169
I0110 23:24:29.397680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.129 > 20) by scale factor 0.993593
I0110 23:24:31.618724  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9645 > 20) by scale factor 0.910561
I0110 23:24:40.159368  4932 solver.cpp:240] Iteration 51240, loss = 0.06138
I0110 23:24:40.159409  4932 solver.cpp:255]     Train net output #0: loss = 0.000216837 (* 1 = 0.000216837 loss)
I0110 23:24:40.159420  4932 solver.cpp:631] Iteration 51240, lr = 1e-08
I0110 23:25:24.538628  4932 solver.cpp:240] Iteration 51260, loss = 0.0484597
I0110 23:25:24.538713  4932 solver.cpp:255]     Train net output #0: loss = 0.0637765 (* 1 = 0.0637765 loss)
I0110 23:25:24.538724  4932 solver.cpp:631] Iteration 51260, lr = 1e-08
I0110 23:26:10.115229  4932 solver.cpp:240] Iteration 51280, loss = 0.0717371
I0110 23:26:10.115316  4932 solver.cpp:255]     Train net output #0: loss = 0.144988 (* 1 = 0.144988 loss)
I0110 23:26:10.115329  4932 solver.cpp:631] Iteration 51280, lr = 1e-08
I0110 23:26:23.773767  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9206 > 20) by scale factor 0.80255
I0110 23:26:25.993321  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8367 > 20) by scale factor 0.959847
I0110 23:26:55.124873  4932 solver.cpp:240] Iteration 51300, loss = 0.0638229
I0110 23:26:55.124971  4932 solver.cpp:255]     Train net output #0: loss = 0.0196616 (* 1 = 0.0196616 loss)
I0110 23:26:55.124985  4932 solver.cpp:631] Iteration 51300, lr = 1e-08
I0110 23:27:02.117422  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0219 > 20) by scale factor 0.832575
I0110 23:27:40.161747  4932 solver.cpp:240] Iteration 51320, loss = 0.0508272
I0110 23:27:40.161841  4932 solver.cpp:255]     Train net output #0: loss = 0.0919526 (* 1 = 0.0919526 loss)
I0110 23:27:40.161855  4932 solver.cpp:631] Iteration 51320, lr = 1e-08
I0110 23:28:09.939628  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.743 > 20) by scale factor 0.919837
I0110 23:28:25.134994  4932 solver.cpp:240] Iteration 51340, loss = 0.0495028
I0110 23:28:25.135087  4932 solver.cpp:255]     Train net output #0: loss = 0.00588717 (* 1 = 0.00588717 loss)
I0110 23:28:25.135098  4932 solver.cpp:631] Iteration 51340, lr = 1e-08
I0110 23:29:07.635563  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2616 > 20) by scale factor 0.898407
I0110 23:29:09.516820  4932 solver.cpp:240] Iteration 51360, loss = 0.0890172
I0110 23:29:09.516860  4932 solver.cpp:255]     Train net output #0: loss = 0.0271748 (* 1 = 0.0271748 loss)
I0110 23:29:09.516870  4932 solver.cpp:631] Iteration 51360, lr = 1e-08
I0110 23:29:12.073781  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4049 > 20) by scale factor 0.787251
I0110 23:29:54.457948  4932 solver.cpp:240] Iteration 51380, loss = 0.0643269
I0110 23:29:54.458055  4932 solver.cpp:255]     Train net output #0: loss = 0.0353882 (* 1 = 0.0353882 loss)
I0110 23:29:54.458067  4932 solver.cpp:631] Iteration 51380, lr = 1e-08
I0110 23:30:39.414659  4932 solver.cpp:240] Iteration 51400, loss = 0.0618768
I0110 23:30:39.414752  4932 solver.cpp:255]     Train net output #0: loss = 0.000546249 (* 1 = 0.000546249 loss)
I0110 23:30:39.414767  4932 solver.cpp:631] Iteration 51400, lr = 1e-08
I0110 23:31:24.217433  4932 solver.cpp:240] Iteration 51420, loss = 0.0782228
I0110 23:31:24.217525  4932 solver.cpp:255]     Train net output #0: loss = 0.337005 (* 1 = 0.337005 loss)
I0110 23:31:24.217536  4932 solver.cpp:631] Iteration 51420, lr = 1e-08
I0110 23:32:04.798089  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5201 > 20) by scale factor 0.815656
I0110 23:32:08.901238  4932 solver.cpp:240] Iteration 51440, loss = 0.0786884
I0110 23:32:08.901284  4932 solver.cpp:255]     Train net output #0: loss = 0.0551591 (* 1 = 0.0551591 loss)
I0110 23:32:08.901298  4932 solver.cpp:631] Iteration 51440, lr = 1e-08
I0110 23:32:53.307934  4932 solver.cpp:240] Iteration 51460, loss = 0.0576851
I0110 23:32:53.308022  4932 solver.cpp:255]     Train net output #0: loss = 0.0267159 (* 1 = 0.0267159 loss)
I0110 23:32:53.308034  4932 solver.cpp:631] Iteration 51460, lr = 1e-08
I0110 23:33:16.682606  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7622 > 20) by scale factor 0.841674
I0110 23:33:38.936636  4932 solver.cpp:240] Iteration 51480, loss = 0.0716111
I0110 23:33:38.936722  4932 solver.cpp:255]     Train net output #0: loss = 0.0256076 (* 1 = 0.0256076 loss)
I0110 23:33:38.936734  4932 solver.cpp:631] Iteration 51480, lr = 1e-08
I0110 23:33:45.934075  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1088 > 20) by scale factor 0.904618
I0110 23:34:24.260546  4932 solver.cpp:240] Iteration 51500, loss = 0.0559872
I0110 23:34:24.260643  4932 solver.cpp:255]     Train net output #0: loss = 0.00586271 (* 1 = 0.00586271 loss)
I0110 23:34:24.260655  4932 solver.cpp:631] Iteration 51500, lr = 1e-08
I0110 23:34:40.127643  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2828 > 20) by scale factor 0.986059
I0110 23:35:09.260222  4932 solver.cpp:240] Iteration 51520, loss = 0.045568
I0110 23:35:09.260321  4932 solver.cpp:255]     Train net output #0: loss = 0.0238735 (* 1 = 0.0238735 loss)
I0110 23:35:09.260335  4932 solver.cpp:631] Iteration 51520, lr = 1e-08
I0110 23:35:50.746531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.681 > 20) by scale factor 0.749596
I0110 23:35:54.847637  4932 solver.cpp:240] Iteration 51540, loss = 0.0622571
I0110 23:35:54.847678  4932 solver.cpp:255]     Train net output #0: loss = 0.186335 (* 1 = 0.186335 loss)
I0110 23:35:54.847689  4932 solver.cpp:631] Iteration 51540, lr = 1e-08
I0110 23:36:24.728644  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.214 > 20) by scale factor 0.900333
I0110 23:36:36.598045  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.541 > 20) by scale factor 0.88727
I0110 23:36:40.697113  4932 solver.cpp:240] Iteration 51560, loss = 0.0869117
I0110 23:36:40.697149  4932 solver.cpp:255]     Train net output #0: loss = 0.00525532 (* 1 = 0.00525532 loss)
I0110 23:36:40.697159  4932 solver.cpp:631] Iteration 51560, lr = 1e-08
I0110 23:37:25.792583  4932 solver.cpp:240] Iteration 51580, loss = 0.0546131
I0110 23:37:25.792683  4932 solver.cpp:255]     Train net output #0: loss = 0.00508679 (* 1 = 0.00508679 loss)
I0110 23:37:25.792697  4932 solver.cpp:631] Iteration 51580, lr = 1e-08
I0110 23:37:30.568596  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1089 > 20) by scale factor 0.994586
I0110 23:38:10.854182  4932 solver.cpp:240] Iteration 51600, loss = 0.0646845
I0110 23:38:10.854275  4932 solver.cpp:255]     Train net output #0: loss = 0.00226082 (* 1 = 0.00226082 loss)
I0110 23:38:10.854287  4932 solver.cpp:631] Iteration 51600, lr = 1e-08
I0110 23:38:45.119014  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.76 > 20) by scale factor 0.878733
I0110 23:38:55.874975  4932 solver.cpp:240] Iteration 51620, loss = 0.044978
I0110 23:38:55.875020  4932 solver.cpp:255]     Train net output #0: loss = 0.251431 (* 1 = 0.251431 loss)
I0110 23:38:55.875036  4932 solver.cpp:631] Iteration 51620, lr = 1e-08
I0110 23:39:05.838176  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7289 > 20) by scale factor 0.964837
I0110 23:39:21.371503  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7394 > 20) by scale factor 0.747961
I0110 23:39:41.544231  4932 solver.cpp:240] Iteration 51640, loss = 0.0947314
I0110 23:39:41.544275  4932 solver.cpp:255]     Train net output #0: loss = 0.0285213 (* 1 = 0.0285213 loss)
I0110 23:39:41.544283  4932 solver.cpp:631] Iteration 51640, lr = 1e-08
I0110 23:39:52.977947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1667 > 20) by scale factor 0.764329
I0110 23:40:16.097334  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7013 > 20) by scale factor 0.749026
I0110 23:40:26.862167  4932 solver.cpp:240] Iteration 51660, loss = 0.0861147
I0110 23:40:26.862260  4932 solver.cpp:255]     Train net output #0: loss = 0.0386215 (* 1 = 0.0386215 loss)
I0110 23:40:26.862274  4932 solver.cpp:631] Iteration 51660, lr = 1e-08
I0110 23:40:56.506526  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2892 > 20) by scale factor 0.985747
I0110 23:41:11.699395  4932 solver.cpp:240] Iteration 51680, loss = 0.072962
I0110 23:41:11.699508  4932 solver.cpp:255]     Train net output #0: loss = 0.00358002 (* 1 = 0.00358002 loss)
I0110 23:41:11.699524  4932 solver.cpp:631] Iteration 51680, lr = 1e-08
I0110 23:41:23.139750  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.046 > 20) by scale factor 0.86783
I0110 23:41:38.678562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0295 > 20) by scale factor 0.998526
I0110 23:41:56.097558  4932 solver.cpp:240] Iteration 51700, loss = 0.0567651
I0110 23:41:56.097652  4932 solver.cpp:255]     Train net output #0: loss = 0.0379148 (* 1 = 0.0379148 loss)
I0110 23:41:56.097666  4932 solver.cpp:631] Iteration 51700, lr = 1e-08
I0110 23:42:05.308862  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9063 > 20) by scale factor 0.772014
I0110 23:42:11.971001  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3654 > 20) by scale factor 0.982057
I0110 23:42:20.847877  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2 > 20) by scale factor 0.709221
I0110 23:42:32.407310  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8155 > 20) by scale factor 0.719023
I0110 23:42:40.944016  4932 solver.cpp:240] Iteration 51720, loss = 0.0877355
I0110 23:42:40.944063  4932 solver.cpp:255]     Train net output #0: loss = 0.0225633 (* 1 = 0.0225633 loss)
I0110 23:42:40.944075  4932 solver.cpp:631] Iteration 51720, lr = 1e-08
I0110 23:42:50.161859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7533 > 20) by scale factor 0.878994
I0110 23:43:10.359143  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4364 > 20) by scale factor 0.978646
I0110 23:43:25.557271  4932 solver.cpp:240] Iteration 51740, loss = 0.0850406
I0110 23:43:25.557312  4932 solver.cpp:255]     Train net output #0: loss = 0.155028 (* 1 = 0.155028 loss)
I0110 23:43:25.557322  4932 solver.cpp:631] Iteration 51740, lr = 1e-08
I0110 23:44:11.204555  4932 solver.cpp:240] Iteration 51760, loss = 0.0824192
I0110 23:44:11.204658  4932 solver.cpp:255]     Train net output #0: loss = 0.16382 (* 1 = 0.16382 loss)
I0110 23:44:11.204674  4932 solver.cpp:631] Iteration 51760, lr = 1e-08
I0110 23:44:13.762187  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9643 > 20) by scale factor 0.954004
I0110 23:44:24.861482  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9072 > 20) by scale factor 0.95661
I0110 23:44:55.591605  4932 solver.cpp:240] Iteration 51780, loss = 0.0795611
I0110 23:44:55.591686  4932 solver.cpp:255]     Train net output #0: loss = 0.277771 (* 1 = 0.277771 loss)
I0110 23:44:55.591696  4932 solver.cpp:631] Iteration 51780, lr = 1e-08
I0110 23:45:33.653780  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5312 > 20) by scale factor 0.815289
I0110 23:45:39.973126  4932 solver.cpp:240] Iteration 51800, loss = 0.0533775
I0110 23:45:39.973173  4932 solver.cpp:255]     Train net output #0: loss = 0.0202715 (* 1 = 0.0202715 loss)
I0110 23:45:39.973186  4932 solver.cpp:631] Iteration 51800, lr = 1e-08
I0110 23:46:05.491477  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.716 > 20) by scale factor 0.777727
I0110 23:46:25.786481  4932 solver.cpp:240] Iteration 51820, loss = 0.068991
I0110 23:46:25.786522  4932 solver.cpp:255]     Train net output #0: loss = 0.0290573 (* 1 = 0.0290573 loss)
I0110 23:46:25.786532  4932 solver.cpp:631] Iteration 51820, lr = 1e-08
I0110 23:46:41.660504  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0419 > 20) by scale factor 0.907364
I0110 23:47:10.852145  4932 solver.cpp:240] Iteration 51840, loss = 0.0554205
I0110 23:47:10.852197  4932 solver.cpp:255]     Train net output #0: loss = 0.0035104 (* 1 = 0.0035104 loss)
I0110 23:47:10.852210  4932 solver.cpp:631] Iteration 51840, lr = 1e-08
I0110 23:47:28.946562  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0337 > 20) by scale factor 0.907699
I0110 23:47:47.021996  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3592 > 20) by scale factor 0.982358
I0110 23:47:51.466759  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7902 > 20) by scale factor 0.877568
I0110 23:47:55.570400  4932 solver.cpp:240] Iteration 51860, loss = 0.0609764
I0110 23:47:55.570441  4932 solver.cpp:255]     Train net output #0: loss = 0.0121456 (* 1 = 0.0121456 loss)
I0110 23:47:55.570451  4932 solver.cpp:631] Iteration 51860, lr = 1e-08
I0110 23:48:14.324894  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3838 > 20) by scale factor 0.935286
I0110 23:48:40.636219  4932 solver.cpp:240] Iteration 51880, loss = 0.0606771
I0110 23:48:40.636270  4932 solver.cpp:255]     Train net output #0: loss = 0.0334296 (* 1 = 0.0334296 loss)
I0110 23:48:40.636286  4932 solver.cpp:631] Iteration 51880, lr = 1e-08
I0110 23:49:06.266540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.438 > 20) by scale factor 0.853316
I0110 23:49:25.897253  4932 solver.cpp:240] Iteration 51900, loss = 0.0593308
I0110 23:49:25.897295  4932 solver.cpp:255]     Train net output #0: loss = 0.00307489 (* 1 = 0.00307489 loss)
I0110 23:49:25.897305  4932 solver.cpp:631] Iteration 51900, lr = 1e-08
I0110 23:49:30.674273  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.5446 > 20) by scale factor 0.614542
I0110 23:49:35.116262  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1109 > 20) by scale factor 0.994487
I0110 23:50:10.284987  4932 solver.cpp:240] Iteration 51920, loss = 0.0853062
I0110 23:50:10.285080  4932 solver.cpp:255]     Train net output #0: loss = 0.0504946 (* 1 = 0.0504946 loss)
I0110 23:50:10.285094  4932 solver.cpp:631] Iteration 51920, lr = 1e-08
I0110 23:50:44.599678  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5403 > 20) by scale factor 0.973695
I0110 23:50:55.359791  4932 solver.cpp:240] Iteration 51940, loss = 0.0733929
I0110 23:50:55.359829  4932 solver.cpp:255]     Train net output #0: loss = 0.0795395 (* 1 = 0.0795395 loss)
I0110 23:50:55.359845  4932 solver.cpp:631] Iteration 51940, lr = 1e-08
I0110 23:51:40.172392  4932 solver.cpp:240] Iteration 51960, loss = 0.0405736
I0110 23:51:40.172511  4932 solver.cpp:255]     Train net output #0: loss = 0.129117 (* 1 = 0.129117 loss)
I0110 23:51:40.172524  4932 solver.cpp:631] Iteration 51960, lr = 1e-08
I0110 23:51:40.511801  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0387 > 20) by scale factor 0.950629
I0110 23:51:51.605634  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7007 > 20) by scale factor 0.881031
I0110 23:52:18.240903  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2468 > 20) by scale factor 0.987808
I0110 23:52:24.562314  4932 solver.cpp:240] Iteration 51980, loss = 0.0488418
I0110 23:52:24.562353  4932 solver.cpp:255]     Train net output #0: loss = 0.0306298 (* 1 = 0.0306298 loss)
I0110 23:52:24.562362  4932 solver.cpp:631] Iteration 51980, lr = 1e-08
I0110 23:52:47.090939  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2668 > 20) by scale factor 0.761416
I0110 23:52:49.698464  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9502 > 20) by scale factor 0.835066
I0110 23:52:54.142282  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0844 > 20) by scale factor 0.948568
I0110 23:53:07.468753  4932 solver.cpp:424] Iteration 52000, Testing net (#0)
I0110 23:53:55.928733  4932 solver.cpp:481]     Test net output #0: accuracy = 0.825263
I0110 23:53:55.928834  4932 solver.cpp:481]     Test net output #1: loss = 0.899572 (* 1 = 0.899572 loss)
I0110 23:53:57.796115  4932 solver.cpp:240] Iteration 52000, loss = 0.0811508
I0110 23:53:57.796160  4932 solver.cpp:255]     Train net output #0: loss = 0.0058012 (* 1 = 0.0058012 loss)
I0110 23:53:57.796172  4932 solver.cpp:631] Iteration 52000, lr = 1e-08
I0110 23:54:42.716357  4932 solver.cpp:240] Iteration 52020, loss = 0.065425
I0110 23:54:42.716452  4932 solver.cpp:255]     Train net output #0: loss = 0.0284448 (* 1 = 0.0284448 loss)
I0110 23:54:42.716465  4932 solver.cpp:631] Iteration 52020, lr = 1e-08
I0110 23:55:07.467195  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5184 > 20) by scale factor 0.929436
I0110 23:55:20.786553  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.3042 > 20) by scale factor 0.619115
I0110 23:55:27.166528  4932 solver.cpp:240] Iteration 52040, loss = 0.0559775
I0110 23:55:27.166563  4932 solver.cpp:255]     Train net output #0: loss = 0.0589665 (* 1 = 0.0589665 loss)
I0110 23:55:27.166571  4932 solver.cpp:631] Iteration 52040, lr = 1e-08
I0110 23:55:58.569151  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0494 > 20) by scale factor 0.950147
I0110 23:56:09.667683  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.525 > 20) by scale factor 0.677392
I0110 23:56:11.549728  4932 solver.cpp:240] Iteration 52060, loss = 0.0750179
I0110 23:56:11.549769  4932 solver.cpp:255]     Train net output #0: loss = 0.0401362 (* 1 = 0.0401362 loss)
I0110 23:56:11.549779  4932 solver.cpp:631] Iteration 52060, lr = 1e-08
I0110 23:56:51.829423  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.347 > 20) by scale factor 0.856641
I0110 23:56:54.052644  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.493 > 20) by scale factor 0.816561
I0110 23:56:55.935878  4932 solver.cpp:240] Iteration 52080, loss = 0.0907675
I0110 23:56:55.935916  4932 solver.cpp:255]     Train net output #0: loss = 0.0378607 (* 1 = 0.0378607 loss)
I0110 23:56:55.935926  4932 solver.cpp:631] Iteration 52080, lr = 1e-08
I0110 23:57:20.680402  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.948 > 20) by scale factor 0.911246
I0110 23:57:40.612128  4932 solver.cpp:240] Iteration 52100, loss = 0.0364049
I0110 23:57:40.612238  4932 solver.cpp:255]     Train net output #0: loss = 0.00653249 (* 1 = 0.00653249 loss)
I0110 23:57:40.612252  4932 solver.cpp:631] Iteration 52100, lr = 1e-08
I0110 23:57:54.266309  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1589 > 20) by scale factor 0.992119
I0110 23:58:25.003840  4932 solver.cpp:240] Iteration 52120, loss = 0.0474067
I0110 23:58:25.003934  4932 solver.cpp:255]     Train net output #0: loss = 0.00761063 (* 1 = 0.00761063 loss)
I0110 23:58:25.003947  4932 solver.cpp:631] Iteration 52120, lr = 1e-08
I0110 23:59:09.702812  4932 solver.cpp:240] Iteration 52140, loss = 0.0431904
I0110 23:59:09.702906  4932 solver.cpp:255]     Train net output #0: loss = 0.0487122 (* 1 = 0.0487122 loss)
I0110 23:59:09.702919  4932 solver.cpp:631] Iteration 52140, lr = 1e-08
I0110 23:59:34.618747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5126 > 20) by scale factor 0.97501
I0110 23:59:54.253154  4932 solver.cpp:240] Iteration 52160, loss = 0.0568638
I0110 23:59:54.253254  4932 solver.cpp:255]     Train net output #0: loss = 0.0506228 (* 1 = 0.0506228 loss)
I0110 23:59:54.253265  4932 solver.cpp:631] Iteration 52160, lr = 1e-08
I0110 23:59:59.030220  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5315 > 20) by scale factor 0.928872
I0111 00:00:17.330328  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7387 > 20) by scale factor 0.842506
I0111 00:00:30.649762  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9884 > 20) by scale factor 0.90957
I0111 00:00:39.677213  4932 solver.cpp:240] Iteration 52180, loss = 0.0936858
I0111 00:00:39.677253  4932 solver.cpp:255]     Train net output #0: loss = 0.0553351 (* 1 = 0.0553351 loss)
I0111 00:00:39.677265  4932 solver.cpp:631] Iteration 52180, lr = 1e-08
I0111 00:00:51.117743  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0224 > 20) by scale factor 0.868718
I0111 00:01:24.405895  4932 solver.cpp:240] Iteration 52200, loss = 0.060684
I0111 00:01:24.405992  4932 solver.cpp:255]     Train net output #0: loss = 0.0110376 (* 1 = 0.0110376 loss)
I0111 00:01:24.406007  4932 solver.cpp:631] Iteration 52200, lr = 1e-08
I0111 00:02:09.614433  4932 solver.cpp:240] Iteration 52220, loss = 0.0503136
I0111 00:02:09.614542  4932 solver.cpp:255]     Train net output #0: loss = 0.058903 (* 1 = 0.058903 loss)
I0111 00:02:09.614557  4932 solver.cpp:631] Iteration 52220, lr = 1e-08
I0111 00:02:39.233911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2754 > 20) by scale factor 0.986417
I0111 00:02:54.430317  4932 solver.cpp:240] Iteration 52240, loss = 0.0655648
I0111 00:02:54.430393  4932 solver.cpp:255]     Train net output #0: loss = 0.133966 (* 1 = 0.133966 loss)
I0111 00:02:54.430405  4932 solver.cpp:631] Iteration 52240, lr = 1e-08
I0111 00:03:38.879760  4932 solver.cpp:240] Iteration 52260, loss = 0.046166
I0111 00:03:38.879866  4932 solver.cpp:255]     Train net output #0: loss = 0.0181409 (* 1 = 0.0181409 loss)
I0111 00:03:38.879884  4932 solver.cpp:631] Iteration 52260, lr = 1e-08
I0111 00:03:48.096438  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4276 > 20) by scale factor 0.979067
I0111 00:04:23.936800  4932 solver.cpp:240] Iteration 52280, loss = 0.0869682
I0111 00:04:23.936887  4932 solver.cpp:255]     Train net output #0: loss = 0.0313937 (* 1 = 0.0313937 loss)
I0111 00:04:23.936899  4932 solver.cpp:631] Iteration 52280, lr = 1e-08
I0111 00:05:08.824048  4932 solver.cpp:240] Iteration 52300, loss = 0.0632344
I0111 00:05:08.824134  4932 solver.cpp:255]     Train net output #0: loss = 0.0346813 (* 1 = 0.0346813 loss)
I0111 00:05:08.824146  4932 solver.cpp:631] Iteration 52300, lr = 1e-08
I0111 00:05:13.599385  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7077 > 20) by scale factor 0.843607
I0111 00:05:53.429723  4932 solver.cpp:240] Iteration 52320, loss = 0.0873396
I0111 00:05:53.429817  4932 solver.cpp:255]     Train net output #0: loss = 0.0144918 (* 1 = 0.0144918 loss)
I0111 00:05:53.429829  4932 solver.cpp:631] Iteration 52320, lr = 1e-08
I0111 00:06:38.096508  4932 solver.cpp:240] Iteration 52340, loss = 0.0373813
I0111 00:06:38.096626  4932 solver.cpp:255]     Train net output #0: loss = 0.0338332 (* 1 = 0.0338332 loss)
I0111 00:06:38.096642  4932 solver.cpp:631] Iteration 52340, lr = 1e-08
I0111 00:07:23.143018  4932 solver.cpp:240] Iteration 52360, loss = 0.061017
I0111 00:07:23.143100  4932 solver.cpp:255]     Train net output #0: loss = 0.138914 (* 1 = 0.138914 loss)
I0111 00:07:23.143112  4932 solver.cpp:631] Iteration 52360, lr = 1e-08
I0111 00:08:07.525190  4932 solver.cpp:240] Iteration 52380, loss = 0.0366649
I0111 00:08:07.525285  4932 solver.cpp:255]     Train net output #0: loss = 0.0665592 (* 1 = 0.0665592 loss)
I0111 00:08:07.525297  4932 solver.cpp:631] Iteration 52380, lr = 1e-08
I0111 00:08:16.737824  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.9832 > 20) by scale factor 0.555815
I0111 00:08:34.492050  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.203 > 20) by scale factor 0.793557
I0111 00:08:50.029167  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9245 > 20) by scale factor 0.802422
I0111 00:08:51.912142  4932 solver.cpp:240] Iteration 52400, loss = 0.0699471
I0111 00:08:51.912179  4932 solver.cpp:255]     Train net output #0: loss = 0.0109066 (* 1 = 0.0109066 loss)
I0111 00:08:51.912189  4932 solver.cpp:631] Iteration 52400, lr = 1e-08
I0111 00:09:10.445399  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5735 > 20) by scale factor 0.972125
I0111 00:09:32.640324  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.5845 > 20) by scale factor 0.562043
I0111 00:09:36.742554  4932 solver.cpp:240] Iteration 52420, loss = 0.0925917
I0111 00:09:36.742601  4932 solver.cpp:255]     Train net output #0: loss = 0.00966928 (* 1 = 0.00966928 loss)
I0111 00:09:36.742614  4932 solver.cpp:631] Iteration 52420, lr = 1e-08
I0111 00:10:21.840634  4932 solver.cpp:240] Iteration 52440, loss = 0.0749078
I0111 00:10:21.840725  4932 solver.cpp:255]     Train net output #0: loss = 0.226464 (* 1 = 0.226464 loss)
I0111 00:10:21.840737  4932 solver.cpp:631] Iteration 52440, lr = 1e-08
I0111 00:10:33.845865  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7953 > 20) by scale factor 0.91763
I0111 00:11:06.793191  4932 solver.cpp:240] Iteration 52460, loss = 0.0708676
I0111 00:11:06.793287  4932 solver.cpp:255]     Train net output #0: loss = 0.00448721 (* 1 = 0.00448721 loss)
I0111 00:11:06.793300  4932 solver.cpp:631] Iteration 52460, lr = 1e-08
I0111 00:11:42.630769  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4382 > 20) by scale factor 0.853309
I0111 00:11:51.168254  4932 solver.cpp:240] Iteration 52480, loss = 0.0730237
I0111 00:11:51.168299  4932 solver.cpp:255]     Train net output #0: loss = 0.0907989 (* 1 = 0.0907989 loss)
I0111 00:11:51.168311  4932 solver.cpp:631] Iteration 52480, lr = 1e-08
I0111 00:11:55.946933  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9219 > 20) by scale factor 0.691518
I0111 00:11:58.166754  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.9282 > 20) by scale factor 0.626405
I0111 00:12:16.158541  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3593 > 20) by scale factor 0.681215
I0111 00:12:22.819766  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7576 > 20) by scale factor 0.878828
I0111 00:12:35.794564  4932 solver.cpp:240] Iteration 52500, loss = 0.112087
I0111 00:12:35.794602  4932 solver.cpp:255]     Train net output #0: loss = 0.0181359 (* 1 = 0.0181359 loss)
I0111 00:12:35.794611  4932 solver.cpp:631] Iteration 52500, lr = 1e-08
I0111 00:13:01.106487  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5098 > 20) by scale factor 0.701514
I0111 00:13:16.644014  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7353 > 20) by scale factor 0.964541
I0111 00:13:20.745605  4932 solver.cpp:240] Iteration 52520, loss = 0.0791704
I0111 00:13:20.745649  4932 solver.cpp:255]     Train net output #0: loss = 0.086539 (* 1 = 0.086539 loss)
I0111 00:13:20.745658  4932 solver.cpp:631] Iteration 52520, lr = 1e-08
I0111 00:14:05.232367  4932 solver.cpp:240] Iteration 52540, loss = 0.0798752
I0111 00:14:05.232468  4932 solver.cpp:255]     Train net output #0: loss = 0.0383286 (* 1 = 0.0383286 loss)
I0111 00:14:05.232481  4932 solver.cpp:631] Iteration 52540, lr = 1e-08
I0111 00:14:10.006665  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0781 > 20) by scale factor 0.905873
I0111 00:14:50.094106  4932 solver.cpp:240] Iteration 52560, loss = 0.077198
I0111 00:14:50.094199  4932 solver.cpp:255]     Train net output #0: loss = 0.149068 (* 1 = 0.149068 loss)
I0111 00:14:50.094211  4932 solver.cpp:631] Iteration 52560, lr = 1e-08
I0111 00:14:50.433430  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4276 > 20) by scale factor 0.933374
I0111 00:15:35.150678  4932 solver.cpp:240] Iteration 52580, loss = 0.0476218
I0111 00:15:35.150776  4932 solver.cpp:255]     Train net output #0: loss = 0.115196 (* 1 = 0.115196 loss)
I0111 00:15:35.150790  4932 solver.cpp:631] Iteration 52580, lr = 1e-08
I0111 00:15:46.586845  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0926 > 20) by scale factor 0.711931
I0111 00:15:53.246603  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4919 > 20) by scale factor 0.930584
I0111 00:16:02.583822  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.537 > 20) by scale factor 0.849725
I0111 00:16:09.247926  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4636 > 20) by scale factor 0.977345
I0111 00:16:20.004966  4932 solver.cpp:240] Iteration 52600, loss = 0.0917121
I0111 00:16:20.005008  4932 solver.cpp:255]     Train net output #0: loss = 0.135984 (* 1 = 0.135984 loss)
I0111 00:16:20.005023  4932 solver.cpp:631] Iteration 52600, lr = 1e-08
I0111 00:17:04.720003  4932 solver.cpp:240] Iteration 52620, loss = 0.0417581
I0111 00:17:04.720082  4932 solver.cpp:255]     Train net output #0: loss = 0.0412683 (* 1 = 0.0412683 loss)
I0111 00:17:04.720093  4932 solver.cpp:631] Iteration 52620, lr = 1e-08
I0111 00:17:47.217453  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1758 > 20) by scale factor 0.944474
I0111 00:17:49.101191  4932 solver.cpp:240] Iteration 52640, loss = 0.0751808
I0111 00:17:49.101230  4932 solver.cpp:255]     Train net output #0: loss = 0.113434 (* 1 = 0.113434 loss)
I0111 00:17:49.101240  4932 solver.cpp:631] Iteration 52640, lr = 1e-08
I0111 00:17:49.440536  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0775 > 20) by scale factor 0.948878
I0111 00:18:34.034415  4932 solver.cpp:240] Iteration 52660, loss = 0.0724612
I0111 00:18:34.034508  4932 solver.cpp:255]     Train net output #0: loss = 0.238869 (* 1 = 0.238869 loss)
I0111 00:18:34.034520  4932 solver.cpp:631] Iteration 52660, lr = 1e-08
I0111 00:19:12.926580  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2675 > 20) by scale factor 0.986801
I0111 00:19:19.245239  4932 solver.cpp:240] Iteration 52680, loss = 0.063876
I0111 00:19:19.245282  4932 solver.cpp:255]     Train net output #0: loss = 0.0848942 (* 1 = 0.0848942 loss)
I0111 00:19:19.245292  4932 solver.cpp:631] Iteration 52680, lr = 1e-08
I0111 00:19:39.769863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8295 > 20) by scale factor 0.745448
I0111 00:19:59.746465  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0636 > 20) by scale factor 0.996829
I0111 00:20:03.847820  4932 solver.cpp:240] Iteration 52700, loss = 0.0613054
I0111 00:20:03.847859  4932 solver.cpp:255]     Train net output #0: loss = 0.0130814 (* 1 = 0.0130814 loss)
I0111 00:20:03.847869  4932 solver.cpp:631] Iteration 52700, lr = 1e-08
I0111 00:20:10.840896  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1154 > 20) by scale factor 0.994262
I0111 00:20:26.376255  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.8628 > 20) by scale factor 0.669729
I0111 00:20:35.257820  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2316 > 20) by scale factor 0.73444
I0111 00:20:48.238859  4932 solver.cpp:240] Iteration 52720, loss = 0.0964476
I0111 00:20:48.238905  4932 solver.cpp:255]     Train net output #0: loss = 0.000743475 (* 1 = 0.000743475 loss)
I0111 00:20:48.238917  4932 solver.cpp:631] Iteration 52720, lr = 1e-08
I0111 00:20:59.670569  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.167 > 20) by scale factor 0.991718
I0111 00:21:33.048276  4932 solver.cpp:240] Iteration 52740, loss = 0.0406936
I0111 00:21:33.048379  4932 solver.cpp:255]     Train net output #0: loss = 0.00449973 (* 1 = 0.00449973 loss)
I0111 00:21:33.048395  4932 solver.cpp:631] Iteration 52740, lr = 1e-08
I0111 00:21:44.485399  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.337 > 20) by scale factor 0.85701
I0111 00:22:18.133667  4932 solver.cpp:240] Iteration 52760, loss = 0.0656231
I0111 00:22:18.133765  4932 solver.cpp:255]     Train net output #0: loss = 0.202808 (* 1 = 0.202808 loss)
I0111 00:22:18.133777  4932 solver.cpp:631] Iteration 52760, lr = 1e-08
I0111 00:22:31.789104  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6274 > 20) by scale factor 0.924753
I0111 00:22:38.454757  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4421 > 20) by scale factor 0.978372
I0111 00:22:42.898620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.626 > 20) by scale factor 0.969649
I0111 00:23:03.260341  4932 solver.cpp:240] Iteration 52780, loss = 0.11241
I0111 00:23:03.260428  4932 solver.cpp:255]     Train net output #0: loss = 0.0198893 (* 1 = 0.0198893 loss)
I0111 00:23:03.260442  4932 solver.cpp:631] Iteration 52780, lr = 1e-08
I0111 00:23:14.697785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7471 > 20) by scale factor 0.776788
I0111 00:23:48.180835  4932 solver.cpp:240] Iteration 52800, loss = 0.0672
I0111 00:23:48.180932  4932 solver.cpp:255]     Train net output #0: loss = 0.145012 (* 1 = 0.145012 loss)
I0111 00:23:48.180945  4932 solver.cpp:631] Iteration 52800, lr = 1e-08
I0111 00:23:55.175278  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3734 > 20) by scale factor 0.935743
I0111 00:24:32.784322  4932 solver.cpp:240] Iteration 52820, loss = 0.0540923
I0111 00:24:32.784416  4932 solver.cpp:255]     Train net output #0: loss = 0.118368 (* 1 = 0.118368 loss)
I0111 00:24:32.784428  4932 solver.cpp:631] Iteration 52820, lr = 1e-08
I0111 00:25:02.750264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3535 > 20) by scale factor 0.98263
I0111 00:25:17.943822  4932 solver.cpp:240] Iteration 52840, loss = 0.04623
I0111 00:25:17.943908  4932 solver.cpp:255]     Train net output #0: loss = 0.149234 (* 1 = 0.149234 loss)
I0111 00:25:17.943920  4932 solver.cpp:631] Iteration 52840, lr = 1e-08
I0111 00:26:02.666812  4932 solver.cpp:240] Iteration 52860, loss = 0.0350589
I0111 00:26:02.666903  4932 solver.cpp:255]     Train net output #0: loss = 0.00658189 (* 1 = 0.00658189 loss)
I0111 00:26:02.666915  4932 solver.cpp:631] Iteration 52860, lr = 1e-08
I0111 00:26:14.745059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2101 > 20) by scale factor 0.942947
I0111 00:26:16.967823  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3747 > 20) by scale factor 0.855626
I0111 00:26:21.409006  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1031 > 20) by scale factor 0.865684
I0111 00:26:28.067329  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4031 > 20) by scale factor 0.757487
I0111 00:26:47.695118  4932 solver.cpp:240] Iteration 52880, loss = 0.105037
I0111 00:26:47.695235  4932 solver.cpp:255]     Train net output #0: loss = 0.0552007 (* 1 = 0.0552007 loss)
I0111 00:26:47.695247  4932 solver.cpp:631] Iteration 52880, lr = 1e-08
I0111 00:26:59.130179  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9332 > 20) by scale factor 0.911861
I0111 00:27:32.941362  4932 solver.cpp:240] Iteration 52900, loss = 0.0494224
I0111 00:27:32.941459  4932 solver.cpp:255]     Train net output #0: loss = 0.000778055 (* 1 = 0.000778055 loss)
I0111 00:27:32.941473  4932 solver.cpp:631] Iteration 52900, lr = 1e-08
I0111 00:27:53.254611  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2957 > 20) by scale factor 0.79065
I0111 00:28:17.325711  4932 solver.cpp:240] Iteration 52920, loss = 0.119953
I0111 00:28:17.325798  4932 solver.cpp:255]     Train net output #0: loss = 0.323098 (* 1 = 0.323098 loss)
I0111 00:28:17.325810  4932 solver.cpp:631] Iteration 52920, lr = 1e-08
I0111 00:29:01.698709  4932 solver.cpp:240] Iteration 52940, loss = 0.0807055
I0111 00:29:01.698796  4932 solver.cpp:255]     Train net output #0: loss = 0.0553811 (* 1 = 0.0553811 loss)
I0111 00:29:01.698807  4932 solver.cpp:631] Iteration 52940, lr = 1e-08
I0111 00:29:19.795266  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4589 > 20) by scale factor 0.890515
I0111 00:29:46.076162  4932 solver.cpp:240] Iteration 52960, loss = 0.0823801
I0111 00:29:46.076238  4932 solver.cpp:255]     Train net output #0: loss = 0.101319 (* 1 = 0.101319 loss)
I0111 00:29:46.076248  4932 solver.cpp:631] Iteration 52960, lr = 1e-08
I0111 00:30:30.463680  4932 solver.cpp:240] Iteration 52980, loss = 0.036045
I0111 00:30:30.463759  4932 solver.cpp:255]     Train net output #0: loss = 0.0376338 (* 1 = 0.0376338 loss)
I0111 00:30:30.463769  4932 solver.cpp:631] Iteration 52980, lr = 1e-08
I0111 00:30:35.243067  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0472 > 20) by scale factor 0.907147
I0111 00:31:13.347628  4932 solver.cpp:424] Iteration 53000, Testing net (#0)
I0111 00:32:04.636893  4932 solver.cpp:481]     Test net output #0: accuracy = 0.816842
I0111 00:32:04.636978  4932 solver.cpp:481]     Test net output #1: loss = 0.957059 (* 1 = 0.957059 loss)
I0111 00:32:06.506122  4932 solver.cpp:240] Iteration 53000, loss = 0.0810923
I0111 00:32:06.506167  4932 solver.cpp:255]     Train net output #0: loss = 0.02677 (* 1 = 0.02677 loss)
I0111 00:32:06.506178  4932 solver.cpp:631] Iteration 53000, lr = 1e-08
I0111 00:32:50.882488  4932 solver.cpp:240] Iteration 53020, loss = 0.0431007
I0111 00:32:50.882593  4932 solver.cpp:255]     Train net output #0: loss = 0.00203418 (* 1 = 0.00203418 loss)
I0111 00:32:50.882611  4932 solver.cpp:631] Iteration 53020, lr = 1e-08
I0111 00:33:35.389163  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6495 > 20) by scale factor 0.968547
I0111 00:33:37.272883  4932 solver.cpp:240] Iteration 53040, loss = 0.0320923
I0111 00:33:37.272923  4932 solver.cpp:255]     Train net output #0: loss = 0.0177385 (* 1 = 0.0177385 loss)
I0111 00:33:37.272933  4932 solver.cpp:631] Iteration 53040, lr = 1e-08
I0111 00:34:04.241117  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0095 > 20) by scale factor 0.999527
I0111 00:34:22.025986  4932 solver.cpp:240] Iteration 53060, loss = 0.0577667
I0111 00:34:22.026057  4932 solver.cpp:255]     Train net output #0: loss = 0.246656 (* 1 = 0.246656 loss)
I0111 00:34:22.026068  4932 solver.cpp:631] Iteration 53060, lr = 1e-08
I0111 00:34:22.366706  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4283 > 20) by scale factor 0.933346
I0111 00:35:07.198516  4932 solver.cpp:240] Iteration 53080, loss = 0.0391633
I0111 00:35:07.198628  4932 solver.cpp:255]     Train net output #0: loss = 0.091869 (* 1 = 0.091869 loss)
I0111 00:35:07.198643  4932 solver.cpp:631] Iteration 53080, lr = 1e-08
I0111 00:35:18.928745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9664 > 20) by scale factor 0.715145
I0111 00:35:51.870682  4932 solver.cpp:240] Iteration 53100, loss = 0.0524149
I0111 00:35:51.870785  4932 solver.cpp:255]     Train net output #0: loss = 0.117043 (* 1 = 0.117043 loss)
I0111 00:35:51.870800  4932 solver.cpp:631] Iteration 53100, lr = 1e-08
I0111 00:35:52.210242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4476 > 20) by scale factor 0.890964
I0111 00:36:36.250035  4932 solver.cpp:240] Iteration 53120, loss = 0.0395754
I0111 00:36:36.250128  4932 solver.cpp:255]     Train net output #0: loss = 0.0107201 (* 1 = 0.0107201 loss)
I0111 00:36:36.250143  4932 solver.cpp:631] Iteration 53120, lr = 1e-08
I0111 00:36:49.903419  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.1903 > 20) by scale factor 0.584962
I0111 00:37:03.219442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7644 > 20) by scale factor 0.878566
I0111 00:37:08.159067  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5676 > 20) by scale factor 0.81408
I0111 00:37:21.133791  4932 solver.cpp:240] Iteration 53140, loss = 0.0693429
I0111 00:37:21.133831  4932 solver.cpp:255]     Train net output #0: loss = 0.0107102 (* 1 = 0.0107102 loss)
I0111 00:37:21.133839  4932 solver.cpp:631] Iteration 53140, lr = 1e-08
I0111 00:38:06.172447  4932 solver.cpp:240] Iteration 53160, loss = 0.0571289
I0111 00:38:06.172518  4932 solver.cpp:255]     Train net output #0: loss = 0.0641331 (* 1 = 0.0641331 loss)
I0111 00:38:06.172528  4932 solver.cpp:631] Iteration 53160, lr = 1e-08
I0111 00:38:10.946589  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6208 > 20) by scale factor 0.884141
I0111 00:38:49.209538  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8446 > 20) by scale factor 0.959482
I0111 00:38:51.092005  4932 solver.cpp:240] Iteration 53180, loss = 0.0803161
I0111 00:38:51.092051  4932 solver.cpp:255]     Train net output #0: loss = 0.0385547 (* 1 = 0.0385547 loss)
I0111 00:38:51.092062  4932 solver.cpp:631] Iteration 53180, lr = 1e-08
I0111 00:38:53.649458  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3058 > 20) by scale factor 0.732446
I0111 00:39:00.932266  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0659 > 20) by scale factor 0.906375
I0111 00:39:09.811518  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.5412 > 20) by scale factor 0.579018
I0111 00:39:36.907466  4932 solver.cpp:240] Iteration 53200, loss = 0.0747853
I0111 00:39:36.907567  4932 solver.cpp:255]     Train net output #0: loss = 0.0427428 (* 1 = 0.0427428 loss)
I0111 00:39:36.907582  4932 solver.cpp:631] Iteration 53200, lr = 1e-08
I0111 00:40:03.874729  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7808 > 20) by scale factor 0.918238
I0111 00:40:21.872265  4932 solver.cpp:240] Iteration 53220, loss = 0.0531406
I0111 00:40:21.872359  4932 solver.cpp:255]     Train net output #0: loss = 0.00743624 (* 1 = 0.00743624 loss)
I0111 00:40:21.872373  4932 solver.cpp:631] Iteration 53220, lr = 1e-08
I0111 00:41:06.788602  4932 solver.cpp:240] Iteration 53240, loss = 0.0479616
I0111 00:41:06.788702  4932 solver.cpp:255]     Train net output #0: loss = 0.0143706 (* 1 = 0.0143706 loss)
I0111 00:41:06.788717  4932 solver.cpp:631] Iteration 53240, lr = 1e-08
I0111 00:41:51.679810  4932 solver.cpp:240] Iteration 53260, loss = 0.0755821
I0111 00:41:51.679903  4932 solver.cpp:255]     Train net output #0: loss = 0.0111607 (* 1 = 0.0111607 loss)
I0111 00:41:51.679915  4932 solver.cpp:631] Iteration 53260, lr = 1e-08
I0111 00:42:16.955202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7235 > 20) by scale factor 0.7775
I0111 00:42:36.940295  4932 solver.cpp:240] Iteration 53280, loss = 0.0569586
I0111 00:42:36.940377  4932 solver.cpp:255]     Train net output #0: loss = 0.00435805 (* 1 = 0.00435805 loss)
I0111 00:42:36.940388  4932 solver.cpp:631] Iteration 53280, lr = 1e-08
I0111 00:43:06.437180  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.2884 > 20) by scale factor 0.619417
I0111 00:43:21.631451  4932 solver.cpp:240] Iteration 53300, loss = 0.0856528
I0111 00:43:21.631546  4932 solver.cpp:255]     Train net output #0: loss = 0.210006 (* 1 = 0.210006 loss)
I0111 00:43:21.631556  4932 solver.cpp:631] Iteration 53300, lr = 1e-08
I0111 00:43:33.067740  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3151 > 20) by scale factor 0.732197
I0111 00:43:53.404671  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7096 > 20) by scale factor 0.921251
I0111 00:44:06.377889  4932 solver.cpp:240] Iteration 53320, loss = 0.0560052
I0111 00:44:06.377929  4932 solver.cpp:255]     Train net output #0: loss = 0.0229761 (* 1 = 0.0229761 loss)
I0111 00:44:06.377938  4932 solver.cpp:631] Iteration 53320, lr = 1e-08
I0111 00:44:51.913779  4932 solver.cpp:240] Iteration 53340, loss = 0.0329702
I0111 00:44:51.913868  4932 solver.cpp:255]     Train net output #0: loss = 0.0321239 (* 1 = 0.0321239 loss)
I0111 00:44:51.913879  4932 solver.cpp:631] Iteration 53340, lr = 1e-08
I0111 00:44:54.470537  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2261 > 20) by scale factor 0.899844
I0111 00:45:26.053097  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7906 > 20) by scale factor 0.806759
I0111 00:45:32.721180  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4092 > 20) by scale factor 0.892489
I0111 00:45:36.823524  4932 solver.cpp:240] Iteration 53360, loss = 0.112963
I0111 00:45:36.823565  4932 solver.cpp:255]     Train net output #0: loss = 0.00486152 (* 1 = 0.00486152 loss)
I0111 00:45:36.823575  4932 solver.cpp:631] Iteration 53360, lr = 1e-08
I0111 00:46:21.657526  4932 solver.cpp:240] Iteration 53380, loss = 0.0501287
I0111 00:46:21.657620  4932 solver.cpp:255]     Train net output #0: loss = 0.0279686 (* 1 = 0.0279686 loss)
I0111 00:46:21.657635  4932 solver.cpp:631] Iteration 53380, lr = 1e-08
I0111 00:47:00.194723  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8013 > 20) by scale factor 0.917378
I0111 00:47:06.513864  4932 solver.cpp:240] Iteration 53400, loss = 0.0631153
I0111 00:47:06.513913  4932 solver.cpp:255]     Train net output #0: loss = 0.0558957 (* 1 = 0.0558957 loss)
I0111 00:47:06.513926  4932 solver.cpp:631] Iteration 53400, lr = 1e-08
I0111 00:47:24.605406  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6615 > 20) by scale factor 0.882556
I0111 00:47:26.825809  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3722 > 20) by scale factor 0.981729
I0111 00:47:35.700399  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7345 > 20) by scale factor 0.808587
I0111 00:47:50.899188  4932 solver.cpp:240] Iteration 53420, loss = 0.085711
I0111 00:47:50.899219  4932 solver.cpp:255]     Train net output #0: loss = 0.0622493 (* 1 = 0.0622493 loss)
I0111 00:47:50.899227  4932 solver.cpp:631] Iteration 53420, lr = 1e-08
I0111 00:47:53.458628  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2668 > 20) by scale factor 0.791552
I0111 00:48:25.185266  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5802 > 20) by scale factor 0.752439
I0111 00:48:27.407368  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3231 > 20) by scale factor 0.759788
I0111 00:48:35.946091  4932 solver.cpp:240] Iteration 53440, loss = 0.0807439
I0111 00:48:35.946131  4932 solver.cpp:255]     Train net output #0: loss = 0.00115294 (* 1 = 0.00115294 loss)
I0111 00:48:35.946146  4932 solver.cpp:631] Iteration 53440, lr = 1e-08
I0111 00:48:38.503232  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9598 > 20) by scale factor 0.834732
I0111 00:49:20.323942  4932 solver.cpp:240] Iteration 53460, loss = 0.0700165
I0111 00:49:20.324050  4932 solver.cpp:255]     Train net output #0: loss = 0.0311695 (* 1 = 0.0311695 loss)
I0111 00:49:20.324065  4932 solver.cpp:631] Iteration 53460, lr = 1e-08
I0111 00:49:29.535871  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9798 > 20) by scale factor 0.870328
I0111 00:49:40.634933  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9181 > 20) by scale factor 0.912486
I0111 00:50:04.700454  4932 solver.cpp:240] Iteration 53480, loss = 0.0761431
I0111 00:50:04.700533  4932 solver.cpp:255]     Train net output #0: loss = 0.00531652 (* 1 = 0.00531652 loss)
I0111 00:50:04.700544  4932 solver.cpp:631] Iteration 53480, lr = 1e-08
I0111 00:50:09.475059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5465 > 20) by scale factor 0.887057
I0111 00:50:16.135161  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2301 > 20) by scale factor 0.762482
I0111 00:50:27.390841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4295 > 20) by scale factor 0.786489
I0111 00:50:49.246819  4932 solver.cpp:240] Iteration 53500, loss = 0.0855343
I0111 00:50:49.246898  4932 solver.cpp:255]     Train net output #0: loss = 0.00682212 (* 1 = 0.00682212 loss)
I0111 00:50:49.246909  4932 solver.cpp:631] Iteration 53500, lr = 1e-08
I0111 00:51:12.077389  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5153 > 20) by scale factor 0.974882
I0111 00:51:33.927686  4932 solver.cpp:240] Iteration 53520, loss = 0.0713703
I0111 00:51:33.927779  4932 solver.cpp:255]     Train net output #0: loss = 0.161232 (* 1 = 0.161232 loss)
I0111 00:51:33.927791  4932 solver.cpp:631] Iteration 53520, lr = 1e-08
I0111 00:51:38.706619  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4744 > 20) by scale factor 0.817179
I0111 00:52:18.303097  4932 solver.cpp:240] Iteration 53540, loss = 0.0431333
I0111 00:52:18.303179  4932 solver.cpp:255]     Train net output #0: loss = 0.0436191 (* 1 = 0.0436191 loss)
I0111 00:52:18.303191  4932 solver.cpp:631] Iteration 53540, lr = 1e-08
I0111 00:53:01.661697  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3109 > 20) by scale factor 0.896422
I0111 00:53:03.543035  4932 solver.cpp:240] Iteration 53560, loss = 0.0849913
I0111 00:53:03.543071  4932 solver.cpp:255]     Train net output #0: loss = 0.0722985 (* 1 = 0.0722985 loss)
I0111 00:53:03.543083  4932 solver.cpp:631] Iteration 53560, lr = 1e-08
I0111 00:53:12.761102  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4769 > 20) by scale factor 0.727883
I0111 00:53:14.985180  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1405 > 20) by scale factor 0.795528
I0111 00:53:35.137370  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.034 > 20) by scale factor 0.868283
I0111 00:53:48.116587  4932 solver.cpp:240] Iteration 53580, loss = 0.0702331
I0111 00:53:48.116628  4932 solver.cpp:255]     Train net output #0: loss = 0.0145598 (* 1 = 0.0145598 loss)
I0111 00:53:48.116750  4932 solver.cpp:631] Iteration 53580, lr = 1e-08
I0111 00:54:33.089879  4932 solver.cpp:240] Iteration 53600, loss = 0.0765391
I0111 00:54:33.089962  4932 solver.cpp:255]     Train net output #0: loss = 0.218912 (* 1 = 0.218912 loss)
I0111 00:54:33.089974  4932 solver.cpp:631] Iteration 53600, lr = 1e-08
I0111 00:54:40.090461  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.234 > 20) by scale factor 0.941886
I0111 00:54:42.312816  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.32 > 20) by scale factor 0.659631
I0111 00:55:17.478003  4932 solver.cpp:240] Iteration 53620, loss = 0.0668039
I0111 00:55:17.478092  4932 solver.cpp:255]     Train net output #0: loss = 0.0103916 (* 1 = 0.0103916 loss)
I0111 00:55:17.478106  4932 solver.cpp:631] Iteration 53620, lr = 1e-08
I0111 00:56:02.268252  4932 solver.cpp:240] Iteration 53640, loss = 0.0516435
I0111 00:56:02.268376  4932 solver.cpp:255]     Train net output #0: loss = 0.1934 (* 1 = 0.1934 loss)
I0111 00:56:02.268393  4932 solver.cpp:631] Iteration 53640, lr = 1e-08
I0111 00:56:04.830096  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1112 > 20) by scale factor 0.765954
I0111 00:56:09.271782  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.551 > 20) by scale factor 0.814631
I0111 00:56:22.595064  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1528 > 20) by scale factor 0.863825
I0111 00:56:47.170089  4932 solver.cpp:240] Iteration 53660, loss = 0.07116
I0111 00:56:47.170191  4932 solver.cpp:255]     Train net output #0: loss = 0.0758011 (* 1 = 0.0758011 loss)
I0111 00:56:47.170204  4932 solver.cpp:631] Iteration 53660, lr = 1e-08
I0111 00:56:51.951402  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9668 > 20) by scale factor 0.770213
I0111 00:57:31.570550  4932 solver.cpp:240] Iteration 53680, loss = 0.0617406
I0111 00:57:31.570642  4932 solver.cpp:255]     Train net output #0: loss = 0.0129743 (* 1 = 0.0129743 loss)
I0111 00:57:31.570655  4932 solver.cpp:631] Iteration 53680, lr = 1e-08
I0111 00:57:40.905817  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2254 > 20) by scale factor 0.942268
I0111 00:57:45.347136  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9099 > 20) by scale factor 0.872985
I0111 00:57:52.004861  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5757 > 20) by scale factor 0.926969
I0111 00:57:54.226059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.763 > 20) by scale factor 0.963252
I0111 00:58:14.205950  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5305 > 20) by scale factor 0.783377
I0111 00:58:16.087992  4932 solver.cpp:240] Iteration 53700, loss = 0.105615
I0111 00:58:16.088030  4932 solver.cpp:255]     Train net output #0: loss = 0.0399975 (* 1 = 0.0399975 loss)
I0111 00:58:16.088040  4932 solver.cpp:631] Iteration 53700, lr = 1e-08
I0111 00:58:20.863348  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5944 > 20) by scale factor 0.971139
I0111 00:59:01.108228  4932 solver.cpp:240] Iteration 53720, loss = 0.0365401
I0111 00:59:01.108325  4932 solver.cpp:255]     Train net output #0: loss = 0.00160982 (* 1 = 0.00160982 loss)
I0111 00:59:01.108337  4932 solver.cpp:631] Iteration 53720, lr = 1e-08
I0111 00:59:05.884768  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6555 > 20) by scale factor 0.923555
I0111 00:59:37.490677  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.7261 > 20) by scale factor 0.650913
I0111 00:59:46.036674  4932 solver.cpp:240] Iteration 53740, loss = 0.0768409
I0111 00:59:46.036717  4932 solver.cpp:255]     Train net output #0: loss = 0.00124612 (* 1 = 0.00124612 loss)
I0111 00:59:46.036728  4932 solver.cpp:631] Iteration 53740, lr = 1e-08
I0111 00:59:51.358048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5569 > 20) by scale factor 0.927779
I0111 00:59:58.014858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.324 > 20) by scale factor 0.759764
I0111 01:00:11.327672  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6244 > 20) by scale factor 0.675119
I0111 01:00:13.550410  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2998 > 20) by scale factor 0.89687
I0111 01:00:20.215296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5014 > 20) by scale factor 0.851011
I0111 01:00:29.355298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.792 > 20) by scale factor 0.746491
I0111 01:00:31.236666  4932 solver.cpp:240] Iteration 53760, loss = 0.107715
I0111 01:00:31.236706  4932 solver.cpp:255]     Train net output #0: loss = 0.171475 (* 1 = 0.171475 loss)
I0111 01:00:31.236714  4932 solver.cpp:631] Iteration 53760, lr = 1e-08
I0111 01:00:40.663810  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3842 > 20) by scale factor 0.935269
I0111 01:00:45.110390  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2821 > 20) by scale factor 0.939756
I0111 01:01:16.925616  4932 solver.cpp:240] Iteration 53780, loss = 0.0747006
I0111 01:01:16.925729  4932 solver.cpp:255]     Train net output #0: loss = 0.000743587 (* 1 = 0.000743587 loss)
I0111 01:01:16.925745  4932 solver.cpp:631] Iteration 53780, lr = 1e-08
I0111 01:01:37.238183  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1806 > 20) by scale factor 0.944261
I0111 01:02:01.755337  4932 solver.cpp:240] Iteration 53800, loss = 0.0480027
I0111 01:02:01.755445  4932 solver.cpp:255]     Train net output #0: loss = 0.00805033 (* 1 = 0.00805033 loss)
I0111 01:02:01.755460  4932 solver.cpp:631] Iteration 53800, lr = 1e-08
I0111 01:02:46.653558  4932 solver.cpp:240] Iteration 53820, loss = 0.0692818
I0111 01:02:46.653656  4932 solver.cpp:255]     Train net output #0: loss = 0.00520846 (* 1 = 0.00520846 loss)
I0111 01:02:46.653669  4932 solver.cpp:631] Iteration 53820, lr = 1e-08
I0111 01:03:09.554169  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0784 > 20) by scale factor 0.866612
I0111 01:03:13.995056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1158 > 20) by scale factor 0.796313
I0111 01:03:31.416568  4932 solver.cpp:240] Iteration 53840, loss = 0.0759974
I0111 01:03:31.416682  4932 solver.cpp:255]     Train net output #0: loss = 0.00343889 (* 1 = 0.00343889 loss)
I0111 01:03:31.416697  4932 solver.cpp:631] Iteration 53840, lr = 1e-08
I0111 01:03:36.194370  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6782 > 20) by scale factor 0.967201
I0111 01:03:38.415361  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2719 > 20) by scale factor 0.733356
I0111 01:03:54.366765  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.459 > 20) by scale factor 0.852552
I0111 01:04:03.249130  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4293 > 20) by scale factor 0.891689
I0111 01:04:05.470525  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4541 > 20) by scale factor 0.977797
I0111 01:04:16.232285  4932 solver.cpp:240] Iteration 53860, loss = 0.108907
I0111 01:04:16.232329  4932 solver.cpp:255]     Train net output #0: loss = 0.0641021 (* 1 = 0.0641021 loss)
I0111 01:04:16.232341  4932 solver.cpp:631] Iteration 53860, lr = 1e-08
I0111 01:04:23.879326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0686 > 20) by scale factor 0.86698
I0111 01:04:39.423148  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0609 > 20) by scale factor 0.831225
I0111 01:05:01.720496  4932 solver.cpp:240] Iteration 53880, loss = 0.0429016
I0111 01:05:01.720536  4932 solver.cpp:255]     Train net output #0: loss = 0.0104013 (* 1 = 0.0104013 loss)
I0111 01:05:01.720546  4932 solver.cpp:631] Iteration 53880, lr = 1e-08
I0111 01:05:46.438578  4932 solver.cpp:240] Iteration 53900, loss = 0.0526951
I0111 01:05:46.438669  4932 solver.cpp:255]     Train net output #0: loss = 0.0399042 (* 1 = 0.0399042 loss)
I0111 01:05:46.438680  4932 solver.cpp:631] Iteration 53900, lr = 1e-08
I0111 01:06:04.643357  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4908 > 20) by scale factor 0.75498
I0111 01:06:09.081142  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5687 > 20) by scale factor 0.814044
I0111 01:06:22.396039  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8511 > 20) by scale factor 0.773662
I0111 01:06:26.839779  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4865 > 20) by scale factor 0.889422
I0111 01:06:30.943433  4932 solver.cpp:240] Iteration 53920, loss = 0.121649
I0111 01:06:30.943476  4932 solver.cpp:255]     Train net output #0: loss = 0.14582 (* 1 = 0.14582 loss)
I0111 01:06:30.943488  4932 solver.cpp:631] Iteration 53920, lr = 1e-08
I0111 01:06:40.156103  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3761 > 20) by scale factor 0.89381
I0111 01:07:15.733777  4932 solver.cpp:240] Iteration 53940, loss = 0.0642976
I0111 01:07:15.733886  4932 solver.cpp:255]     Train net output #0: loss = 0.0461937 (* 1 = 0.0461937 loss)
I0111 01:07:15.733896  4932 solver.cpp:631] Iteration 53940, lr = 1e-08
I0111 01:07:27.341670  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7806 > 20) by scale factor 0.807083
I0111 01:07:49.543128  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4244 > 20) by scale factor 0.891887
I0111 01:08:00.303344  4932 solver.cpp:240] Iteration 53960, loss = 0.0719857
I0111 01:08:00.303381  4932 solver.cpp:255]     Train net output #0: loss = 0.0251597 (* 1 = 0.0251597 loss)
I0111 01:08:00.303390  4932 solver.cpp:631] Iteration 53960, lr = 1e-08
I0111 01:08:03.170091  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6366 > 20) by scale factor 0.883526
I0111 01:08:07.611532  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4522 > 20) by scale factor 0.932307
I0111 01:08:45.003376  4932 solver.cpp:240] Iteration 53980, loss = 0.073116
I0111 01:08:45.003464  4932 solver.cpp:255]     Train net output #0: loss = 0.0257709 (* 1 = 0.0257709 loss)
I0111 01:08:45.003478  4932 solver.cpp:631] Iteration 53980, lr = 1e-08
I0111 01:08:58.664266  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7787 > 20) by scale factor 0.878012
I0111 01:09:00.884606  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8651 > 20) by scale factor 0.874695
I0111 01:09:14.201212  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6571 > 20) by scale factor 0.923486
I0111 01:09:27.524978  4932 solver.cpp:424] Iteration 54000, Testing net (#0)
I0111 01:10:16.417701  4932 solver.cpp:481]     Test net output #0: accuracy = 0.846316
I0111 01:10:16.417779  4932 solver.cpp:481]     Test net output #1: loss = 0.764922 (* 1 = 0.764922 loss)
I0111 01:10:18.283665  4932 solver.cpp:240] Iteration 54000, loss = 0.0870037
I0111 01:10:18.283704  4932 solver.cpp:255]     Train net output #0: loss = 0.0970801 (* 1 = 0.0970801 loss)
I0111 01:10:18.283718  4932 solver.cpp:631] Iteration 54000, lr = 1e-08
I0111 01:10:43.036487  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5853 > 20) by scale factor 0.885533
I0111 01:11:03.186906  4932 solver.cpp:240] Iteration 54020, loss = 0.0609356
I0111 01:11:03.186998  4932 solver.cpp:255]     Train net output #0: loss = 0.00374443 (* 1 = 0.00374443 loss)
I0111 01:11:03.187010  4932 solver.cpp:631] Iteration 54020, lr = 1e-08
I0111 01:11:14.620277  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.742 > 20) by scale factor 0.879431
I0111 01:11:47.576499  4932 solver.cpp:240] Iteration 54040, loss = 0.058407
I0111 01:11:47.576591  4932 solver.cpp:255]     Train net output #0: loss = 0.0354721 (* 1 = 0.0354721 loss)
I0111 01:11:47.576603  4932 solver.cpp:631] Iteration 54040, lr = 1e-08
I0111 01:11:52.992797  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2742 > 20) by scale factor 0.823921
I0111 01:12:12.969658  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7265 > 20) by scale factor 0.964947
I0111 01:12:33.089273  4932 solver.cpp:240] Iteration 54060, loss = 0.106296
I0111 01:12:33.089376  4932 solver.cpp:255]     Train net output #0: loss = 0.00979698 (* 1 = 0.00979698 loss)
I0111 01:12:33.089392  4932 solver.cpp:631] Iteration 54060, lr = 1e-08
I0111 01:12:40.087973  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7894 > 20) by scale factor 0.962031
I0111 01:12:48.969442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9547 > 20) by scale factor 0.834908
I0111 01:13:17.956640  4932 solver.cpp:240] Iteration 54080, loss = 0.0892429
I0111 01:13:17.956758  4932 solver.cpp:255]     Train net output #0: loss = 0.00136131 (* 1 = 0.00136131 loss)
I0111 01:13:17.956773  4932 solver.cpp:631] Iteration 54080, lr = 1e-08
I0111 01:13:22.738507  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5398 > 20) by scale factor 0.700777
I0111 01:14:02.342541  4932 solver.cpp:240] Iteration 54100, loss = 0.0940937
I0111 01:14:02.342630  4932 solver.cpp:255]     Train net output #0: loss = 0.242111 (* 1 = 0.242111 loss)
I0111 01:14:02.342643  4932 solver.cpp:631] Iteration 54100, lr = 1e-08
I0111 01:14:02.681630  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9066 > 20) by scale factor 0.836588
I0111 01:14:13.855105  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5029 > 20) by scale factor 0.888774
I0111 01:14:47.370671  4932 solver.cpp:240] Iteration 54120, loss = 0.0629895
I0111 01:14:47.370757  4932 solver.cpp:255]     Train net output #0: loss = 0.0404904 (* 1 = 0.0404904 loss)
I0111 01:14:47.370769  4932 solver.cpp:631] Iteration 54120, lr = 1e-08
I0111 01:15:32.210495  4932 solver.cpp:240] Iteration 54140, loss = 0.0450638
I0111 01:15:32.210592  4932 solver.cpp:255]     Train net output #0: loss = 0.0876972 (* 1 = 0.0876972 loss)
I0111 01:15:32.210607  4932 solver.cpp:631] Iteration 54140, lr = 1e-08
I0111 01:15:36.987872  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2138 > 20) by scale factor 0.989425
I0111 01:16:14.725100  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7673 > 20) by scale factor 0.91881
I0111 01:16:16.605317  4932 solver.cpp:240] Iteration 54160, loss = 0.0706967
I0111 01:16:16.605355  4932 solver.cpp:255]     Train net output #0: loss = 0.066388 (* 1 = 0.066388 loss)
I0111 01:16:16.605365  4932 solver.cpp:631] Iteration 54160, lr = 1e-08
I0111 01:16:50.222605  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5016 > 20) by scale factor 0.930165
I0111 01:17:00.985795  4932 solver.cpp:240] Iteration 54180, loss = 0.070958
I0111 01:17:00.985828  4932 solver.cpp:255]     Train net output #0: loss = 0.10012 (* 1 = 0.10012 loss)
I0111 01:17:00.985836  4932 solver.cpp:631] Iteration 54180, lr = 1e-08
I0111 01:17:15.054750  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9481 > 20) by scale factor 0.95474
I0111 01:17:45.782460  4932 solver.cpp:240] Iteration 54200, loss = 0.061093
I0111 01:17:45.782559  4932 solver.cpp:255]     Train net output #0: loss = 0.0497875 (* 1 = 0.0497875 loss)
I0111 01:17:45.782573  4932 solver.cpp:631] Iteration 54200, lr = 1e-08
I0111 01:18:08.973611  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6647 > 20) by scale factor 0.810875
I0111 01:18:11.193238  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1776 > 20) by scale factor 0.862901
I0111 01:18:22.288450  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2164 > 20) by scale factor 0.825885
I0111 01:18:30.824214  4932 solver.cpp:240] Iteration 54220, loss = 0.0701341
I0111 01:18:30.824261  4932 solver.cpp:255]     Train net output #0: loss = 0.0730982 (* 1 = 0.0730982 loss)
I0111 01:18:30.824275  4932 solver.cpp:631] Iteration 54220, lr = 1e-08
I0111 01:18:51.134654  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.696 > 20) by scale factor 0.673491
I0111 01:19:06.674666  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4632 > 20) by scale factor 0.931827
I0111 01:19:15.214042  4932 solver.cpp:240] Iteration 54240, loss = 0.0729176
I0111 01:19:15.214079  4932 solver.cpp:255]     Train net output #0: loss = 0.012035 (* 1 = 0.012035 loss)
I0111 01:19:15.214088  4932 solver.cpp:631] Iteration 54240, lr = 1e-08
I0111 01:19:35.764395  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8266 > 20) by scale factor 0.876169
I0111 01:19:42.422163  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4108 > 20) by scale factor 0.854307
I0111 01:19:55.737062  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3511 > 20) by scale factor 0.758982
I0111 01:19:59.836143  4932 solver.cpp:240] Iteration 54260, loss = 0.0904914
I0111 01:19:59.836179  4932 solver.cpp:255]     Train net output #0: loss = 0.0177879 (* 1 = 0.0177879 loss)
I0111 01:19:59.836187  4932 solver.cpp:631] Iteration 54260, lr = 1e-08
I0111 01:20:13.780362  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.025 > 20) by scale factor 0.768493
I0111 01:20:20.446632  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5017 > 20) by scale factor 0.784261
I0111 01:20:22.668398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5098 > 20) by scale factor 0.888502
I0111 01:20:44.921272  4932 solver.cpp:240] Iteration 54280, loss = 0.0601938
I0111 01:20:44.921355  4932 solver.cpp:255]     Train net output #0: loss = 0.0296721 (* 1 = 0.0296721 loss)
I0111 01:20:44.921367  4932 solver.cpp:631] Iteration 54280, lr = 1e-08
I0111 01:21:29.351353  4932 solver.cpp:240] Iteration 54300, loss = 0.05168
I0111 01:21:29.351445  4932 solver.cpp:255]     Train net output #0: loss = 0.000937971 (* 1 = 0.000937971 loss)
I0111 01:21:29.351459  4932 solver.cpp:631] Iteration 54300, lr = 1e-08
I0111 01:21:43.010045  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1915 > 20) by scale factor 0.763607
I0111 01:22:13.740495  4932 solver.cpp:240] Iteration 54320, loss = 0.0724172
I0111 01:22:13.740579  4932 solver.cpp:255]     Train net output #0: loss = 0.0719469 (* 1 = 0.0719469 loss)
I0111 01:22:13.740592  4932 solver.cpp:631] Iteration 54320, lr = 1e-08
I0111 01:22:22.955941  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4884 > 20) by scale factor 0.678232
I0111 01:22:58.502887  4932 solver.cpp:240] Iteration 54340, loss = 0.0808749
I0111 01:22:58.502984  4932 solver.cpp:255]     Train net output #0: loss = 0.0158281 (* 1 = 0.0158281 loss)
I0111 01:22:58.502996  4932 solver.cpp:631] Iteration 54340, lr = 1e-08
I0111 01:23:30.106626  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7751 > 20) by scale factor 0.918481
I0111 01:23:36.767740  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9483 > 20) by scale factor 0.95473
I0111 01:23:43.087508  4932 solver.cpp:240] Iteration 54360, loss = 0.0914696
I0111 01:23:43.087545  4932 solver.cpp:255]     Train net output #0: loss = 0.0194374 (* 1 = 0.0194374 loss)
I0111 01:23:43.087555  4932 solver.cpp:631] Iteration 54360, lr = 1e-08
I0111 01:24:01.185672  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9533 > 20) by scale factor 0.667705
I0111 01:24:25.936236  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9057 > 20) by scale factor 0.956675
I0111 01:24:27.818244  4932 solver.cpp:240] Iteration 54380, loss = 0.0870074
I0111 01:24:27.818286  4932 solver.cpp:255]     Train net output #0: loss = 0.167674 (* 1 = 0.167674 loss)
I0111 01:24:27.818296  4932 solver.cpp:631] Iteration 54380, lr = 1e-08
I0111 01:24:32.593715  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.3699 > 20) by scale factor 0.599342
I0111 01:24:37.031052  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.529 > 20) by scale factor 0.974229
I0111 01:24:50.744884  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0615 > 20) by scale factor 0.867245
I0111 01:25:12.596632  4932 solver.cpp:240] Iteration 54400, loss = 0.0767387
I0111 01:25:12.596725  4932 solver.cpp:255]     Train net output #0: loss = 0.176966 (* 1 = 0.176966 loss)
I0111 01:25:12.596738  4932 solver.cpp:631] Iteration 54400, lr = 1e-08
I0111 01:25:49.103188  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5356 > 20) by scale factor 0.928696
I0111 01:25:57.682267  4932 solver.cpp:240] Iteration 54420, loss = 0.0613699
I0111 01:25:57.682302  4932 solver.cpp:255]     Train net output #0: loss = 0.0559495 (* 1 = 0.0559495 loss)
I0111 01:25:57.682317  4932 solver.cpp:631] Iteration 54420, lr = 1e-08
I0111 01:26:17.998613  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8941 > 20) by scale factor 0.743659
I0111 01:26:24.658840  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.829 > 20) by scale factor 0.718675
I0111 01:26:42.076771  4932 solver.cpp:240] Iteration 54440, loss = 0.068448
I0111 01:26:42.076807  4932 solver.cpp:255]     Train net output #0: loss = 0.043517 (* 1 = 0.043517 loss)
I0111 01:26:42.076817  4932 solver.cpp:631] Iteration 54440, lr = 1e-08
I0111 01:26:51.298588  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9945 > 20) by scale factor 0.833523
I0111 01:26:55.740192  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5388 > 20) by scale factor 0.84966
I0111 01:27:26.476081  4932 solver.cpp:240] Iteration 54460, loss = 0.0619916
I0111 01:27:26.476182  4932 solver.cpp:255]     Train net output #0: loss = 0.241269 (* 1 = 0.241269 loss)
I0111 01:27:26.476196  4932 solver.cpp:631] Iteration 54460, lr = 1e-08
I0111 01:27:26.815348  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1225 > 20) by scale factor 0.904056
I0111 01:27:53.972165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5735 > 20) by scale factor 0.813884
I0111 01:27:56.193641  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3951 > 20) by scale factor 0.980629
I0111 01:28:11.388903  4932 solver.cpp:240] Iteration 54480, loss = 0.0806672
I0111 01:28:11.388993  4932 solver.cpp:255]     Train net output #0: loss = 0.00419574 (* 1 = 0.00419574 loss)
I0111 01:28:11.389006  4932 solver.cpp:631] Iteration 54480, lr = 1e-08
I0111 01:28:20.604426  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5495 > 20) by scale factor 0.928095
I0111 01:28:55.827996  4932 solver.cpp:240] Iteration 54500, loss = 0.067152
I0111 01:28:55.828083  4932 solver.cpp:255]     Train net output #0: loss = 0.0219358 (* 1 = 0.0219358 loss)
I0111 01:28:55.828094  4932 solver.cpp:631] Iteration 54500, lr = 1e-08
I0111 01:29:14.609923  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.305 > 20) by scale factor 0.938745
I0111 01:29:32.372838  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0285 > 20) by scale factor 0.951089
I0111 01:29:41.621842  4932 solver.cpp:240] Iteration 54520, loss = 0.0542613
I0111 01:29:41.621884  4932 solver.cpp:255]     Train net output #0: loss = 0.011413 (* 1 = 0.011413 loss)
I0111 01:29:41.621896  4932 solver.cpp:631] Iteration 54520, lr = 1e-08
I0111 01:29:44.178073  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3161 > 20) by scale factor 0.857778
I0111 01:30:26.458266  4932 solver.cpp:240] Iteration 54540, loss = 0.0601043
I0111 01:30:26.458355  4932 solver.cpp:255]     Train net output #0: loss = 0.0667996 (* 1 = 0.0667996 loss)
I0111 01:30:26.458370  4932 solver.cpp:631] Iteration 54540, lr = 1e-08
I0111 01:30:56.235916  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3773 > 20) by scale factor 0.981482
I0111 01:31:11.430727  4932 solver.cpp:240] Iteration 54560, loss = 0.0485154
I0111 01:31:11.430824  4932 solver.cpp:255]     Train net output #0: loss = 0.0579359 (* 1 = 0.0579359 loss)
I0111 01:31:11.430836  4932 solver.cpp:631] Iteration 54560, lr = 1e-08
I0111 01:31:36.720924  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2028 > 20) by scale factor 0.94327
I0111 01:31:56.362331  4932 solver.cpp:240] Iteration 54580, loss = 0.0473018
I0111 01:31:56.362413  4932 solver.cpp:255]     Train net output #0: loss = 0.0490981 (* 1 = 0.0490981 loss)
I0111 01:31:56.362424  4932 solver.cpp:631] Iteration 54580, lr = 1e-08
I0111 01:32:41.363967  4932 solver.cpp:240] Iteration 54600, loss = 0.0635905
I0111 01:32:41.364080  4932 solver.cpp:255]     Train net output #0: loss = 0.0307387 (* 1 = 0.0307387 loss)
I0111 01:32:41.364099  4932 solver.cpp:631] Iteration 54600, lr = 1e-08
I0111 01:33:25.746572  4932 solver.cpp:240] Iteration 54620, loss = 0.0528454
I0111 01:33:25.746672  4932 solver.cpp:255]     Train net output #0: loss = 0.0018633 (* 1 = 0.0018633 loss)
I0111 01:33:25.746685  4932 solver.cpp:631] Iteration 54620, lr = 1e-08
I0111 01:33:32.750303  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5306 > 20) by scale factor 0.88768
I0111 01:34:10.362409  4932 solver.cpp:240] Iteration 54640, loss = 0.0603737
I0111 01:34:10.362496  4932 solver.cpp:255]     Train net output #0: loss = 0.00428518 (* 1 = 0.00428518 loss)
I0111 01:34:10.362509  4932 solver.cpp:631] Iteration 54640, lr = 1e-08
I0111 01:34:21.796238  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6009 > 20) by scale factor 0.884919
I0111 01:34:35.116624  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8053 > 20) by scale factor 0.876988
I0111 01:34:53.186805  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9591 > 20) by scale factor 0.690628
I0111 01:34:55.068312  4932 solver.cpp:240] Iteration 54660, loss = 0.0828304
I0111 01:34:55.068356  4932 solver.cpp:255]     Train net output #0: loss = 0.0509847 (* 1 = 0.0509847 loss)
I0111 01:34:55.068367  4932 solver.cpp:631] Iteration 54660, lr = 1e-08
I0111 01:35:13.162720  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7353 > 20) by scale factor 0.920163
I0111 01:35:22.303887  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9216 > 20) by scale factor 0.912342
I0111 01:35:37.833068  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7502 > 20) by scale factor 0.91953
I0111 01:35:39.714043  4932 solver.cpp:240] Iteration 54680, loss = 0.0679489
I0111 01:35:39.714090  4932 solver.cpp:255]     Train net output #0: loss = 0.191929 (* 1 = 0.191929 loss)
I0111 01:35:39.714103  4932 solver.cpp:631] Iteration 54680, lr = 1e-08
I0111 01:35:42.275583  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1817 > 20) by scale factor 0.990996
I0111 01:36:24.431535  4932 solver.cpp:240] Iteration 54700, loss = 0.053478
I0111 01:36:24.431632  4932 solver.cpp:255]     Train net output #0: loss = 0.00788017 (* 1 = 0.00788017 loss)
I0111 01:36:24.431644  4932 solver.cpp:631] Iteration 54700, lr = 1e-08
I0111 01:36:32.333531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8527 > 20) by scale factor 0.718064
I0111 01:36:38.992094  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.637 > 20) by scale factor 0.811786
I0111 01:37:10.228513  4932 solver.cpp:240] Iteration 54720, loss = 0.0794913
I0111 01:37:10.228610  4932 solver.cpp:255]     Train net output #0: loss = 0.0321704 (* 1 = 0.0321704 loss)
I0111 01:37:10.228622  4932 solver.cpp:631] Iteration 54720, lr = 1e-08
I0111 01:37:12.785135  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9154 > 20) by scale factor 0.956235
I0111 01:37:19.440721  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2391 > 20) by scale factor 0.988184
I0111 01:37:48.296680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9149 > 20) by scale factor 0.802733
I0111 01:37:52.739697  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2798 > 20) by scale factor 0.986203
I0111 01:37:54.621148  4932 solver.cpp:240] Iteration 54740, loss = 0.0804673
I0111 01:37:54.621182  4932 solver.cpp:255]     Train net output #0: loss = 0.0519787 (* 1 = 0.0519787 loss)
I0111 01:37:54.621191  4932 solver.cpp:631] Iteration 54740, lr = 1e-08
I0111 01:38:08.660554  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.283 > 20) by scale factor 0.733058
I0111 01:38:17.538357  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.124 > 20) by scale factor 0.82905
I0111 01:38:22.124990  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3538 > 20) by scale factor 0.936603
I0111 01:38:39.540053  4932 solver.cpp:240] Iteration 54760, loss = 0.0541736
I0111 01:38:39.540097  4932 solver.cpp:255]     Train net output #0: loss = 0.0003125 (* 1 = 0.0003125 loss)
I0111 01:38:39.540112  4932 solver.cpp:631] Iteration 54760, lr = 1e-08
I0111 01:38:55.410405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2743 > 20) by scale factor 0.986471
I0111 01:39:23.924144  4932 solver.cpp:240] Iteration 54780, loss = 0.0645384
I0111 01:39:23.924180  4932 solver.cpp:255]     Train net output #0: loss = 0.113349 (* 1 = 0.113349 loss)
I0111 01:39:23.924188  4932 solver.cpp:631] Iteration 54780, lr = 1e-08
I0111 01:40:09.047433  4932 solver.cpp:240] Iteration 54800, loss = 0.0586384
I0111 01:40:09.047521  4932 solver.cpp:255]     Train net output #0: loss = 0.0223828 (* 1 = 0.0223828 loss)
I0111 01:40:09.047533  4932 solver.cpp:631] Iteration 54800, lr = 1e-08
I0111 01:40:16.040670  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6488 > 20) by scale factor 0.845709
I0111 01:40:54.005290  4932 solver.cpp:240] Iteration 54820, loss = 0.0778573
I0111 01:40:54.005379  4932 solver.cpp:255]     Train net output #0: loss = 0.00841069 (* 1 = 0.00841069 loss)
I0111 01:40:54.005391  4932 solver.cpp:631] Iteration 54820, lr = 1e-08
I0111 01:41:05.439563  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.772 > 20) by scale factor 0.841325
I0111 01:41:38.635689  4932 solver.cpp:240] Iteration 54840, loss = 0.0607097
I0111 01:41:38.635788  4932 solver.cpp:255]     Train net output #0: loss = 0.0191488 (* 1 = 0.0191488 loss)
I0111 01:41:38.635804  4932 solver.cpp:631] Iteration 54840, lr = 1e-08
I0111 01:42:01.206549  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4353 > 20) by scale factor 0.657132
I0111 01:42:23.054885  4932 solver.cpp:240] Iteration 54860, loss = 0.0544447
I0111 01:42:23.054985  4932 solver.cpp:255]     Train net output #0: loss = 0.00796918 (* 1 = 0.00796918 loss)
I0111 01:42:23.054997  4932 solver.cpp:631] Iteration 54860, lr = 1e-08
I0111 01:42:39.253662  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0173 > 20) by scale factor 0.740267
I0111 01:43:07.934559  4932 solver.cpp:240] Iteration 54880, loss = 0.0333887
I0111 01:43:07.934658  4932 solver.cpp:255]     Train net output #0: loss = 0.00158361 (* 1 = 0.00158361 loss)
I0111 01:43:07.934671  4932 solver.cpp:631] Iteration 54880, lr = 1e-08
I0111 01:43:37.125375  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2465 > 20) by scale factor 0.860344
I0111 01:43:52.324287  4932 solver.cpp:240] Iteration 54900, loss = 0.0740912
I0111 01:43:52.324383  4932 solver.cpp:255]     Train net output #0: loss = 0.0544893 (* 1 = 0.0544893 loss)
I0111 01:43:52.324394  4932 solver.cpp:631] Iteration 54900, lr = 1e-08
I0111 01:43:57.104158  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.1236 > 20) by scale factor 0.538741
I0111 01:44:36.713491  4932 solver.cpp:240] Iteration 54920, loss = 0.0550097
I0111 01:44:36.713587  4932 solver.cpp:255]     Train net output #0: loss = 0.0200405 (* 1 = 0.0200405 loss)
I0111 01:44:36.713601  4932 solver.cpp:631] Iteration 54920, lr = 1e-08
I0111 01:44:45.936923  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7423 > 20) by scale factor 0.879417
I0111 01:45:10.343533  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.515 > 20) by scale factor 0.85052
I0111 01:45:21.475008  4932 solver.cpp:240] Iteration 54940, loss = 0.101162
I0111 01:45:21.475049  4932 solver.cpp:255]     Train net output #0: loss = 0.0766339 (* 1 = 0.0766339 loss)
I0111 01:45:21.475057  4932 solver.cpp:631] Iteration 54940, lr = 1e-08
I0111 01:45:30.686651  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8353 > 20) by scale factor 0.915948
I0111 01:45:41.784806  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8221 > 20) by scale factor 0.876342
I0111 01:46:06.375404  4932 solver.cpp:240] Iteration 54960, loss = 0.0458276
I0111 01:46:06.375448  4932 solver.cpp:255]     Train net output #0: loss = 0.00447637 (* 1 = 0.00447637 loss)
I0111 01:46:06.375458  4932 solver.cpp:631] Iteration 54960, lr = 1e-08
I0111 01:46:51.219671  4932 solver.cpp:240] Iteration 54980, loss = 0.0580199
I0111 01:46:51.219787  4932 solver.cpp:255]     Train net output #0: loss = 0.00638766 (* 1 = 0.00638766 loss)
I0111 01:46:51.219805  4932 solver.cpp:631] Iteration 54980, lr = 1e-08
I0111 01:47:24.972103  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3995 > 20) by scale factor 0.819689
I0111 01:47:33.862861  4932 solver.cpp:424] Iteration 55000, Testing net (#0)
I0111 01:48:24.502414  4932 solver.cpp:481]     Test net output #0: accuracy = 0.833684
I0111 01:48:24.502501  4932 solver.cpp:481]     Test net output #1: loss = 0.759483 (* 1 = 0.759483 loss)
I0111 01:48:26.368870  4932 solver.cpp:240] Iteration 55000, loss = 0.0621946
I0111 01:48:26.368903  4932 solver.cpp:255]     Train net output #0: loss = 0.154112 (* 1 = 0.154112 loss)
I0111 01:48:26.368913  4932 solver.cpp:631] Iteration 55000, lr = 1e-08
I0111 01:48:35.587196  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3171 > 20) by scale factor 0.984393
I0111 01:49:07.029306  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1642 > 20) by scale factor 0.94499
I0111 01:49:11.129361  4932 solver.cpp:240] Iteration 55020, loss = 0.0758426
I0111 01:49:11.129402  4932 solver.cpp:255]     Train net output #0: loss = 0.00186749 (* 1 = 0.00186749 loss)
I0111 01:49:11.129412  4932 solver.cpp:631] Iteration 55020, lr = 1e-08
I0111 01:49:46.980775  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3074 > 20) by scale factor 0.896565
I0111 01:49:53.645503  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7356 > 20) by scale factor 0.808551
I0111 01:49:55.943092  4932 solver.cpp:240] Iteration 55040, loss = 0.097551
I0111 01:49:55.943135  4932 solver.cpp:255]     Train net output #0: loss = 0.126921 (* 1 = 0.126921 loss)
I0111 01:49:55.943145  4932 solver.cpp:631] Iteration 55040, lr = 1e-08
I0111 01:50:09.590234  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0815 > 20) by scale factor 0.905735
I0111 01:50:27.341713  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5774 > 20) by scale factor 0.971942
I0111 01:50:38.873260  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2026 > 20) by scale factor 0.98997
I0111 01:50:40.755625  4932 solver.cpp:240] Iteration 55060, loss = 0.0707827
I0111 01:50:40.755666  4932 solver.cpp:255]     Train net output #0: loss = 0.000701199 (* 1 = 0.000701199 loss)
I0111 01:50:40.755676  4932 solver.cpp:631] Iteration 55060, lr = 1e-08
I0111 01:50:49.976711  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6673 > 20) by scale factor 0.779203
I0111 01:50:54.416214  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2454 > 20) by scale factor 0.899063
I0111 01:51:19.238782  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6982 > 20) by scale factor 0.921735
I0111 01:51:25.561252  4932 solver.cpp:240] Iteration 55080, loss = 0.097117
I0111 01:51:25.561295  4932 solver.cpp:255]     Train net output #0: loss = 0.0337175 (* 1 = 0.0337175 loss)
I0111 01:51:25.561305  4932 solver.cpp:631] Iteration 55080, lr = 1e-08
I0111 01:52:10.566148  4932 solver.cpp:240] Iteration 55100, loss = 0.042861
I0111 01:52:10.566241  4932 solver.cpp:255]     Train net output #0: loss = 0.0178595 (* 1 = 0.0178595 loss)
I0111 01:52:10.566256  4932 solver.cpp:631] Iteration 55100, lr = 1e-08
I0111 01:52:46.478498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0404 > 20) by scale factor 0.831934
I0111 01:52:50.919381  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.9394 > 20) by scale factor 0.607175
I0111 01:52:55.022378  4932 solver.cpp:240] Iteration 55120, loss = 0.0811634
I0111 01:52:55.022415  4932 solver.cpp:255]     Train net output #0: loss = 0.0129818 (* 1 = 0.0129818 loss)
I0111 01:52:55.022428  4932 solver.cpp:631] Iteration 55120, lr = 1e-08
I0111 01:53:02.022166  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6922 > 20) by scale factor 0.844159
I0111 01:53:04.243147  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0549 > 20) by scale factor 0.99726
I0111 01:53:35.636539  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9731 > 20) by scale factor 0.83427
I0111 01:53:39.737820  4932 solver.cpp:240] Iteration 55140, loss = 0.0752897
I0111 01:53:39.737869  4932 solver.cpp:255]     Train net output #0: loss = 0.144915 (* 1 = 0.144915 loss)
I0111 01:53:39.737881  4932 solver.cpp:631] Iteration 55140, lr = 1e-08
I0111 01:53:44.520809  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.3796 > 20) by scale factor 0.599169
I0111 01:54:11.160485  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0752 > 20) by scale factor 0.86673
I0111 01:54:24.140709  4932 solver.cpp:240] Iteration 55160, loss = 0.083678
I0111 01:54:24.140763  4932 solver.cpp:255]     Train net output #0: loss = 0.0352701 (* 1 = 0.0352701 loss)
I0111 01:54:24.140777  4932 solver.cpp:631] Iteration 55160, lr = 1e-08
I0111 01:54:57.778369  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1755 > 20) by scale factor 0.991302
I0111 01:55:08.546816  4932 solver.cpp:240] Iteration 55180, loss = 0.058816
I0111 01:55:08.546856  4932 solver.cpp:255]     Train net output #0: loss = 0.165308 (* 1 = 0.165308 loss)
I0111 01:55:08.546866  4932 solver.cpp:631] Iteration 55180, lr = 1e-08
I0111 01:55:26.634551  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4284 > 20) by scale factor 0.933341
I0111 01:55:39.955708  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2736 > 20) by scale factor 0.897923
I0111 01:55:52.936532  4932 solver.cpp:240] Iteration 55200, loss = 0.0597608
I0111 01:55:52.936578  4932 solver.cpp:255]     Train net output #0: loss = 0.00142809 (* 1 = 0.00142809 loss)
I0111 01:55:52.936589  4932 solver.cpp:631] Iteration 55200, lr = 1e-08
I0111 01:56:24.349022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.784 > 20) by scale factor 0.746714
I0111 01:56:37.330267  4932 solver.cpp:240] Iteration 55220, loss = 0.0791621
I0111 01:56:37.330319  4932 solver.cpp:255]     Train net output #0: loss = 0.0349862 (* 1 = 0.0349862 loss)
I0111 01:56:37.330333  4932 solver.cpp:631] Iteration 55220, lr = 1e-08
I0111 01:56:50.991897  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2644 > 20) by scale factor 0.898293
I0111 01:56:59.875586  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8262 > 20) by scale factor 0.805599
I0111 01:57:17.819123  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7146 > 20) by scale factor 0.880492
I0111 01:57:21.919450  4932 solver.cpp:240] Iteration 55240, loss = 0.069468
I0111 01:57:21.919492  4932 solver.cpp:255]     Train net output #0: loss = 0.019203 (* 1 = 0.019203 loss)
I0111 01:57:21.919502  4932 solver.cpp:631] Iteration 55240, lr = 1e-08
I0111 01:57:37.799288  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4782 > 20) by scale factor 0.817054
I0111 01:58:06.827277  4932 solver.cpp:240] Iteration 55260, loss = 0.0653067
I0111 01:58:06.827322  4932 solver.cpp:255]     Train net output #0: loss = 0.00215142 (* 1 = 0.00215142 loss)
I0111 01:58:06.827332  4932 solver.cpp:631] Iteration 55260, lr = 1e-08
I0111 01:58:51.215373  4932 solver.cpp:240] Iteration 55280, loss = 0.0508966
I0111 01:58:51.215484  4932 solver.cpp:255]     Train net output #0: loss = 0.000696572 (* 1 = 0.000696572 loss)
I0111 01:58:51.215500  4932 solver.cpp:631] Iteration 55280, lr = 1e-08
I0111 01:58:58.212858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9808 > 20) by scale factor 0.909884
I0111 01:59:29.289389  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8082 > 20) by scale factor 0.917088
I0111 01:59:35.609738  4932 solver.cpp:240] Iteration 55300, loss = 0.0841442
I0111 01:59:35.609788  4932 solver.cpp:255]     Train net output #0: loss = 0.128196 (* 1 = 0.128196 loss)
I0111 01:59:35.609802  4932 solver.cpp:631] Iteration 55300, lr = 1e-08
I0111 01:59:44.829046  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0624 > 20) by scale factor 0.949558
I0111 02:00:20.015581  4932 solver.cpp:240] Iteration 55320, loss = 0.0406796
I0111 02:00:20.015681  4932 solver.cpp:255]     Train net output #0: loss = 0.0162425 (* 1 = 0.0162425 loss)
I0111 02:00:20.015696  4932 solver.cpp:631] Iteration 55320, lr = 1e-08
I0111 02:01:04.405367  4932 solver.cpp:240] Iteration 55340, loss = 0.0404825
I0111 02:01:04.405458  4932 solver.cpp:255]     Train net output #0: loss = 0.00295785 (* 1 = 0.00295785 loss)
I0111 02:01:04.405472  4932 solver.cpp:631] Iteration 55340, lr = 1e-08
I0111 02:01:48.796979  4932 solver.cpp:240] Iteration 55360, loss = 0.0378129
I0111 02:01:48.797071  4932 solver.cpp:255]     Train net output #0: loss = 0.152568 (* 1 = 0.152568 loss)
I0111 02:01:48.797085  4932 solver.cpp:631] Iteration 55360, lr = 1e-08
I0111 02:01:51.356958  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3118 > 20) by scale factor 0.68232
I0111 02:02:26.864713  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0995 > 20) by scale factor 0.99505
I0111 02:02:33.187544  4932 solver.cpp:240] Iteration 55380, loss = 0.09371
I0111 02:02:33.187590  4932 solver.cpp:255]     Train net output #0: loss = 0.170432 (* 1 = 0.170432 loss)
I0111 02:02:33.187604  4932 solver.cpp:631] Iteration 55380, lr = 1e-08
I0111 02:02:40.185453  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0816 > 20) by scale factor 0.948695
I0111 02:02:49.067760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7449 > 20) by scale factor 0.96409
I0111 02:03:17.585633  4932 solver.cpp:240] Iteration 55400, loss = 0.073406
I0111 02:03:17.585705  4932 solver.cpp:255]     Train net output #0: loss = 0.0219858 (* 1 = 0.0219858 loss)
I0111 02:03:17.585714  4932 solver.cpp:631] Iteration 55400, lr = 1e-08
I0111 02:03:26.806295  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.607 > 20) by scale factor 0.970542
I0111 02:03:42.728183  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2584 > 20) by scale factor 0.940804
I0111 02:04:02.372053  4932 solver.cpp:240] Iteration 55420, loss = 0.0814907
I0111 02:04:02.372164  4932 solver.cpp:255]     Train net output #0: loss = 0.106112 (* 1 = 0.106112 loss)
I0111 02:04:02.372180  4932 solver.cpp:631] Iteration 55420, lr = 1e-08
I0111 02:04:13.807515  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0336 > 20) by scale factor 0.998323
I0111 02:04:34.454257  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3721 > 20) by scale factor 0.935798
I0111 02:04:47.426717  4932 solver.cpp:240] Iteration 55440, loss = 0.0583928
I0111 02:04:47.426748  4932 solver.cpp:255]     Train net output #0: loss = 0.0299898 (* 1 = 0.0299898 loss)
I0111 02:04:47.426759  4932 solver.cpp:631] Iteration 55440, lr = 1e-08
I0111 02:04:54.423279  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2504 > 20) by scale factor 0.898859
I0111 02:04:58.865025  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.2161 > 20) by scale factor 0.734858
I0111 02:05:31.833958  4932 solver.cpp:240] Iteration 55460, loss = 0.0700374
I0111 02:05:31.834049  4932 solver.cpp:255]     Train net output #0: loss = 0.019027 (* 1 = 0.019027 loss)
I0111 02:05:31.834061  4932 solver.cpp:631] Iteration 55460, lr = 1e-08
I0111 02:06:16.234774  4932 solver.cpp:240] Iteration 55480, loss = 0.0473704
I0111 02:06:16.234891  4932 solver.cpp:255]     Train net output #0: loss = 0.000540114 (* 1 = 0.000540114 loss)
I0111 02:06:16.234905  4932 solver.cpp:631] Iteration 55480, lr = 1e-08
I0111 02:06:34.335002  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7565 > 20) by scale factor 0.87887
I0111 02:06:38.779389  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5335 > 20) by scale factor 0.783285
I0111 02:06:52.097939  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.8525 > 20) by scale factor 0.744809
I0111 02:06:58.763092  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6187 > 20) by scale factor 0.925124
I0111 02:07:00.646036  4932 solver.cpp:240] Iteration 55500, loss = 0.0742735
I0111 02:07:00.646075  4932 solver.cpp:255]     Train net output #0: loss = 0.00493576 (* 1 = 0.00493576 loss)
I0111 02:07:00.646085  4932 solver.cpp:631] Iteration 55500, lr = 1e-08
I0111 02:07:45.046017  4932 solver.cpp:240] Iteration 55520, loss = 0.0526957
I0111 02:07:45.046128  4932 solver.cpp:255]     Train net output #0: loss = 0.0251114 (* 1 = 0.0251114 loss)
I0111 02:07:45.046144  4932 solver.cpp:631] Iteration 55520, lr = 1e-08
I0111 02:08:29.438722  4932 solver.cpp:240] Iteration 55540, loss = 0.0651279
I0111 02:08:29.438802  4932 solver.cpp:255]     Train net output #0: loss = 0.00406163 (* 1 = 0.00406163 loss)
I0111 02:08:29.438817  4932 solver.cpp:631] Iteration 55540, lr = 1e-08
I0111 02:08:47.538357  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5726 > 20) by scale factor 0.9271
I0111 02:08:58.636888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2778 > 20) by scale factor 0.859186
I0111 02:09:13.840122  4932 solver.cpp:240] Iteration 55560, loss = 0.0675292
I0111 02:09:13.840198  4932 solver.cpp:255]     Train net output #0: loss = 0.00894238 (* 1 = 0.00894238 loss)
I0111 02:09:13.840209  4932 solver.cpp:631] Iteration 55560, lr = 1e-08
I0111 02:09:58.282279  4932 solver.cpp:240] Iteration 55580, loss = 0.0477017
I0111 02:09:58.282378  4932 solver.cpp:255]     Train net output #0: loss = 0.00910347 (* 1 = 0.00910347 loss)
I0111 02:09:58.282392  4932 solver.cpp:631] Iteration 55580, lr = 1e-08
I0111 02:10:42.673046  4932 solver.cpp:240] Iteration 55600, loss = 0.0568336
I0111 02:10:42.673138  4932 solver.cpp:255]     Train net output #0: loss = 0.0437707 (* 1 = 0.0437707 loss)
I0111 02:10:42.673152  4932 solver.cpp:631] Iteration 55600, lr = 1e-08
I0111 02:11:27.297309  4932 solver.cpp:240] Iteration 55620, loss = 0.0642206
I0111 02:11:27.297406  4932 solver.cpp:255]     Train net output #0: loss = 0.143242 (* 1 = 0.143242 loss)
I0111 02:11:27.297422  4932 solver.cpp:631] Iteration 55620, lr = 1e-08
I0111 02:11:27.638150  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4223 > 20) by scale factor 0.818922
I0111 02:11:38.737622  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3964 > 20) by scale factor 0.893001
I0111 02:12:00.946799  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.288 > 20) by scale factor 0.858813
I0111 02:12:11.839588  4932 solver.cpp:240] Iteration 55640, loss = 0.0863896
I0111 02:12:11.839632  4932 solver.cpp:255]     Train net output #0: loss = 0.0633322 (* 1 = 0.0633322 loss)
I0111 02:12:11.839643  4932 solver.cpp:631] Iteration 55640, lr = 1e-08
I0111 02:12:25.501510  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4636 > 20) by scale factor 0.890327
I0111 02:12:52.633837  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3848 > 20) by scale factor 0.935244
I0111 02:12:56.733527  4932 solver.cpp:240] Iteration 55660, loss = 0.048845
I0111 02:12:56.733569  4932 solver.cpp:255]     Train net output #0: loss = 0.00619302 (* 1 = 0.00619302 loss)
I0111 02:12:56.733578  4932 solver.cpp:631] Iteration 55660, lr = 1e-08
I0111 02:13:08.174450  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3077 > 20) by scale factor 0.858085
I0111 02:13:41.277729  4932 solver.cpp:240] Iteration 55680, loss = 0.0570474
I0111 02:13:41.277843  4932 solver.cpp:255]     Train net output #0: loss = 0.00685235 (* 1 = 0.00685235 loss)
I0111 02:13:41.277856  4932 solver.cpp:631] Iteration 55680, lr = 1e-08
I0111 02:14:06.037578  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7136 > 20) by scale factor 0.880529
I0111 02:14:17.139969  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5592 > 20) by scale factor 0.972798
I0111 02:14:25.685154  4932 solver.cpp:240] Iteration 55700, loss = 0.0765677
I0111 02:14:25.685196  4932 solver.cpp:255]     Train net output #0: loss = 0.0182864 (* 1 = 0.0182864 loss)
I0111 02:14:25.685209  4932 solver.cpp:631] Iteration 55700, lr = 1e-08
I0111 02:15:10.084820  4932 solver.cpp:240] Iteration 55720, loss = 0.0776603
I0111 02:15:10.084939  4932 solver.cpp:255]     Train net output #0: loss = 0.000738203 (* 1 = 0.000738203 loss)
I0111 02:15:10.084956  4932 solver.cpp:631] Iteration 55720, lr = 1e-08
I0111 02:15:54.488410  4932 solver.cpp:240] Iteration 55740, loss = 0.0407559
I0111 02:15:54.488509  4932 solver.cpp:255]     Train net output #0: loss = 0.0032072 (* 1 = 0.0032072 loss)
I0111 02:15:54.488523  4932 solver.cpp:631] Iteration 55740, lr = 1e-08
I0111 02:16:38.190760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7645 > 20) by scale factor 0.87856
I0111 02:16:40.073333  4932 solver.cpp:240] Iteration 55760, loss = 0.082574
I0111 02:16:40.073374  4932 solver.cpp:255]     Train net output #0: loss = 0.0822546 (* 1 = 0.0822546 loss)
I0111 02:16:40.073384  4932 solver.cpp:631] Iteration 55760, lr = 1e-08
I0111 02:16:51.515007  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0059 > 20) by scale factor 0.952113
I0111 02:17:04.837743  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5441 > 20) by scale factor 0.84947
I0111 02:17:20.378461  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3894 > 20) by scale factor 0.757879
I0111 02:17:24.481850  4932 solver.cpp:240] Iteration 55780, loss = 0.0886005
I0111 02:17:24.481884  4932 solver.cpp:255]     Train net output #0: loss = 0.00345204 (* 1 = 0.00345204 loss)
I0111 02:17:24.481894  4932 solver.cpp:631] Iteration 55780, lr = 1e-08
I0111 02:17:33.699239  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5776 > 20) by scale factor 0.699848
I0111 02:17:35.923707  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5103 > 20) by scale factor 0.975121
I0111 02:18:07.003022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8039 > 20) by scale factor 0.961357
I0111 02:18:08.884788  4932 solver.cpp:240] Iteration 55800, loss = 0.0454065
I0111 02:18:08.884827  4932 solver.cpp:255]     Train net output #0: loss = 0.0265466 (* 1 = 0.0265466 loss)
I0111 02:18:08.884840  4932 solver.cpp:631] Iteration 55800, lr = 1e-08
I0111 02:18:53.574537  4932 solver.cpp:240] Iteration 55820, loss = 0.0427378
I0111 02:18:53.574630  4932 solver.cpp:255]     Train net output #0: loss = 0.0225869 (* 1 = 0.0225869 loss)
I0111 02:18:53.574643  4932 solver.cpp:631] Iteration 55820, lr = 1e-08
I0111 02:19:05.006346  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.7048 > 20) by scale factor 0.651364
I0111 02:19:20.550146  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1074 > 20) by scale factor 0.904676
I0111 02:19:31.646004  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9023 > 20) by scale factor 0.83674
I0111 02:19:37.967679  4932 solver.cpp:240] Iteration 55840, loss = 0.101976
I0111 02:19:37.967720  4932 solver.cpp:255]     Train net output #0: loss = 0.126154 (* 1 = 0.126154 loss)
I0111 02:19:37.967730  4932 solver.cpp:631] Iteration 55840, lr = 1e-08
I0111 02:19:51.626776  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8571 > 20) by scale factor 0.69307
I0111 02:20:22.704810  4932 solver.cpp:240] Iteration 55860, loss = 0.0702485
I0111 02:20:22.704938  4932 solver.cpp:255]     Train net output #0: loss = 0.00165293 (* 1 = 0.00165293 loss)
I0111 02:20:22.704954  4932 solver.cpp:631] Iteration 55860, lr = 1e-08
I0111 02:20:38.575148  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1836 > 20) by scale factor 0.862678
I0111 02:20:40.797034  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5955 > 20) by scale factor 0.813155
I0111 02:20:47.458636  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3667 > 20) by scale factor 0.681044
I0111 02:21:07.467475  4932 solver.cpp:240] Iteration 55880, loss = 0.0847206
I0111 02:21:07.467567  4932 solver.cpp:255]     Train net output #0: loss = 0.015574 (* 1 = 0.015574 loss)
I0111 02:21:07.467579  4932 solver.cpp:631] Iteration 55880, lr = 1e-08
I0111 02:21:18.901576  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8437 > 20) by scale factor 0.805034
I0111 02:21:51.993186  4932 solver.cpp:240] Iteration 55900, loss = 0.0807331
I0111 02:21:51.993284  4932 solver.cpp:255]     Train net output #0: loss = 0.209878 (* 1 = 0.209878 loss)
I0111 02:21:51.993297  4932 solver.cpp:631] Iteration 55900, lr = 1e-08
I0111 02:22:36.387316  4932 solver.cpp:240] Iteration 55920, loss = 0.0515596
I0111 02:22:36.387403  4932 solver.cpp:255]     Train net output #0: loss = 0.16527 (* 1 = 0.16527 loss)
I0111 02:22:36.387413  4932 solver.cpp:631] Iteration 55920, lr = 1e-08
I0111 02:23:20.768360  4932 solver.cpp:240] Iteration 55940, loss = 0.0490828
I0111 02:23:20.768473  4932 solver.cpp:255]     Train net output #0: loss = 0.0066207 (* 1 = 0.0066207 loss)
I0111 02:23:20.768488  4932 solver.cpp:631] Iteration 55940, lr = 1e-08
I0111 02:23:23.327898  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3934 > 20) by scale factor 0.93487
I0111 02:24:05.153311  4932 solver.cpp:240] Iteration 55960, loss = 0.0720111
I0111 02:24:05.153411  4932 solver.cpp:255]     Train net output #0: loss = 0.174361 (* 1 = 0.174361 loss)
I0111 02:24:05.153425  4932 solver.cpp:631] Iteration 55960, lr = 1e-08
I0111 02:24:05.494526  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5899 > 20) by scale factor 0.752165
I0111 02:24:23.260921  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1128 > 20) by scale factor 0.904452
I0111 02:24:25.483446  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6151 > 20) by scale factor 0.884363
I0111 02:24:36.578318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6885 > 20) by scale factor 0.881505
I0111 02:24:49.553406  4932 solver.cpp:240] Iteration 55980, loss = 0.065912
I0111 02:24:49.553449  4932 solver.cpp:255]     Train net output #0: loss = 0.0317228 (* 1 = 0.0317228 loss)
I0111 02:24:49.553458  4932 solver.cpp:631] Iteration 55980, lr = 1e-08
I0111 02:25:07.649967  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7221 > 20) by scale factor 0.672901
I0111 02:25:20.967608  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9164 > 20) by scale factor 0.956186
I0111 02:25:32.076293  4932 solver.cpp:424] Iteration 56000, Testing net (#0)
I0111 02:26:23.202543  4932 solver.cpp:481]     Test net output #0: accuracy = 0.825263
I0111 02:26:23.202631  4932 solver.cpp:481]     Test net output #1: loss = 0.898118 (* 1 = 0.898118 loss)
I0111 02:26:25.068423  4932 solver.cpp:240] Iteration 56000, loss = 0.0497568
I0111 02:26:25.068462  4932 solver.cpp:255]     Train net output #0: loss = 0.0302678 (* 1 = 0.0302678 loss)
I0111 02:26:25.068472  4932 solver.cpp:631] Iteration 56000, lr = 1e-08
I0111 02:26:38.726249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.349 > 20) by scale factor 0.599719
I0111 02:26:49.831130  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4921 > 20) by scale factor 0.851349
I0111 02:27:09.479943  4932 solver.cpp:240] Iteration 56020, loss = 0.0727108
I0111 02:27:09.480057  4932 solver.cpp:255]     Train net output #0: loss = 0.0102235 (* 1 = 0.0102235 loss)
I0111 02:27:09.480072  4932 solver.cpp:631] Iteration 56020, lr = 1e-08
I0111 02:27:20.922431  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7886 > 20) by scale factor 0.775536
I0111 02:27:47.571683  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3039 > 20) by scale factor 0.638899
I0111 02:27:53.896019  4932 solver.cpp:240] Iteration 56040, loss = 0.0541826
I0111 02:27:53.896064  4932 solver.cpp:255]     Train net output #0: loss = 0.017679 (* 1 = 0.017679 loss)
I0111 02:27:53.896075  4932 solver.cpp:631] Iteration 56040, lr = 1e-08
I0111 02:28:03.116261  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0116 > 20) by scale factor 0.799627
I0111 02:28:38.580904  4932 solver.cpp:240] Iteration 56060, loss = 0.0698403
I0111 02:28:38.580986  4932 solver.cpp:255]     Train net output #0: loss = 0.0856446 (* 1 = 0.0856446 loss)
I0111 02:28:38.580998  4932 solver.cpp:631] Iteration 56060, lr = 1e-08
I0111 02:28:38.920193  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4668 > 20) by scale factor 0.785335
I0111 02:28:45.575449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7466 > 20) by scale factor 0.964011
I0111 02:29:05.553129  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8268 > 20) by scale factor 0.960302
I0111 02:29:23.137670  4932 solver.cpp:240] Iteration 56080, loss = 0.0749137
I0111 02:29:23.137751  4932 solver.cpp:255]     Train net output #0: loss = 0.0117876 (* 1 = 0.0117876 loss)
I0111 02:29:23.137763  4932 solver.cpp:631] Iteration 56080, lr = 1e-08
I0111 02:29:27.914573  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2845 > 20) by scale factor 0.82357
I0111 02:30:07.670859  4932 solver.cpp:240] Iteration 56100, loss = 0.05108
I0111 02:30:07.670912  4932 solver.cpp:255]     Train net output #0: loss = 0.00297106 (* 1 = 0.00297106 loss)
I0111 02:30:07.670922  4932 solver.cpp:631] Iteration 56100, lr = 1e-08
I0111 02:30:23.543354  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8717 > 20) by scale factor 0.773046
I0111 02:30:50.177999  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3574 > 20) by scale factor 0.758801
I0111 02:30:52.059523  4932 solver.cpp:240] Iteration 56120, loss = 0.0763894
I0111 02:30:52.059562  4932 solver.cpp:255]     Train net output #0: loss = 0.0115416 (* 1 = 0.0115416 loss)
I0111 02:30:52.059572  4932 solver.cpp:631] Iteration 56120, lr = 1e-08
I0111 02:30:59.053344  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7979 > 20) by scale factor 0.694494
I0111 02:31:36.519112  4932 solver.cpp:240] Iteration 56140, loss = 0.0561389
I0111 02:31:36.519208  4932 solver.cpp:255]     Train net output #0: loss = 0.0836364 (* 1 = 0.0836364 loss)
I0111 02:31:36.519222  4932 solver.cpp:631] Iteration 56140, lr = 1e-08
I0111 02:31:43.514873  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.2092 > 20) by scale factor 0.568033
I0111 02:31:52.390213  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3348 > 20) by scale factor 0.85709
I0111 02:32:20.898265  4932 solver.cpp:240] Iteration 56160, loss = 0.0811469
I0111 02:32:20.898358  4932 solver.cpp:255]     Train net output #0: loss = 0.0338326 (* 1 = 0.0338326 loss)
I0111 02:32:20.898370  4932 solver.cpp:631] Iteration 56160, lr = 1e-08
I0111 02:32:34.552492  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3692 > 20) by scale factor 0.820708
I0111 02:32:50.092533  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6725 > 20) by scale factor 0.810618
I0111 02:33:01.193903  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.034 > 20) by scale factor 0.998305
I0111 02:33:05.293054  4932 solver.cpp:240] Iteration 56180, loss = 0.0921112
I0111 02:33:05.293093  4932 solver.cpp:255]     Train net output #0: loss = 0.165479 (* 1 = 0.165479 loss)
I0111 02:33:05.293102  4932 solver.cpp:631] Iteration 56180, lr = 1e-08
I0111 02:33:49.988404  4932 solver.cpp:240] Iteration 56200, loss = 0.0450383
I0111 02:33:49.988503  4932 solver.cpp:255]     Train net output #0: loss = 0.0268277 (* 1 = 0.0268277 loss)
I0111 02:33:49.988517  4932 solver.cpp:631] Iteration 56200, lr = 1e-08
I0111 02:34:34.620744  4932 solver.cpp:240] Iteration 56220, loss = 0.0413609
I0111 02:34:34.620833  4932 solver.cpp:255]     Train net output #0: loss = 0.144111 (* 1 = 0.144111 loss)
I0111 02:34:34.620846  4932 solver.cpp:631] Iteration 56220, lr = 1e-08
I0111 02:35:06.261349  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7106 > 20) by scale factor 0.843506
I0111 02:35:17.357197  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7486 > 20) by scale factor 0.963923
I0111 02:35:19.239116  4932 solver.cpp:240] Iteration 56240, loss = 0.0648323
I0111 02:35:19.239161  4932 solver.cpp:255]     Train net output #0: loss = 0.0491042 (* 1 = 0.0491042 loss)
I0111 02:35:19.239172  4932 solver.cpp:631] Iteration 56240, lr = 1e-08
I0111 02:36:03.620789  4932 solver.cpp:240] Iteration 56260, loss = 0.069767
I0111 02:36:03.620872  4932 solver.cpp:255]     Train net output #0: loss = 0.000559873 (* 1 = 0.000559873 loss)
I0111 02:36:03.620883  4932 solver.cpp:631] Iteration 56260, lr = 1e-08
I0111 02:36:37.261335  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0416 > 20) by scale factor 0.867994
I0111 02:36:43.921331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.413 > 20) by scale factor 0.97977
I0111 02:36:48.024232  4932 solver.cpp:240] Iteration 56280, loss = 0.0611601
I0111 02:36:48.024276  4932 solver.cpp:255]     Train net output #0: loss = 0.00262877 (* 1 = 0.00262877 loss)
I0111 02:36:48.024402  4932 solver.cpp:631] Iteration 56280, lr = 1e-08
I0111 02:37:14.992835  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9016 > 20) by scale factor 0.873301
I0111 02:37:32.411316  4932 solver.cpp:240] Iteration 56300, loss = 0.0498862
I0111 02:37:32.411365  4932 solver.cpp:255]     Train net output #0: loss = 0.105652 (* 1 = 0.105652 loss)
I0111 02:37:32.411377  4932 solver.cpp:631] Iteration 56300, lr = 1e-08
I0111 02:37:54.954047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1429 > 20) by scale factor 0.864195
I0111 02:38:16.859253  4932 solver.cpp:240] Iteration 56320, loss = 0.0831831
I0111 02:38:16.859297  4932 solver.cpp:255]     Train net output #0: loss = 0.0161077 (* 1 = 0.0161077 loss)
I0111 02:38:16.859308  4932 solver.cpp:631] Iteration 56320, lr = 1e-08
I0111 02:38:41.610074  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3635 > 20) by scale factor 0.98215
I0111 02:39:01.257928  4932 solver.cpp:240] Iteration 56340, loss = 0.0601856
I0111 02:39:01.257973  4932 solver.cpp:255]     Train net output #0: loss = 0.0234267 (* 1 = 0.0234267 loss)
I0111 02:39:01.257985  4932 solver.cpp:631] Iteration 56340, lr = 1e-08
I0111 02:39:43.775054  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9584 > 20) by scale factor 0.690646
I0111 02:39:45.657953  4932 solver.cpp:240] Iteration 56360, loss = 0.0643427
I0111 02:39:45.658004  4932 solver.cpp:255]     Train net output #0: loss = 0.01499 (* 1 = 0.01499 loss)
I0111 02:39:45.658017  4932 solver.cpp:631] Iteration 56360, lr = 1e-08
I0111 02:40:30.051689  4932 solver.cpp:240] Iteration 56380, loss = 0.0881977
I0111 02:40:30.051792  4932 solver.cpp:255]     Train net output #0: loss = 0.20402 (* 1 = 0.20402 loss)
I0111 02:40:30.051805  4932 solver.cpp:631] Iteration 56380, lr = 1e-08
I0111 02:41:14.454177  4932 solver.cpp:240] Iteration 56400, loss = 0.0699014
I0111 02:41:14.454282  4932 solver.cpp:255]     Train net output #0: loss = 0.00888321 (* 1 = 0.00888321 loss)
I0111 02:41:14.454301  4932 solver.cpp:631] Iteration 56400, lr = 1e-08
I0111 02:41:58.857529  4932 solver.cpp:240] Iteration 56420, loss = 0.0548342
I0111 02:41:58.857628  4932 solver.cpp:255]     Train net output #0: loss = 0.0552863 (* 1 = 0.0552863 loss)
I0111 02:41:58.857642  4932 solver.cpp:631] Iteration 56420, lr = 1e-08
I0111 02:42:19.177403  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0418 > 20) by scale factor 0.997913
I0111 02:42:21.398146  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0597 > 20) by scale factor 0.997023
I0111 02:42:43.250645  4932 solver.cpp:240] Iteration 56440, loss = 0.0966805
I0111 02:42:43.250718  4932 solver.cpp:255]     Train net output #0: loss = 0.13583 (* 1 = 0.13583 loss)
I0111 02:42:43.250730  4932 solver.cpp:631] Iteration 56440, lr = 1e-08
I0111 02:43:27.742334  4932 solver.cpp:240] Iteration 56460, loss = 0.0711846
I0111 02:43:27.742434  4932 solver.cpp:255]     Train net output #0: loss = 0.04141 (* 1 = 0.04141 loss)
I0111 02:43:27.742446  4932 solver.cpp:631] Iteration 56460, lr = 1e-08
I0111 02:43:43.621289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.4508 > 20) by scale factor 0.564162
I0111 02:44:01.377039  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5868 > 20) by scale factor 0.971496
I0111 02:44:05.818231  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3398 > 20) by scale factor 0.937215
I0111 02:44:12.145817  4932 solver.cpp:240] Iteration 56480, loss = 0.0813725
I0111 02:44:12.145859  4932 solver.cpp:255]     Train net output #0: loss = 0.0399363 (* 1 = 0.0399363 loss)
I0111 02:44:12.145869  4932 solver.cpp:631] Iteration 56480, lr = 1e-08
I0111 02:44:57.021615  4932 solver.cpp:240] Iteration 56500, loss = 0.0591603
I0111 02:44:57.021725  4932 solver.cpp:255]     Train net output #0: loss = 0.129383 (* 1 = 0.129383 loss)
I0111 02:44:57.021740  4932 solver.cpp:631] Iteration 56500, lr = 1e-08
I0111 02:45:41.882947  4932 solver.cpp:240] Iteration 56520, loss = 0.0611251
I0111 02:45:41.883049  4932 solver.cpp:255]     Train net output #0: loss = 0.0406068 (* 1 = 0.0406068 loss)
I0111 02:45:41.883064  4932 solver.cpp:631] Iteration 56520, lr = 1e-08
I0111 02:46:04.417768  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5172 > 20) by scale factor 0.677571
I0111 02:46:26.449672  4932 solver.cpp:240] Iteration 56540, loss = 0.0658725
I0111 02:46:26.449779  4932 solver.cpp:255]     Train net output #0: loss = 0.0528824 (* 1 = 0.0528824 loss)
I0111 02:46:26.449792  4932 solver.cpp:631] Iteration 56540, lr = 1e-08
I0111 02:46:31.233705  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6692 > 20) by scale factor 0.722824
I0111 02:46:49.141078  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9208 > 20) by scale factor 0.691544
I0111 02:47:02.460808  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1994 > 20) by scale factor 0.943424
I0111 02:47:11.005012  4932 solver.cpp:240] Iteration 56560, loss = 0.0936823
I0111 02:47:11.005053  4932 solver.cpp:255]     Train net output #0: loss = 0.156759 (* 1 = 0.156759 loss)
I0111 02:47:11.005062  4932 solver.cpp:631] Iteration 56560, lr = 1e-08
I0111 02:47:11.344331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5621 > 20) by scale factor 0.848819
I0111 02:47:55.982841  4932 solver.cpp:240] Iteration 56580, loss = 0.0601497
I0111 02:47:55.982934  4932 solver.cpp:255]     Train net output #0: loss = 0.00103049 (* 1 = 0.00103049 loss)
I0111 02:47:55.982947  4932 solver.cpp:631] Iteration 56580, lr = 1e-08
I0111 02:48:40.651177  4932 solver.cpp:240] Iteration 56600, loss = 0.0440386
I0111 02:48:40.651278  4932 solver.cpp:255]     Train net output #0: loss = 0.0164549 (* 1 = 0.0164549 loss)
I0111 02:48:40.651293  4932 solver.cpp:631] Iteration 56600, lr = 1e-08
I0111 02:48:54.310070  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7227 > 20) by scale factor 0.808974
I0111 02:49:12.529055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5293 > 20) by scale factor 0.850005
I0111 02:49:25.502719  4932 solver.cpp:240] Iteration 56620, loss = 0.0522922
I0111 02:49:25.502768  4932 solver.cpp:255]     Train net output #0: loss = 0.135323 (* 1 = 0.135323 loss)
I0111 02:49:25.502785  4932 solver.cpp:631] Iteration 56620, lr = 1e-08
I0111 02:49:25.843333  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0433 > 20) by scale factor 0.95042
I0111 02:49:50.429136  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1564 > 20) by scale factor 0.764631
I0111 02:50:10.062042  4932 solver.cpp:240] Iteration 56640, loss = 0.0539324
I0111 02:50:10.062086  4932 solver.cpp:255]     Train net output #0: loss = 0.0128616 (* 1 = 0.0128616 loss)
I0111 02:50:10.062211  4932 solver.cpp:631] Iteration 56640, lr = 1e-08
I0111 02:50:55.460142  4932 solver.cpp:240] Iteration 56660, loss = 0.0415764
I0111 02:50:55.460243  4932 solver.cpp:255]     Train net output #0: loss = 0.000293077 (* 1 = 0.000293077 loss)
I0111 02:50:55.460258  4932 solver.cpp:631] Iteration 56660, lr = 1e-08
I0111 02:51:15.771683  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.375 > 20) by scale factor 0.981595
I0111 02:51:24.650818  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3218 > 20) by scale factor 0.857567
I0111 02:51:40.278072  4932 solver.cpp:240] Iteration 56680, loss = 0.0740474
I0111 02:51:40.278175  4932 solver.cpp:255]     Train net output #0: loss = 0.00232945 (* 1 = 0.00232945 loss)
I0111 02:51:40.278189  4932 solver.cpp:631] Iteration 56680, lr = 1e-08
I0111 02:52:00.588119  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1585 > 20) by scale factor 0.90259
I0111 02:52:22.777798  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4567 > 20) by scale factor 0.932111
I0111 02:52:24.659188  4932 solver.cpp:240] Iteration 56700, loss = 0.0585539
I0111 02:52:24.659221  4932 solver.cpp:255]     Train net output #0: loss = 0.0256179 (* 1 = 0.0256179 loss)
I0111 02:52:24.659230  4932 solver.cpp:631] Iteration 56700, lr = 1e-08
I0111 02:52:36.097165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1996 > 20) by scale factor 0.990119
I0111 02:52:58.287849  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.573 > 20) by scale factor 0.886013
I0111 02:53:00.510076  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9905 > 20) by scale factor 0.909482
I0111 02:53:09.047965  4932 solver.cpp:240] Iteration 56720, loss = 0.0906091
I0111 02:53:09.047997  4932 solver.cpp:255]     Train net output #0: loss = 0.0302099 (* 1 = 0.0302099 loss)
I0111 02:53:09.048007  4932 solver.cpp:631] Iteration 56720, lr = 1e-08
I0111 02:53:53.640789  4932 solver.cpp:240] Iteration 56740, loss = 0.0462498
I0111 02:53:53.640871  4932 solver.cpp:255]     Train net output #0: loss = 0.0113044 (* 1 = 0.0113044 loss)
I0111 02:53:53.640882  4932 solver.cpp:631] Iteration 56740, lr = 1e-08
I0111 02:53:58.416183  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9859 > 20) by scale factor 0.645455
I0111 02:54:13.952288  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.866 > 20) by scale factor 0.874661
I0111 02:54:38.029623  4932 solver.cpp:240] Iteration 56760, loss = 0.145283
I0111 02:54:38.029716  4932 solver.cpp:255]     Train net output #0: loss = 0.0390483 (* 1 = 0.0390483 loss)
I0111 02:54:38.029729  4932 solver.cpp:631] Iteration 56760, lr = 1e-08
I0111 02:54:49.468483  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8473 > 20) by scale factor 0.875378
I0111 02:55:20.534823  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3214 > 20) by scale factor 0.896
I0111 02:55:22.416739  4932 solver.cpp:240] Iteration 56780, loss = 0.0494985
I0111 02:55:22.416777  4932 solver.cpp:255]     Train net output #0: loss = 0.000906588 (* 1 = 0.000906588 loss)
I0111 02:55:22.416795  4932 solver.cpp:631] Iteration 56780, lr = 1e-08
I0111 02:55:36.368449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.8534 > 20) by scale factor 0.66994
I0111 02:55:40.817773  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.7165 > 20) by scale factor 0.651115
I0111 02:56:07.394682  4932 solver.cpp:240] Iteration 56800, loss = 0.0739105
I0111 02:56:07.394780  4932 solver.cpp:255]     Train net output #0: loss = 0.0133729 (* 1 = 0.0133729 loss)
I0111 02:56:07.394793  4932 solver.cpp:631] Iteration 56800, lr = 1e-08
I0111 02:56:27.708394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2026 > 20) by scale factor 0.943279
I0111 02:56:47.842396  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1956 > 20) by scale factor 0.862232
I0111 02:56:51.942728  4932 solver.cpp:240] Iteration 56820, loss = 0.0985804
I0111 02:56:51.942775  4932 solver.cpp:255]     Train net output #0: loss = 0.119938 (* 1 = 0.119938 loss)
I0111 02:56:51.942788  4932 solver.cpp:631] Iteration 56820, lr = 1e-08
I0111 02:57:03.386147  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0983 > 20) by scale factor 0.947945
I0111 02:57:36.701082  4932 solver.cpp:240] Iteration 56840, loss = 0.0474169
I0111 02:57:36.701177  4932 solver.cpp:255]     Train net output #0: loss = 0.123495 (* 1 = 0.123495 loss)
I0111 02:57:36.701192  4932 solver.cpp:631] Iteration 56840, lr = 1e-08
I0111 02:57:53.009474  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9379 > 20) by scale factor 0.87192
I0111 02:57:57.454300  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0664 > 20) by scale factor 0.996691
I0111 02:58:21.522020  4932 solver.cpp:240] Iteration 56860, loss = 0.0682365
I0111 02:58:21.522099  4932 solver.cpp:255]     Train net output #0: loss = 0.103766 (* 1 = 0.103766 loss)
I0111 02:58:21.522111  4932 solver.cpp:631] Iteration 56860, lr = 1e-08
I0111 02:58:55.204644  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7577 > 20) by scale factor 0.919216
I0111 02:59:05.959501  4932 solver.cpp:240] Iteration 56880, loss = 0.0569062
I0111 02:59:05.959553  4932 solver.cpp:255]     Train net output #0: loss = 0.115766 (* 1 = 0.115766 loss)
I0111 02:59:05.959710  4932 solver.cpp:631] Iteration 56880, lr = 1e-08
I0111 02:59:46.431792  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9565 > 20) by scale factor 0.954358
I0111 02:59:50.534517  4932 solver.cpp:240] Iteration 56900, loss = 0.0709102
I0111 02:59:50.534565  4932 solver.cpp:255]     Train net output #0: loss = 0.122353 (* 1 = 0.122353 loss)
I0111 02:59:50.534579  4932 solver.cpp:631] Iteration 56900, lr = 1e-08
I0111 03:00:11.394919  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1055 > 20) by scale factor 0.796638
I0111 03:00:35.471884  4932 solver.cpp:240] Iteration 56920, loss = 0.0574048
I0111 03:00:35.471985  4932 solver.cpp:255]     Train net output #0: loss = 0.054586 (* 1 = 0.054586 loss)
I0111 03:00:35.471999  4932 solver.cpp:631] Iteration 56920, lr = 1e-08
I0111 03:00:58.551858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9763 > 20) by scale factor 0.953457
I0111 03:01:20.417445  4932 solver.cpp:240] Iteration 56940, loss = 0.0718464
I0111 03:01:20.417548  4932 solver.cpp:255]     Train net output #0: loss = 0.0102757 (* 1 = 0.0102757 loss)
I0111 03:01:20.417564  4932 solver.cpp:631] Iteration 56940, lr = 1e-08
I0111 03:01:39.016643  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.047 > 20) by scale factor 0.867793
I0111 03:02:01.507275  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2993 > 20) by scale factor 0.938996
I0111 03:02:05.613271  4932 solver.cpp:240] Iteration 56960, loss = 0.056022
I0111 03:02:05.613332  4932 solver.cpp:255]     Train net output #0: loss = 0.149119 (* 1 = 0.149119 loss)
I0111 03:02:05.613487  4932 solver.cpp:631] Iteration 56960, lr = 1e-08
I0111 03:02:50.073007  4932 solver.cpp:240] Iteration 56980, loss = 0.0717138
I0111 03:02:50.073108  4932 solver.cpp:255]     Train net output #0: loss = 0.116327 (* 1 = 0.116327 loss)
I0111 03:02:50.073119  4932 solver.cpp:631] Iteration 56980, lr = 1e-08
I0111 03:03:08.166857  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1064 > 20) by scale factor 0.99471
I0111 03:03:33.023733  4932 solver.cpp:424] Iteration 57000, Testing net (#0)
I0111 03:04:24.875629  4932 solver.cpp:481]     Test net output #0: accuracy = 0.82
I0111 03:04:24.875712  4932 solver.cpp:481]     Test net output #1: loss = 0.941993 (* 1 = 0.941993 loss)
I0111 03:04:26.741611  4932 solver.cpp:240] Iteration 57000, loss = 0.0879914
I0111 03:04:26.741650  4932 solver.cpp:255]     Train net output #0: loss = 0.00429943 (* 1 = 0.00429943 loss)
I0111 03:04:26.741659  4932 solver.cpp:631] Iteration 57000, lr = 1e-08
I0111 03:04:42.608834  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.3524 > 20) by scale factor 0.658927
I0111 03:05:11.118194  4932 solver.cpp:240] Iteration 57020, loss = 0.0641521
I0111 03:05:11.118283  4932 solver.cpp:255]     Train net output #0: loss = 0.0807244 (* 1 = 0.0807244 loss)
I0111 03:05:11.118295  4932 solver.cpp:631] Iteration 57020, lr = 1e-08
I0111 03:05:22.547076  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.067 > 20) by scale factor 0.996659
I0111 03:05:42.524001  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7347 > 20) by scale factor 0.879713
I0111 03:05:55.505936  4932 solver.cpp:240] Iteration 57040, loss = 0.105402
I0111 03:05:55.505976  4932 solver.cpp:255]     Train net output #0: loss = 0.00310491 (* 1 = 0.00310491 loss)
I0111 03:05:55.505985  4932 solver.cpp:631] Iteration 57040, lr = 1e-08
I0111 03:06:15.813575  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7745 > 20) by scale factor 0.962717
I0111 03:06:26.914762  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2285 > 20) by scale factor 0.988703
I0111 03:06:39.891232  4932 solver.cpp:240] Iteration 57060, loss = 0.0533459
I0111 03:06:39.891278  4932 solver.cpp:255]     Train net output #0: loss = 0.178022 (* 1 = 0.178022 loss)
I0111 03:06:39.891290  4932 solver.cpp:631] Iteration 57060, lr = 1e-08
I0111 03:07:02.674693  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.466 > 20) by scale factor 0.977231
I0111 03:07:09.331900  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1178 > 20) by scale factor 0.796249
I0111 03:07:24.528627  4932 solver.cpp:240] Iteration 57080, loss = 0.0899118
I0111 03:07:24.528661  4932 solver.cpp:255]     Train net output #0: loss = 0.146523 (* 1 = 0.146523 loss)
I0111 03:07:24.528669  4932 solver.cpp:631] Iteration 57080, lr = 1e-08
I0111 03:07:34.206847  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8315 > 20) by scale factor 0.960085
I0111 03:07:36.427772  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3127 > 20) by scale factor 0.984607
I0111 03:08:09.381817  4932 solver.cpp:240] Iteration 57100, loss = 0.0606539
I0111 03:08:09.381911  4932 solver.cpp:255]     Train net output #0: loss = 0.0543438 (* 1 = 0.0543438 loss)
I0111 03:08:09.381922  4932 solver.cpp:631] Iteration 57100, lr = 1e-08
I0111 03:08:31.910069  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.8001 > 20) by scale factor 0.671138
I0111 03:08:45.234782  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.513 > 20) by scale factor 0.850592
I0111 03:08:53.776175  4932 solver.cpp:240] Iteration 57120, loss = 0.0809786
I0111 03:08:53.776213  4932 solver.cpp:255]     Train net output #0: loss = 0.184889 (* 1 = 0.184889 loss)
I0111 03:08:53.776223  4932 solver.cpp:631] Iteration 57120, lr = 1e-08
I0111 03:08:54.115146  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3062 > 20) by scale factor 0.858141
I0111 03:09:00.772785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5943 > 20) by scale factor 0.971141
I0111 03:09:22.996953  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.7084 > 20) by scale factor 0.721802
I0111 03:09:38.193559  4932 solver.cpp:240] Iteration 57140, loss = 0.0705059
I0111 03:09:38.193605  4932 solver.cpp:255]     Train net output #0: loss = 0.0274934 (* 1 = 0.0274934 loss)
I0111 03:09:38.193617  4932 solver.cpp:631] Iteration 57140, lr = 1e-08
I0111 03:10:22.716572  4932 solver.cpp:240] Iteration 57160, loss = 0.0606534
I0111 03:10:22.716662  4932 solver.cpp:255]     Train net output #0: loss = 0.108015 (* 1 = 0.108015 loss)
I0111 03:10:22.716673  4932 solver.cpp:631] Iteration 57160, lr = 1e-08
I0111 03:10:47.515678  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5324 > 20) by scale factor 0.815248
I0111 03:11:07.149075  4932 solver.cpp:240] Iteration 57180, loss = 0.0584426
I0111 03:11:07.149169  4932 solver.cpp:255]     Train net output #0: loss = 0.0115663 (* 1 = 0.0115663 loss)
I0111 03:11:07.149183  4932 solver.cpp:631] Iteration 57180, lr = 1e-08
I0111 03:11:27.456717  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.8779 > 20) by scale factor 0.669391
I0111 03:11:43.046630  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.961 > 20) by scale factor 0.770386
I0111 03:11:51.586388  4932 solver.cpp:240] Iteration 57200, loss = 0.101656
I0111 03:11:51.586436  4932 solver.cpp:255]     Train net output #0: loss = 0.00844345 (* 1 = 0.00844345 loss)
I0111 03:11:51.586448  4932 solver.cpp:631] Iteration 57200, lr = 1e-08
I0111 03:11:56.365149  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9641 > 20) by scale factor 0.910576
I0111 03:12:36.048663  4932 solver.cpp:240] Iteration 57220, loss = 0.0396222
I0111 03:12:36.048755  4932 solver.cpp:255]     Train net output #0: loss = 0.00178468 (* 1 = 0.00178468 loss)
I0111 03:12:36.048768  4932 solver.cpp:631] Iteration 57220, lr = 1e-08
I0111 03:12:47.480823  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3179 > 20) by scale factor 0.857709
I0111 03:12:54.138351  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2244 > 20) by scale factor 0.942311
I0111 03:13:20.429297  4932 solver.cpp:240] Iteration 57240, loss = 0.113712
I0111 03:13:20.429392  4932 solver.cpp:255]     Train net output #0: loss = 0.00699561 (* 1 = 0.00699561 loss)
I0111 03:13:20.429404  4932 solver.cpp:631] Iteration 57240, lr = 1e-08
I0111 03:13:22.987531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1376 > 20) by scale factor 0.946179
I0111 03:13:27.427897  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4651 > 20) by scale factor 0.728197
I0111 03:14:04.808459  4932 solver.cpp:240] Iteration 57260, loss = 0.0808778
I0111 03:14:04.808543  4932 solver.cpp:255]     Train net output #0: loss = 0.0362134 (* 1 = 0.0362134 loss)
I0111 03:14:04.808555  4932 solver.cpp:631] Iteration 57260, lr = 1e-08
I0111 03:14:49.181242  4932 solver.cpp:240] Iteration 57280, loss = 0.0568527
I0111 03:14:49.181318  4932 solver.cpp:255]     Train net output #0: loss = 0.0384054 (* 1 = 0.0384054 loss)
I0111 03:14:49.181329  4932 solver.cpp:631] Iteration 57280, lr = 1e-08
I0111 03:15:11.712030  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7506 > 20) by scale factor 0.879099
I0111 03:15:25.028654  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9506 > 20) by scale factor 0.954626
I0111 03:15:33.564577  4932 solver.cpp:240] Iteration 57300, loss = 0.0724645
I0111 03:15:33.564620  4932 solver.cpp:255]     Train net output #0: loss = 0.00761241 (* 1 = 0.00761241 loss)
I0111 03:15:33.564631  4932 solver.cpp:631] Iteration 57300, lr = 1e-08
I0111 03:16:00.535580  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.0216 > 20) by scale factor 0.624579
I0111 03:16:17.950721  4932 solver.cpp:240] Iteration 57320, loss = 0.0893485
I0111 03:16:17.950758  4932 solver.cpp:255]     Train net output #0: loss = 0.00406892 (* 1 = 0.00406892 loss)
I0111 03:16:17.950767  4932 solver.cpp:631] Iteration 57320, lr = 1e-08
I0111 03:17:02.492844  4932 solver.cpp:240] Iteration 57340, loss = 0.0218143
I0111 03:17:02.492924  4932 solver.cpp:255]     Train net output #0: loss = 0.0450475 (* 1 = 0.0450475 loss)
I0111 03:17:02.492935  4932 solver.cpp:631] Iteration 57340, lr = 1e-08
I0111 03:17:46.928133  4932 solver.cpp:240] Iteration 57360, loss = 0.0627904
I0111 03:17:46.928217  4932 solver.cpp:255]     Train net output #0: loss = 0.0600638 (* 1 = 0.0600638 loss)
I0111 03:17:46.928228  4932 solver.cpp:631] Iteration 57360, lr = 1e-08
I0111 03:17:53.921803  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5795 > 20) by scale factor 0.752458
I0111 03:18:02.803275  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6274 > 20) by scale factor 0.812102
I0111 03:18:05.024240  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7421 > 20) by scale factor 0.776936
I0111 03:18:31.321328  4932 solver.cpp:240] Iteration 57380, loss = 0.0940756
I0111 03:18:31.321437  4932 solver.cpp:255]     Train net output #0: loss = 0.00939553 (* 1 = 0.00939553 loss)
I0111 03:18:31.321454  4932 solver.cpp:631] Iteration 57380, lr = 1e-08
I0111 03:18:36.099447  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5912 > 20) by scale factor 0.926302
I0111 03:19:16.059562  4932 solver.cpp:240] Iteration 57400, loss = 0.0536627
I0111 03:19:16.059672  4932 solver.cpp:255]     Train net output #0: loss = 0.0557257 (* 1 = 0.0557257 loss)
I0111 03:19:16.059689  4932 solver.cpp:631] Iteration 57400, lr = 1e-08
I0111 03:19:29.773033  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8555 > 20) by scale factor 0.915101
I0111 03:19:31.996233  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2283 > 20) by scale factor 0.899753
I0111 03:19:51.969930  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8831 > 20) by scale factor 0.913949
I0111 03:20:00.604475  4932 solver.cpp:240] Iteration 57420, loss = 0.0884203
I0111 03:20:00.604512  4932 solver.cpp:255]     Train net output #0: loss = 0.00480138 (* 1 = 0.00480138 loss)
I0111 03:20:00.604521  4932 solver.cpp:631] Iteration 57420, lr = 1e-08
I0111 03:20:09.821609  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5831 > 20) by scale factor 0.971672
I0111 03:20:38.672649  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3722 > 20) by scale factor 0.820606
I0111 03:20:44.987561  4932 solver.cpp:240] Iteration 57440, loss = 0.078532
I0111 03:20:44.987591  4932 solver.cpp:255]     Train net output #0: loss = 0.149093 (* 1 = 0.149093 loss)
I0111 03:20:44.987599  4932 solver.cpp:631] Iteration 57440, lr = 1e-08
I0111 03:21:03.074501  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.341 > 20) by scale factor 0.895217
I0111 03:21:27.484756  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1658 > 20) by scale factor 0.90229
I0111 03:21:29.367369  4932 solver.cpp:240] Iteration 57460, loss = 0.0736103
I0111 03:21:29.367408  4932 solver.cpp:255]     Train net output #0: loss = 0.00373792 (* 1 = 0.00373792 loss)
I0111 03:21:29.367418  4932 solver.cpp:631] Iteration 57460, lr = 1e-08
I0111 03:21:54.113286  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5936 > 20) by scale factor 0.971177
I0111 03:22:13.748359  4932 solver.cpp:240] Iteration 57480, loss = 0.0780153
I0111 03:22:13.748437  4932 solver.cpp:255]     Train net output #0: loss = 0.00176142 (* 1 = 0.00176142 loss)
I0111 03:22:13.748448  4932 solver.cpp:631] Iteration 57480, lr = 1e-08
I0111 03:22:36.275226  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2153 > 20) by scale factor 0.8615
I0111 03:22:58.217367  4932 solver.cpp:240] Iteration 57500, loss = 0.0459746
I0111 03:22:58.217469  4932 solver.cpp:255]     Train net output #0: loss = 0.0604113 (* 1 = 0.0604113 loss)
I0111 03:22:58.217481  4932 solver.cpp:631] Iteration 57500, lr = 1e-08
I0111 03:23:25.179342  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.607 > 20) by scale factor 0.653446
I0111 03:23:42.592948  4932 solver.cpp:240] Iteration 57520, loss = 0.0911423
I0111 03:23:42.593037  4932 solver.cpp:255]     Train net output #0: loss = 0.0142977 (* 1 = 0.0142977 loss)
I0111 03:23:42.593050  4932 solver.cpp:631] Iteration 57520, lr = 1e-08
I0111 03:23:47.368821  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4874 > 20) by scale factor 0.889389
I0111 03:24:22.877459  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7597 > 20) by scale factor 0.963404
I0111 03:24:26.975576  4932 solver.cpp:240] Iteration 57540, loss = 0.0806366
I0111 03:24:26.975615  4932 solver.cpp:255]     Train net output #0: loss = 0.0563421 (* 1 = 0.0563421 loss)
I0111 03:24:26.975625  4932 solver.cpp:631] Iteration 57540, lr = 1e-08
I0111 03:25:07.261548  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5259 > 20) by scale factor 0.887866
I0111 03:25:11.362018  4932 solver.cpp:240] Iteration 57560, loss = 0.0412064
I0111 03:25:11.362057  4932 solver.cpp:255]     Train net output #0: loss = 0.0587186 (* 1 = 0.0587186 loss)
I0111 03:25:11.362066  4932 solver.cpp:631] Iteration 57560, lr = 1e-08
I0111 03:25:56.005224  4932 solver.cpp:240] Iteration 57580, loss = 0.0804841
I0111 03:25:56.005314  4932 solver.cpp:255]     Train net output #0: loss = 0.24568 (* 1 = 0.24568 loss)
I0111 03:25:56.005326  4932 solver.cpp:631] Iteration 57580, lr = 1e-08
I0111 03:26:38.829582  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8887 > 20) by scale factor 0.873794
I0111 03:26:40.712555  4932 solver.cpp:240] Iteration 57600, loss = 0.0583838
I0111 03:26:40.712596  4932 solver.cpp:255]     Train net output #0: loss = 0.196614 (* 1 = 0.196614 loss)
I0111 03:26:40.712606  4932 solver.cpp:631] Iteration 57600, lr = 1e-08
I0111 03:27:01.024320  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0649 > 20) by scale factor 0.906417
I0111 03:27:25.257300  4932 solver.cpp:240] Iteration 57620, loss = 0.0749337
I0111 03:27:25.257392  4932 solver.cpp:255]     Train net output #0: loss = 0.0549092 (* 1 = 0.0549092 loss)
I0111 03:27:25.257405  4932 solver.cpp:631] Iteration 57620, lr = 1e-08
I0111 03:28:01.315352  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5545 > 20) by scale factor 0.725834
I0111 03:28:09.855746  4932 solver.cpp:240] Iteration 57640, loss = 0.100989
I0111 03:28:09.855780  4932 solver.cpp:255]     Train net output #0: loss = 0.194437 (* 1 = 0.194437 loss)
I0111 03:28:09.855790  4932 solver.cpp:631] Iteration 57640, lr = 1e-08
I0111 03:28:39.034273  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5415 > 20) by scale factor 0.78304
I0111 03:28:54.232308  4932 solver.cpp:240] Iteration 57660, loss = 0.0535165
I0111 03:28:54.232353  4932 solver.cpp:255]     Train net output #0: loss = 0.00308154 (* 1 = 0.00308154 loss)
I0111 03:28:54.232365  4932 solver.cpp:631] Iteration 57660, lr = 1e-08
I0111 03:29:21.202277  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4586 > 20) by scale factor 0.852567
I0111 03:29:38.615041  4932 solver.cpp:240] Iteration 57680, loss = 0.0603507
I0111 03:29:38.615078  4932 solver.cpp:255]     Train net output #0: loss = 0.0470661 (* 1 = 0.0470661 loss)
I0111 03:29:38.615087  4932 solver.cpp:631] Iteration 57680, lr = 1e-08
I0111 03:29:58.920444  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6444 > 20) by scale factor 0.924025
I0111 03:30:07.799476  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1928 > 20) by scale factor 0.990451
I0111 03:30:22.989044  4932 solver.cpp:240] Iteration 57700, loss = 0.0811965
I0111 03:30:22.989084  4932 solver.cpp:255]     Train net output #0: loss = 0.00514842 (* 1 = 0.00514842 loss)
I0111 03:30:22.989092  4932 solver.cpp:631] Iteration 57700, lr = 1e-08
I0111 03:30:54.399842  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.3267 > 20) by scale factor 0.582636
I0111 03:31:03.281690  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.608 > 20) by scale factor 0.884643
I0111 03:31:07.382580  4932 solver.cpp:240] Iteration 57720, loss = 0.0587634
I0111 03:31:07.382617  4932 solver.cpp:255]     Train net output #0: loss = 0.00479847 (* 1 = 0.00479847 loss)
I0111 03:31:07.382627  4932 solver.cpp:631] Iteration 57720, lr = 1e-08
I0111 03:31:09.939430  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6635 > 20) by scale factor 0.967891
I0111 03:31:14.379106  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1348 > 20) by scale factor 0.946306
I0111 03:31:30.024163  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8986 > 20) by scale factor 0.913302
I0111 03:31:51.877424  4932 solver.cpp:240] Iteration 57740, loss = 0.0465972
I0111 03:31:51.877463  4932 solver.cpp:255]     Train net output #0: loss = 0.00980894 (* 1 = 0.00980894 loss)
I0111 03:31:51.877472  4932 solver.cpp:631] Iteration 57740, lr = 1e-08
I0111 03:31:54.433749  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5301 > 20) by scale factor 0.974182
I0111 03:32:36.339051  4932 solver.cpp:240] Iteration 57760, loss = 0.0564651
I0111 03:32:36.339140  4932 solver.cpp:255]     Train net output #0: loss = 0.0339504 (* 1 = 0.0339504 loss)
I0111 03:32:36.339154  4932 solver.cpp:631] Iteration 57760, lr = 1e-08
I0111 03:32:45.692543  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1236 > 20) by scale factor 0.904013
I0111 03:33:12.317891  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9445 > 20) by scale factor 0.954903
I0111 03:33:20.856992  4932 solver.cpp:240] Iteration 57780, loss = 0.0458652
I0111 03:33:20.857038  4932 solver.cpp:255]     Train net output #0: loss = 0.0354769 (* 1 = 0.0354769 loss)
I0111 03:33:20.857050  4932 solver.cpp:631] Iteration 57780, lr = 1e-08
I0111 03:34:05.232573  4932 solver.cpp:240] Iteration 57800, loss = 0.0571034
I0111 03:34:05.232669  4932 solver.cpp:255]     Train net output #0: loss = 0.144184 (* 1 = 0.144184 loss)
I0111 03:34:05.232682  4932 solver.cpp:631] Iteration 57800, lr = 1e-08
I0111 03:34:12.227916  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2847 > 20) by scale factor 0.939643
I0111 03:34:18.886062  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.263 > 20) by scale factor 0.987019
I0111 03:34:49.906515  4932 solver.cpp:240] Iteration 57820, loss = 0.044237
I0111 03:34:49.906599  4932 solver.cpp:255]     Train net output #0: loss = 0.0126576 (* 1 = 0.0126576 loss)
I0111 03:34:49.906610  4932 solver.cpp:631] Iteration 57820, lr = 1e-08
I0111 03:34:56.898736  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0407 > 20) by scale factor 0.950538
I0111 03:35:34.718030  4932 solver.cpp:240] Iteration 57840, loss = 0.0502401
I0111 03:35:34.718130  4932 solver.cpp:255]     Train net output #0: loss = 0.0976459 (* 1 = 0.0976459 loss)
I0111 03:35:34.718143  4932 solver.cpp:631] Iteration 57840, lr = 1e-08
I0111 03:36:12.773599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0744 > 20) by scale factor 0.797625
I0111 03:36:19.293527  4932 solver.cpp:240] Iteration 57860, loss = 0.0475327
I0111 03:36:19.293572  4932 solver.cpp:255]     Train net output #0: loss = 0.0176704 (* 1 = 0.0176704 loss)
I0111 03:36:19.293584  4932 solver.cpp:631] Iteration 57860, lr = 1e-08
I0111 03:36:44.040119  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8395 > 20) by scale factor 0.693492
I0111 03:37:03.868369  4932 solver.cpp:240] Iteration 57880, loss = 0.085533
I0111 03:37:03.868417  4932 solver.cpp:255]     Train net output #0: loss = 0.000961996 (* 1 = 0.000961996 loss)
I0111 03:37:03.868427  4932 solver.cpp:631] Iteration 57880, lr = 1e-08
I0111 03:37:28.609540  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2811 > 20) by scale factor 0.823686
I0111 03:37:48.242086  4932 solver.cpp:240] Iteration 57900, loss = 0.0500914
I0111 03:37:48.242126  4932 solver.cpp:255]     Train net output #0: loss = 0.0649171 (* 1 = 0.0649171 loss)
I0111 03:37:48.242135  4932 solver.cpp:631] Iteration 57900, lr = 1e-08
I0111 03:37:53.021939  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5738 > 20) by scale factor 0.782051
I0111 03:38:15.213903  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4584 > 20) by scale factor 0.852573
I0111 03:38:32.625007  4932 solver.cpp:240] Iteration 57920, loss = 0.0902616
I0111 03:38:32.625046  4932 solver.cpp:255]     Train net output #0: loss = 0.000913807 (* 1 = 0.000913807 loss)
I0111 03:38:32.625054  4932 solver.cpp:631] Iteration 57920, lr = 1e-08
I0111 03:39:06.251425  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9131 > 20) by scale factor 0.836362
I0111 03:39:17.009080  4932 solver.cpp:240] Iteration 57940, loss = 0.0927188
I0111 03:39:17.009127  4932 solver.cpp:255]     Train net output #0: loss = 0.0128528 (* 1 = 0.0128528 loss)
I0111 03:39:17.009140  4932 solver.cpp:631] Iteration 57940, lr = 1e-08
I0111 03:39:21.787542  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.731 > 20) by scale factor 0.777274
I0111 03:40:01.387267  4932 solver.cpp:240] Iteration 57960, loss = 0.0566886
I0111 03:40:01.387364  4932 solver.cpp:255]     Train net output #0: loss = 0.0382746 (* 1 = 0.0382746 loss)
I0111 03:40:01.387377  4932 solver.cpp:631] Iteration 57960, lr = 1e-08
I0111 03:40:41.669250  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4952 > 20) by scale factor 0.97584
I0111 03:40:45.771456  4932 solver.cpp:240] Iteration 57980, loss = 0.0749778
I0111 03:40:45.771495  4932 solver.cpp:255]     Train net output #0: loss = 0.189023 (* 1 = 0.189023 loss)
I0111 03:40:45.771504  4932 solver.cpp:631] Iteration 57980, lr = 1e-08
I0111 03:40:57.209895  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0348 > 20) by scale factor 0.950805
I0111 03:40:59.430593  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5299 > 20) by scale factor 0.887709
I0111 03:41:28.288185  4932 solver.cpp:424] Iteration 58000, Testing net (#0)
I0111 03:42:20.584560  4932 solver.cpp:481]     Test net output #0: accuracy = 0.844211
I0111 03:42:20.584662  4932 solver.cpp:481]     Test net output #1: loss = 0.769189 (* 1 = 0.769189 loss)
I0111 03:42:22.451294  4932 solver.cpp:240] Iteration 58000, loss = 0.0664439
I0111 03:42:22.451328  4932 solver.cpp:255]     Train net output #0: loss = 0.016987 (* 1 = 0.016987 loss)
I0111 03:42:22.451337  4932 solver.cpp:631] Iteration 58000, lr = 1e-08
I0111 03:43:07.470017  4932 solver.cpp:240] Iteration 58020, loss = 0.0556157
I0111 03:43:07.470109  4932 solver.cpp:255]     Train net output #0: loss = 0.00299246 (* 1 = 0.00299246 loss)
I0111 03:43:07.470124  4932 solver.cpp:631] Iteration 58020, lr = 1e-08
I0111 03:43:10.028983  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2259 > 20) by scale factor 0.825561
I0111 03:43:12.250599  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0039 > 20) by scale factor 0.90893
I0111 03:43:16.689437  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3612 > 20) by scale factor 0.856119
I0111 03:43:51.875254  4932 solver.cpp:240] Iteration 58040, loss = 0.082102
I0111 03:43:51.875331  4932 solver.cpp:255]     Train net output #0: loss = 0.0391089 (* 1 = 0.0391089 loss)
I0111 03:43:51.875341  4932 solver.cpp:631] Iteration 58040, lr = 1e-08
I0111 03:44:01.095849  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1327 > 20) by scale factor 0.795777
I0111 03:44:36.838769  4932 solver.cpp:240] Iteration 58060, loss = 0.0393499
I0111 03:44:36.838871  4932 solver.cpp:255]     Train net output #0: loss = 0.00499914 (* 1 = 0.00499914 loss)
I0111 03:44:36.838882  4932 solver.cpp:631] Iteration 58060, lr = 1e-08
I0111 03:45:21.508885  4932 solver.cpp:240] Iteration 58080, loss = 0.0361294
I0111 03:45:21.508978  4932 solver.cpp:255]     Train net output #0: loss = 0.00423158 (* 1 = 0.00423158 loss)
I0111 03:45:21.508993  4932 solver.cpp:631] Iteration 58080, lr = 1e-08
I0111 03:46:05.899890  4932 solver.cpp:240] Iteration 58100, loss = 0.0778398
I0111 03:46:05.899981  4932 solver.cpp:255]     Train net output #0: loss = 0.135855 (* 1 = 0.135855 loss)
I0111 03:46:05.899992  4932 solver.cpp:631] Iteration 58100, lr = 1e-08
I0111 03:46:06.238943  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5904 > 20) by scale factor 0.971326
I0111 03:46:50.289288  4932 solver.cpp:240] Iteration 58120, loss = 0.0351021
I0111 03:46:50.289384  4932 solver.cpp:255]     Train net output #0: loss = 0.0103505 (* 1 = 0.0103505 loss)
I0111 03:46:50.289397  4932 solver.cpp:631] Iteration 58120, lr = 1e-08
I0111 03:47:28.358947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9526 > 20) by scale factor 0.80152
I0111 03:47:34.679527  4932 solver.cpp:240] Iteration 58140, loss = 0.0441896
I0111 03:47:34.679569  4932 solver.cpp:255]     Train net output #0: loss = 0.0577317 (* 1 = 0.0577317 loss)
I0111 03:47:34.679577  4932 solver.cpp:631] Iteration 58140, lr = 1e-08
I0111 03:47:41.677048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9764 > 20) by scale factor 0.834155
I0111 03:48:19.062695  4932 solver.cpp:240] Iteration 58160, loss = 0.0913207
I0111 03:48:19.062762  4932 solver.cpp:255]     Train net output #0: loss = 0.263078 (* 1 = 0.263078 loss)
I0111 03:48:19.062772  4932 solver.cpp:631] Iteration 58160, lr = 1e-08
I0111 03:48:19.402043  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7094 > 20) by scale factor 0.843546
I0111 03:49:03.459262  4932 solver.cpp:240] Iteration 58180, loss = 0.0455304
I0111 03:49:03.459352  4932 solver.cpp:255]     Train net output #0: loss = 0.165309 (* 1 = 0.165309 loss)
I0111 03:49:03.459364  4932 solver.cpp:631] Iteration 58180, lr = 1e-08
I0111 03:49:06.020534  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.045 > 20) by scale factor 0.665669
I0111 03:49:47.939733  4932 solver.cpp:240] Iteration 58200, loss = 0.0755435
I0111 03:49:47.939831  4932 solver.cpp:255]     Train net output #0: loss = 0.0129333 (* 1 = 0.0129333 loss)
I0111 03:49:47.939842  4932 solver.cpp:631] Iteration 58200, lr = 1e-08
I0111 03:49:50.497565  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0616 > 20) by scale factor 0.867241
I0111 03:49:54.941620  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8435 > 20) by scale factor 0.805039
I0111 03:49:59.681202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1754 > 20) by scale factor 0.862985
I0111 03:50:32.822599  4932 solver.cpp:240] Iteration 58220, loss = 0.0684252
I0111 03:50:32.822695  4932 solver.cpp:255]     Train net output #0: loss = 0.0428108 (* 1 = 0.0428108 loss)
I0111 03:50:32.822707  4932 solver.cpp:631] Iteration 58220, lr = 1e-08
I0111 03:51:17.246248  4932 solver.cpp:240] Iteration 58240, loss = 0.0588934
I0111 03:51:17.246345  4932 solver.cpp:255]     Train net output #0: loss = 0.00768743 (* 1 = 0.00768743 loss)
I0111 03:51:17.246357  4932 solver.cpp:631] Iteration 58240, lr = 1e-08
I0111 03:51:24.244282  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7306 > 20) by scale factor 0.920361
I0111 03:52:01.635653  4932 solver.cpp:240] Iteration 58260, loss = 0.0681123
I0111 03:52:01.635759  4932 solver.cpp:255]     Train net output #0: loss = 0.00578949 (* 1 = 0.00578949 loss)
I0111 03:52:01.635771  4932 solver.cpp:631] Iteration 58260, lr = 1e-08
I0111 03:52:46.018901  4932 solver.cpp:240] Iteration 58280, loss = 0.0536119
I0111 03:52:46.019016  4932 solver.cpp:255]     Train net output #0: loss = 0.033267 (* 1 = 0.033267 loss)
I0111 03:52:46.019032  4932 solver.cpp:631] Iteration 58280, lr = 1e-08
I0111 03:53:30.409449  4932 solver.cpp:240] Iteration 58300, loss = 0.042484
I0111 03:53:30.409548  4932 solver.cpp:255]     Train net output #0: loss = 0.155321 (* 1 = 0.155321 loss)
I0111 03:53:30.409562  4932 solver.cpp:631] Iteration 58300, lr = 1e-08
I0111 03:54:14.808874  4932 solver.cpp:240] Iteration 58320, loss = 0.0392824
I0111 03:54:14.808971  4932 solver.cpp:255]     Train net output #0: loss = 0.049565 (* 1 = 0.049565 loss)
I0111 03:54:14.808984  4932 solver.cpp:631] Iteration 58320, lr = 1e-08
I0111 03:54:24.025398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.182 > 20) by scale factor 0.990982
I0111 03:54:28.465840  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2849 > 20) by scale factor 0.985955
I0111 03:54:59.562602  4932 solver.cpp:240] Iteration 58340, loss = 0.0832318
I0111 03:54:59.562682  4932 solver.cpp:255]     Train net output #0: loss = 0.126605 (* 1 = 0.126605 loss)
I0111 03:54:59.562692  4932 solver.cpp:631] Iteration 58340, lr = 1e-08
I0111 03:55:43.955904  4932 solver.cpp:240] Iteration 58360, loss = 0.0390716
I0111 03:55:43.956006  4932 solver.cpp:255]     Train net output #0: loss = 0.0963982 (* 1 = 0.0963982 loss)
I0111 03:55:43.956020  4932 solver.cpp:631] Iteration 58360, lr = 1e-08
I0111 03:56:26.691889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9433 > 20) by scale factor 0.871714
I0111 03:56:28.574995  4932 solver.cpp:240] Iteration 58380, loss = 0.0679359
I0111 03:56:28.575031  4932 solver.cpp:255]     Train net output #0: loss = 0.0287883 (* 1 = 0.0287883 loss)
I0111 03:56:28.575039  4932 solver.cpp:631] Iteration 58380, lr = 1e-08
I0111 03:57:12.972574  4932 solver.cpp:240] Iteration 58400, loss = 0.0421407
I0111 03:57:12.972673  4932 solver.cpp:255]     Train net output #0: loss = 0.0284899 (* 1 = 0.0284899 loss)
I0111 03:57:12.972687  4932 solver.cpp:631] Iteration 58400, lr = 1e-08
I0111 03:57:57.355105  4932 solver.cpp:240] Iteration 58420, loss = 0.0532626
I0111 03:57:57.355197  4932 solver.cpp:255]     Train net output #0: loss = 0.174824 (* 1 = 0.174824 loss)
I0111 03:57:57.355209  4932 solver.cpp:631] Iteration 58420, lr = 1e-08
I0111 03:58:11.294837  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6563 > 20) by scale factor 0.697927
I0111 03:58:29.049829  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4627 > 20) by scale factor 0.890363
I0111 03:58:40.149734  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2685 > 20) by scale factor 0.940359
I0111 03:58:42.120899  4932 solver.cpp:240] Iteration 58440, loss = 0.113845
I0111 03:58:42.120940  4932 solver.cpp:255]     Train net output #0: loss = 0.0289638 (* 1 = 0.0289638 loss)
I0111 03:58:42.120950  4932 solver.cpp:631] Iteration 58440, lr = 1e-08
I0111 03:59:26.641603  4932 solver.cpp:240] Iteration 58460, loss = 0.0486022
I0111 03:59:26.641695  4932 solver.cpp:255]     Train net output #0: loss = 0.000832135 (* 1 = 0.000832135 loss)
I0111 03:59:26.641708  4932 solver.cpp:631] Iteration 58460, lr = 1e-08
I0111 03:59:40.301245  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8958 > 20) by scale factor 0.913416
I0111 03:59:49.181241  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7374 > 20) by scale factor 0.96444
I0111 03:59:53.621785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7645 > 20) by scale factor 0.878561
I0111 04:00:11.040170  4932 solver.cpp:240] Iteration 58480, loss = 0.087792
I0111 04:00:11.040252  4932 solver.cpp:255]     Train net output #0: loss = 0.0157499 (* 1 = 0.0157499 loss)
I0111 04:00:11.040263  4932 solver.cpp:631] Iteration 58480, lr = 1e-08
I0111 04:00:44.674391  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6185 > 20) by scale factor 0.884231
I0111 04:00:55.433785  4932 solver.cpp:240] Iteration 58500, loss = 0.070731
I0111 04:00:55.433820  4932 solver.cpp:255]     Train net output #0: loss = 0.0303892 (* 1 = 0.0303892 loss)
I0111 04:00:55.433830  4932 solver.cpp:631] Iteration 58500, lr = 1e-08
I0111 04:01:17.969261  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.229 > 20) by scale factor 0.942107
I0111 04:01:40.048786  4932 solver.cpp:240] Iteration 58520, loss = 0.0641283
I0111 04:01:40.048830  4932 solver.cpp:255]     Train net output #0: loss = 0.00762896 (* 1 = 0.00762896 loss)
I0111 04:01:40.048841  4932 solver.cpp:631] Iteration 58520, lr = 1e-08
I0111 04:02:04.793957  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5481 > 20) by scale factor 0.973324
I0111 04:02:16.051816  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3185 > 20) by scale factor 0.896116
I0111 04:02:24.590476  4932 solver.cpp:240] Iteration 58540, loss = 0.0695946
I0111 04:02:24.590522  4932 solver.cpp:255]     Train net output #0: loss = 0.0436595 (* 1 = 0.0436595 loss)
I0111 04:02:24.590533  4932 solver.cpp:631] Iteration 58540, lr = 1e-08
I0111 04:02:29.372766  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6414 > 20) by scale factor 0.924153
I0111 04:02:42.690497  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9229 > 20) by scale factor 0.836019
I0111 04:02:49.351047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6624 > 20) by scale factor 0.845222
I0111 04:02:58.257051  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4399 > 20) by scale factor 0.932842
I0111 04:03:09.022814  4932 solver.cpp:240] Iteration 58560, loss = 0.0955924
I0111 04:03:09.022863  4932 solver.cpp:255]     Train net output #0: loss = 0.00846773 (* 1 = 0.00846773 loss)
I0111 04:03:09.022876  4932 solver.cpp:631] Iteration 58560, lr = 1e-08
I0111 04:03:22.682055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9125 > 20) by scale factor 0.646987
I0111 04:03:31.749146  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5207 > 20) by scale factor 0.888073
I0111 04:03:36.190254  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9473 > 20) by scale factor 0.871564
I0111 04:03:42.846607  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6741 > 20) by scale factor 0.882064
I0111 04:03:45.067819  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3388 > 20) by scale factor 0.895302
I0111 04:03:53.606778  4932 solver.cpp:240] Iteration 58580, loss = 0.114144
I0111 04:03:53.606837  4932 solver.cpp:255]     Train net output #0: loss = 0.000895469 (* 1 = 0.000895469 loss)
I0111 04:03:53.606849  4932 solver.cpp:631] Iteration 58580, lr = 1e-08
I0111 04:04:20.570626  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4622 > 20) by scale factor 0.852436
I0111 04:04:38.086457  4932 solver.cpp:240] Iteration 58600, loss = 0.0492762
I0111 04:04:38.086550  4932 solver.cpp:255]     Train net output #0: loss = 0.019 (* 1 = 0.019 loss)
I0111 04:04:38.086562  4932 solver.cpp:631] Iteration 58600, lr = 1e-08
I0111 04:04:47.300621  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1334 > 20) by scale factor 0.903614
I0111 04:04:58.397698  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3218 > 20) by scale factor 0.857565
I0111 04:05:22.467190  4932 solver.cpp:240] Iteration 58620, loss = 0.0628356
I0111 04:05:22.467277  4932 solver.cpp:255]     Train net output #0: loss = 0.0953199 (* 1 = 0.0953199 loss)
I0111 04:05:22.467288  4932 solver.cpp:631] Iteration 58620, lr = 1e-08
I0111 04:05:22.806567  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6292 > 20) by scale factor 0.924677
I0111 04:06:00.562834  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5594 > 20) by scale factor 0.927669
I0111 04:06:06.884402  4932 solver.cpp:240] Iteration 58640, loss = 0.0750368
I0111 04:06:06.884441  4932 solver.cpp:255]     Train net output #0: loss = 0.0187691 (* 1 = 0.0187691 loss)
I0111 04:06:06.884451  4932 solver.cpp:631] Iteration 58640, lr = 1e-08
I0111 04:06:29.478924  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7281 > 20) by scale factor 0.696182
I0111 04:06:51.330286  4932 solver.cpp:240] Iteration 58660, loss = 0.0349588
I0111 04:06:51.330380  4932 solver.cpp:255]     Train net output #0: loss = 0.0237163 (* 1 = 0.0237163 loss)
I0111 04:06:51.330392  4932 solver.cpp:631] Iteration 58660, lr = 1e-08
I0111 04:07:07.201011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6436 > 20) by scale factor 0.81157
I0111 04:07:35.712829  4932 solver.cpp:240] Iteration 58680, loss = 0.0750109
I0111 04:07:35.712916  4932 solver.cpp:255]     Train net output #0: loss = 0.0633609 (* 1 = 0.0633609 loss)
I0111 04:07:35.712929  4932 solver.cpp:631] Iteration 58680, lr = 1e-08
I0111 04:08:00.457134  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2282 > 20) by scale factor 0.899757
I0111 04:08:20.477620  4932 solver.cpp:240] Iteration 58700, loss = 0.0569904
I0111 04:08:20.477722  4932 solver.cpp:255]     Train net output #0: loss = 0.0557323 (* 1 = 0.0557323 loss)
I0111 04:08:20.477735  4932 solver.cpp:631] Iteration 58700, lr = 1e-08
I0111 04:08:40.785626  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6023 > 20) by scale factor 0.751815
I0111 04:08:58.606356  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8867 > 20) by scale factor 0.957549
I0111 04:09:04.926848  4932 solver.cpp:240] Iteration 58720, loss = 0.0703196
I0111 04:09:04.926888  4932 solver.cpp:255]     Train net output #0: loss = 0.00799713 (* 1 = 0.00799713 loss)
I0111 04:09:04.926898  4932 solver.cpp:631] Iteration 58720, lr = 1e-08
I0111 04:09:20.798281  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2124 > 20) by scale factor 0.861609
I0111 04:09:38.551498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8306 > 20) by scale factor 0.960127
I0111 04:09:40.773088  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9985 > 20) by scale factor 0.952451
I0111 04:09:49.312474  4932 solver.cpp:240] Iteration 58740, loss = 0.0764789
I0111 04:09:49.312515  4932 solver.cpp:255]     Train net output #0: loss = 0.111972 (* 1 = 0.111972 loss)
I0111 04:09:49.312531  4932 solver.cpp:631] Iteration 58740, lr = 1e-08
I0111 04:09:49.651824  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5982 > 20) by scale factor 0.75193
I0111 04:10:34.231356  4932 solver.cpp:240] Iteration 58760, loss = 0.0272882
I0111 04:10:34.231434  4932 solver.cpp:255]     Train net output #0: loss = 0.0152282 (* 1 = 0.0152282 loss)
I0111 04:10:34.231446  4932 solver.cpp:631] Iteration 58760, lr = 1e-08
I0111 04:10:50.102972  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0582 > 20) by scale factor 0.86737
I0111 04:11:08.038832  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4738 > 20) by scale factor 0.889925
I0111 04:11:18.794859  4932 solver.cpp:240] Iteration 58780, loss = 0.0988522
I0111 04:11:18.794906  4932 solver.cpp:255]     Train net output #0: loss = 0.0705156 (* 1 = 0.0705156 loss)
I0111 04:11:18.794917  4932 solver.cpp:631] Iteration 58780, lr = 1e-08
I0111 04:11:39.100287  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5627 > 20) by scale factor 0.927529
I0111 04:12:03.375730  4932 solver.cpp:240] Iteration 58800, loss = 0.0764091
I0111 04:12:03.375768  4932 solver.cpp:255]     Train net output #0: loss = 0.0320381 (* 1 = 0.0320381 loss)
I0111 04:12:03.375778  4932 solver.cpp:631] Iteration 58800, lr = 1e-08
I0111 04:12:14.812667  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3936 > 20) by scale factor 0.980698
I0111 04:12:23.704367  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0373 > 20) by scale factor 0.832042
I0111 04:12:34.803328  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0776 > 20) by scale factor 0.797526
I0111 04:12:37.024876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9572 > 20) by scale factor 0.954327
I0111 04:12:47.785203  4932 solver.cpp:240] Iteration 58820, loss = 0.0734181
I0111 04:12:47.785316  4932 solver.cpp:255]     Train net output #0: loss = 0.113954 (* 1 = 0.113954 loss)
I0111 04:12:47.785332  4932 solver.cpp:631] Iteration 58820, lr = 1e-08
I0111 04:13:01.438011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6922 > 20) by scale factor 0.778446
I0111 04:13:30.574527  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9151 > 20) by scale factor 0.743078
I0111 04:13:32.455461  4932 solver.cpp:240] Iteration 58840, loss = 0.090204
I0111 04:13:32.455497  4932 solver.cpp:255]     Train net output #0: loss = 0.0416315 (* 1 = 0.0416315 loss)
I0111 04:13:32.455507  4932 solver.cpp:631] Iteration 58840, lr = 1e-08
I0111 04:13:41.668265  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8051 > 20) by scale factor 0.961305
I0111 04:14:16.838520  4932 solver.cpp:240] Iteration 58860, loss = 0.0529979
I0111 04:14:16.838630  4932 solver.cpp:255]     Train net output #0: loss = 0.0277385 (* 1 = 0.0277385 loss)
I0111 04:14:16.838647  4932 solver.cpp:631] Iteration 58860, lr = 1e-08
I0111 04:14:28.284847  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0001 > 20) by scale factor 0.86956
I0111 04:14:34.942121  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0428 > 20) by scale factor 0.867949
I0111 04:14:48.512626  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6676 > 20) by scale factor 0.697652
I0111 04:15:01.490452  4932 solver.cpp:240] Iteration 58880, loss = 0.0813381
I0111 04:15:01.490484  4932 solver.cpp:255]     Train net output #0: loss = 0.005956 (* 1 = 0.005956 loss)
I0111 04:15:01.490494  4932 solver.cpp:631] Iteration 58880, lr = 1e-08
I0111 04:15:10.704953  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9434 > 20) by scale factor 0.871709
I0111 04:15:19.587340  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1485 > 20) by scale factor 0.686142
I0111 04:15:44.001317  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7233 > 20) by scale factor 0.965097
I0111 04:15:45.882113  4932 solver.cpp:240] Iteration 58900, loss = 0.0757735
I0111 04:15:45.882146  4932 solver.cpp:255]     Train net output #0: loss = 0.00581815 (* 1 = 0.00581815 loss)
I0111 04:15:45.882156  4932 solver.cpp:631] Iteration 58900, lr = 1e-08
I0111 04:16:30.280642  4932 solver.cpp:240] Iteration 58920, loss = 0.0559639
I0111 04:16:30.280733  4932 solver.cpp:255]     Train net output #0: loss = 0.123979 (* 1 = 0.123979 loss)
I0111 04:16:30.280746  4932 solver.cpp:631] Iteration 58920, lr = 1e-08
I0111 04:16:32.844503  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3387 > 20) by scale factor 0.759338
I0111 04:17:14.989435  4932 solver.cpp:240] Iteration 58940, loss = 0.0333365
I0111 04:17:14.989513  4932 solver.cpp:255]     Train net output #0: loss = 0.0116352 (* 1 = 0.0116352 loss)
I0111 04:17:14.989523  4932 solver.cpp:631] Iteration 58940, lr = 1e-08
I0111 04:17:19.765758  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2522 > 20) by scale factor 0.941079
I0111 04:17:33.085330  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1261 > 20) by scale factor 0.828976
I0111 04:17:46.403722  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8654 > 20) by scale factor 0.958525
I0111 04:17:59.377624  4932 solver.cpp:240] Iteration 58960, loss = 0.0530324
I0111 04:17:59.377678  4932 solver.cpp:255]     Train net output #0: loss = 0.00166315 (* 1 = 0.00166315 loss)
I0111 04:17:59.377691  4932 solver.cpp:631] Iteration 58960, lr = 1e-08
I0111 04:18:06.374471  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4235 > 20) by scale factor 0.933554
I0111 04:18:13.155055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1305 > 20) by scale factor 0.903729
I0111 04:18:22.033874  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0155 > 20) by scale factor 0.951677
I0111 04:18:43.881523  4932 solver.cpp:240] Iteration 58980, loss = 0.0879479
I0111 04:18:43.881561  4932 solver.cpp:255]     Train net output #0: loss = 0.257471 (* 1 = 0.257471 loss)
I0111 04:18:43.881570  4932 solver.cpp:631] Iteration 58980, lr = 1e-08
I0111 04:19:13.179447  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3671 > 20) by scale factor 0.89417
I0111 04:19:26.685142  4932 solver.cpp:424] Iteration 59000, Testing net (#0)
I0111 04:20:18.388661  4932 solver.cpp:481]     Test net output #0: accuracy = 0.838947
I0111 04:20:18.388777  4932 solver.cpp:481]     Test net output #1: loss = 0.746871 (* 1 = 0.746871 loss)
I0111 04:20:20.256573  4932 solver.cpp:240] Iteration 59000, loss = 0.074762
I0111 04:20:20.256610  4932 solver.cpp:255]     Train net output #0: loss = 0.00594864 (* 1 = 0.00594864 loss)
I0111 04:20:20.256620  4932 solver.cpp:631] Iteration 59000, lr = 1e-08
I0111 04:21:04.629259  4932 solver.cpp:240] Iteration 59020, loss = 0.0700927
I0111 04:21:04.629364  4932 solver.cpp:255]     Train net output #0: loss = 0.00185493 (* 1 = 0.00185493 loss)
I0111 04:21:04.629379  4932 solver.cpp:631] Iteration 59020, lr = 1e-08
I0111 04:21:07.188256  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2717 > 20) by scale factor 0.940215
I0111 04:21:13.843194  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0952 > 20) by scale factor 0.948085
I0111 04:21:31.595563  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.96 > 20) by scale factor 0.74184
I0111 04:21:49.008412  4932 solver.cpp:240] Iteration 59040, loss = 0.100417
I0111 04:21:49.008502  4932 solver.cpp:255]     Train net output #0: loss = 0.31761 (* 1 = 0.31761 loss)
I0111 04:21:49.008517  4932 solver.cpp:631] Iteration 59040, lr = 1e-08
I0111 04:22:13.815102  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7207 > 20) by scale factor 0.748484
I0111 04:22:33.443224  4932 solver.cpp:240] Iteration 59060, loss = 0.0763396
I0111 04:22:33.443315  4932 solver.cpp:255]     Train net output #0: loss = 0.15011 (* 1 = 0.15011 loss)
I0111 04:22:33.443326  4932 solver.cpp:631] Iteration 59060, lr = 1e-08
I0111 04:23:17.818817  4932 solver.cpp:240] Iteration 59080, loss = 0.0508257
I0111 04:23:17.818902  4932 solver.cpp:255]     Train net output #0: loss = 0.0177425 (* 1 = 0.0177425 loss)
I0111 04:23:17.818913  4932 solver.cpp:631] Iteration 59080, lr = 1e-08
I0111 04:23:42.559571  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4972 > 20) by scale factor 0.975744
I0111 04:24:02.193130  4932 solver.cpp:240] Iteration 59100, loss = 0.0299087
I0111 04:24:02.193214  4932 solver.cpp:255]     Train net output #0: loss = 0.0651013 (* 1 = 0.0651013 loss)
I0111 04:24:02.193228  4932 solver.cpp:631] Iteration 59100, lr = 1e-08
I0111 04:24:31.377759  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.2409 > 20) by scale factor 0.683974
I0111 04:24:38.038115  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5344 > 20) by scale factor 0.677177
I0111 04:24:46.576124  4932 solver.cpp:240] Iteration 59120, loss = 0.0790357
I0111 04:24:46.576170  4932 solver.cpp:255]     Train net output #0: loss = 0.00383585 (* 1 = 0.00383585 loss)
I0111 04:24:46.576181  4932 solver.cpp:631] Iteration 59120, lr = 1e-08
I0111 04:25:20.202298  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9398 > 20) by scale factor 0.646416
I0111 04:25:30.959806  4932 solver.cpp:240] Iteration 59140, loss = 0.0758403
I0111 04:25:30.959846  4932 solver.cpp:255]     Train net output #0: loss = 0.159299 (* 1 = 0.159299 loss)
I0111 04:25:30.959857  4932 solver.cpp:631] Iteration 59140, lr = 1e-08
I0111 04:26:15.330651  4932 solver.cpp:240] Iteration 59160, loss = 0.0440258
I0111 04:26:15.330745  4932 solver.cpp:255]     Train net output #0: loss = 0.0277302 (* 1 = 0.0277302 loss)
I0111 04:26:15.330759  4932 solver.cpp:631] Iteration 59160, lr = 1e-08
I0111 04:26:24.545531  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3168 > 20) by scale factor 0.857751
I0111 04:26:59.706713  4932 solver.cpp:240] Iteration 59180, loss = 0.0999086
I0111 04:26:59.706794  4932 solver.cpp:255]     Train net output #0: loss = 0.00227733 (* 1 = 0.00227733 loss)
I0111 04:26:59.706804  4932 solver.cpp:631] Iteration 59180, lr = 1e-08
I0111 04:27:44.083950  4932 solver.cpp:240] Iteration 59200, loss = 0.034662
I0111 04:27:44.084028  4932 solver.cpp:255]     Train net output #0: loss = 0.138807 (* 1 = 0.138807 loss)
I0111 04:27:44.084038  4932 solver.cpp:631] Iteration 59200, lr = 1e-08
I0111 04:28:28.458951  4932 solver.cpp:240] Iteration 59220, loss = 0.0446028
I0111 04:28:28.459025  4932 solver.cpp:255]     Train net output #0: loss = 0.0127775 (* 1 = 0.0127775 loss)
I0111 04:28:28.459036  4932 solver.cpp:631] Iteration 59220, lr = 1e-08
I0111 04:28:42.401309  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8967 > 20) by scale factor 0.873489
I0111 04:29:13.127550  4932 solver.cpp:240] Iteration 59240, loss = 0.0552262
I0111 04:29:13.127638  4932 solver.cpp:255]     Train net output #0: loss = 0.0206226 (* 1 = 0.0206226 loss)
I0111 04:29:13.127650  4932 solver.cpp:631] Iteration 59240, lr = 1e-08
I0111 04:29:42.396642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0308 > 20) by scale factor 0.665982
I0111 04:29:57.902027  4932 solver.cpp:240] Iteration 59260, loss = 0.0574797
I0111 04:29:57.902115  4932 solver.cpp:255]     Train net output #0: loss = 0.0714745 (* 1 = 0.0714745 loss)
I0111 04:29:57.902128  4932 solver.cpp:631] Iteration 59260, lr = 1e-08
I0111 04:30:00.458739  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9382 > 20) by scale factor 0.955191
I0111 04:30:42.275900  4932 solver.cpp:240] Iteration 59280, loss = 0.0548921
I0111 04:30:42.275985  4932 solver.cpp:255]     Train net output #0: loss = 0.167358 (* 1 = 0.167358 loss)
I0111 04:30:42.275997  4932 solver.cpp:631] Iteration 59280, lr = 1e-08
I0111 04:30:42.615070  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6092 > 20) by scale factor 0.970441
I0111 04:31:26.839932  4932 solver.cpp:240] Iteration 59300, loss = 0.0837522
I0111 04:31:26.839980  4932 solver.cpp:255]     Train net output #0: loss = 0.0186178 (* 1 = 0.0186178 loss)
I0111 04:31:26.839990  4932 solver.cpp:631] Iteration 59300, lr = 1e-08
I0111 04:32:11.213726  4932 solver.cpp:240] Iteration 59320, loss = 0.0542074
I0111 04:32:11.213821  4932 solver.cpp:255]     Train net output #0: loss = 0.122849 (* 1 = 0.122849 loss)
I0111 04:32:11.213835  4932 solver.cpp:631] Iteration 59320, lr = 1e-08
I0111 04:32:22.696446  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3668 > 20) by scale factor 0.82079
I0111 04:32:55.638105  4932 solver.cpp:240] Iteration 59340, loss = 0.0576846
I0111 04:32:55.638202  4932 solver.cpp:255]     Train net output #0: loss = 0.132474 (* 1 = 0.132474 loss)
I0111 04:32:55.638216  4932 solver.cpp:631] Iteration 59340, lr = 1e-08
I0111 04:33:00.411993  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6567 > 20) by scale factor 0.968207
I0111 04:33:40.006345  4932 solver.cpp:240] Iteration 59360, loss = 0.077775
I0111 04:33:40.006430  4932 solver.cpp:255]     Train net output #0: loss = 0.0049449 (* 1 = 0.0049449 loss)
I0111 04:33:40.006441  4932 solver.cpp:631] Iteration 59360, lr = 1e-08
I0111 04:33:51.601569  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9942 > 20) by scale factor 0.952643
I0111 04:33:53.824376  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6937 > 20) by scale factor 0.778401
I0111 04:34:22.667312  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0495 > 20) by scale factor 0.867696
I0111 04:34:24.550858  4932 solver.cpp:240] Iteration 59380, loss = 0.061404
I0111 04:34:24.550902  4932 solver.cpp:255]     Train net output #0: loss = 0.00267855 (* 1 = 0.00267855 loss)
I0111 04:34:24.550915  4932 solver.cpp:631] Iteration 59380, lr = 1e-08
I0111 04:35:08.922554  4932 solver.cpp:240] Iteration 59400, loss = 0.063849
I0111 04:35:08.922642  4932 solver.cpp:255]     Train net output #0: loss = 0.247464 (* 1 = 0.247464 loss)
I0111 04:35:08.922653  4932 solver.cpp:631] Iteration 59400, lr = 1e-08
I0111 04:35:53.291875  4932 solver.cpp:240] Iteration 59420, loss = 0.0471813
I0111 04:35:53.291967  4932 solver.cpp:255]     Train net output #0: loss = 0.0996677 (* 1 = 0.0996677 loss)
I0111 04:35:53.291981  4932 solver.cpp:631] Iteration 59420, lr = 1e-08
I0111 04:36:37.663229  4932 solver.cpp:240] Iteration 59440, loss = 0.0369906
I0111 04:36:37.663297  4932 solver.cpp:255]     Train net output #0: loss = 0.0644657 (* 1 = 0.0644657 loss)
I0111 04:36:37.663307  4932 solver.cpp:631] Iteration 59440, lr = 1e-08
I0111 04:36:38.002899  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.154 > 20) by scale factor 0.945446
I0111 04:36:44.659703  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6446 > 20) by scale factor 0.77989
I0111 04:37:13.500493  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8466 > 20) by scale factor 0.693323
I0111 04:37:22.051389  4932 solver.cpp:240] Iteration 59460, loss = 0.132813
I0111 04:37:22.051440  4932 solver.cpp:255]     Train net output #0: loss = 0.190949 (* 1 = 0.190949 loss)
I0111 04:37:22.051452  4932 solver.cpp:631] Iteration 59460, lr = 1e-08
I0111 04:37:22.392534  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.426 > 20) by scale factor 0.729235
I0111 04:37:44.580905  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0203 > 20) by scale factor 0.998986
I0111 04:38:06.427268  4932 solver.cpp:240] Iteration 59480, loss = 0.0363928
I0111 04:38:06.427315  4932 solver.cpp:255]     Train net output #0: loss = 0.0123041 (* 1 = 0.0123041 loss)
I0111 04:38:06.427327  4932 solver.cpp:631] Iteration 59480, lr = 1e-08
I0111 04:38:50.801159  4932 solver.cpp:240] Iteration 59500, loss = 0.0471498
I0111 04:38:50.801246  4932 solver.cpp:255]     Train net output #0: loss = 0.00430744 (* 1 = 0.00430744 loss)
I0111 04:38:50.801259  4932 solver.cpp:631] Iteration 59500, lr = 1e-08
I0111 04:38:55.576804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9205 > 20) by scale factor 0.955998
I0111 04:39:35.179128  4932 solver.cpp:240] Iteration 59520, loss = 0.0558912
I0111 04:39:35.179211  4932 solver.cpp:255]     Train net output #0: loss = 0.0382412 (* 1 = 0.0382412 loss)
I0111 04:39:35.179222  4932 solver.cpp:631] Iteration 59520, lr = 1e-08
I0111 04:39:37.740025  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2248 > 20) by scale factor 0.79287
I0111 04:40:17.794510  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.665 > 20) by scale factor 0.923149
I0111 04:40:19.678961  4932 solver.cpp:240] Iteration 59540, loss = 0.0892939
I0111 04:40:19.678999  4932 solver.cpp:255]     Train net output #0: loss = 0.276329 (* 1 = 0.276329 loss)
I0111 04:40:19.679008  4932 solver.cpp:631] Iteration 59540, lr = 1e-08
I0111 04:40:20.018332  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2594 > 20) by scale factor 0.791784
I0111 04:40:42.208745  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7289 > 20) by scale factor 0.842854
I0111 04:41:02.269345  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2076 > 20) by scale factor 0.763137
I0111 04:41:04.150826  4932 solver.cpp:240] Iteration 59560, loss = 0.0869455
I0111 04:41:04.150876  4932 solver.cpp:255]     Train net output #0: loss = 0.00777783 (* 1 = 0.00777783 loss)
I0111 04:41:04.151011  4932 solver.cpp:631] Iteration 59560, lr = 1e-08
I0111 04:41:11.159787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1949 > 20) by scale factor 0.862258
I0111 04:41:48.762749  4932 solver.cpp:240] Iteration 59580, loss = 0.0529385
I0111 04:41:48.762840  4932 solver.cpp:255]     Train net output #0: loss = 0.0565814 (* 1 = 0.0565814 loss)
I0111 04:41:48.762854  4932 solver.cpp:631] Iteration 59580, lr = 1e-08
I0111 04:41:51.323169  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0415 > 20) by scale factor 0.688669
I0111 04:42:22.539638  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5799 > 20) by scale factor 0.781865
I0111 04:42:33.296217  4932 solver.cpp:240] Iteration 59600, loss = 0.0798257
I0111 04:42:33.296267  4932 solver.cpp:255]     Train net output #0: loss = 0.0277089 (* 1 = 0.0277089 loss)
I0111 04:42:33.296279  4932 solver.cpp:631] Iteration 59600, lr = 1e-08
I0111 04:42:35.857688  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.418 > 20) by scale factor 0.729448
I0111 04:43:17.695987  4932 solver.cpp:240] Iteration 59620, loss = 0.0614582
I0111 04:43:17.696089  4932 solver.cpp:255]     Train net output #0: loss = 0.00297741 (* 1 = 0.00297741 loss)
I0111 04:43:17.696102  4932 solver.cpp:631] Iteration 59620, lr = 1e-08
I0111 04:44:02.083778  4932 solver.cpp:240] Iteration 59640, loss = 0.0502354
I0111 04:44:02.083870  4932 solver.cpp:255]     Train net output #0: loss = 0.010555 (* 1 = 0.010555 loss)
I0111 04:44:02.083884  4932 solver.cpp:631] Iteration 59640, lr = 1e-08
I0111 04:44:20.181478  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5204 > 20) by scale factor 0.850326
I0111 04:44:46.479897  4932 solver.cpp:240] Iteration 59660, loss = 0.0213384
I0111 04:44:46.479996  4932 solver.cpp:255]     Train net output #0: loss = 0.00144834 (* 1 = 0.00144834 loss)
I0111 04:44:46.480012  4932 solver.cpp:631] Iteration 59660, lr = 1e-08
I0111 04:45:31.162314  4932 solver.cpp:240] Iteration 59680, loss = 0.0579578
I0111 04:45:31.162405  4932 solver.cpp:255]     Train net output #0: loss = 0.00940717 (* 1 = 0.00940717 loss)
I0111 04:45:31.162417  4932 solver.cpp:631] Iteration 59680, lr = 1e-08
I0111 04:46:04.806216  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 41.5325 > 20) by scale factor 0.481551
I0111 04:46:15.569366  4932 solver.cpp:240] Iteration 59700, loss = 0.0691402
I0111 04:46:15.569403  4932 solver.cpp:255]     Train net output #0: loss = 0.00330769 (* 1 = 0.00330769 loss)
I0111 04:46:15.569413  4932 solver.cpp:631] Iteration 59700, lr = 1e-08
I0111 04:46:59.964850  4932 solver.cpp:240] Iteration 59720, loss = 0.0418043
I0111 04:46:59.964941  4932 solver.cpp:255]     Train net output #0: loss = 0.0225268 (* 1 = 0.0225268 loss)
I0111 04:46:59.964954  4932 solver.cpp:631] Iteration 59720, lr = 1e-08
I0111 04:47:27.281029  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.7234 > 20) by scale factor 0.696296
I0111 04:47:44.700233  4932 solver.cpp:240] Iteration 59740, loss = 0.0582893
I0111 04:47:44.700311  4932 solver.cpp:255]     Train net output #0: loss = 0.0196922 (* 1 = 0.0196922 loss)
I0111 04:47:44.700322  4932 solver.cpp:631] Iteration 59740, lr = 1e-08
I0111 04:48:16.421882  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3226 > 20) by scale factor 0.984127
I0111 04:48:29.408722  4932 solver.cpp:240] Iteration 59760, loss = 0.0488335
I0111 04:48:29.408766  4932 solver.cpp:255]     Train net output #0: loss = 0.0478703 (* 1 = 0.0478703 loss)
I0111 04:48:29.408779  4932 solver.cpp:631] Iteration 59760, lr = 1e-08
I0111 04:48:39.108572  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3698 > 20) by scale factor 0.981847
I0111 04:49:14.585516  4932 solver.cpp:240] Iteration 59780, loss = 0.0615224
I0111 04:49:14.585613  4932 solver.cpp:255]     Train net output #0: loss = 0.00236051 (* 1 = 0.00236051 loss)
I0111 04:49:14.585624  4932 solver.cpp:631] Iteration 59780, lr = 1e-08
I0111 04:49:32.685626  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4913 > 20) by scale factor 0.976026
I0111 04:49:58.979379  4932 solver.cpp:240] Iteration 59800, loss = 0.0531537
I0111 04:49:58.979472  4932 solver.cpp:255]     Train net output #0: loss = 0.0681809 (* 1 = 0.0681809 loss)
I0111 04:49:58.979487  4932 solver.cpp:631] Iteration 59800, lr = 1e-08
I0111 04:50:17.081516  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4487 > 20) by scale factor 0.785896
I0111 04:50:39.280467  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.7964 > 20) by scale factor 0.671221
I0111 04:50:43.379560  4932 solver.cpp:240] Iteration 59820, loss = 0.079697
I0111 04:50:43.379590  4932 solver.cpp:255]     Train net output #0: loss = 0.00557989 (* 1 = 0.00557989 loss)
I0111 04:50:43.379600  4932 solver.cpp:631] Iteration 59820, lr = 1e-08
I0111 04:51:05.914866  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4757 > 20) by scale factor 0.678525
I0111 04:51:27.772689  4932 solver.cpp:240] Iteration 59840, loss = 0.0763007
I0111 04:51:27.772770  4932 solver.cpp:255]     Train net output #0: loss = 0.0829655 (* 1 = 0.0829655 loss)
I0111 04:51:27.772780  4932 solver.cpp:631] Iteration 59840, lr = 1e-08
I0111 04:51:52.520560  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6331 > 20) by scale factor 0.969314
I0111 04:52:12.206045  4932 solver.cpp:240] Iteration 59860, loss = 0.0723305
I0111 04:52:12.206145  4932 solver.cpp:255]     Train net output #0: loss = 0.269621 (* 1 = 0.269621 loss)
I0111 04:52:12.206157  4932 solver.cpp:631] Iteration 59860, lr = 1e-08
I0111 04:52:56.725390  4932 solver.cpp:240] Iteration 59880, loss = 0.0348303
I0111 04:52:56.725487  4932 solver.cpp:255]     Train net output #0: loss = 0.0113195 (* 1 = 0.0113195 loss)
I0111 04:52:56.725502  4932 solver.cpp:631] Iteration 59880, lr = 1e-08
I0111 04:52:59.285485  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8202 > 20) by scale factor 0.960607
I0111 04:53:41.281829  4932 solver.cpp:240] Iteration 59900, loss = 0.0737328
I0111 04:53:41.281921  4932 solver.cpp:255]     Train net output #0: loss = 0.00890648 (* 1 = 0.00890648 loss)
I0111 04:53:41.281932  4932 solver.cpp:631] Iteration 59900, lr = 1e-08
I0111 04:54:23.796059  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9753 > 20) by scale factor 0.953502
I0111 04:54:25.678347  4932 solver.cpp:240] Iteration 59920, loss = 0.110579
I0111 04:54:25.678388  4932 solver.cpp:255]     Train net output #0: loss = 0.233134 (* 1 = 0.233134 loss)
I0111 04:54:25.678396  4932 solver.cpp:631] Iteration 59920, lr = 1e-08
I0111 04:55:10.069100  4932 solver.cpp:240] Iteration 59940, loss = 0.0585185
I0111 04:55:10.069200  4932 solver.cpp:255]     Train net output #0: loss = 0.227156 (* 1 = 0.227156 loss)
I0111 04:55:10.069212  4932 solver.cpp:631] Iteration 59940, lr = 1e-08
I0111 04:55:10.408449  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3408 > 20) by scale factor 0.895224
I0111 04:55:21.510380  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.6253 > 20) by scale factor 0.653054
I0111 04:55:39.336920  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6465 > 20) by scale factor 0.923936
I0111 04:55:50.431388  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 45.5162 > 20) by scale factor 0.439404
I0111 04:55:54.530552  4932 solver.cpp:240] Iteration 59960, loss = 0.0967182
I0111 04:55:54.530599  4932 solver.cpp:255]     Train net output #0: loss = 0.0445786 (* 1 = 0.0445786 loss)
I0111 04:55:54.530611  4932 solver.cpp:631] Iteration 59960, lr = 1e-08
I0111 04:56:32.604156  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5888 > 20) by scale factor 0.847858
I0111 04:56:38.928086  4932 solver.cpp:240] Iteration 59980, loss = 0.0544497
I0111 04:56:38.928139  4932 solver.cpp:255]     Train net output #0: loss = 0.0316578 (* 1 = 0.0316578 loss)
I0111 04:56:38.928153  4932 solver.cpp:631] Iteration 59980, lr = 1e-08
I0111 04:57:21.464330  4932 solver.cpp:424] Iteration 60000, Testing net (#0)
I0111 04:58:11.169005  4932 solver.cpp:481]     Test net output #0: accuracy = 0.822105
I0111 04:58:11.169095  4932 solver.cpp:481]     Test net output #1: loss = 0.919619 (* 1 = 0.919619 loss)
I0111 04:58:13.036250  4932 solver.cpp:240] Iteration 60000, loss = 0.043939
I0111 04:58:13.036286  4932 solver.cpp:255]     Train net output #0: loss = 0.0756763 (* 1 = 0.0756763 loss)
I0111 04:58:13.036295  4932 solver.cpp:631] Iteration 60000, lr = 1e-08
I0111 04:58:17.811167  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.204 > 20) by scale factor 0.94322
I0111 04:58:57.413108  4932 solver.cpp:240] Iteration 60020, loss = 0.0884613
I0111 04:58:57.413197  4932 solver.cpp:255]     Train net output #0: loss = 0.0489613 (* 1 = 0.0489613 loss)
I0111 04:58:57.413208  4932 solver.cpp:631] Iteration 60020, lr = 1e-08
I0111 04:59:15.503614  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0208 > 20) by scale factor 0.799335
I0111 04:59:28.818969  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3793 > 20) by scale factor 0.893685
I0111 04:59:41.798672  4932 solver.cpp:240] Iteration 60040, loss = 0.0791757
I0111 04:59:41.798713  4932 solver.cpp:255]     Train net output #0: loss = 0.042863 (* 1 = 0.042863 loss)
I0111 04:59:41.798723  4932 solver.cpp:631] Iteration 60040, lr = 1e-08
I0111 04:59:44.357048  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3656 > 20) by scale factor 0.982047
I0111 05:00:15.426801  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3195 > 20) by scale factor 0.938108
I0111 05:00:26.178448  4932 solver.cpp:240] Iteration 60060, loss = 0.0755346
I0111 05:00:26.178486  4932 solver.cpp:255]     Train net output #0: loss = 0.0252464 (* 1 = 0.0252464 loss)
I0111 05:00:26.178495  4932 solver.cpp:631] Iteration 60060, lr = 1e-08
I0111 05:01:10.559545  4932 solver.cpp:240] Iteration 60080, loss = 0.0496972
I0111 05:01:10.559617  4932 solver.cpp:255]     Train net output #0: loss = 0.00871253 (* 1 = 0.00871253 loss)
I0111 05:01:10.559625  4932 solver.cpp:631] Iteration 60080, lr = 1e-08
I0111 05:01:54.933078  4932 solver.cpp:240] Iteration 60100, loss = 0.0476062
I0111 05:01:54.933163  4932 solver.cpp:255]     Train net output #0: loss = 0.0630987 (* 1 = 0.0630987 loss)
I0111 05:01:54.933176  4932 solver.cpp:631] Iteration 60100, lr = 1e-08
I0111 05:02:13.023977  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6602 > 20) by scale factor 0.968043
I0111 05:02:39.319000  4932 solver.cpp:240] Iteration 60120, loss = 0.0832258
I0111 05:02:39.319077  4932 solver.cpp:255]     Train net output #0: loss = 0.00710873 (* 1 = 0.00710873 loss)
I0111 05:02:39.319087  4932 solver.cpp:631] Iteration 60120, lr = 1e-08
I0111 05:02:59.630340  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6536 > 20) by scale factor 0.923635
I0111 05:03:08.506572  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6263 > 20) by scale factor 0.780447
I0111 05:03:23.705193  4932 solver.cpp:240] Iteration 60140, loss = 0.104879
I0111 05:03:23.705266  4932 solver.cpp:255]     Train net output #0: loss = 0.10208 (* 1 = 0.10208 loss)
I0111 05:03:23.705278  4932 solver.cpp:631] Iteration 60140, lr = 1e-08
I0111 05:03:44.015982  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9884 > 20) by scale factor 0.90957
I0111 05:04:01.767946  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.207 > 20) by scale factor 0.793432
I0111 05:04:06.206406  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7352 > 20) by scale factor 0.879694
I0111 05:04:08.087963  4932 solver.cpp:240] Iteration 60160, loss = 0.0761572
I0111 05:04:08.087993  4932 solver.cpp:255]     Train net output #0: loss = 0.0251864 (* 1 = 0.0251864 loss)
I0111 05:04:08.088001  4932 solver.cpp:631] Iteration 60160, lr = 1e-08
I0111 05:04:30.613126  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1886 > 20) by scale factor 0.99066
I0111 05:04:46.148109  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5424 > 20) by scale factor 0.753512
I0111 05:04:52.466684  4932 solver.cpp:240] Iteration 60180, loss = 0.0657493
I0111 05:04:52.466717  4932 solver.cpp:255]     Train net output #0: loss = 0.12472 (* 1 = 0.12472 loss)
I0111 05:04:52.466725  4932 solver.cpp:631] Iteration 60180, lr = 1e-08
I0111 05:05:36.842875  4932 solver.cpp:240] Iteration 60200, loss = 0.0373424
I0111 05:05:36.842964  4932 solver.cpp:255]     Train net output #0: loss = 0.0217819 (* 1 = 0.0217819 loss)
I0111 05:05:36.842978  4932 solver.cpp:631] Iteration 60200, lr = 1e-08
I0111 05:05:39.404065  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8469 > 20) by scale factor 0.875392
I0111 05:05:46.061269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8665 > 20) by scale factor 0.914641
I0111 05:05:50.498682  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2592 > 20) by scale factor 0.898505
I0111 05:06:21.220352  4932 solver.cpp:240] Iteration 60220, loss = 0.0863062
I0111 05:06:21.220425  4932 solver.cpp:255]     Train net output #0: loss = 0.0129596 (* 1 = 0.0129596 loss)
I0111 05:06:21.220435  4932 solver.cpp:631] Iteration 60220, lr = 1e-08
I0111 05:06:39.308830  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2426 > 20) by scale factor 0.899173
I0111 05:07:05.602444  4932 solver.cpp:240] Iteration 60240, loss = 0.0633757
I0111 05:07:05.602519  4932 solver.cpp:255]     Train net output #0: loss = 0.108371 (* 1 = 0.108371 loss)
I0111 05:07:05.602530  4932 solver.cpp:631] Iteration 60240, lr = 1e-08
I0111 05:07:50.043083  4932 solver.cpp:240] Iteration 60260, loss = 0.0603139
I0111 05:07:50.043179  4932 solver.cpp:255]     Train net output #0: loss = 0.00164201 (* 1 = 0.00164201 loss)
I0111 05:07:50.043190  4932 solver.cpp:631] Iteration 60260, lr = 1e-08
I0111 05:07:59.255194  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5939 > 20) by scale factor 0.926188
I0111 05:08:10.351752  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5339 > 20) by scale factor 0.974
I0111 05:08:34.659145  4932 solver.cpp:240] Iteration 60280, loss = 0.081285
I0111 05:08:34.659240  4932 solver.cpp:255]     Train net output #0: loss = 0.0671104 (* 1 = 0.0671104 loss)
I0111 05:08:34.659250  4932 solver.cpp:631] Iteration 60280, lr = 1e-08
I0111 05:08:57.183393  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5533 > 20) by scale factor 0.927932
I0111 05:09:19.039419  4932 solver.cpp:240] Iteration 60300, loss = 0.0674366
I0111 05:09:19.039510  4932 solver.cpp:255]     Train net output #0: loss = 0.0607884 (* 1 = 0.0607884 loss)
I0111 05:09:19.039523  4932 solver.cpp:631] Iteration 60300, lr = 1e-08
I0111 05:09:21.598984  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5805 > 20) by scale factor 0.725151
I0111 05:09:26.039413  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6178 > 20) by scale factor 0.780706
I0111 05:09:30.478235  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4833 > 20) by scale factor 0.85167
I0111 05:10:03.504796  4932 solver.cpp:240] Iteration 60320, loss = 0.0734789
I0111 05:10:03.504889  4932 solver.cpp:255]     Train net output #0: loss = 0.132686 (* 1 = 0.132686 loss)
I0111 05:10:03.504902  4932 solver.cpp:631] Iteration 60320, lr = 1e-08
I0111 05:10:32.687832  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6405 > 20) by scale factor 0.698311
I0111 05:10:39.346101  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5834 > 20) by scale factor 0.676056
I0111 05:10:47.894855  4932 solver.cpp:240] Iteration 60340, loss = 0.0717559
I0111 05:10:47.894896  4932 solver.cpp:255]     Train net output #0: loss = 0.0729502 (* 1 = 0.0729502 loss)
I0111 05:10:47.894906  4932 solver.cpp:631] Iteration 60340, lr = 1e-08
I0111 05:11:12.640137  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4066 > 20) by scale factor 0.892593
I0111 05:11:28.430824  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9889 > 20) by scale factor 0.90955
I0111 05:11:32.530865  4932 solver.cpp:240] Iteration 60360, loss = 0.0904832
I0111 05:11:32.530900  4932 solver.cpp:255]     Train net output #0: loss = 0.300277 (* 1 = 0.300277 loss)
I0111 05:11:32.530908  4932 solver.cpp:631] Iteration 60360, lr = 1e-08
I0111 05:11:32.870007  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5951 > 20) by scale factor 0.971103
I0111 05:12:16.916334  4932 solver.cpp:240] Iteration 60380, loss = 0.0471102
I0111 05:12:16.916432  4932 solver.cpp:255]     Train net output #0: loss = 0.0830305 (* 1 = 0.0830305 loss)
I0111 05:12:16.916445  4932 solver.cpp:631] Iteration 60380, lr = 1e-08
I0111 05:13:01.333487  4932 solver.cpp:240] Iteration 60400, loss = 0.0712634
I0111 05:13:01.333588  4932 solver.cpp:255]     Train net output #0: loss = 0.00381364 (* 1 = 0.00381364 loss)
I0111 05:13:01.333600  4932 solver.cpp:631] Iteration 60400, lr = 1e-08
I0111 05:13:45.849455  4932 solver.cpp:240] Iteration 60420, loss = 0.0756182
I0111 05:13:45.849567  4932 solver.cpp:255]     Train net output #0: loss = 0.16963 (* 1 = 0.16963 loss)
I0111 05:13:45.849583  4932 solver.cpp:631] Iteration 60420, lr = 1e-08
I0111 05:14:30.227396  4932 solver.cpp:240] Iteration 60440, loss = 0.0468921
I0111 05:14:30.227489  4932 solver.cpp:255]     Train net output #0: loss = 0.0130046 (* 1 = 0.0130046 loss)
I0111 05:14:30.227501  4932 solver.cpp:631] Iteration 60440, lr = 1e-08
I0111 05:15:14.595849  4932 solver.cpp:240] Iteration 60460, loss = 0.0726645
I0111 05:15:14.595943  4932 solver.cpp:255]     Train net output #0: loss = 0.0968189 (* 1 = 0.0968189 loss)
I0111 05:15:14.595957  4932 solver.cpp:631] Iteration 60460, lr = 1e-08
I0111 05:15:58.969911  4932 solver.cpp:240] Iteration 60480, loss = 0.0841124
I0111 05:15:58.970010  4932 solver.cpp:255]     Train net output #0: loss = 0.148729 (* 1 = 0.148729 loss)
I0111 05:15:58.970022  4932 solver.cpp:631] Iteration 60480, lr = 1e-08
I0111 05:16:10.499269  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9373 > 20) by scale factor 0.69115
I0111 05:16:12.720872  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9354 > 20) by scale factor 0.872014
I0111 05:16:43.445209  4932 solver.cpp:240] Iteration 60500, loss = 0.0521483
I0111 05:16:43.445298  4932 solver.cpp:255]     Train net output #0: loss = 0.0125724 (* 1 = 0.0125724 loss)
I0111 05:16:43.445310  4932 solver.cpp:631] Iteration 60500, lr = 1e-08
I0111 05:17:14.855126  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1018 > 20) by scale factor 0.865735
I0111 05:17:27.832833  4932 solver.cpp:240] Iteration 60520, loss = 0.0611919
I0111 05:17:27.832875  4932 solver.cpp:255]     Train net output #0: loss = 0.106744 (* 1 = 0.106744 loss)
I0111 05:17:27.832885  4932 solver.cpp:631] Iteration 60520, lr = 1e-08
I0111 05:17:30.391299  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6595 > 20) by scale factor 0.811046
I0111 05:18:12.285219  4932 solver.cpp:240] Iteration 60540, loss = 0.0881503
I0111 05:18:12.285326  4932 solver.cpp:255]     Train net output #0: loss = 0.197616 (* 1 = 0.197616 loss)
I0111 05:18:12.285342  4932 solver.cpp:631] Iteration 60540, lr = 1e-08
I0111 05:18:32.595077  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4572 > 20) by scale factor 0.852616
I0111 05:18:41.469909  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3298 > 20) by scale factor 0.895663
I0111 05:18:56.666726  4932 solver.cpp:240] Iteration 60560, loss = 0.0817652
I0111 05:18:56.666836  4932 solver.cpp:255]     Train net output #0: loss = 0.0358088 (* 1 = 0.0358088 loss)
I0111 05:18:56.666849  4932 solver.cpp:631] Iteration 60560, lr = 1e-08
I0111 05:19:23.641647  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5498 > 20) by scale factor 0.814672
I0111 05:19:41.052505  4932 solver.cpp:240] Iteration 60580, loss = 0.0409386
I0111 05:19:41.052620  4932 solver.cpp:255]     Train net output #0: loss = 0.00143445 (* 1 = 0.00143445 loss)
I0111 05:19:41.052636  4932 solver.cpp:631] Iteration 60580, lr = 1e-08
I0111 05:20:14.673934  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1705 > 20) by scale factor 0.94471
I0111 05:20:25.430397  4932 solver.cpp:240] Iteration 60600, loss = 0.0543814
I0111 05:20:25.430438  4932 solver.cpp:255]     Train net output #0: loss = 0.10154 (* 1 = 0.10154 loss)
I0111 05:20:25.430449  4932 solver.cpp:631] Iteration 60600, lr = 1e-08
I0111 05:20:52.528519  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1459 > 20) by scale factor 0.9031
I0111 05:21:09.942610  4932 solver.cpp:240] Iteration 60620, loss = 0.0644832
I0111 05:21:09.942651  4932 solver.cpp:255]     Train net output #0: loss = 0.0261703 (* 1 = 0.0261703 loss)
I0111 05:21:09.942659  4932 solver.cpp:631] Iteration 60620, lr = 1e-08
I0111 05:21:39.126655  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0371 > 20) by scale factor 0.868165
I0111 05:21:54.320550  4932 solver.cpp:240] Iteration 60640, loss = 0.0547318
I0111 05:21:54.320590  4932 solver.cpp:255]     Train net output #0: loss = 0.0482051 (* 1 = 0.0482051 loss)
I0111 05:21:54.320600  4932 solver.cpp:631] Iteration 60640, lr = 1e-08
I0111 05:22:38.694576  4932 solver.cpp:240] Iteration 60660, loss = 0.0594331
I0111 05:22:38.694665  4932 solver.cpp:255]     Train net output #0: loss = 0.00540879 (* 1 = 0.00540879 loss)
I0111 05:22:38.694677  4932 solver.cpp:631] Iteration 60660, lr = 1e-08
I0111 05:22:52.347851  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.464 > 20) by scale factor 0.890312
I0111 05:23:23.075319  4932 solver.cpp:240] Iteration 60680, loss = 0.0590317
I0111 05:23:23.075409  4932 solver.cpp:255]     Train net output #0: loss = 0.0276219 (* 1 = 0.0276219 loss)
I0111 05:23:23.075423  4932 solver.cpp:631] Iteration 60680, lr = 1e-08
I0111 05:23:32.286249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.103 > 20) by scale factor 0.947733
I0111 05:23:43.384007  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6701 > 20) by scale factor 0.922929
I0111 05:23:54.480787  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6209 > 20) by scale factor 0.969891
I0111 05:24:07.457449  4932 solver.cpp:240] Iteration 60700, loss = 0.0837463
I0111 05:24:07.457489  4932 solver.cpp:255]     Train net output #0: loss = 0.00409576 (* 1 = 0.00409576 loss)
I0111 05:24:07.457497  4932 solver.cpp:631] Iteration 60700, lr = 1e-08
I0111 05:24:34.430071  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2281 > 20) by scale factor 0.988724
I0111 05:24:51.845367  4932 solver.cpp:240] Iteration 60720, loss = 0.0719928
I0111 05:24:51.845412  4932 solver.cpp:255]     Train net output #0: loss = 0.189958 (* 1 = 0.189958 loss)
I0111 05:24:51.845422  4932 solver.cpp:631] Iteration 60720, lr = 1e-08
I0111 05:25:03.274960  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4426 > 20) by scale factor 0.932725
I0111 05:25:36.215692  4932 solver.cpp:240] Iteration 60740, loss = 0.0487416
I0111 05:25:36.215768  4932 solver.cpp:255]     Train net output #0: loss = 0.018938 (* 1 = 0.018938 loss)
I0111 05:25:36.215778  4932 solver.cpp:631] Iteration 60740, lr = 1e-08
I0111 05:26:05.398551  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3741 > 20) by scale factor 0.93571
I0111 05:26:09.839993  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.433 > 20) by scale factor 0.679509
I0111 05:26:20.613327  4932 solver.cpp:240] Iteration 60760, loss = 0.0953278
I0111 05:26:20.613366  4932 solver.cpp:255]     Train net output #0: loss = 0.19951 (* 1 = 0.19951 loss)
I0111 05:26:20.613378  4932 solver.cpp:631] Iteration 60760, lr = 1e-08
I0111 05:26:20.953917  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4044 > 20) by scale factor 0.704117
I0111 05:26:54.245359  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5953 > 20) by scale factor 0.971094
I0111 05:26:56.465430  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9795 > 20) by scale factor 0.690142
I0111 05:27:05.003569  4932 solver.cpp:240] Iteration 60780, loss = 0.0962776
I0111 05:27:05.003609  4932 solver.cpp:255]     Train net output #0: loss = 0.231512 (* 1 = 0.231512 loss)
I0111 05:27:05.003619  4932 solver.cpp:631] Iteration 60780, lr = 1e-08
I0111 05:27:05.343144  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1746 > 20) by scale factor 0.764099
I0111 05:27:16.437726  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0981 > 20) by scale factor 0.99512
I0111 05:27:25.316532  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0227 > 20) by scale factor 0.951354
I0111 05:27:27.536814  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9946 > 20) by scale factor 0.909314
I0111 05:27:49.388160  4932 solver.cpp:240] Iteration 60800, loss = 0.0474951
I0111 05:27:49.388196  4932 solver.cpp:255]     Train net output #0: loss = 0.0386053 (* 1 = 0.0386053 loss)
I0111 05:27:49.388205  4932 solver.cpp:631] Iteration 60800, lr = 1e-08
I0111 05:28:33.769625  4932 solver.cpp:240] Iteration 60820, loss = 0.0453724
I0111 05:28:33.769717  4932 solver.cpp:255]     Train net output #0: loss = 0.0821656 (* 1 = 0.0821656 loss)
I0111 05:28:33.769729  4932 solver.cpp:631] Iteration 60820, lr = 1e-08
I0111 05:29:14.051352  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.5448 > 20) by scale factor 0.614537
I0111 05:29:18.154253  4932 solver.cpp:240] Iteration 60840, loss = 0.0537069
I0111 05:29:18.154296  4932 solver.cpp:255]     Train net output #0: loss = 0.00333502 (* 1 = 0.00333502 loss)
I0111 05:29:18.154311  4932 solver.cpp:631] Iteration 60840, lr = 1e-08
I0111 05:30:02.525760  4932 solver.cpp:240] Iteration 60860, loss = 0.0587078
I0111 05:30:02.525840  4932 solver.cpp:255]     Train net output #0: loss = 0.175618 (* 1 = 0.175618 loss)
I0111 05:30:02.525848  4932 solver.cpp:631] Iteration 60860, lr = 1e-08
I0111 05:30:46.906402  4932 solver.cpp:240] Iteration 60880, loss = 0.0333048
I0111 05:30:46.906493  4932 solver.cpp:255]     Train net output #0: loss = 0.00619702 (* 1 = 0.00619702 loss)
I0111 05:30:46.906505  4932 solver.cpp:631] Iteration 60880, lr = 1e-08
I0111 05:30:51.685554  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1345 > 20) by scale factor 0.946322
I0111 05:31:31.433806  4932 solver.cpp:240] Iteration 60900, loss = 0.0502365
I0111 05:31:31.433907  4932 solver.cpp:255]     Train net output #0: loss = 0.00504947 (* 1 = 0.00504947 loss)
I0111 05:31:31.433923  4932 solver.cpp:631] Iteration 60900, lr = 1e-08
I0111 05:32:15.811939  4932 solver.cpp:240] Iteration 60920, loss = 0.0515276
I0111 05:32:15.812031  4932 solver.cpp:255]     Train net output #0: loss = 0.0266127 (* 1 = 0.0266127 loss)
I0111 05:32:15.812043  4932 solver.cpp:631] Iteration 60920, lr = 1e-08
I0111 05:32:27.247428  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4239 > 20) by scale factor 0.933536
I0111 05:33:00.302503  4932 solver.cpp:240] Iteration 60940, loss = 0.069414
I0111 05:33:00.302636  4932 solver.cpp:255]     Train net output #0: loss = 0.0291323 (* 1 = 0.0291323 loss)
I0111 05:33:00.302656  4932 solver.cpp:631] Iteration 60940, lr = 1e-08
I0111 05:33:22.834273  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0236 > 20) by scale factor 0.908116
I0111 05:33:44.688287  4932 solver.cpp:240] Iteration 60960, loss = 0.0577664
I0111 05:33:44.688383  4932 solver.cpp:255]     Train net output #0: loss = 0.0423535 (* 1 = 0.0423535 loss)
I0111 05:33:44.688395  4932 solver.cpp:631] Iteration 60960, lr = 1e-08
I0111 05:34:29.067039  4932 solver.cpp:240] Iteration 60980, loss = 0.076376
I0111 05:34:29.067124  4932 solver.cpp:255]     Train net output #0: loss = 0.0332357 (* 1 = 0.0332357 loss)
I0111 05:34:29.067137  4932 solver.cpp:631] Iteration 60980, lr = 1e-08
I0111 05:35:11.595340  4932 solver.cpp:424] Iteration 61000, Testing net (#0)
I0111 05:36:00.812925  4932 solver.cpp:481]     Test net output #0: accuracy = 0.818947
I0111 05:36:00.813026  4932 solver.cpp:481]     Test net output #1: loss = 0.934817 (* 1 = 0.934817 loss)
I0111 05:36:02.679050  4932 solver.cpp:240] Iteration 61000, loss = 0.0451319
I0111 05:36:02.679090  4932 solver.cpp:255]     Train net output #0: loss = 0.00687396 (* 1 = 0.00687396 loss)
I0111 05:36:02.679100  4932 solver.cpp:631] Iteration 61000, lr = 1e-08
I0111 05:36:09.675364  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.529 > 20) by scale factor 0.974232
I0111 05:36:14.115635  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9994 > 20) by scale factor 0.869589
I0111 05:36:25.213230  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8015 > 20) by scale factor 0.961469
I0111 05:36:40.749670  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5365 > 20) by scale factor 0.849745
I0111 05:36:47.069219  4932 solver.cpp:240] Iteration 61020, loss = 0.0758107
I0111 05:36:47.069267  4932 solver.cpp:255]     Train net output #0: loss = 0.00851654 (* 1 = 0.00851654 loss)
I0111 05:36:47.069278  4932 solver.cpp:631] Iteration 61020, lr = 1e-08
I0111 05:37:31.460162  4932 solver.cpp:240] Iteration 61040, loss = 0.0481221
I0111 05:37:31.460253  4932 solver.cpp:255]     Train net output #0: loss = 0.00762139 (* 1 = 0.00762139 loss)
I0111 05:37:31.460264  4932 solver.cpp:631] Iteration 61040, lr = 1e-08
I0111 05:38:15.838328  4932 solver.cpp:240] Iteration 61060, loss = 0.0375688
I0111 05:38:15.838441  4932 solver.cpp:255]     Train net output #0: loss = 0.0729751 (* 1 = 0.0729751 loss)
I0111 05:38:15.838457  4932 solver.cpp:631] Iteration 61060, lr = 1e-08
I0111 05:38:18.398115  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6283 > 20) by scale factor 0.96954
I0111 05:39:00.227731  4932 solver.cpp:240] Iteration 61080, loss = 0.0589359
I0111 05:39:00.227818  4932 solver.cpp:255]     Train net output #0: loss = 0.122599 (* 1 = 0.122599 loss)
I0111 05:39:00.227828  4932 solver.cpp:631] Iteration 61080, lr = 1e-08
I0111 05:39:44.608485  4932 solver.cpp:240] Iteration 61100, loss = 0.0560427
I0111 05:39:44.608570  4932 solver.cpp:255]     Train net output #0: loss = 0.049677 (* 1 = 0.049677 loss)
I0111 05:39:44.608582  4932 solver.cpp:631] Iteration 61100, lr = 1e-08
I0111 05:39:47.166656  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.7635 > 20) by scale factor 0.544019
I0111 05:40:04.924676  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1119 > 20) by scale factor 0.994436
I0111 05:40:07.147020  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7295 > 20) by scale factor 0.920409
I0111 05:40:28.997625  4932 solver.cpp:240] Iteration 61120, loss = 0.094636
I0111 05:40:28.997699  4932 solver.cpp:255]     Train net output #0: loss = 0.00468597 (* 1 = 0.00468597 loss)
I0111 05:40:28.997709  4932 solver.cpp:631] Iteration 61120, lr = 1e-08
I0111 05:40:38.209995  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3661 > 20) by scale factor 0.820812
I0111 05:41:04.868405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0833 > 20) by scale factor 0.905663
I0111 05:41:13.411339  4932 solver.cpp:240] Iteration 61140, loss = 0.0815176
I0111 05:41:13.411370  4932 solver.cpp:255]     Train net output #0: loss = 0.0761088 (* 1 = 0.0761088 loss)
I0111 05:41:13.411378  4932 solver.cpp:631] Iteration 61140, lr = 1e-08
I0111 05:41:31.517035  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7594 > 20) by scale factor 0.776417
I0111 05:41:57.936226  4932 solver.cpp:240] Iteration 61160, loss = 0.0641773
I0111 05:41:57.936313  4932 solver.cpp:255]     Train net output #0: loss = 0.10893 (* 1 = 0.10893 loss)
I0111 05:41:57.936326  4932 solver.cpp:631] Iteration 61160, lr = 1e-08
I0111 05:41:58.275132  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2196 > 20) by scale factor 0.900108
I0111 05:42:25.058089  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6896 > 20) by scale factor 0.722294
I0111 05:42:42.475724  4932 solver.cpp:240] Iteration 61180, loss = 0.0641133
I0111 05:42:42.475811  4932 solver.cpp:255]     Train net output #0: loss = 0.239028 (* 1 = 0.239028 loss)
I0111 05:42:42.475822  4932 solver.cpp:631] Iteration 61180, lr = 1e-08
I0111 05:42:42.816329  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3143 > 20) by scale factor 0.984528
I0111 05:43:18.328130  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.2142 > 20) by scale factor 0.66194
I0111 05:43:27.173487  4932 solver.cpp:240] Iteration 61200, loss = 0.0605663
I0111 05:43:27.173537  4932 solver.cpp:255]     Train net output #0: loss = 0.0308802 (* 1 = 0.0308802 loss)
I0111 05:43:27.173549  4932 solver.cpp:631] Iteration 61200, lr = 1e-08
I0111 05:44:11.570658  4932 solver.cpp:240] Iteration 61220, loss = 0.0695034
I0111 05:44:11.570755  4932 solver.cpp:255]     Train net output #0: loss = 0.0268787 (* 1 = 0.0268787 loss)
I0111 05:44:11.570770  4932 solver.cpp:631] Iteration 61220, lr = 1e-08
I0111 05:44:14.131243  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8239 > 20) by scale factor 0.960437
I0111 05:44:55.978032  4932 solver.cpp:240] Iteration 61240, loss = 0.0543424
I0111 05:44:55.978123  4932 solver.cpp:255]     Train net output #0: loss = 0.0674922 (* 1 = 0.0674922 loss)
I0111 05:44:55.978137  4932 solver.cpp:631] Iteration 61240, lr = 1e-08
I0111 05:45:40.475790  4932 solver.cpp:240] Iteration 61260, loss = 0.0560404
I0111 05:45:40.475836  4932 solver.cpp:255]     Train net output #0: loss = 0.070091 (* 1 = 0.070091 loss)
I0111 05:45:40.475845  4932 solver.cpp:631] Iteration 61260, lr = 1e-08
I0111 05:45:49.690553  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4537 > 20) by scale factor 0.679032
I0111 05:46:24.857709  4932 solver.cpp:240] Iteration 61280, loss = 0.058414
I0111 05:46:24.857812  4932 solver.cpp:255]     Train net output #0: loss = 0.121319 (* 1 = 0.121319 loss)
I0111 05:46:24.857825  4932 solver.cpp:631] Iteration 61280, lr = 1e-08
I0111 05:46:42.949347  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5203 > 20) by scale factor 0.815652
I0111 05:46:51.825855  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9163 > 20) by scale factor 0.87274
I0111 05:47:09.243353  4932 solver.cpp:240] Iteration 61300, loss = 0.0801336
I0111 05:47:09.243465  4932 solver.cpp:255]     Train net output #0: loss = 0.201484 (* 1 = 0.201484 loss)
I0111 05:47:09.243481  4932 solver.cpp:631] Iteration 61300, lr = 1e-08
I0111 05:47:09.584592  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.802 > 20) by scale factor 0.694395
I0111 05:47:29.559705  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0739 > 20) by scale factor 0.830775
I0111 05:47:53.758709  4932 solver.cpp:240] Iteration 61320, loss = 0.0708604
I0111 05:47:53.758800  4932 solver.cpp:255]     Train net output #0: loss = 0.00791647 (* 1 = 0.00791647 loss)
I0111 05:47:53.758813  4932 solver.cpp:631] Iteration 61320, lr = 1e-08
I0111 05:48:38.144629  4932 solver.cpp:240] Iteration 61340, loss = 0.0424283
I0111 05:48:38.144742  4932 solver.cpp:255]     Train net output #0: loss = 0.0781688 (* 1 = 0.0781688 loss)
I0111 05:48:38.144757  4932 solver.cpp:631] Iteration 61340, lr = 1e-08
I0111 05:49:05.105327  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0706 > 20) by scale factor 0.665102
I0111 05:49:11.767292  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8945 > 20) by scale factor 0.913471
I0111 05:49:22.525481  4932 solver.cpp:240] Iteration 61360, loss = 0.0782391
I0111 05:49:22.525522  4932 solver.cpp:255]     Train net output #0: loss = 0.0130348 (* 1 = 0.0130348 loss)
I0111 05:49:22.525532  4932 solver.cpp:631] Iteration 61360, lr = 1e-08
I0111 05:50:06.910675  4932 solver.cpp:240] Iteration 61380, loss = 0.0549497
I0111 05:50:06.910764  4932 solver.cpp:255]     Train net output #0: loss = 0.179344 (* 1 = 0.179344 loss)
I0111 05:50:06.910776  4932 solver.cpp:631] Iteration 61380, lr = 1e-08
I0111 05:50:42.763861  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1518 > 20) by scale factor 0.863862
I0111 05:50:51.305155  4932 solver.cpp:240] Iteration 61400, loss = 0.0730762
I0111 05:50:51.305194  4932 solver.cpp:255]     Train net output #0: loss = 0.00683735 (* 1 = 0.00683735 loss)
I0111 05:50:51.305204  4932 solver.cpp:631] Iteration 61400, lr = 1e-08
I0111 05:50:53.863117  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.444 > 20) by scale factor 0.932661
I0111 05:51:09.397050  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0663 > 20) by scale factor 0.90636
I0111 05:51:20.493067  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0667 > 20) by scale factor 0.996676
I0111 05:51:22.713742  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3938 > 20) by scale factor 0.854928
I0111 05:51:35.689469  4932 solver.cpp:240] Iteration 61420, loss = 0.0814853
I0111 05:51:35.689510  4932 solver.cpp:255]     Train net output #0: loss = 0.0399037 (* 1 = 0.0399037 loss)
I0111 05:51:35.689520  4932 solver.cpp:631] Iteration 61420, lr = 1e-08
I0111 05:52:20.070227  4932 solver.cpp:240] Iteration 61440, loss = 0.0445926
I0111 05:52:20.070314  4932 solver.cpp:255]     Train net output #0: loss = 0.00267362 (* 1 = 0.00267362 loss)
I0111 05:52:20.070327  4932 solver.cpp:631] Iteration 61440, lr = 1e-08
I0111 05:52:24.846511  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9349 > 20) by scale factor 0.742531
I0111 05:53:00.358616  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8449 > 20) by scale factor 0.915545
I0111 05:53:04.459563  4932 solver.cpp:240] Iteration 61460, loss = 0.0577512
I0111 05:53:04.459597  4932 solver.cpp:255]     Train net output #0: loss = 0.0817333 (* 1 = 0.0817333 loss)
I0111 05:53:04.459606  4932 solver.cpp:631] Iteration 61460, lr = 1e-08
I0111 05:53:11.455183  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9428 > 20) by scale factor 0.770925
I0111 05:53:20.333642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3324 > 20) by scale factor 0.983654
I0111 05:53:48.889649  4932 solver.cpp:240] Iteration 61480, loss = 0.0644543
I0111 05:53:48.889744  4932 solver.cpp:255]     Train net output #0: loss = 0.00653587 (* 1 = 0.00653587 loss)
I0111 05:53:48.889756  4932 solver.cpp:631] Iteration 61480, lr = 1e-08
I0111 05:54:02.542296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7807 > 20) by scale factor 0.746806
I0111 05:54:18.079263  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2051 > 20) by scale factor 0.943169
I0111 05:54:33.276911  4932 solver.cpp:240] Iteration 61500, loss = 0.0692656
I0111 05:54:33.277012  4932 solver.cpp:255]     Train net output #0: loss = 0.0765104 (* 1 = 0.0765104 loss)
I0111 05:54:33.277025  4932 solver.cpp:631] Iteration 61500, lr = 1e-08
I0111 05:54:40.273088  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4951 > 20) by scale factor 0.851242
I0111 05:55:17.751920  4932 solver.cpp:240] Iteration 61520, loss = 0.0482959
I0111 05:55:17.752028  4932 solver.cpp:255]     Train net output #0: loss = 0.00873405 (* 1 = 0.00873405 loss)
I0111 05:55:17.752040  4932 solver.cpp:631] Iteration 61520, lr = 1e-08
I0111 05:56:02.296905  4932 solver.cpp:240] Iteration 61540, loss = 0.0557149
I0111 05:56:02.296977  4932 solver.cpp:255]     Train net output #0: loss = 0.0119275 (* 1 = 0.0119275 loss)
I0111 05:56:02.296988  4932 solver.cpp:631] Iteration 61540, lr = 1e-08
I0111 05:56:24.822937  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4225 > 20) by scale factor 0.979311
I0111 05:56:46.673774  4932 solver.cpp:240] Iteration 61560, loss = 0.0830858
I0111 05:56:46.673885  4932 solver.cpp:255]     Train net output #0: loss = 0.074675 (* 1 = 0.074675 loss)
I0111 05:56:46.673902  4932 solver.cpp:631] Iteration 61560, lr = 1e-08
I0111 05:57:04.773277  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.9036 > 20) by scale factor 0.668817
I0111 05:57:31.173091  4932 solver.cpp:240] Iteration 61580, loss = 0.0409033
I0111 05:57:31.173177  4932 solver.cpp:255]     Train net output #0: loss = 0.0118602 (* 1 = 0.0118602 loss)
I0111 05:57:31.173189  4932 solver.cpp:631] Iteration 61580, lr = 1e-08
I0111 05:57:38.167609  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8808 > 20) by scale factor 0.874096
I0111 05:58:00.360126  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1249 > 20) by scale factor 0.737331
I0111 05:58:15.557360  4932 solver.cpp:240] Iteration 61600, loss = 0.0612539
I0111 05:58:15.557445  4932 solver.cpp:255]     Train net output #0: loss = 0.0787764 (* 1 = 0.0787764 loss)
I0111 05:58:15.557456  4932 solver.cpp:631] Iteration 61600, lr = 1e-08
I0111 05:58:20.334244  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1367 > 20) by scale factor 0.864427
I0111 05:58:59.941056  4932 solver.cpp:240] Iteration 61620, loss = 0.11798
I0111 05:58:59.941140  4932 solver.cpp:255]     Train net output #0: loss = 0.0244705 (* 1 = 0.0244705 loss)
I0111 05:58:59.941151  4932 solver.cpp:631] Iteration 61620, lr = 1e-08
I0111 05:59:44.321549  4932 solver.cpp:240] Iteration 61640, loss = 0.0550528
I0111 05:59:44.321640  4932 solver.cpp:255]     Train net output #0: loss = 0.0665581 (* 1 = 0.0665581 loss)
I0111 05:59:44.321652  4932 solver.cpp:631] Iteration 61640, lr = 1e-08
I0111 05:59:55.755956  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3175 > 20) by scale factor 0.984371
I0111 06:00:04.636165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4416 > 20) by scale factor 0.932765
I0111 06:00:06.857915  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7434 > 20) by scale factor 0.842339
I0111 06:00:28.707010  4932 solver.cpp:240] Iteration 61660, loss = 0.087455
I0111 06:00:28.707077  4932 solver.cpp:255]     Train net output #0: loss = 0.0279247 (* 1 = 0.0279247 loss)
I0111 06:00:28.707087  4932 solver.cpp:631] Iteration 61660, lr = 1e-08
I0111 06:00:35.704584  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8401 > 20) by scale factor 0.80515
I0111 06:00:44.581785  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.381 > 20) by scale factor 0.758122
I0111 06:00:51.313760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5004 > 20) by scale factor 0.975592
I0111 06:01:09.070500  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1837 > 20) by scale factor 0.944121
I0111 06:01:13.170426  4932 solver.cpp:240] Iteration 61680, loss = 0.06672
I0111 06:01:13.170464  4932 solver.cpp:255]     Train net output #0: loss = 0.0402463 (* 1 = 0.0402463 loss)
I0111 06:01:13.170473  4932 solver.cpp:631] Iteration 61680, lr = 1e-08
I0111 06:01:49.005692  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.2822 > 20) by scale factor 0.683009
I0111 06:01:55.663658  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6517 > 20) by scale factor 0.811303
I0111 06:01:57.546838  4932 solver.cpp:240] Iteration 61700, loss = 0.0707378
I0111 06:01:57.546880  4932 solver.cpp:255]     Train net output #0: loss = 0.0614973 (* 1 = 0.0614973 loss)
I0111 06:01:57.546893  4932 solver.cpp:631] Iteration 61700, lr = 1e-08
I0111 06:02:28.950590  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.97 > 20) by scale factor 0.953744
I0111 06:02:31.172080  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1124 > 20) by scale factor 0.947311
I0111 06:02:41.927057  4932 solver.cpp:240] Iteration 61720, loss = 0.0633549
I0111 06:02:41.927106  4932 solver.cpp:255]     Train net output #0: loss = 0.00216527 (* 1 = 0.00216527 loss)
I0111 06:02:41.927125  4932 solver.cpp:631] Iteration 61720, lr = 1e-08
I0111 06:02:46.707341  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5692 > 20) by scale factor 0.700055
I0111 06:03:26.305480  4932 solver.cpp:240] Iteration 61740, loss = 0.0739872
I0111 06:03:26.305557  4932 solver.cpp:255]     Train net output #0: loss = 0.112454 (* 1 = 0.112454 loss)
I0111 06:03:26.305567  4932 solver.cpp:631] Iteration 61740, lr = 1e-08
I0111 06:04:10.683708  4932 solver.cpp:240] Iteration 61760, loss = 0.0586739
I0111 06:04:10.683799  4932 solver.cpp:255]     Train net output #0: loss = 0.0584336 (* 1 = 0.0584336 loss)
I0111 06:04:10.683812  4932 solver.cpp:631] Iteration 61760, lr = 1e-08
I0111 06:04:55.149515  4932 solver.cpp:240] Iteration 61780, loss = 0.0471408
I0111 06:04:55.149628  4932 solver.cpp:255]     Train net output #0: loss = 0.00870518 (* 1 = 0.00870518 loss)
I0111 06:04:55.149646  4932 solver.cpp:631] Iteration 61780, lr = 1e-08
I0111 06:05:04.365952  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.323 > 20) by scale factor 0.895939
I0111 06:05:22.117398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5615 > 20) by scale factor 0.72565
I0111 06:05:37.652858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1485 > 20) by scale factor 0.992632
I0111 06:05:39.535694  4932 solver.cpp:240] Iteration 61800, loss = 0.0837199
I0111 06:05:39.535734  4932 solver.cpp:255]     Train net output #0: loss = 0.175933 (* 1 = 0.175933 loss)
I0111 06:05:39.535744  4932 solver.cpp:631] Iteration 61800, lr = 1e-08
I0111 06:05:44.313225  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4273 > 20) by scale factor 0.93339
I0111 06:05:48.753008  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8215 > 20) by scale factor 0.916527
I0111 06:06:04.288498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9803 > 20) by scale factor 0.83402
I0111 06:06:23.920941  4932 solver.cpp:240] Iteration 61820, loss = 0.0769773
I0111 06:06:23.921037  4932 solver.cpp:255]     Train net output #0: loss = 0.067973 (* 1 = 0.067973 loss)
I0111 06:06:23.921051  4932 solver.cpp:631] Iteration 61820, lr = 1e-08
I0111 06:07:02.048873  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7032 > 20) by scale factor 0.80961
I0111 06:07:08.371932  4932 solver.cpp:240] Iteration 61840, loss = 0.0490429
I0111 06:07:08.371974  4932 solver.cpp:255]     Train net output #0: loss = 0.123449 (* 1 = 0.123449 loss)
I0111 06:07:08.371984  4932 solver.cpp:631] Iteration 61840, lr = 1e-08
I0111 06:07:30.905364  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.934 > 20) by scale factor 0.771189
I0111 06:07:52.758657  4932 solver.cpp:240] Iteration 61860, loss = 0.062055
I0111 06:07:52.758735  4932 solver.cpp:255]     Train net output #0: loss = 0.0430031 (* 1 = 0.0430031 loss)
I0111 06:07:52.758746  4932 solver.cpp:631] Iteration 61860, lr = 1e-08
I0111 06:07:55.318586  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.557 > 20) by scale factor 0.654515
I0111 06:08:10.859747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3789 > 20) by scale factor 0.981409
I0111 06:08:28.610224  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.8178 > 20) by scale factor 0.648975
I0111 06:08:37.148433  4932 solver.cpp:240] Iteration 61880, loss = 0.0628064
I0111 06:08:37.148468  4932 solver.cpp:255]     Train net output #0: loss = 0.00917419 (* 1 = 0.00917419 loss)
I0111 06:08:37.148478  4932 solver.cpp:631] Iteration 61880, lr = 1e-08
I0111 06:08:41.924942  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5279 > 20) by scale factor 0.753924
I0111 06:09:21.531471  4932 solver.cpp:240] Iteration 61900, loss = 0.0587134
I0111 06:09:21.531569  4932 solver.cpp:255]     Train net output #0: loss = 0.0911923 (* 1 = 0.0911923 loss)
I0111 06:09:21.531582  4932 solver.cpp:631] Iteration 61900, lr = 1e-08
I0111 06:09:57.390601  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5488 > 20) by scale factor 0.849299
I0111 06:10:05.927608  4932 solver.cpp:240] Iteration 61920, loss = 0.0575584
I0111 06:10:05.927654  4932 solver.cpp:255]     Train net output #0: loss = 0.132702 (* 1 = 0.132702 loss)
I0111 06:10:05.927665  4932 solver.cpp:631] Iteration 61920, lr = 1e-08
I0111 06:10:12.927736  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1009 > 20) by scale factor 0.904942
I0111 06:10:32.899330  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0423 > 20) by scale factor 0.867968
I0111 06:10:43.999006  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3567 > 20) by scale factor 0.982476
I0111 06:10:50.317456  4932 solver.cpp:240] Iteration 61940, loss = 0.0650474
I0111 06:10:50.317507  4932 solver.cpp:255]     Train net output #0: loss = 0.000589987 (* 1 = 0.000589987 loss)
I0111 06:10:50.317520  4932 solver.cpp:631] Iteration 61940, lr = 1e-08
I0111 06:10:52.879886  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.573 > 20) by scale factor 0.782074
I0111 06:11:23.958629  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6834 > 20) by scale factor 0.810261
I0111 06:11:32.842257  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.827 > 20) by scale factor 0.774384
I0111 06:11:34.724488  4932 solver.cpp:240] Iteration 61960, loss = 0.0803158
I0111 06:11:34.724529  4932 solver.cpp:255]     Train net output #0: loss = 0.00154531 (* 1 = 0.00154531 loss)
I0111 06:11:34.724539  4932 solver.cpp:631] Iteration 61960, lr = 1e-08
I0111 06:12:19.117852  4932 solver.cpp:240] Iteration 61980, loss = 0.0476033
I0111 06:12:19.117947  4932 solver.cpp:255]     Train net output #0: loss = 0.290274 (* 1 = 0.290274 loss)
I0111 06:12:19.117961  4932 solver.cpp:631] Iteration 61980, lr = 1e-08
I0111 06:12:19.457245  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8242 > 20) by scale factor 0.960419
I0111 06:12:32.780887  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0125 > 20) by scale factor 0.999374
I0111 06:13:01.811537  4932 solver.cpp:424] Iteration 62000, Testing net (#0)
I0111 06:13:50.660289  4932 solver.cpp:481]     Test net output #0: accuracy = 0.847368
I0111 06:13:50.660373  4932 solver.cpp:481]     Test net output #1: loss = 0.774353 (* 1 = 0.774353 loss)
I0111 06:13:52.526346  4932 solver.cpp:240] Iteration 62000, loss = 0.0526654
I0111 06:13:52.526384  4932 solver.cpp:255]     Train net output #0: loss = 0.0035841 (* 1 = 0.0035841 loss)
I0111 06:13:52.526392  4932 solver.cpp:631] Iteration 62000, lr = 1e-08
I0111 06:14:32.814347  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3183 > 20) by scale factor 0.938159
I0111 06:14:36.913681  4932 solver.cpp:240] Iteration 62020, loss = 0.0637255
I0111 06:14:36.913723  4932 solver.cpp:255]     Train net output #0: loss = 0.156669 (* 1 = 0.156669 loss)
I0111 06:14:36.913739  4932 solver.cpp:631] Iteration 62020, lr = 1e-08
I0111 06:14:37.253082  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2118 > 20) by scale factor 0.763016
I0111 06:15:21.315613  4932 solver.cpp:240] Iteration 62040, loss = 0.048019
I0111 06:15:21.315724  4932 solver.cpp:255]     Train net output #0: loss = 0.00308682 (* 1 = 0.00308682 loss)
I0111 06:15:21.315737  4932 solver.cpp:631] Iteration 62040, lr = 1e-08
I0111 06:16:05.703222  4932 solver.cpp:240] Iteration 62060, loss = 0.0539998
I0111 06:16:05.703305  4932 solver.cpp:255]     Train net output #0: loss = 0.0612112 (* 1 = 0.0612112 loss)
I0111 06:16:05.703320  4932 solver.cpp:631] Iteration 62060, lr = 1e-08
I0111 06:16:50.096981  4932 solver.cpp:240] Iteration 62080, loss = 0.0809537
I0111 06:16:50.097060  4932 solver.cpp:255]     Train net output #0: loss = 0.0183098 (* 1 = 0.0183098 loss)
I0111 06:16:50.097070  4932 solver.cpp:631] Iteration 62080, lr = 1e-08
I0111 06:17:08.188863  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5868 > 20) by scale factor 0.813445
I0111 06:17:14.852306  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0729 > 20) by scale factor 0.90609
I0111 06:17:30.392122  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0939 > 20) by scale factor 0.738174
I0111 06:17:34.492028  4932 solver.cpp:240] Iteration 62100, loss = 0.0675013
I0111 06:17:34.492066  4932 solver.cpp:255]     Train net output #0: loss = 0.0338274 (* 1 = 0.0338274 loss)
I0111 06:17:34.492075  4932 solver.cpp:631] Iteration 62100, lr = 1e-08
I0111 06:17:54.807377  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5293 > 20) by scale factor 0.850004
I0111 06:18:18.892649  4932 solver.cpp:240] Iteration 62120, loss = 0.0706618
I0111 06:18:18.892720  4932 solver.cpp:255]     Train net output #0: loss = 0.0280921 (* 1 = 0.0280921 loss)
I0111 06:18:18.892730  4932 solver.cpp:631] Iteration 62120, lr = 1e-08
I0111 06:19:03.284198  4932 solver.cpp:240] Iteration 62140, loss = 0.0511783
I0111 06:19:03.284289  4932 solver.cpp:255]     Train net output #0: loss = 0.00248417 (* 1 = 0.00248417 loss)
I0111 06:19:03.284301  4932 solver.cpp:631] Iteration 62140, lr = 1e-08
I0111 06:19:34.695343  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6506 > 20) by scale factor 0.779709
I0111 06:19:45.792326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7936 > 20) by scale factor 0.917701
I0111 06:19:47.673437  4932 solver.cpp:240] Iteration 62160, loss = 0.0813281
I0111 06:19:47.673485  4932 solver.cpp:255]     Train net output #0: loss = 0.0113869 (* 1 = 0.0113869 loss)
I0111 06:19:47.673498  4932 solver.cpp:631] Iteration 62160, lr = 1e-08
I0111 06:20:32.138878  4932 solver.cpp:240] Iteration 62180, loss = 0.0320724
I0111 06:20:32.138965  4932 solver.cpp:255]     Train net output #0: loss = 0.0250008 (* 1 = 0.0250008 loss)
I0111 06:20:32.138975  4932 solver.cpp:631] Iteration 62180, lr = 1e-08
I0111 06:20:34.696918  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.831 > 20) by scale factor 0.774262
I0111 06:20:54.677279  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5032 > 20) by scale factor 0.727187
I0111 06:21:14.652181  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4301 > 20) by scale factor 0.89166
I0111 06:21:16.534111  4932 solver.cpp:240] Iteration 62200, loss = 0.0784765
I0111 06:21:16.534155  4932 solver.cpp:255]     Train net output #0: loss = 0.0183765 (* 1 = 0.0183765 loss)
I0111 06:21:16.534168  4932 solver.cpp:631] Iteration 62200, lr = 1e-08
I0111 06:21:39.067778  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.5741 > 20) by scale factor 0.532282
I0111 06:22:00.926407  4932 solver.cpp:240] Iteration 62220, loss = 0.0759843
I0111 06:22:00.926517  4932 solver.cpp:255]     Train net output #0: loss = 0.005514 (* 1 = 0.005514 loss)
I0111 06:22:00.926529  4932 solver.cpp:631] Iteration 62220, lr = 1e-08
I0111 06:22:03.484693  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8397 > 20) by scale factor 0.875669
I0111 06:22:07.925577  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8769 > 20) by scale factor 0.772891
I0111 06:22:25.704663  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.6097 > 20) by scale factor 0.531778
I0111 06:22:45.345902  4932 solver.cpp:240] Iteration 62240, loss = 0.0874263
I0111 06:22:45.346004  4932 solver.cpp:255]     Train net output #0: loss = 0.0367242 (* 1 = 0.0367242 loss)
I0111 06:22:45.346016  4932 solver.cpp:631] Iteration 62240, lr = 1e-08
I0111 06:22:50.127346  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9644 > 20) by scale factor 0.910564
I0111 06:22:59.007495  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9987 > 20) by scale factor 0.95244
I0111 06:23:23.429719  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.1964 > 20) by scale factor 0.709311
I0111 06:23:29.838156  4932 solver.cpp:240] Iteration 62260, loss = 0.0733566
I0111 06:23:29.838198  4932 solver.cpp:255]     Train net output #0: loss = 0.232937 (* 1 = 0.232937 loss)
I0111 06:23:29.838209  4932 solver.cpp:631] Iteration 62260, lr = 1e-08
I0111 06:24:14.243682  4932 solver.cpp:240] Iteration 62280, loss = 0.0602313
I0111 06:24:14.243772  4932 solver.cpp:255]     Train net output #0: loss = 0.0549618 (* 1 = 0.0549618 loss)
I0111 06:24:14.243785  4932 solver.cpp:631] Iteration 62280, lr = 1e-08
I0111 06:24:58.634869  4932 solver.cpp:240] Iteration 62300, loss = 0.0759316
I0111 06:24:58.634963  4932 solver.cpp:255]     Train net output #0: loss = 0.00602256 (* 1 = 0.00602256 loss)
I0111 06:24:58.634976  4932 solver.cpp:631] Iteration 62300, lr = 1e-08
I0111 06:25:25.637429  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1149 > 20) by scale factor 0.99429
I0111 06:25:43.056206  4932 solver.cpp:240] Iteration 62320, loss = 0.0710979
I0111 06:25:43.056301  4932 solver.cpp:255]     Train net output #0: loss = 0.0301206 (* 1 = 0.0301206 loss)
I0111 06:25:43.056318  4932 solver.cpp:631] Iteration 62320, lr = 1e-08
I0111 06:26:12.534049  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4453 > 20) by scale factor 0.891054
I0111 06:26:23.633952  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.381 > 20) by scale factor 0.787991
I0111 06:26:27.734992  4932 solver.cpp:240] Iteration 62340, loss = 0.0758029
I0111 06:26:27.735043  4932 solver.cpp:255]     Train net output #0: loss = 0.0101359 (* 1 = 0.0101359 loss)
I0111 06:26:27.735056  4932 solver.cpp:631] Iteration 62340, lr = 1e-08
I0111 06:27:12.408730  4932 solver.cpp:240] Iteration 62360, loss = 0.0734454
I0111 06:27:12.408824  4932 solver.cpp:255]     Train net output #0: loss = 0.108249 (* 1 = 0.108249 loss)
I0111 06:27:12.408838  4932 solver.cpp:631] Iteration 62360, lr = 1e-08
I0111 06:27:26.063115  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7401 > 20) by scale factor 0.747939
I0111 06:27:32.723774  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9415 > 20) by scale factor 0.955043
I0111 06:27:55.190902  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1209 > 20) by scale factor 0.993992
I0111 06:27:57.072173  4932 solver.cpp:240] Iteration 62380, loss = 0.0742309
I0111 06:27:57.072216  4932 solver.cpp:255]     Train net output #0: loss = 0.0439564 (* 1 = 0.0439564 loss)
I0111 06:27:57.072226  4932 solver.cpp:631] Iteration 62380, lr = 1e-08
I0111 06:28:21.834568  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8797 > 20) by scale factor 0.914088
I0111 06:28:26.277845  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1221 > 20) by scale factor 0.946873
I0111 06:28:35.154846  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0164 > 20) by scale factor 0.689264
I0111 06:28:39.599212  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0016 > 20) by scale factor 0.714246
I0111 06:28:41.482215  4932 solver.cpp:240] Iteration 62400, loss = 0.0823673
I0111 06:28:41.482259  4932 solver.cpp:255]     Train net output #0: loss = 0.315625 (* 1 = 0.315625 loss)
I0111 06:28:41.482270  4932 solver.cpp:631] Iteration 62400, lr = 1e-08
I0111 06:28:41.822721  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0933 > 20) by scale factor 0.905252
I0111 06:28:46.261760  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.919 > 20) by scale factor 0.872639
I0111 06:29:25.868928  4932 solver.cpp:240] Iteration 62420, loss = 0.0569756
I0111 06:29:25.869024  4932 solver.cpp:255]     Train net output #0: loss = 0.0350561 (* 1 = 0.0350561 loss)
I0111 06:29:25.869035  4932 solver.cpp:631] Iteration 62420, lr = 1e-08
I0111 06:29:28.428803  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.913 > 20) by scale factor 0.956341
I0111 06:29:41.746284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3113 > 20) by scale factor 0.732298
I0111 06:30:10.252197  4932 solver.cpp:240] Iteration 62440, loss = 0.120284
I0111 06:30:10.252285  4932 solver.cpp:255]     Train net output #0: loss = 0.161582 (* 1 = 0.161582 loss)
I0111 06:30:10.252296  4932 solver.cpp:631] Iteration 62440, lr = 1e-08
I0111 06:30:43.892866  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1848 > 20) by scale factor 0.944072
I0111 06:30:54.650919  4932 solver.cpp:240] Iteration 62460, loss = 0.0709692
I0111 06:30:54.650954  4932 solver.cpp:255]     Train net output #0: loss = 0.000219226 (* 1 = 0.000219226 loss)
I0111 06:30:54.650962  4932 solver.cpp:631] Iteration 62460, lr = 1e-08
I0111 06:31:39.050344  4932 solver.cpp:240] Iteration 62480, loss = 0.0235509
I0111 06:31:39.050415  4932 solver.cpp:255]     Train net output #0: loss = 0.0193815 (* 1 = 0.0193815 loss)
I0111 06:31:39.050426  4932 solver.cpp:631] Iteration 62480, lr = 1e-08
I0111 06:32:23.560264  4932 solver.cpp:240] Iteration 62500, loss = 0.0502807
I0111 06:32:23.560371  4932 solver.cpp:255]     Train net output #0: loss = 0.00592034 (* 1 = 0.00592034 loss)
I0111 06:32:23.560389  4932 solver.cpp:631] Iteration 62500, lr = 1e-08
I0111 06:32:57.201195  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2375 > 20) by scale factor 0.792471
I0111 06:33:07.959620  4932 solver.cpp:240] Iteration 62520, loss = 0.0493614
I0111 06:33:07.959671  4932 solver.cpp:255]     Train net output #0: loss = 0.00213508 (* 1 = 0.00213508 loss)
I0111 06:33:07.959692  4932 solver.cpp:631] Iteration 62520, lr = 1e-08
I0111 06:33:17.184595  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2503 > 20) by scale factor 0.941162
I0111 06:33:52.360869  4932 solver.cpp:240] Iteration 62540, loss = 0.0729758
I0111 06:33:52.360952  4932 solver.cpp:255]     Train net output #0: loss = 0.0218761 (* 1 = 0.0218761 loss)
I0111 06:33:52.360963  4932 solver.cpp:631] Iteration 62540, lr = 1e-08
I0111 06:34:36.758029  4932 solver.cpp:240] Iteration 62560, loss = 0.0251932
I0111 06:34:36.758121  4932 solver.cpp:255]     Train net output #0: loss = 0.0204917 (* 1 = 0.0204917 loss)
I0111 06:34:36.758134  4932 solver.cpp:631] Iteration 62560, lr = 1e-08
I0111 06:34:54.996927  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6453 > 20) by scale factor 0.674643
I0111 06:35:03.873867  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8879 > 20) by scale factor 0.957492
I0111 06:35:21.296622  4932 solver.cpp:240] Iteration 62580, loss = 0.0950102
I0111 06:35:21.296718  4932 solver.cpp:255]     Train net output #0: loss = 0.109127 (* 1 = 0.109127 loss)
I0111 06:35:21.296732  4932 solver.cpp:631] Iteration 62580, lr = 1e-08
I0111 06:35:37.179210  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9136 > 20) by scale factor 0.743119
I0111 06:35:46.058671  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1099 > 20) by scale factor 0.829535
I0111 06:36:05.696904  4932 solver.cpp:240] Iteration 62600, loss = 0.105982
I0111 06:36:05.697026  4932 solver.cpp:255]     Train net output #0: loss = 0.0528397 (* 1 = 0.0528397 loss)
I0111 06:36:05.697041  4932 solver.cpp:631] Iteration 62600, lr = 1e-08
I0111 06:36:12.699889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3351 > 20) by scale factor 0.759443
I0111 06:36:50.096801  4932 solver.cpp:240] Iteration 62620, loss = 0.0734798
I0111 06:36:50.096884  4932 solver.cpp:255]     Train net output #0: loss = 0.260144 (* 1 = 0.260144 loss)
I0111 06:36:50.096895  4932 solver.cpp:631] Iteration 62620, lr = 1e-08
I0111 06:37:12.634268  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9141 > 20) by scale factor 0.912655
I0111 06:37:34.485081  4932 solver.cpp:240] Iteration 62640, loss = 0.0842195
I0111 06:37:34.485182  4932 solver.cpp:255]     Train net output #0: loss = 0.163609 (* 1 = 0.163609 loss)
I0111 06:37:34.485195  4932 solver.cpp:631] Iteration 62640, lr = 1e-08
I0111 06:37:54.802325  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.08 > 20) by scale factor 0.830564
I0111 06:38:18.878026  4932 solver.cpp:240] Iteration 62660, loss = 0.0894565
I0111 06:38:18.878124  4932 solver.cpp:255]     Train net output #0: loss = 0.0776628 (* 1 = 0.0776628 loss)
I0111 06:38:18.878141  4932 solver.cpp:631] Iteration 62660, lr = 1e-08
I0111 06:38:32.534055  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3828 > 20) by scale factor 0.935333
I0111 06:38:45.858680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4278 > 20) by scale factor 0.89175
I0111 06:39:03.283285  4932 solver.cpp:240] Iteration 62680, loss = 0.0317435
I0111 06:39:03.283350  4932 solver.cpp:255]     Train net output #0: loss = 0.00627887 (* 1 = 0.00627887 loss)
I0111 06:39:03.283361  4932 solver.cpp:631] Iteration 62680, lr = 1e-08
I0111 06:39:23.601831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2851 > 20) by scale factor 0.82355
I0111 06:39:47.682343  4932 solver.cpp:240] Iteration 62700, loss = 0.0837223
I0111 06:39:47.682415  4932 solver.cpp:255]     Train net output #0: loss = 0.00635575 (* 1 = 0.00635575 loss)
I0111 06:39:47.682425  4932 solver.cpp:631] Iteration 62700, lr = 1e-08
I0111 06:40:32.081890  4932 solver.cpp:240] Iteration 62720, loss = 0.0659587
I0111 06:40:32.081972  4932 solver.cpp:255]     Train net output #0: loss = 0.320501 (* 1 = 0.320501 loss)
I0111 06:40:32.081984  4932 solver.cpp:631] Iteration 62720, lr = 1e-08
I0111 06:40:32.421293  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1619 > 20) by scale factor 0.99197
I0111 06:41:16.478519  4932 solver.cpp:240] Iteration 62740, loss = 0.0458582
I0111 06:41:16.478597  4932 solver.cpp:255]     Train net output #0: loss = 0.0308191 (* 1 = 0.0308191 loss)
I0111 06:41:16.478610  4932 solver.cpp:631] Iteration 62740, lr = 1e-08
I0111 06:42:01.047102  4932 solver.cpp:240] Iteration 62760, loss = 0.0539909
I0111 06:42:01.047204  4932 solver.cpp:255]     Train net output #0: loss = 0.00403465 (* 1 = 0.00403465 loss)
I0111 06:42:01.047220  4932 solver.cpp:631] Iteration 62760, lr = 1e-08
I0111 06:42:45.444341  4932 solver.cpp:240] Iteration 62780, loss = 0.0405682
I0111 06:42:45.444433  4932 solver.cpp:255]     Train net output #0: loss = 0.195509 (* 1 = 0.195509 loss)
I0111 06:42:45.444444  4932 solver.cpp:631] Iteration 62780, lr = 1e-08
I0111 06:42:45.783591  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8456 > 20) by scale factor 0.959435
I0111 06:43:29.836607  4932 solver.cpp:240] Iteration 62800, loss = 0.0780315
I0111 06:43:29.836702  4932 solver.cpp:255]     Train net output #0: loss = 0.344769 (* 1 = 0.344769 loss)
I0111 06:43:29.836714  4932 solver.cpp:631] Iteration 62800, lr = 1e-08
I0111 06:43:30.175992  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8613 > 20) by scale factor 0.914858
I0111 06:43:41.281496  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1522 > 20) by scale factor 0.863849
I0111 06:43:59.039980  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5816 > 20) by scale factor 0.725121
I0111 06:44:14.238690  4932 solver.cpp:240] Iteration 62820, loss = 0.0836157
I0111 06:44:14.238819  4932 solver.cpp:255]     Train net output #0: loss = 0.234567 (* 1 = 0.234567 loss)
I0111 06:44:14.238836  4932 solver.cpp:631] Iteration 62820, lr = 1e-08
I0111 06:44:14.579262  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6734 > 20) by scale factor 0.967426
I0111 06:44:50.098448  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6568 > 20) by scale factor 0.968204
I0111 06:44:58.639837  4932 solver.cpp:240] Iteration 62840, loss = 0.0494622
I0111 06:44:58.639885  4932 solver.cpp:255]     Train net output #0: loss = 0.00510293 (* 1 = 0.00510293 loss)
I0111 06:44:58.639899  4932 solver.cpp:631] Iteration 62840, lr = 1e-08
I0111 06:45:03.421712  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4244 > 20) by scale factor 0.756877
I0111 06:45:43.034225  4932 solver.cpp:240] Iteration 62860, loss = 0.0442238
I0111 06:45:43.034294  4932 solver.cpp:255]     Train net output #0: loss = 0.0990862 (* 1 = 0.0990862 loss)
I0111 06:45:43.034304  4932 solver.cpp:631] Iteration 62860, lr = 1e-08
I0111 06:45:43.373598  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3162 > 20) by scale factor 0.857774
I0111 06:46:03.357370  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2587 > 20) by scale factor 0.94079
I0111 06:46:27.436234  4932 solver.cpp:240] Iteration 62880, loss = 0.0835381
I0111 06:46:27.436303  4932 solver.cpp:255]     Train net output #0: loss = 0.0386808 (* 1 = 0.0386808 loss)
I0111 06:46:27.436313  4932 solver.cpp:631] Iteration 62880, lr = 1e-08
I0111 06:46:38.870936  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.732 > 20) by scale factor 0.630278
I0111 06:46:54.413247  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.926 > 20) by scale factor 0.771426
I0111 06:47:03.290751  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5558 > 20) by scale factor 0.849048
I0111 06:47:11.836429  4932 solver.cpp:240] Iteration 62900, loss = 0.101379
I0111 06:47:11.836469  4932 solver.cpp:255]     Train net output #0: loss = 0.390402 (* 1 = 0.390402 loss)
I0111 06:47:11.836479  4932 solver.cpp:631] Iteration 62900, lr = 1e-08
I0111 06:47:12.176102  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7603 > 20) by scale factor 0.776388
I0111 06:47:45.469605  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1781 > 20) by scale factor 0.991174
I0111 06:47:56.235636  4932 solver.cpp:240] Iteration 62920, loss = 0.0505038
I0111 06:47:56.235682  4932 solver.cpp:255]     Train net output #0: loss = 0.00740854 (* 1 = 0.00740854 loss)
I0111 06:47:56.235693  4932 solver.cpp:631] Iteration 62920, lr = 1e-08
I0111 06:47:58.796797  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3453 > 20) by scale factor 0.895041
I0111 06:48:14.335476  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5494 > 20) by scale factor 0.782796
I0111 06:48:40.634390  4932 solver.cpp:240] Iteration 62940, loss = 0.0650295
I0111 06:48:40.634488  4932 solver.cpp:255]     Train net output #0: loss = 0.231107 (* 1 = 0.231107 loss)
I0111 06:48:40.634503  4932 solver.cpp:631] Iteration 62940, lr = 1e-08
I0111 06:48:40.975445  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8132 > 20) by scale factor 0.694126
I0111 06:48:56.511998  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1095 > 20) by scale factor 0.829549
I0111 06:49:25.032232  4932 solver.cpp:240] Iteration 62960, loss = 0.065963
I0111 06:49:25.032336  4932 solver.cpp:255]     Train net output #0: loss = 0.0149567 (* 1 = 0.0149567 loss)
I0111 06:49:25.032347  4932 solver.cpp:631] Iteration 62960, lr = 1e-08
I0111 06:49:27.589257  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3778 > 20) by scale factor 0.935552
I0111 06:49:40.915122  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4231 > 20) by scale factor 0.818896
I0111 06:50:09.436234  4932 solver.cpp:240] Iteration 62980, loss = 0.0782563
I0111 06:50:09.436331  4932 solver.cpp:255]     Train net output #0: loss = 0.0612897 (* 1 = 0.0612897 loss)
I0111 06:50:09.436343  4932 solver.cpp:631] Iteration 62980, lr = 1e-08
I0111 06:50:51.963343  4932 solver.cpp:424] Iteration 63000, Testing net (#0)
I0111 06:51:40.894937  4932 solver.cpp:481]     Test net output #0: accuracy = 0.842105
I0111 06:51:40.895016  4932 solver.cpp:481]     Test net output #1: loss = 0.748277 (* 1 = 0.748277 loss)
I0111 06:51:42.760599  4932 solver.cpp:240] Iteration 63000, loss = 0.049168
I0111 06:51:42.760629  4932 solver.cpp:255]     Train net output #0: loss = 0.146436 (* 1 = 0.146436 loss)
I0111 06:51:42.760638  4932 solver.cpp:631] Iteration 63000, lr = 1e-08
I0111 06:51:49.753666  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1494 > 20) by scale factor 0.902959
I0111 06:52:27.140164  4932 solver.cpp:240] Iteration 63020, loss = 0.0813475
I0111 06:52:27.140252  4932 solver.cpp:255]     Train net output #0: loss = 0.00298831 (* 1 = 0.00298831 loss)
I0111 06:52:27.140265  4932 solver.cpp:631] Iteration 63020, lr = 1e-08
I0111 06:52:43.010473  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9713 > 20) by scale factor 0.953686
I0111 06:53:11.525424  4932 solver.cpp:240] Iteration 63040, loss = 0.0662313
I0111 06:53:11.525523  4932 solver.cpp:255]     Train net output #0: loss = 0.0261222 (* 1 = 0.0261222 loss)
I0111 06:53:11.525537  4932 solver.cpp:631] Iteration 63040, lr = 1e-08
I0111 06:53:55.890396  4932 solver.cpp:240] Iteration 63060, loss = 0.0631419
I0111 06:53:55.890483  4932 solver.cpp:255]     Train net output #0: loss = 0.00796669 (* 1 = 0.00796669 loss)
I0111 06:53:55.890494  4932 solver.cpp:631] Iteration 63060, lr = 1e-08
I0111 06:54:20.644405  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2206 > 20) by scale factor 0.942478
I0111 06:54:40.280478  4932 solver.cpp:240] Iteration 63080, loss = 0.0537374
I0111 06:54:40.280585  4932 solver.cpp:255]     Train net output #0: loss = 0.0472396 (* 1 = 0.0472396 loss)
I0111 06:54:40.280601  4932 solver.cpp:631] Iteration 63080, lr = 1e-08
I0111 06:54:56.150660  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1501 > 20) by scale factor 0.828154
I0111 06:55:16.125195  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4893 > 20) by scale factor 0.930697
I0111 06:55:20.565289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9103 > 20) by scale factor 0.83646
I0111 06:55:24.666568  4932 solver.cpp:240] Iteration 63100, loss = 0.083798
I0111 06:55:24.666607  4932 solver.cpp:255]     Train net output #0: loss = 0.0166018 (* 1 = 0.0166018 loss)
I0111 06:55:24.666616  4932 solver.cpp:631] Iteration 63100, lr = 1e-08
I0111 06:55:33.881494  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 37.7054 > 20) by scale factor 0.530428
I0111 06:56:09.044634  4932 solver.cpp:240] Iteration 63120, loss = 0.0748375
I0111 06:56:09.044718  4932 solver.cpp:255]     Train net output #0: loss = 0.0261393 (* 1 = 0.0261393 loss)
I0111 06:56:09.044729  4932 solver.cpp:631] Iteration 63120, lr = 1e-08
I0111 06:56:49.327034  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1826 > 20) by scale factor 0.827039
I0111 06:56:53.428031  4932 solver.cpp:240] Iteration 63140, loss = 0.0482639
I0111 06:56:53.428077  4932 solver.cpp:255]     Train net output #0: loss = 0.0102379 (* 1 = 0.0102379 loss)
I0111 06:56:53.428089  4932 solver.cpp:631] Iteration 63140, lr = 1e-08
I0111 06:57:13.747643  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2287 > 20) by scale factor 0.988694
I0111 06:57:37.817479  4932 solver.cpp:240] Iteration 63160, loss = 0.0283041
I0111 06:57:37.817567  4932 solver.cpp:255]     Train net output #0: loss = 0.00187492 (* 1 = 0.00187492 loss)
I0111 06:57:37.817579  4932 solver.cpp:631] Iteration 63160, lr = 1e-08
I0111 06:57:47.035971  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8197 > 20) by scale factor 0.774601
I0111 06:58:04.794674  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.9443 > 20) by scale factor 0.770882
I0111 06:58:09.236459  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2878 > 20) by scale factor 0.858819
I0111 06:58:11.460420  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7758 > 20) by scale factor 0.962659
I0111 06:58:22.217638  4932 solver.cpp:240] Iteration 63180, loss = 0.0833355
I0111 06:58:22.217680  4932 solver.cpp:255]     Train net output #0: loss = 0.0571833 (* 1 = 0.0571833 loss)
I0111 06:58:22.217690  4932 solver.cpp:631] Iteration 63180, lr = 1e-08
I0111 06:58:53.618278  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.2887 > 20) by scale factor 0.583282
I0111 06:59:06.596211  4932 solver.cpp:240] Iteration 63200, loss = 0.0617046
I0111 06:59:06.596264  4932 solver.cpp:255]     Train net output #0: loss = 0.0110479 (* 1 = 0.0110479 loss)
I0111 06:59:06.596277  4932 solver.cpp:631] Iteration 63200, lr = 1e-08
I0111 06:59:26.905815  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1314 > 20) by scale factor 0.903692
I0111 06:59:50.975117  4932 solver.cpp:240] Iteration 63220, loss = 0.100399
I0111 06:59:50.975150  4932 solver.cpp:255]     Train net output #0: loss = 0.0154176 (* 1 = 0.0154176 loss)
I0111 06:59:50.975159  4932 solver.cpp:631] Iteration 63220, lr = 1e-08
I0111 07:00:35.362434  4932 solver.cpp:240] Iteration 63240, loss = 0.0692207
I0111 07:00:35.362504  4932 solver.cpp:255]     Train net output #0: loss = 0.115811 (* 1 = 0.115811 loss)
I0111 07:00:35.362514  4932 solver.cpp:631] Iteration 63240, lr = 1e-08
I0111 07:01:11.202968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.4213 > 20) by scale factor 0.72936
I0111 07:01:13.424361  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5163 > 20) by scale factor 0.92953
I0111 07:01:19.742735  4932 solver.cpp:240] Iteration 63260, loss = 0.075613
I0111 07:01:19.742775  4932 solver.cpp:255]     Train net output #0: loss = 0.00639643 (* 1 = 0.00639643 loss)
I0111 07:01:19.742785  4932 solver.cpp:631] Iteration 63260, lr = 1e-08
I0111 07:02:04.128089  4932 solver.cpp:240] Iteration 63280, loss = 0.0857234
I0111 07:02:04.128170  4932 solver.cpp:255]     Train net output #0: loss = 0.125931 (* 1 = 0.125931 loss)
I0111 07:02:04.128181  4932 solver.cpp:631] Iteration 63280, lr = 1e-08
I0111 07:02:39.978876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7034 > 20) by scale factor 0.880924
I0111 07:02:48.521018  4932 solver.cpp:240] Iteration 63300, loss = 0.0741734
I0111 07:02:48.521059  4932 solver.cpp:255]     Train net output #0: loss = 0.00153189 (* 1 = 0.00153189 loss)
I0111 07:02:48.521070  4932 solver.cpp:631] Iteration 63300, lr = 1e-08
I0111 07:03:04.391345  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.251 > 20) by scale factor 0.733919
I0111 07:03:26.594807  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6589 > 20) by scale factor 0.750217
I0111 07:03:28.818498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2271 > 20) by scale factor 0.988772
I0111 07:03:32.921408  4932 solver.cpp:240] Iteration 63320, loss = 0.0683628
I0111 07:03:32.921447  4932 solver.cpp:255]     Train net output #0: loss = 0.0272288 (* 1 = 0.0272288 loss)
I0111 07:03:32.921456  4932 solver.cpp:631] Iteration 63320, lr = 1e-08
I0111 07:03:44.356869  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6703 > 20) by scale factor 0.882213
I0111 07:03:48.799613  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0953 > 20) by scale factor 0.948077
I0111 07:03:51.022296  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0628 > 20) by scale factor 0.767376
I0111 07:04:17.318305  4932 solver.cpp:240] Iteration 63340, loss = 0.086078
I0111 07:04:17.318418  4932 solver.cpp:255]     Train net output #0: loss = 0.00587636 (* 1 = 0.00587636 loss)
I0111 07:04:17.318433  4932 solver.cpp:631] Iteration 63340, lr = 1e-08
I0111 07:04:53.169466  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6362 > 20) by scale factor 0.924375
I0111 07:04:55.390898  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7909 > 20) by scale factor 0.961961
I0111 07:05:01.709862  4932 solver.cpp:240] Iteration 63360, loss = 0.0884371
I0111 07:05:01.709895  4932 solver.cpp:255]     Train net output #0: loss = 0.0660673 (* 1 = 0.0660673 loss)
I0111 07:05:01.709904  4932 solver.cpp:631] Iteration 63360, lr = 1e-08
I0111 07:05:15.366096  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.927 > 20) by scale factor 0.626429
I0111 07:05:26.469086  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0769 > 20) by scale factor 0.948908
I0111 07:05:42.004391  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4356 > 20) by scale factor 0.978685
I0111 07:05:46.104811  4932 solver.cpp:240] Iteration 63380, loss = 0.0770955
I0111 07:05:46.104851  4932 solver.cpp:255]     Train net output #0: loss = 0.000221775 (* 1 = 0.000221775 loss)
I0111 07:05:46.104859  4932 solver.cpp:631] Iteration 63380, lr = 1e-08
I0111 07:06:30.491622  4932 solver.cpp:240] Iteration 63400, loss = 0.0465838
I0111 07:06:30.491705  4932 solver.cpp:255]     Train net output #0: loss = 0.00556664 (* 1 = 0.00556664 loss)
I0111 07:06:30.491716  4932 solver.cpp:631] Iteration 63400, lr = 1e-08
I0111 07:07:14.876147  4932 solver.cpp:240] Iteration 63420, loss = 0.0436624
I0111 07:07:14.876235  4932 solver.cpp:255]     Train net output #0: loss = 0.000462016 (* 1 = 0.000462016 loss)
I0111 07:07:14.876246  4932 solver.cpp:631] Iteration 63420, lr = 1e-08
I0111 07:07:32.961575  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9545 > 20) by scale factor 0.95445
I0111 07:07:59.252415  4932 solver.cpp:240] Iteration 63440, loss = 0.0656916
I0111 07:07:59.252487  4932 solver.cpp:255]     Train net output #0: loss = 0.0101904 (* 1 = 0.0101904 loss)
I0111 07:07:59.252498  4932 solver.cpp:631] Iteration 63440, lr = 1e-08
I0111 07:08:08.464331  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2069 > 20) by scale factor 0.989762
I0111 07:08:43.626536  4932 solver.cpp:240] Iteration 63460, loss = 0.0434476
I0111 07:08:43.626606  4932 solver.cpp:255]     Train net output #0: loss = 0.0207421 (* 1 = 0.0207421 loss)
I0111 07:08:43.626616  4932 solver.cpp:631] Iteration 63460, lr = 1e-08
I0111 07:09:26.137284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9785 > 20) by scale factor 0.74133
I0111 07:09:28.019693  4932 solver.cpp:240] Iteration 63480, loss = 0.0583925
I0111 07:09:28.019726  4932 solver.cpp:255]     Train net output #0: loss = 0.0508504 (* 1 = 0.0508504 loss)
I0111 07:09:28.019736  4932 solver.cpp:631] Iteration 63480, lr = 1e-08
I0111 07:09:32.798362  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2689 > 20) by scale factor 0.940338
I0111 07:09:39.458242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1974 > 20) by scale factor 0.901005
I0111 07:09:43.897116  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9316 > 20) by scale factor 0.691286
I0111 07:09:46.118186  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0362 > 20) by scale factor 0.998195
I0111 07:10:12.411001  4932 solver.cpp:240] Iteration 63500, loss = 0.0821312
I0111 07:10:12.411088  4932 solver.cpp:255]     Train net output #0: loss = 0.00130769 (* 1 = 0.00130769 loss)
I0111 07:10:12.411098  4932 solver.cpp:631] Iteration 63500, lr = 1e-08
I0111 07:10:56.792328  4932 solver.cpp:240] Iteration 63520, loss = 0.0501233
I0111 07:10:56.792412  4932 solver.cpp:255]     Train net output #0: loss = 0.0120433 (* 1 = 0.0120433 loss)
I0111 07:10:56.792423  4932 solver.cpp:631] Iteration 63520, lr = 1e-08
I0111 07:11:41.178174  4932 solver.cpp:240] Iteration 63540, loss = 0.0761147
I0111 07:11:41.178259  4932 solver.cpp:255]     Train net output #0: loss = 0.188191 (* 1 = 0.188191 loss)
I0111 07:11:41.178269  4932 solver.cpp:631] Iteration 63540, lr = 1e-08
I0111 07:11:41.517284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.282 > 20) by scale factor 0.986094
I0111 07:11:59.273538  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3941 > 20) by scale factor 0.980677
I0111 07:12:25.571184  4932 solver.cpp:240] Iteration 63560, loss = 0.0603582
I0111 07:12:25.571261  4932 solver.cpp:255]     Train net output #0: loss = 0.082113 (* 1 = 0.082113 loss)
I0111 07:12:25.571272  4932 solver.cpp:631] Iteration 63560, lr = 1e-08
I0111 07:12:50.315493  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5701 > 20) by scale factor 0.927208
I0111 07:13:09.957319  4932 solver.cpp:240] Iteration 63580, loss = 0.0802182
I0111 07:13:09.957404  4932 solver.cpp:255]     Train net output #0: loss = 0.0993606 (* 1 = 0.0993606 loss)
I0111 07:13:09.957417  4932 solver.cpp:631] Iteration 63580, lr = 1e-08
I0111 07:13:12.518663  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0993 > 20) by scale factor 0.766303
I0111 07:13:30.269403  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2722 > 20) by scale factor 0.76126
I0111 07:13:54.348021  4932 solver.cpp:240] Iteration 63600, loss = 0.109618
I0111 07:13:54.348100  4932 solver.cpp:255]     Train net output #0: loss = 0.00781655 (* 1 = 0.00781655 loss)
I0111 07:13:54.348114  4932 solver.cpp:631] Iteration 63600, lr = 1e-08
I0111 07:14:38.730778  4932 solver.cpp:240] Iteration 63620, loss = 0.0552373
I0111 07:14:38.730875  4932 solver.cpp:255]     Train net output #0: loss = 0.209397 (* 1 = 0.209397 loss)
I0111 07:14:38.730891  4932 solver.cpp:631] Iteration 63620, lr = 1e-08
I0111 07:15:01.260488  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7752 > 20) by scale factor 0.878147
I0111 07:15:16.795697  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9152 > 20) by scale factor 0.956243
I0111 07:15:23.112679  4932 solver.cpp:240] Iteration 63640, loss = 0.094657
I0111 07:15:23.112715  4932 solver.cpp:255]     Train net output #0: loss = 0.0356478 (* 1 = 0.0356478 loss)
I0111 07:15:23.112725  4932 solver.cpp:631] Iteration 63640, lr = 1e-08
I0111 07:15:25.671365  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1459 > 20) by scale factor 0.992756
I0111 07:15:50.083555  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8498 > 20) by scale factor 0.915341
I0111 07:16:05.618289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6378 > 20) by scale factor 0.780099
I0111 07:16:07.500258  4932 solver.cpp:240] Iteration 63660, loss = 0.105287
I0111 07:16:07.500295  4932 solver.cpp:255]     Train net output #0: loss = 0.468585 (* 1 = 0.468585 loss)
I0111 07:16:07.500304  4932 solver.cpp:631] Iteration 63660, lr = 1e-08
I0111 07:16:51.866035  4932 solver.cpp:240] Iteration 63680, loss = 0.0624361
I0111 07:16:51.866127  4932 solver.cpp:255]     Train net output #0: loss = 0.0822499 (* 1 = 0.0822499 loss)
I0111 07:16:51.866140  4932 solver.cpp:631] Iteration 63680, lr = 1e-08
I0111 07:17:07.741798  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5732 > 20) by scale factor 0.699957
I0111 07:17:36.253700  4932 solver.cpp:240] Iteration 63700, loss = 0.0679568
I0111 07:17:36.253808  4932 solver.cpp:255]     Train net output #0: loss = 0.0853439 (* 1 = 0.0853439 loss)
I0111 07:17:36.253821  4932 solver.cpp:631] Iteration 63700, lr = 1e-08
I0111 07:18:20.643332  4932 solver.cpp:240] Iteration 63720, loss = 0.0586889
I0111 07:18:20.643402  4932 solver.cpp:255]     Train net output #0: loss = 0.305497 (* 1 = 0.305497 loss)
I0111 07:18:20.643412  4932 solver.cpp:631] Iteration 63720, lr = 1e-08
I0111 07:18:20.982492  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0535 > 20) by scale factor 0.997332
I0111 07:18:43.181134  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1596 > 20) by scale factor 0.992085
I0111 07:19:05.038722  4932 solver.cpp:240] Iteration 63740, loss = 0.056724
I0111 07:19:05.038797  4932 solver.cpp:255]     Train net output #0: loss = 0.113887 (* 1 = 0.113887 loss)
I0111 07:19:05.038808  4932 solver.cpp:631] Iteration 63740, lr = 1e-08
I0111 07:19:14.253358  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8544 > 20) by scale factor 0.915147
I0111 07:19:27.574326  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6567 > 20) by scale factor 0.968207
I0111 07:19:49.427666  4932 solver.cpp:240] Iteration 63760, loss = 0.0907643
I0111 07:19:49.427737  4932 solver.cpp:255]     Train net output #0: loss = 0.00258823 (* 1 = 0.00258823 loss)
I0111 07:19:49.427747  4932 solver.cpp:631] Iteration 63760, lr = 1e-08
I0111 07:20:33.808648  4932 solver.cpp:240] Iteration 63780, loss = 0.0449999
I0111 07:20:33.808737  4932 solver.cpp:255]     Train net output #0: loss = 0.0132005 (* 1 = 0.0132005 loss)
I0111 07:20:33.808750  4932 solver.cpp:631] Iteration 63780, lr = 1e-08
I0111 07:20:40.809340  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3466 > 20) by scale factor 0.856655
I0111 07:21:07.439702  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.937 > 20) by scale factor 0.955249
I0111 07:21:18.197854  4932 solver.cpp:240] Iteration 63800, loss = 0.0745335
I0111 07:21:18.197893  4932 solver.cpp:255]     Train net output #0: loss = 0.007459 (* 1 = 0.007459 loss)
I0111 07:21:18.197902  4932 solver.cpp:631] Iteration 63800, lr = 1e-08
I0111 07:21:51.830654  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0648 > 20) by scale factor 0.94945
I0111 07:21:56.270246  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6364 > 20) by scale factor 0.924369
I0111 07:21:58.492216  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.288 > 20) by scale factor 0.897345
I0111 07:22:02.592540  4932 solver.cpp:240] Iteration 63820, loss = 0.0647568
I0111 07:22:02.592588  4932 solver.cpp:255]     Train net output #0: loss = 0.0335338 (* 1 = 0.0335338 loss)
I0111 07:22:02.592600  4932 solver.cpp:631] Iteration 63820, lr = 1e-08
I0111 07:22:05.152474  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9695 > 20) by scale factor 0.870719
I0111 07:22:31.784389  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7557 > 20) by scale factor 0.776528
I0111 07:22:46.978188  4932 solver.cpp:240] Iteration 63840, loss = 0.0740662
I0111 07:22:46.978245  4932 solver.cpp:255]     Train net output #0: loss = 0.179389 (* 1 = 0.179389 loss)
I0111 07:22:46.978260  4932 solver.cpp:631] Iteration 63840, lr = 1e-08
I0111 07:22:47.319730  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8784 > 20) by scale factor 0.957927
I0111 07:23:31.370476  4932 solver.cpp:240] Iteration 63860, loss = 0.0320022
I0111 07:23:31.370549  4932 solver.cpp:255]     Train net output #0: loss = 0.0256873 (* 1 = 0.0256873 loss)
I0111 07:23:31.370559  4932 solver.cpp:631] Iteration 63860, lr = 1e-08
I0111 07:23:42.806011  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1465 > 20) by scale factor 0.736744
I0111 07:24:15.745532  4932 solver.cpp:240] Iteration 63880, loss = 0.0540115
I0111 07:24:15.745630  4932 solver.cpp:255]     Train net output #0: loss = 0.0067462 (* 1 = 0.0067462 loss)
I0111 07:24:15.745641  4932 solver.cpp:631] Iteration 63880, lr = 1e-08
I0111 07:24:24.961263  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4793 > 20) by scale factor 0.755308
I0111 07:25:00.121894  4932 solver.cpp:240] Iteration 63900, loss = 0.0592488
I0111 07:25:00.121974  4932 solver.cpp:255]     Train net output #0: loss = 0.00805909 (* 1 = 0.00805909 loss)
I0111 07:25:00.121984  4932 solver.cpp:631] Iteration 63900, lr = 1e-08
I0111 07:25:07.120156  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5895 > 20) by scale factor 0.926375
I0111 07:25:36.087505  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1782 > 20) by scale factor 0.685444
I0111 07:25:44.626579  4932 solver.cpp:240] Iteration 63920, loss = 0.0656003
I0111 07:25:44.626613  4932 solver.cpp:255]     Train net output #0: loss = 0.0572538 (* 1 = 0.0572538 loss)
I0111 07:25:44.626622  4932 solver.cpp:631] Iteration 63920, lr = 1e-08
I0111 07:26:20.478255  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5467 > 20) by scale factor 0.973394
I0111 07:26:29.023612  4932 solver.cpp:240] Iteration 63940, loss = 0.0735819
I0111 07:26:29.023646  4932 solver.cpp:255]     Train net output #0: loss = 7.93784e-05 (* 1 = 7.93784e-05 loss)
I0111 07:26:29.023656  4932 solver.cpp:631] Iteration 63940, lr = 1e-08
I0111 07:27:13.397524  4932 solver.cpp:240] Iteration 63960, loss = 0.055895
I0111 07:27:13.397614  4932 solver.cpp:255]     Train net output #0: loss = 0.0040666 (* 1 = 0.0040666 loss)
I0111 07:27:13.397629  4932 solver.cpp:631] Iteration 63960, lr = 1e-08
I0111 07:27:22.614008  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0497 > 20) by scale factor 0.997521
I0111 07:27:57.775804  4932 solver.cpp:240] Iteration 63980, loss = 0.0536306
I0111 07:27:57.775878  4932 solver.cpp:255]     Train net output #0: loss = 0.0767146 (* 1 = 0.0767146 loss)
I0111 07:27:57.775888  4932 solver.cpp:631] Iteration 63980, lr = 1e-08
I0111 07:28:18.081271  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.912 > 20) by scale factor 0.956387
I0111 07:28:40.279171  4932 solver.cpp:424] Iteration 64000, Testing net (#0)
I0111 07:29:31.151666  4932 solver.cpp:481]     Test net output #0: accuracy = 0.826316
I0111 07:29:31.151751  4932 solver.cpp:481]     Test net output #1: loss = 0.924243 (* 1 = 0.924243 loss)
I0111 07:29:33.018484  4932 solver.cpp:240] Iteration 64000, loss = 0.0705818
I0111 07:29:33.018514  4932 solver.cpp:255]     Train net output #0: loss = 0.171965 (* 1 = 0.171965 loss)
I0111 07:29:33.018523  4932 solver.cpp:631] Iteration 64000, lr = 1e-08
I0111 07:30:17.438845  4932 solver.cpp:240] Iteration 64020, loss = 0.0488266
I0111 07:30:17.438921  4932 solver.cpp:255]     Train net output #0: loss = 0.208537 (* 1 = 0.208537 loss)
I0111 07:30:17.438932  4932 solver.cpp:631] Iteration 64020, lr = 1e-08
I0111 07:30:28.873160  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8112 > 20) by scale factor 0.774858
I0111 07:31:01.843684  4932 solver.cpp:240] Iteration 64040, loss = 0.0719898
I0111 07:31:01.843745  4932 solver.cpp:255]     Train net output #0: loss = 0.067533 (* 1 = 0.067533 loss)
I0111 07:31:01.843755  4932 solver.cpp:631] Iteration 64040, lr = 1e-08
I0111 07:31:46.225867  4932 solver.cpp:240] Iteration 64060, loss = 0.0631955
I0111 07:31:46.225952  4932 solver.cpp:255]     Train net output #0: loss = 0.190159 (* 1 = 0.190159 loss)
I0111 07:31:46.225963  4932 solver.cpp:631] Iteration 64060, lr = 1e-08
I0111 07:31:48.782467  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8069 > 20) by scale factor 0.87693
I0111 07:32:30.619961  4932 solver.cpp:240] Iteration 64080, loss = 0.0599717
I0111 07:32:30.620051  4932 solver.cpp:255]     Train net output #0: loss = 0.0885982 (* 1 = 0.0885982 loss)
I0111 07:32:30.620065  4932 solver.cpp:631] Iteration 64080, lr = 1e-08
I0111 07:33:15.003072  4932 solver.cpp:240] Iteration 64100, loss = 0.0485543
I0111 07:33:15.003199  4932 solver.cpp:255]     Train net output #0: loss = 0.107593 (* 1 = 0.107593 loss)
I0111 07:33:15.003216  4932 solver.cpp:631] Iteration 64100, lr = 1e-08
I0111 07:33:46.407615  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1314 > 20) by scale factor 0.828795
I0111 07:33:59.388633  4932 solver.cpp:240] Iteration 64120, loss = 0.0662413
I0111 07:33:59.388677  4932 solver.cpp:255]     Train net output #0: loss = 0.0929699 (* 1 = 0.0929699 loss)
I0111 07:33:59.388689  4932 solver.cpp:631] Iteration 64120, lr = 1e-08
I0111 07:34:06.385812  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.16 > 20) by scale factor 0.641848
I0111 07:34:10.830019  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.093 > 20) by scale factor 0.711921
I0111 07:34:21.924917  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0193 > 20) by scale factor 0.832664
I0111 07:34:30.803839  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3901 > 20) by scale factor 0.855062
I0111 07:34:43.776773  4932 solver.cpp:240] Iteration 64140, loss = 0.0747
I0111 07:34:43.776821  4932 solver.cpp:255]     Train net output #0: loss = 0.0495876 (* 1 = 0.0495876 loss)
I0111 07:34:43.776834  4932 solver.cpp:631] Iteration 64140, lr = 1e-08
I0111 07:35:34.660892  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6149 > 20) by scale factor 0.970174
I0111 07:35:36.543108  4932 solver.cpp:240] Iteration 64160, loss = 0.0700835
I0111 07:35:36.543140  4932 solver.cpp:255]     Train net output #0: loss = 0.169941 (* 1 = 0.169941 loss)
I0111 07:35:36.543149  4932 solver.cpp:631] Iteration 64160, lr = 1e-08
I0111 07:35:43.537498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9586 > 20) by scale factor 0.834774
I0111 07:35:45.759796  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3195 > 20) by scale factor 0.938109
I0111 07:36:16.832453  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5868 > 20) by scale factor 0.699623
I0111 07:36:20.935813  4932 solver.cpp:240] Iteration 64180, loss = 0.0865492
I0111 07:36:20.935853  4932 solver.cpp:255]     Train net output #0: loss = 0.0583033 (* 1 = 0.0583033 loss)
I0111 07:36:20.935864  4932 solver.cpp:631] Iteration 64180, lr = 1e-08
I0111 07:37:05.342787  4932 solver.cpp:240] Iteration 64200, loss = 0.0473385
I0111 07:37:05.342897  4932 solver.cpp:255]     Train net output #0: loss = 0.0143211 (* 1 = 0.0143211 loss)
I0111 07:37:05.342913  4932 solver.cpp:631] Iteration 64200, lr = 1e-08
I0111 07:37:25.667242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2639 > 20) by scale factor 0.986978
I0111 07:37:49.756481  4932 solver.cpp:240] Iteration 64220, loss = 0.0767953
I0111 07:37:49.756574  4932 solver.cpp:255]     Train net output #0: loss = 0.0645478 (* 1 = 0.0645478 loss)
I0111 07:37:49.756587  4932 solver.cpp:631] Iteration 64220, lr = 1e-08
I0111 07:38:32.283432  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2098 > 20) by scale factor 0.900503
I0111 07:38:34.166199  4932 solver.cpp:240] Iteration 64240, loss = 0.0464448
I0111 07:38:34.166250  4932 solver.cpp:255]     Train net output #0: loss = 0.0121027 (* 1 = 0.0121027 loss)
I0111 07:38:34.166394  4932 solver.cpp:631] Iteration 64240, lr = 1e-08
I0111 07:39:03.399464  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4793 > 20) by scale factor 0.817016
I0111 07:39:10.054718  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9484 > 20) by scale factor 0.871519
I0111 07:39:18.591348  4932 solver.cpp:240] Iteration 64260, loss = 0.0512809
I0111 07:39:18.591384  4932 solver.cpp:255]     Train net output #0: loss = 0.00697435 (* 1 = 0.00697435 loss)
I0111 07:39:18.591394  4932 solver.cpp:631] Iteration 64260, lr = 1e-08
I0111 07:39:38.895941  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8179 > 20) by scale factor 0.916679
I0111 07:40:02.966998  4932 solver.cpp:240] Iteration 64280, loss = 0.0534523
I0111 07:40:02.967037  4932 solver.cpp:255]     Train net output #0: loss = 0.0330858 (* 1 = 0.0330858 loss)
I0111 07:40:02.967047  4932 solver.cpp:631] Iteration 64280, lr = 1e-08
I0111 07:40:12.185636  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3596 > 20) by scale factor 0.936347
I0111 07:40:21.062981  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9747 > 20) by scale factor 0.910136
I0111 07:40:41.046403  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5741 > 20) by scale factor 0.92704
I0111 07:40:47.371186  4932 solver.cpp:240] Iteration 64300, loss = 0.0721664
I0111 07:40:47.371270  4932 solver.cpp:255]     Train net output #0: loss = 0.0374507 (* 1 = 0.0374507 loss)
I0111 07:40:47.371281  4932 solver.cpp:631] Iteration 64300, lr = 1e-08
I0111 07:40:54.367804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2233 > 20) by scale factor 0.899956
I0111 07:41:31.764533  4932 solver.cpp:240] Iteration 64320, loss = 0.0570491
I0111 07:41:31.764639  4932 solver.cpp:255]     Train net output #0: loss = 0.00149056 (* 1 = 0.00149056 loss)
I0111 07:41:31.764653  4932 solver.cpp:631] Iteration 64320, lr = 1e-08
I0111 07:41:49.890741  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4155 > 20) by scale factor 0.979649
I0111 07:42:16.180172  4932 solver.cpp:240] Iteration 64340, loss = 0.0805786
I0111 07:42:16.180261  4932 solver.cpp:255]     Train net output #0: loss = 0.158629 (* 1 = 0.158629 loss)
I0111 07:42:16.180272  4932 solver.cpp:631] Iteration 64340, lr = 1e-08
I0111 07:43:00.566232  4932 solver.cpp:240] Iteration 64360, loss = 0.0493388
I0111 07:43:00.566334  4932 solver.cpp:255]     Train net output #0: loss = 0.0247146 (* 1 = 0.0247146 loss)
I0111 07:43:00.566350  4932 solver.cpp:631] Iteration 64360, lr = 1e-08
I0111 07:43:12.007431  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.094 > 20) by scale factor 0.866025
I0111 07:43:27.539621  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5954 > 20) by scale factor 0.885137
I0111 07:43:45.036960  4932 solver.cpp:240] Iteration 64380, loss = 0.0819226
I0111 07:43:45.037060  4932 solver.cpp:255]     Train net output #0: loss = 0.0623349 (* 1 = 0.0623349 loss)
I0111 07:43:45.037075  4932 solver.cpp:631] Iteration 64380, lr = 1e-08
I0111 07:44:12.009922  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1799 > 20) by scale factor 0.827133
I0111 07:44:29.423177  4932 solver.cpp:240] Iteration 64400, loss = 0.0712395
I0111 07:44:29.423274  4932 solver.cpp:255]     Train net output #0: loss = 0.121991 (* 1 = 0.121991 loss)
I0111 07:44:29.423285  4932 solver.cpp:631] Iteration 64400, lr = 1e-08
I0111 07:44:58.610448  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.753 > 20) by scale factor 0.610632
I0111 07:45:13.803620  4932 solver.cpp:240] Iteration 64420, loss = 0.0453123
I0111 07:45:13.803712  4932 solver.cpp:255]     Train net output #0: loss = 0.00574849 (* 1 = 0.00574849 loss)
I0111 07:45:13.803725  4932 solver.cpp:631] Iteration 64420, lr = 1e-08
I0111 07:45:49.647558  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.0097 > 20) by scale factor 0.689425
I0111 07:45:58.186878  4932 solver.cpp:240] Iteration 64440, loss = 0.0569537
I0111 07:45:58.186918  4932 solver.cpp:255]     Train net output #0: loss = 0.0354971 (* 1 = 0.0354971 loss)
I0111 07:45:58.186929  4932 solver.cpp:631] Iteration 64440, lr = 1e-08
I0111 07:46:14.059267  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.119 > 20) by scale factor 0.86509
I0111 07:46:42.562791  4932 solver.cpp:240] Iteration 64460, loss = 0.0619232
I0111 07:46:42.562894  4932 solver.cpp:255]     Train net output #0: loss = 0.0251461 (* 1 = 0.0251461 loss)
I0111 07:46:42.562911  4932 solver.cpp:631] Iteration 64460, lr = 1e-08
I0111 07:47:05.096215  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0552 > 20) by scale factor 0.867481
I0111 07:47:13.971537  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2263 > 20) by scale factor 0.861091
I0111 07:47:26.953405  4932 solver.cpp:240] Iteration 64480, loss = 0.0439187
I0111 07:47:26.953445  4932 solver.cpp:255]     Train net output #0: loss = 0.0122413 (* 1 = 0.0122413 loss)
I0111 07:47:26.953457  4932 solver.cpp:631] Iteration 64480, lr = 1e-08
I0111 07:48:05.022364  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1085 > 20) by scale factor 0.994604
I0111 07:48:11.344413  4932 solver.cpp:240] Iteration 64500, loss = 0.0629857
I0111 07:48:11.344446  4932 solver.cpp:255]     Train net output #0: loss = 0.159476 (* 1 = 0.159476 loss)
I0111 07:48:11.344456  4932 solver.cpp:631] Iteration 64500, lr = 1e-08
I0111 07:48:33.869766  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1726 > 20) by scale factor 0.902013
I0111 07:48:53.839876  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5944 > 20) by scale factor 0.926165
I0111 07:48:55.721830  4932 solver.cpp:240] Iteration 64520, loss = 0.101648
I0111 07:48:55.721871  4932 solver.cpp:255]     Train net output #0: loss = 0.427231 (* 1 = 0.427231 loss)
I0111 07:48:55.721881  4932 solver.cpp:631] Iteration 64520, lr = 1e-08
I0111 07:48:56.061089  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9791 > 20) by scale factor 0.870355
I0111 07:49:40.093168  4932 solver.cpp:240] Iteration 64540, loss = 0.0575226
I0111 07:49:40.093261  4932 solver.cpp:255]     Train net output #0: loss = 0.0149662 (* 1 = 0.0149662 loss)
I0111 07:49:40.093274  4932 solver.cpp:631] Iteration 64540, lr = 1e-08
I0111 07:50:18.156878  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1096 > 20) by scale factor 0.99455
I0111 07:50:24.480154  4932 solver.cpp:240] Iteration 64560, loss = 0.0701283
I0111 07:50:24.480195  4932 solver.cpp:255]     Train net output #0: loss = 0.00943381 (* 1 = 0.00943381 loss)
I0111 07:50:24.480206  4932 solver.cpp:631] Iteration 64560, lr = 1e-08
I0111 07:51:08.923048  4932 solver.cpp:240] Iteration 64580, loss = 0.0555391
I0111 07:51:08.923131  4932 solver.cpp:255]     Train net output #0: loss = 0.0253601 (* 1 = 0.0253601 loss)
I0111 07:51:08.923142  4932 solver.cpp:631] Iteration 64580, lr = 1e-08
I0111 07:51:24.795889  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.137 > 20) by scale factor 0.864416
I0111 07:51:42.550285  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5955 > 20) by scale factor 0.885131
I0111 07:51:49.210505  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4057 > 20) by scale factor 0.854494
I0111 07:51:53.311288  4932 solver.cpp:240] Iteration 64600, loss = 0.0821787
I0111 07:51:53.311326  4932 solver.cpp:255]     Train net output #0: loss = 0.214904 (* 1 = 0.214904 loss)
I0111 07:51:53.311336  4932 solver.cpp:631] Iteration 64600, lr = 1e-08
I0111 07:52:13.620893  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6384 > 20) by scale factor 0.846081
I0111 07:52:26.941938  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4961 > 20) by scale factor 0.851204
I0111 07:52:35.817019  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.0096 > 20) by scale factor 0.740477
I0111 07:52:37.698799  4932 solver.cpp:240] Iteration 64620, loss = 0.0784891
I0111 07:52:37.698840  4932 solver.cpp:255]     Train net output #0: loss = 0.129581 (* 1 = 0.129581 loss)
I0111 07:52:37.698850  4932 solver.cpp:631] Iteration 64620, lr = 1e-08
I0111 07:52:38.037879  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6958 > 20) by scale factor 0.844033
I0111 07:53:09.114878  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2846 > 20) by scale factor 0.89748
I0111 07:53:15.772204  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5279 > 20) by scale factor 0.887789
I0111 07:53:22.091727  4932 solver.cpp:240] Iteration 64640, loss = 0.0724457
I0111 07:53:22.091770  4932 solver.cpp:255]     Train net output #0: loss = 0.0136282 (* 1 = 0.0136282 loss)
I0111 07:53:22.091783  4932 solver.cpp:631] Iteration 64640, lr = 1e-08
I0111 07:53:55.725647  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4065 > 20) by scale factor 0.934296
I0111 07:54:06.481968  4932 solver.cpp:240] Iteration 64660, loss = 0.075044
I0111 07:54:06.482008  4932 solver.cpp:255]     Train net output #0: loss = 0.0633504 (* 1 = 0.0633504 loss)
I0111 07:54:06.482017  4932 solver.cpp:631] Iteration 64660, lr = 1e-08
I0111 07:54:42.337448  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8123 > 20) by scale factor 0.839902
I0111 07:54:50.877769  4932 solver.cpp:240] Iteration 64680, loss = 0.0442856
I0111 07:54:50.877816  4932 solver.cpp:255]     Train net output #0: loss = 0.0690285 (* 1 = 0.0690285 loss)
I0111 07:54:50.877827  4932 solver.cpp:631] Iteration 64680, lr = 1e-08
I0111 07:55:35.259019  4932 solver.cpp:240] Iteration 64700, loss = 0.0533193
I0111 07:55:35.259096  4932 solver.cpp:255]     Train net output #0: loss = 0.0427317 (* 1 = 0.0427317 loss)
I0111 07:55:35.259110  4932 solver.cpp:631] Iteration 64700, lr = 1e-08
I0111 07:56:19.642410  4932 solver.cpp:240] Iteration 64720, loss = 0.0685292
I0111 07:56:19.642480  4932 solver.cpp:255]     Train net output #0: loss = 0.0999677 (* 1 = 0.0999677 loss)
I0111 07:56:19.642493  4932 solver.cpp:631] Iteration 64720, lr = 1e-08
I0111 07:57:04.021201  4932 solver.cpp:240] Iteration 64740, loss = 0.0646834
I0111 07:57:04.021275  4932 solver.cpp:255]     Train net output #0: loss = 0.0433295 (* 1 = 0.0433295 loss)
I0111 07:57:04.021288  4932 solver.cpp:631] Iteration 64740, lr = 1e-08
I0111 07:57:30.994313  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2798 > 20) by scale factor 0.986201
I0111 07:57:48.406394  4932 solver.cpp:240] Iteration 64760, loss = 0.0493068
I0111 07:57:48.406471  4932 solver.cpp:255]     Train net output #0: loss = 0.011234 (* 1 = 0.011234 loss)
I0111 07:57:48.406481  4932 solver.cpp:631] Iteration 64760, lr = 1e-08
I0111 07:58:17.589066  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8541 > 20) by scale factor 0.773571
I0111 07:58:32.784266  4932 solver.cpp:240] Iteration 64780, loss = 0.0902485
I0111 07:58:32.784351  4932 solver.cpp:255]     Train net output #0: loss = 0.0598461 (* 1 = 0.0598461 loss)
I0111 07:58:32.784363  4932 solver.cpp:631] Iteration 64780, lr = 1e-08
I0111 07:59:17.155683  4932 solver.cpp:240] Iteration 64800, loss = 0.0367463
I0111 07:59:17.155774  4932 solver.cpp:255]     Train net output #0: loss = 0.0208058 (* 1 = 0.0208058 loss)
I0111 07:59:17.155788  4932 solver.cpp:631] Iteration 64800, lr = 1e-08
I0111 07:59:26.372047  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2579 > 20) by scale factor 0.98727
I0111 07:59:33.030140  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2255 > 20) by scale factor 0.861123
I0111 07:59:44.126874  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8868 > 20) by scale factor 0.837283
I0111 08:00:01.539686  4932 solver.cpp:240] Iteration 64820, loss = 0.121194
I0111 08:00:01.539767  4932 solver.cpp:255]     Train net output #0: loss = 0.260753 (* 1 = 0.260753 loss)
I0111 08:00:01.539777  4932 solver.cpp:631] Iteration 64820, lr = 1e-08
I0111 08:00:01.879020  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.6425 > 20) by scale factor 0.632062
I0111 08:00:45.926743  4932 solver.cpp:240] Iteration 64840, loss = 0.0374066
I0111 08:00:45.926822  4932 solver.cpp:255]     Train net output #0: loss = 0.03675 (* 1 = 0.03675 loss)
I0111 08:00:45.926833  4932 solver.cpp:631] Iteration 64840, lr = 1e-08
I0111 08:01:30.301584  4932 solver.cpp:240] Iteration 64860, loss = 0.0347941
I0111 08:01:30.301672  4932 solver.cpp:255]     Train net output #0: loss = 0.00919794 (* 1 = 0.00919794 loss)
I0111 08:01:30.301683  4932 solver.cpp:631] Iteration 64860, lr = 1e-08
I0111 08:01:55.046609  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.844 > 20) by scale factor 0.875505
I0111 08:02:14.684509  4932 solver.cpp:240] Iteration 64880, loss = 0.0524667
I0111 08:02:14.684605  4932 solver.cpp:255]     Train net output #0: loss = 0.0651862 (* 1 = 0.0651862 loss)
I0111 08:02:14.684618  4932 solver.cpp:631] Iteration 64880, lr = 1e-08
I0111 08:02:19.463049  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4904 > 20) by scale factor 0.976068
I0111 08:02:28.339962  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1417 > 20) by scale factor 0.864241
I0111 08:02:32.783651  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2526 > 20) by scale factor 0.791999
I0111 08:02:59.074626  4932 solver.cpp:240] Iteration 64900, loss = 0.080359
I0111 08:02:59.074725  4932 solver.cpp:255]     Train net output #0: loss = 0.0151558 (* 1 = 0.0151558 loss)
I0111 08:02:59.074741  4932 solver.cpp:631] Iteration 64900, lr = 1e-08
I0111 08:03:43.859352  4932 solver.cpp:240] Iteration 64920, loss = 0.0662155
I0111 08:03:43.859446  4932 solver.cpp:255]     Train net output #0: loss = 0.242004 (* 1 = 0.242004 loss)
I0111 08:03:43.859458  4932 solver.cpp:631] Iteration 64920, lr = 1e-08
I0111 08:03:50.858230  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0741 > 20) by scale factor 0.99631
I0111 08:04:15.270875  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1441 > 20) by scale factor 0.903174
I0111 08:04:28.250516  4932 solver.cpp:240] Iteration 64940, loss = 0.0693464
I0111 08:04:28.250548  4932 solver.cpp:255]     Train net output #0: loss = 0.021434 (* 1 = 0.021434 loss)
I0111 08:04:28.250557  4932 solver.cpp:631] Iteration 64940, lr = 1e-08
I0111 08:05:12.628553  4932 solver.cpp:240] Iteration 64960, loss = 0.0523058
I0111 08:05:12.628643  4932 solver.cpp:255]     Train net output #0: loss = 0.0105924 (* 1 = 0.0105924 loss)
I0111 08:05:12.628656  4932 solver.cpp:631] Iteration 64960, lr = 1e-08
I0111 08:05:35.156930  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1391 > 20) by scale factor 0.946116
I0111 08:05:57.007623  4932 solver.cpp:240] Iteration 64980, loss = 0.0671347
I0111 08:05:57.007719  4932 solver.cpp:255]     Train net output #0: loss = 0.0574985 (* 1 = 0.0574985 loss)
I0111 08:05:57.007730  4932 solver.cpp:631] Iteration 64980, lr = 1e-08
I0111 08:06:26.193097  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0697 > 20) by scale factor 0.767174
I0111 08:06:30.632309  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.3354 > 20) by scale factor 0.599963
I0111 08:06:39.515486  4932 solver.cpp:424] Iteration 65000, Testing net (#0)
I0111 08:07:30.855103  4932 solver.cpp:481]     Test net output #0: accuracy = 0.814737
I0111 08:07:30.855206  4932 solver.cpp:481]     Test net output #1: loss = 0.950453 (* 1 = 0.950453 loss)
I0111 08:07:32.721765  4932 solver.cpp:240] Iteration 65000, loss = 0.0883366
I0111 08:07:32.721796  4932 solver.cpp:255]     Train net output #0: loss = 0.0131297 (* 1 = 0.0131297 loss)
I0111 08:07:32.721806  4932 solver.cpp:631] Iteration 65000, lr = 1e-08
I0111 08:08:06.332346  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4746 > 20) by scale factor 0.851985
I0111 08:08:17.082375  4932 solver.cpp:240] Iteration 65020, loss = 0.0743608
I0111 08:08:17.082420  4932 solver.cpp:255]     Train net output #0: loss = 0.140688 (* 1 = 0.140688 loss)
I0111 08:08:17.082432  4932 solver.cpp:631] Iteration 65020, lr = 1e-08
I0111 08:08:26.296757  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1328 > 20) by scale factor 0.993402
I0111 08:09:01.454335  4932 solver.cpp:240] Iteration 65040, loss = 0.0622976
I0111 08:09:01.454464  4932 solver.cpp:255]     Train net output #0: loss = 0.162619 (* 1 = 0.162619 loss)
I0111 08:09:01.454479  4932 solver.cpp:631] Iteration 65040, lr = 1e-08
I0111 08:09:12.888123  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9514 > 20) by scale factor 0.954592
I0111 08:09:45.830649  4932 solver.cpp:240] Iteration 65060, loss = 0.0499261
I0111 08:09:45.830745  4932 solver.cpp:255]     Train net output #0: loss = 0.00441118 (* 1 = 0.00441118 loss)
I0111 08:09:45.830760  4932 solver.cpp:631] Iteration 65060, lr = 1e-08
I0111 08:10:23.885169  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3536 > 20) by scale factor 0.936611
I0111 08:10:30.206589  4932 solver.cpp:240] Iteration 65080, loss = 0.0532315
I0111 08:10:30.206627  4932 solver.cpp:255]     Train net output #0: loss = 0.150076 (* 1 = 0.150076 loss)
I0111 08:10:30.206637  4932 solver.cpp:631] Iteration 65080, lr = 1e-08
I0111 08:10:30.546051  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4878 > 20) by scale factor 0.851505
I0111 08:10:46.073252  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1133 > 20) by scale factor 0.904431
I0111 08:11:14.582464  4932 solver.cpp:240] Iteration 65100, loss = 0.0476599
I0111 08:11:14.582538  4932 solver.cpp:255]     Train net output #0: loss = 0.00697366 (* 1 = 0.00697366 loss)
I0111 08:11:14.582548  4932 solver.cpp:631] Iteration 65100, lr = 1e-08
I0111 08:11:23.798374  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3899 > 20) by scale factor 0.93502
I0111 08:11:57.084501  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5875 > 20) by scale factor 0.847906
I0111 08:11:58.966511  4932 solver.cpp:240] Iteration 65120, loss = 0.0420988
I0111 08:11:58.966549  4932 solver.cpp:255]     Train net output #0: loss = 0.0547355 (* 1 = 0.0547355 loss)
I0111 08:11:58.966558  4932 solver.cpp:631] Iteration 65120, lr = 1e-08
I0111 08:12:08.185240  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4175 > 20) by scale factor 0.933814
I0111 08:12:41.463639  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6586 > 20) by scale factor 0.923422
I0111 08:12:43.345737  4932 solver.cpp:240] Iteration 65140, loss = 0.0641961
I0111 08:12:43.345777  4932 solver.cpp:255]     Train net output #0: loss = 0.0107837 (* 1 = 0.0107837 loss)
I0111 08:12:43.345789  4932 solver.cpp:631] Iteration 65140, lr = 1e-08
I0111 08:14:04.524148  4932 solver.cpp:240] Iteration 65160, loss = 0.0567985
I0111 08:14:04.524232  4932 solver.cpp:255]     Train net output #0: loss = 0.0613382 (* 1 = 0.0613382 loss)
I0111 08:14:04.524245  4932 solver.cpp:631] Iteration 65160, lr = 1e-08
I0111 08:14:49.225417  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.4956 > 20) by scale factor 0.655832
I0111 08:14:57.049675  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.1303 > 20) by scale factor 0.68657
I0111 08:15:21.827105  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4188 > 20) by scale factor 0.757038
I0111 08:16:03.079846  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5247 > 20) by scale factor 0.783554
I0111 08:16:12.293009  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5992 > 20) by scale factor 0.847485
I0111 08:16:26.707806  4932 solver.cpp:240] Iteration 65180, loss = 0.111283
I0111 08:16:26.707839  4932 solver.cpp:255]     Train net output #0: loss = 0.0135407 (* 1 = 0.0135407 loss)
I0111 08:16:26.707846  4932 solver.cpp:631] Iteration 65180, lr = 1e-08
I0111 08:17:04.270138  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1663 > 20) by scale factor 0.902271
I0111 08:17:53.556434  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9994 > 20) by scale factor 0.909114
I0111 08:18:06.526480  4932 solver.cpp:240] Iteration 65200, loss = 0.0840825
I0111 08:18:06.526521  4932 solver.cpp:255]     Train net output #0: loss = 0.0476512 (* 1 = 0.0476512 loss)
I0111 08:18:06.526530  4932 solver.cpp:631] Iteration 65200, lr = 1e-08
I0111 08:18:22.392650  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4954 > 20) by scale factor 0.816481
I0111 08:18:26.829022  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8249 > 20) by scale factor 0.774447
I0111 08:18:50.897681  4932 solver.cpp:240] Iteration 65220, loss = 0.0750784
I0111 08:18:50.897728  4932 solver.cpp:255]     Train net output #0: loss = 0.00521222 (* 1 = 0.00521222 loss)
I0111 08:18:50.897739  4932 solver.cpp:631] Iteration 65220, lr = 1e-08
I0111 08:19:22.300096  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5782 > 20) by scale factor 0.88581
I0111 08:19:35.272797  4932 solver.cpp:240] Iteration 65240, loss = 0.0544315
I0111 08:19:35.272838  4932 solver.cpp:255]     Train net output #0: loss = 0.0350337 (* 1 = 0.0350337 loss)
I0111 08:19:35.272847  4932 solver.cpp:631] Iteration 65240, lr = 1e-08
I0111 08:19:42.270313  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.9719 > 20) by scale factor 0.645746
I0111 08:20:19.655208  4932 solver.cpp:240] Iteration 65260, loss = 0.0564148
I0111 08:20:19.655303  4932 solver.cpp:255]     Train net output #0: loss = 0.0181587 (* 1 = 0.0181587 loss)
I0111 08:20:19.655318  4932 solver.cpp:631] Iteration 65260, lr = 1e-08
I0111 08:20:35.529220  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3047 > 20) by scale factor 0.984992
I0111 08:20:53.281081  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1037 > 20) by scale factor 0.829748
I0111 08:21:04.036458  4932 solver.cpp:240] Iteration 65280, loss = 0.051997
I0111 08:21:04.036497  4932 solver.cpp:255]     Train net output #0: loss = 0.139712 (* 1 = 0.139712 loss)
I0111 08:21:04.036507  4932 solver.cpp:631] Iteration 65280, lr = 1e-08
I0111 08:21:39.877012  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0623 > 20) by scale factor 0.949565
I0111 08:21:48.418052  4932 solver.cpp:240] Iteration 65300, loss = 0.0595278
I0111 08:21:48.418099  4932 solver.cpp:255]     Train net output #0: loss = 0.102554 (* 1 = 0.102554 loss)
I0111 08:21:48.418112  4932 solver.cpp:631] Iteration 65300, lr = 1e-08
I0111 08:21:48.758242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8746 > 20) by scale factor 0.717498
I0111 08:22:22.041265  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1995 > 20) by scale factor 0.943417
I0111 08:22:32.797499  4932 solver.cpp:240] Iteration 65320, loss = 0.0404944
I0111 08:22:32.797549  4932 solver.cpp:255]     Train net output #0: loss = 0.000980781 (* 1 = 0.000980781 loss)
I0111 08:22:32.797562  4932 solver.cpp:631] Iteration 65320, lr = 1e-08
I0111 08:22:35.360769  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.22 > 20) by scale factor 0.584454
I0111 08:22:39.806455  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.182 > 20) by scale factor 0.862739
I0111 08:22:53.119451  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0488 > 20) by scale factor 0.950172
I0111 08:23:17.187925  4932 solver.cpp:240] Iteration 65340, loss = 0.0894611
I0111 08:23:17.187966  4932 solver.cpp:255]     Train net output #0: loss = 0.121801 (* 1 = 0.121801 loss)
I0111 08:23:17.187975  4932 solver.cpp:631] Iteration 65340, lr = 1e-08
I0111 08:23:19.746747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9619 > 20) by scale factor 0.834659
I0111 08:24:01.576575  4932 solver.cpp:240] Iteration 65360, loss = 0.046439
I0111 08:24:01.576671  4932 solver.cpp:255]     Train net output #0: loss = 0.00306766 (* 1 = 0.00306766 loss)
I0111 08:24:01.576684  4932 solver.cpp:631] Iteration 65360, lr = 1e-08
I0111 08:24:45.953557  4932 solver.cpp:240] Iteration 65380, loss = 0.0312928
I0111 08:24:45.953691  4932 solver.cpp:255]     Train net output #0: loss = 0.0066961 (* 1 = 0.0066961 loss)
I0111 08:24:45.953707  4932 solver.cpp:631] Iteration 65380, lr = 1e-08
I0111 08:25:04.046481  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0572 > 20) by scale factor 0.831353
I0111 08:25:30.338575  4932 solver.cpp:240] Iteration 65400, loss = 0.0581623
I0111 08:25:30.338666  4932 solver.cpp:255]     Train net output #0: loss = 0.0305163 (* 1 = 0.0305163 loss)
I0111 08:25:30.338678  4932 solver.cpp:631] Iteration 65400, lr = 1e-08
I0111 08:25:46.209864  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8745 > 20) by scale factor 0.804038
I0111 08:26:08.404834  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8897 > 20) by scale factor 0.95741
I0111 08:26:12.845247  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0336 > 20) by scale factor 0.950862
I0111 08:26:14.727560  4932 solver.cpp:240] Iteration 65420, loss = 0.0831958
I0111 08:26:14.727601  4932 solver.cpp:255]     Train net output #0: loss = 0.0645201 (* 1 = 0.0645201 loss)
I0111 08:26:14.727610  4932 solver.cpp:631] Iteration 65420, lr = 1e-08
I0111 08:26:48.357255  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5841 > 20) by scale factor 0.971626
I0111 08:26:59.117251  4932 solver.cpp:240] Iteration 65440, loss = 0.0896454
I0111 08:26:59.117296  4932 solver.cpp:255]     Train net output #0: loss = 0.0224716 (* 1 = 0.0224716 loss)
I0111 08:26:59.117308  4932 solver.cpp:631] Iteration 65440, lr = 1e-08
I0111 08:27:08.334722  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4737 > 20) by scale factor 0.785125
I0111 08:27:19.438398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4538 > 20) by scale factor 0.977813
I0111 08:27:43.511713  4932 solver.cpp:240] Iteration 65460, loss = 0.0565364
I0111 08:27:43.511765  4932 solver.cpp:255]     Train net output #0: loss = 0.000576564 (* 1 = 0.000576564 loss)
I0111 08:27:43.511778  4932 solver.cpp:631] Iteration 65460, lr = 1e-08
I0111 08:27:50.512238  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0907 > 20) by scale factor 0.866151
I0111 08:27:59.385740  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9416 > 20) by scale factor 0.955035
I0111 08:28:03.827565  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.262 > 20) by scale factor 0.940645
I0111 08:28:27.895947  4932 solver.cpp:240] Iteration 65480, loss = 0.0802134
I0111 08:28:27.896028  4932 solver.cpp:255]     Train net output #0: loss = 0.0192889 (* 1 = 0.0192889 loss)
I0111 08:28:27.896039  4932 solver.cpp:631] Iteration 65480, lr = 1e-08
I0111 08:28:32.669044  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3074 > 20) by scale factor 0.822795
I0111 08:29:12.278264  4932 solver.cpp:240] Iteration 65500, loss = 0.0432087
I0111 08:29:12.278338  4932 solver.cpp:255]     Train net output #0: loss = 0.0985117 (* 1 = 0.0985117 loss)
I0111 08:29:12.278350  4932 solver.cpp:631] Iteration 65500, lr = 1e-08
I0111 08:29:56.663385  4932 solver.cpp:240] Iteration 65520, loss = 0.0649246
I0111 08:29:56.663449  4932 solver.cpp:255]     Train net output #0: loss = 0.142032 (* 1 = 0.142032 loss)
I0111 08:29:56.663458  4932 solver.cpp:631] Iteration 65520, lr = 1e-08
I0111 08:30:41.045131  4932 solver.cpp:240] Iteration 65540, loss = 0.020672
I0111 08:30:41.045202  4932 solver.cpp:255]     Train net output #0: loss = 0.0118448 (* 1 = 0.0118448 loss)
I0111 08:30:41.045212  4932 solver.cpp:631] Iteration 65540, lr = 1e-08
I0111 08:31:25.435778  4932 solver.cpp:240] Iteration 65560, loss = 0.0802634
I0111 08:31:25.435856  4932 solver.cpp:255]     Train net output #0: loss = 0.391641 (* 1 = 0.391641 loss)
I0111 08:31:25.435866  4932 solver.cpp:631] Iteration 65560, lr = 1e-08
I0111 08:31:25.775018  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0899 > 20) by scale factor 0.995527
I0111 08:32:09.829188  4932 solver.cpp:240] Iteration 65580, loss = 0.0384403
I0111 08:32:09.829300  4932 solver.cpp:255]     Train net output #0: loss = 0.0343106 (* 1 = 0.0343106 loss)
I0111 08:32:09.829314  4932 solver.cpp:631] Iteration 65580, lr = 1e-08
I0111 08:32:27.921998  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1898 > 20) by scale factor 0.763657
I0111 08:32:41.241999  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3271 > 20) by scale factor 0.822128
I0111 08:32:54.218665  4932 solver.cpp:240] Iteration 65600, loss = 0.056253
I0111 08:32:54.218704  4932 solver.cpp:255]     Train net output #0: loss = 0.0627357 (* 1 = 0.0627357 loss)
I0111 08:32:54.218713  4932 solver.cpp:631] Iteration 65600, lr = 1e-08
I0111 08:33:38.597793  4932 solver.cpp:240] Iteration 65620, loss = 0.0434343
I0111 08:33:38.597873  4932 solver.cpp:255]     Train net output #0: loss = 0.00249538 (* 1 = 0.00249538 loss)
I0111 08:33:38.597884  4932 solver.cpp:631] Iteration 65620, lr = 1e-08
I0111 08:34:22.985988  4932 solver.cpp:240] Iteration 65640, loss = 0.0303497
I0111 08:34:22.986073  4932 solver.cpp:255]     Train net output #0: loss = 0.0154878 (* 1 = 0.0154878 loss)
I0111 08:34:22.986084  4932 solver.cpp:631] Iteration 65640, lr = 1e-08
I0111 08:35:07.377075  4932 solver.cpp:240] Iteration 65660, loss = 0.0952331
I0111 08:35:07.377166  4932 solver.cpp:255]     Train net output #0: loss = 0.0686962 (* 1 = 0.0686962 loss)
I0111 08:35:07.377182  4932 solver.cpp:631] Iteration 65660, lr = 1e-08
I0111 08:35:18.813451  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1992 > 20) by scale factor 0.990139
I0111 08:35:49.885998  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3312 > 20) by scale factor 0.983708
I0111 08:35:51.767987  4932 solver.cpp:240] Iteration 65680, loss = 0.057856
I0111 08:35:51.768024  4932 solver.cpp:255]     Train net output #0: loss = 0.0522707 (* 1 = 0.0522707 loss)
I0111 08:35:51.768033  4932 solver.cpp:631] Iteration 65680, lr = 1e-08
I0111 08:35:54.324864  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1147 > 20) by scale factor 0.737607
I0111 08:36:05.421494  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3979 > 20) by scale factor 0.980493
I0111 08:36:36.156111  4932 solver.cpp:240] Iteration 65700, loss = 0.0794553
I0111 08:36:36.156203  4932 solver.cpp:255]     Train net output #0: loss = 0.0141002 (* 1 = 0.0141002 loss)
I0111 08:36:36.156215  4932 solver.cpp:631] Iteration 65700, lr = 1e-08
I0111 08:37:03.127563  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5049 > 20) by scale factor 0.930022
I0111 08:37:20.536269  4932 solver.cpp:240] Iteration 65720, loss = 0.0664865
I0111 08:37:20.536346  4932 solver.cpp:255]     Train net output #0: loss = 0.085306 (* 1 = 0.085306 loss)
I0111 08:37:20.536356  4932 solver.cpp:631] Iteration 65720, lr = 1e-08
I0111 08:37:40.850422  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.5638 > 20) by scale factor 0.752904
I0111 08:38:04.928442  4932 solver.cpp:240] Iteration 65740, loss = 0.068627
I0111 08:38:04.928509  4932 solver.cpp:255]     Train net output #0: loss = 0.0155508 (* 1 = 0.0155508 loss)
I0111 08:38:04.928520  4932 solver.cpp:631] Iteration 65740, lr = 1e-08
I0111 08:38:31.897565  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2989 > 20) by scale factor 0.939016
I0111 08:38:49.320992  4932 solver.cpp:240] Iteration 65760, loss = 0.0353532
I0111 08:38:49.321068  4932 solver.cpp:255]     Train net output #0: loss = 0.0197263 (* 1 = 0.0197263 loss)
I0111 08:38:49.321079  4932 solver.cpp:631] Iteration 65760, lr = 1e-08
I0111 08:39:20.729928  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8823 > 20) by scale factor 0.874038
I0111 08:39:31.830127  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.176 > 20) by scale factor 0.764059
I0111 08:39:33.713616  4932 solver.cpp:240] Iteration 65780, loss = 0.0840669
I0111 08:39:33.713659  4932 solver.cpp:255]     Train net output #0: loss = 0.0066365 (* 1 = 0.0066365 loss)
I0111 08:39:33.713670  4932 solver.cpp:631] Iteration 65780, lr = 1e-08
I0111 08:40:18.098242  4932 solver.cpp:240] Iteration 65800, loss = 0.0627734
I0111 08:40:18.098320  4932 solver.cpp:255]     Train net output #0: loss = 0.342611 (* 1 = 0.342611 loss)
I0111 08:40:18.098330  4932 solver.cpp:631] Iteration 65800, lr = 1e-08
I0111 08:40:36.187204  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.4917 > 20) by scale factor 0.678156
I0111 08:40:40.629442  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9377 > 20) by scale factor 0.715877
I0111 08:40:56.162937  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 34.2158 > 20) by scale factor 0.584525
I0111 08:41:02.482894  4932 solver.cpp:240] Iteration 65820, loss = 0.0807827
I0111 08:41:02.482933  4932 solver.cpp:255]     Train net output #0: loss = 0.0475384 (* 1 = 0.0475384 loss)
I0111 08:41:02.482942  4932 solver.cpp:631] Iteration 65820, lr = 1e-08
I0111 08:41:46.862741  4932 solver.cpp:240] Iteration 65840, loss = 0.0690423
I0111 08:41:46.862815  4932 solver.cpp:255]     Train net output #0: loss = 0.0729877 (* 1 = 0.0729877 loss)
I0111 08:41:46.862826  4932 solver.cpp:631] Iteration 65840, lr = 1e-08
I0111 08:42:09.384526  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6145 > 20) by scale factor 0.970189
I0111 08:42:27.141214  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 40.4968 > 20) by scale factor 0.493866
I0111 08:42:31.244381  4932 solver.cpp:240] Iteration 65860, loss = 0.112283
I0111 08:42:31.244426  4932 solver.cpp:255]     Train net output #0: loss = 0.00622191 (* 1 = 0.00622191 loss)
I0111 08:42:31.244437  4932 solver.cpp:631] Iteration 65860, lr = 1e-08
I0111 08:42:49.334318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1655 > 20) by scale factor 0.863351
I0111 08:43:02.647189  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4274 > 20) by scale factor 0.933384
I0111 08:43:15.628535  4932 solver.cpp:240] Iteration 65880, loss = 0.0626753
I0111 08:43:15.628583  4932 solver.cpp:255]     Train net output #0: loss = 0.0384773 (* 1 = 0.0384773 loss)
I0111 08:43:15.628597  4932 solver.cpp:631] Iteration 65880, lr = 1e-08
I0111 08:44:00.017766  4932 solver.cpp:240] Iteration 65900, loss = 0.0728396
I0111 08:44:00.017843  4932 solver.cpp:255]     Train net output #0: loss = 0.278608 (* 1 = 0.278608 loss)
I0111 08:44:00.017853  4932 solver.cpp:631] Iteration 65900, lr = 1e-08
I0111 08:44:00.357322  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2892 > 20) by scale factor 0.823411
I0111 08:44:44.388909  4932 solver.cpp:240] Iteration 65920, loss = 0.047034
I0111 08:44:44.388990  4932 solver.cpp:255]     Train net output #0: loss = 0.313881 (* 1 = 0.313881 loss)
I0111 08:44:44.389000  4932 solver.cpp:631] Iteration 65920, lr = 1e-08
I0111 08:44:46.947088  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8155 > 20) by scale factor 0.805948
I0111 08:44:55.830226  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1256 > 20) by scale factor 0.864843
I0111 08:45:13.585723  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1255 > 20) by scale factor 0.796005
I0111 08:45:15.807360  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1804 > 20) by scale factor 0.794268
I0111 08:45:28.793458  4932 solver.cpp:240] Iteration 65940, loss = 0.0859069
I0111 08:45:28.793505  4932 solver.cpp:255]     Train net output #0: loss = 0.027873 (* 1 = 0.027873 loss)
I0111 08:45:28.793516  4932 solver.cpp:631] Iteration 65940, lr = 1e-08
I0111 08:45:49.101966  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7854 > 20) by scale factor 0.775634
I0111 08:46:13.172976  4932 solver.cpp:240] Iteration 65960, loss = 0.0528587
I0111 08:46:13.173030  4932 solver.cpp:255]     Train net output #0: loss = 0.0258297 (* 1 = 0.0258297 loss)
I0111 08:46:13.173043  4932 solver.cpp:631] Iteration 65960, lr = 1e-08
I0111 08:46:57.548029  4932 solver.cpp:240] Iteration 65980, loss = 0.0499213
I0111 08:46:57.548128  4932 solver.cpp:255]     Train net output #0: loss = 0.0834323 (* 1 = 0.0834323 loss)
I0111 08:46:57.548144  4932 solver.cpp:631] Iteration 65980, lr = 1e-08
I0111 08:47:04.553170  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.765 > 20) by scale factor 0.878541
I0111 08:47:22.308318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8372 > 20) by scale factor 0.805244
I0111 08:47:40.062782  4932 solver.cpp:424] Iteration 66000, Testing net (#0)
I0111 08:48:30.918303  4932 solver.cpp:481]     Test net output #0: accuracy = 0.852632
I0111 08:48:30.918380  4932 solver.cpp:481]     Test net output #1: loss = 0.72522 (* 1 = 0.72522 loss)
I0111 08:48:32.785122  4932 solver.cpp:240] Iteration 66000, loss = 0.0733558
I0111 08:48:32.785159  4932 solver.cpp:255]     Train net output #0: loss = 0.119249 (* 1 = 0.119249 loss)
I0111 08:48:32.785168  4932 solver.cpp:631] Iteration 66000, lr = 1e-08
I0111 08:48:48.655226  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7436 > 20) by scale factor 0.919809
I0111 08:49:17.161255  4932 solver.cpp:240] Iteration 66020, loss = 0.0355701
I0111 08:49:17.161346  4932 solver.cpp:255]     Train net output #0: loss = 0.029073 (* 1 = 0.029073 loss)
I0111 08:49:17.161356  4932 solver.cpp:631] Iteration 66020, lr = 1e-08
I0111 08:50:01.532272  4932 solver.cpp:240] Iteration 66040, loss = 0.0704277
I0111 08:50:01.532366  4932 solver.cpp:255]     Train net output #0: loss = 0.0851677 (* 1 = 0.0851677 loss)
I0111 08:50:01.532378  4932 solver.cpp:631] Iteration 66040, lr = 1e-08
I0111 08:50:06.310614  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8808 > 20) by scale factor 0.837493
I0111 08:50:17.406925  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4024 > 20) by scale factor 0.892762
I0111 08:50:45.924147  4932 solver.cpp:240] Iteration 66060, loss = 0.0785135
I0111 08:50:45.924224  4932 solver.cpp:255]     Train net output #0: loss = 0.00910294 (* 1 = 0.00910294 loss)
I0111 08:50:45.924234  4932 solver.cpp:631] Iteration 66060, lr = 1e-08
I0111 08:51:30.302280  4932 solver.cpp:240] Iteration 66080, loss = 0.0893491
I0111 08:51:30.302355  4932 solver.cpp:255]     Train net output #0: loss = 0.0467878 (* 1 = 0.0467878 loss)
I0111 08:51:30.302364  4932 solver.cpp:631] Iteration 66080, lr = 1e-08
I0111 08:52:14.663259  4932 solver.cpp:240] Iteration 66100, loss = 0.0232984
I0111 08:52:14.663338  4932 solver.cpp:255]     Train net output #0: loss = 0.0177697 (* 1 = 0.0177697 loss)
I0111 08:52:14.663348  4932 solver.cpp:631] Iteration 66100, lr = 1e-08
I0111 08:52:34.968286  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5415 > 20) by scale factor 0.973641
I0111 08:52:48.286168  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2754 > 20) by scale factor 0.823879
I0111 08:52:59.045598  4932 solver.cpp:240] Iteration 66120, loss = 0.0929261
I0111 08:52:59.045642  4932 solver.cpp:255]     Train net output #0: loss = 0.272829 (* 1 = 0.272829 loss)
I0111 08:52:59.045655  4932 solver.cpp:631] Iteration 66120, lr = 1e-08
I0111 08:53:19.363015  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9127 > 20) by scale factor 0.956355
I0111 08:53:43.430874  4932 solver.cpp:240] Iteration 66140, loss = 0.0914053
I0111 08:53:43.430912  4932 solver.cpp:255]     Train net output #0: loss = 0.0674532 (* 1 = 0.0674532 loss)
I0111 08:53:43.430922  4932 solver.cpp:631] Iteration 66140, lr = 1e-08
I0111 08:54:27.817780  4932 solver.cpp:240] Iteration 66160, loss = 0.0495854
I0111 08:54:27.817879  4932 solver.cpp:255]     Train net output #0: loss = 0.0423984 (* 1 = 0.0423984 loss)
I0111 08:54:27.817890  4932 solver.cpp:631] Iteration 66160, lr = 1e-08
I0111 08:54:43.689141  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1208 > 20) by scale factor 0.796153
I0111 08:54:54.792165  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6499 > 20) by scale factor 0.84567
I0111 08:54:57.013001  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.7919 > 20) by scale factor 0.746494
I0111 08:55:10.326391  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.957 > 20) by scale factor 0.834829
I0111 08:55:12.208545  4932 solver.cpp:240] Iteration 66180, loss = 0.0835331
I0111 08:55:12.208577  4932 solver.cpp:255]     Train net output #0: loss = 0.0059759 (* 1 = 0.0059759 loss)
I0111 08:55:12.208587  4932 solver.cpp:631] Iteration 66180, lr = 1e-08
I0111 08:55:16.986682  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7745 > 20) by scale factor 0.807281
I0111 08:55:30.308872  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6642 > 20) by scale factor 0.967857
I0111 08:55:56.596451  4932 solver.cpp:240] Iteration 66200, loss = 0.0679768
I0111 08:55:56.596531  4932 solver.cpp:255]     Train net output #0: loss = 0.0986161 (* 1 = 0.0986161 loss)
I0111 08:55:56.596541  4932 solver.cpp:631] Iteration 66200, lr = 1e-08
I0111 08:56:27.995028  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.7055 > 20) by scale factor 0.593375
I0111 08:56:40.964669  4932 solver.cpp:240] Iteration 66220, loss = 0.0766587
I0111 08:56:40.964714  4932 solver.cpp:255]     Train net output #0: loss = 0.0679334 (* 1 = 0.0679334 loss)
I0111 08:56:40.964725  4932 solver.cpp:631] Iteration 66220, lr = 1e-08
I0111 08:57:25.341605  4932 solver.cpp:240] Iteration 66240, loss = 0.0632153
I0111 08:57:25.341681  4932 solver.cpp:255]     Train net output #0: loss = 0.0432382 (* 1 = 0.0432382 loss)
I0111 08:57:25.341691  4932 solver.cpp:631] Iteration 66240, lr = 1e-08
I0111 08:57:32.336539  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0046 > 20) by scale factor 0.714169
I0111 08:58:09.719039  4932 solver.cpp:240] Iteration 66260, loss = 0.0746089
I0111 08:58:09.719117  4932 solver.cpp:255]     Train net output #0: loss = 0.0106498 (* 1 = 0.0106498 loss)
I0111 08:58:09.719127  4932 solver.cpp:631] Iteration 66260, lr = 1e-08
I0111 08:58:54.093171  4932 solver.cpp:240] Iteration 66280, loss = 0.0321689
I0111 08:58:54.093245  4932 solver.cpp:255]     Train net output #0: loss = 0.00267494 (* 1 = 0.00267494 loss)
I0111 08:58:54.093255  4932 solver.cpp:631] Iteration 66280, lr = 1e-08
I0111 08:59:05.523282  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.3759 > 20) by scale factor 0.565357
I0111 08:59:36.584100  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0896 > 20) by scale factor 0.995542
I0111 08:59:38.463846  4932 solver.cpp:240] Iteration 66300, loss = 0.0427131
I0111 08:59:38.463883  4932 solver.cpp:255]     Train net output #0: loss = 0.00899881 (* 1 = 0.00899881 loss)
I0111 08:59:38.463891  4932 solver.cpp:631] Iteration 66300, lr = 1e-08
I0111 08:59:45.460412  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0151 > 20) by scale factor 0.951699
I0111 09:00:22.846141  4932 solver.cpp:240] Iteration 66320, loss = 0.0672695
I0111 09:00:22.846225  4932 solver.cpp:255]     Train net output #0: loss = 0.0253128 (* 1 = 0.0253128 loss)
I0111 09:00:22.846236  4932 solver.cpp:631] Iteration 66320, lr = 1e-08
I0111 09:00:36.496004  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5826 > 20) by scale factor 0.848084
I0111 09:01:07.220253  4932 solver.cpp:240] Iteration 66340, loss = 0.0513378
I0111 09:01:07.220338  4932 solver.cpp:255]     Train net output #0: loss = 0.00384821 (* 1 = 0.00384821 loss)
I0111 09:01:07.220351  4932 solver.cpp:631] Iteration 66340, lr = 1e-08
I0111 09:01:25.310639  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7114 > 20) by scale factor 0.921177
I0111 09:01:34.186925  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6179 > 20) by scale factor 0.780706
I0111 09:01:51.604406  4932 solver.cpp:240] Iteration 66360, loss = 0.0751676
I0111 09:01:51.604502  4932 solver.cpp:255]     Train net output #0: loss = 0.0134558 (* 1 = 0.0134558 loss)
I0111 09:01:51.604512  4932 solver.cpp:631] Iteration 66360, lr = 1e-08
I0111 09:02:20.785681  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7391 > 20) by scale factor 0.964363
I0111 09:02:25.225832  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6393 > 20) by scale factor 0.924246
I0111 09:02:35.990377  4932 solver.cpp:240] Iteration 66380, loss = 0.0551468
I0111 09:02:35.990419  4932 solver.cpp:255]     Train net output #0: loss = 0.00728617 (* 1 = 0.00728617 loss)
I0111 09:02:35.990432  4932 solver.cpp:631] Iteration 66380, lr = 1e-08
I0111 09:02:45.202744  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 38.8845 > 20) by scale factor 0.514344
I0111 09:03:05.171571  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9475 > 20) by scale factor 0.871553
I0111 09:03:20.369282  4932 solver.cpp:240] Iteration 66400, loss = 0.070295
I0111 09:03:20.369321  4932 solver.cpp:255]     Train net output #0: loss = 0.160792 (* 1 = 0.160792 loss)
I0111 09:03:20.369331  4932 solver.cpp:631] Iteration 66400, lr = 1e-08
I0111 09:04:04.747905  4932 solver.cpp:240] Iteration 66420, loss = 0.0327416
I0111 09:04:04.747969  4932 solver.cpp:255]     Train net output #0: loss = 0.0147621 (* 1 = 0.0147621 loss)
I0111 09:04:04.747979  4932 solver.cpp:631] Iteration 66420, lr = 1e-08
I0111 09:04:16.182312  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1699 > 20) by scale factor 0.764237
I0111 09:04:18.403947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.415 > 20) by scale factor 0.729528
I0111 09:04:25.060888  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8145 > 20) by scale factor 0.805981
I0111 09:04:36.158906  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2233 > 20) by scale factor 0.988958
I0111 09:04:49.134079  4932 solver.cpp:240] Iteration 66440, loss = 0.0720639
I0111 09:04:49.134110  4932 solver.cpp:255]     Train net output #0: loss = 0.0459866 (* 1 = 0.0459866 loss)
I0111 09:04:49.134119  4932 solver.cpp:631] Iteration 66440, lr = 1e-08
I0111 09:05:11.657035  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0147 > 20) by scale factor 0.999265
I0111 09:05:13.878998  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7186 > 20) by scale factor 0.843219
I0111 09:05:33.515825  4932 solver.cpp:240] Iteration 66460, loss = 0.0781546
I0111 09:05:33.515861  4932 solver.cpp:255]     Train net output #0: loss = 0.0380143 (* 1 = 0.0380143 loss)
I0111 09:05:33.515869  4932 solver.cpp:631] Iteration 66460, lr = 1e-08
I0111 09:05:38.290134  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9855 > 20) by scale factor 0.953041
I0111 09:05:44.948400  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.4641 > 20) by scale factor 0.597656
I0111 09:06:17.886921  4932 solver.cpp:240] Iteration 66480, loss = 0.0616771
I0111 09:06:17.886999  4932 solver.cpp:255]     Train net output #0: loss = 0.0193629 (* 1 = 0.0193629 loss)
I0111 09:06:17.887009  4932 solver.cpp:631] Iteration 66480, lr = 1e-08
I0111 09:06:24.880339  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6887 > 20) by scale factor 0.922139
I0111 09:06:47.075752  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8708 > 20) by scale factor 0.804155
I0111 09:06:49.296840  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2435 > 20) by scale factor 0.941467
I0111 09:07:02.274196  4932 solver.cpp:240] Iteration 66500, loss = 0.0801041
I0111 09:07:02.274233  4932 solver.cpp:255]     Train net output #0: loss = 0.0251658 (* 1 = 0.0251658 loss)
I0111 09:07:02.274248  4932 solver.cpp:631] Iteration 66500, lr = 1e-08
I0111 09:07:18.144335  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8497 > 20) by scale factor 0.773704
I0111 09:07:33.674953  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.77 > 20) by scale factor 0.962927
I0111 09:07:38.114398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.3236 > 20) by scale factor 0.759774
I0111 09:07:46.651459  4932 solver.cpp:240] Iteration 66520, loss = 0.10346
I0111 09:07:46.651497  4932 solver.cpp:255]     Train net output #0: loss = 0.0360979 (* 1 = 0.0360979 loss)
I0111 09:07:46.651505  4932 solver.cpp:631] Iteration 66520, lr = 1e-08
I0111 09:08:31.025755  4932 solver.cpp:240] Iteration 66540, loss = 0.0636415
I0111 09:08:31.025835  4932 solver.cpp:255]     Train net output #0: loss = 0.00265733 (* 1 = 0.00265733 loss)
I0111 09:08:31.025846  4932 solver.cpp:631] Iteration 66540, lr = 1e-08
I0111 09:08:42.453951  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6302 > 20) by scale factor 0.883774
I0111 09:09:15.397461  4932 solver.cpp:240] Iteration 66560, loss = 0.094238
I0111 09:09:15.397531  4932 solver.cpp:255]     Train net output #0: loss = 0.0323282 (* 1 = 0.0323282 loss)
I0111 09:09:15.397539  4932 solver.cpp:631] Iteration 66560, lr = 1e-08
I0111 09:09:57.895711  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.124 > 20) by scale factor 0.737354
I0111 09:09:59.777072  4932 solver.cpp:240] Iteration 66580, loss = 0.0465007
I0111 09:09:59.777110  4932 solver.cpp:255]     Train net output #0: loss = 0.236499 (* 1 = 0.236499 loss)
I0111 09:09:59.777119  4932 solver.cpp:631] Iteration 66580, lr = 1e-08
I0111 09:10:08.988175  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5887 > 20) by scale factor 0.781595
I0111 09:10:22.303127  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2634 > 20) by scale factor 0.987001
I0111 09:10:44.155196  4932 solver.cpp:240] Iteration 66600, loss = 0.052704
I0111 09:10:44.155275  4932 solver.cpp:255]     Train net output #0: loss = 0.00477241 (* 1 = 0.00477241 loss)
I0111 09:10:44.155287  4932 solver.cpp:631] Iteration 66600, lr = 1e-08
I0111 09:11:28.524253  4932 solver.cpp:240] Iteration 66620, loss = 0.0626222
I0111 09:11:28.524333  4932 solver.cpp:255]     Train net output #0: loss = 0.0138871 (* 1 = 0.0138871 loss)
I0111 09:11:28.524343  4932 solver.cpp:631] Iteration 66620, lr = 1e-08
I0111 09:12:12.912255  4932 solver.cpp:240] Iteration 66640, loss = 0.0488366
I0111 09:12:12.912330  4932 solver.cpp:255]     Train net output #0: loss = 0.0158922 (* 1 = 0.0158922 loss)
I0111 09:12:12.912340  4932 solver.cpp:631] Iteration 66640, lr = 1e-08
I0111 09:12:17.691633  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.0358 > 20) by scale factor 0.665872
I0111 09:12:55.421175  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7486 > 20) by scale factor 0.776741
I0111 09:12:57.302839  4932 solver.cpp:240] Iteration 66660, loss = 0.083488
I0111 09:12:57.302870  4932 solver.cpp:255]     Train net output #0: loss = 0.148202 (* 1 = 0.148202 loss)
I0111 09:12:57.302878  4932 solver.cpp:631] Iteration 66660, lr = 1e-08
I0111 09:13:41.676744  4932 solver.cpp:240] Iteration 66680, loss = 0.049503
I0111 09:13:41.676816  4932 solver.cpp:255]     Train net output #0: loss = 0.10104 (* 1 = 0.10104 loss)
I0111 09:13:41.676826  4932 solver.cpp:631] Iteration 66680, lr = 1e-08
I0111 09:13:57.552561  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1492 > 20) by scale factor 0.902968
I0111 09:14:26.057512  4932 solver.cpp:240] Iteration 66700, loss = 0.0532179
I0111 09:14:26.057601  4932 solver.cpp:255]     Train net output #0: loss = 0.0356415 (* 1 = 0.0356415 loss)
I0111 09:14:26.057615  4932 solver.cpp:631] Iteration 66700, lr = 1e-08
I0111 09:14:30.834920  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5315 > 20) by scale factor 0.815279
I0111 09:14:41.930019  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2575 > 20) by scale factor 0.940843
I0111 09:15:10.447546  4932 solver.cpp:240] Iteration 66720, loss = 0.0642661
I0111 09:15:10.447635  4932 solver.cpp:255]     Train net output #0: loss = 0.038416 (* 1 = 0.038416 loss)
I0111 09:15:10.447646  4932 solver.cpp:631] Iteration 66720, lr = 1e-08
I0111 09:15:24.099161  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6887 > 20) by scale factor 0.966709
I0111 09:15:54.828225  4932 solver.cpp:240] Iteration 66740, loss = 0.0991978
I0111 09:15:54.828302  4932 solver.cpp:255]     Train net output #0: loss = 0.0670635 (* 1 = 0.0670635 loss)
I0111 09:15:54.828312  4932 solver.cpp:631] Iteration 66740, lr = 1e-08
I0111 09:16:12.918570  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.1031 > 20) by scale factor 0.737923
I0111 09:16:15.138242  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9454 > 20) by scale factor 0.911352
I0111 09:16:32.886739  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2992 > 20) by scale factor 0.823072
I0111 09:16:39.202606  4932 solver.cpp:240] Iteration 66760, loss = 0.0873626
I0111 09:16:39.202653  4932 solver.cpp:255]     Train net output #0: loss = 0.0152131 (* 1 = 0.0152131 loss)
I0111 09:16:39.202666  4932 solver.cpp:631] Iteration 66760, lr = 1e-08
I0111 09:16:41.763119  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.5586 > 20) by scale factor 0.88658
I0111 09:17:23.581285  4932 solver.cpp:240] Iteration 66780, loss = 0.0619992
I0111 09:17:23.581359  4932 solver.cpp:255]     Train net output #0: loss = 0.0305057 (* 1 = 0.0305057 loss)
I0111 09:17:23.581369  4932 solver.cpp:631] Iteration 66780, lr = 1e-08
I0111 09:17:30.575291  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4142 > 20) by scale factor 0.757167
I0111 09:17:57.201763  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9617 > 20) by scale factor 0.954123
I0111 09:18:07.957062  4932 solver.cpp:240] Iteration 66800, loss = 0.0806046
I0111 09:18:07.957100  4932 solver.cpp:255]     Train net output #0: loss = 0.0478751 (* 1 = 0.0478751 loss)
I0111 09:18:07.957109  4932 solver.cpp:631] Iteration 66800, lr = 1e-08
I0111 09:18:34.937635  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8464 > 20) by scale factor 0.9594
I0111 09:18:46.031617  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1492 > 20) by scale factor 0.795254
I0111 09:18:52.348770  4932 solver.cpp:240] Iteration 66820, loss = 0.0936472
I0111 09:18:52.348809  4932 solver.cpp:255]     Train net output #0: loss = 0.0959104 (* 1 = 0.0959104 loss)
I0111 09:18:52.348817  4932 solver.cpp:631] Iteration 66820, lr = 1e-08
I0111 09:19:01.568202  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2009 > 20) by scale factor 0.709198
I0111 09:19:28.195858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.6867 > 20) by scale factor 0.673702
I0111 09:19:36.733878  4932 solver.cpp:240] Iteration 66840, loss = 0.0864839
I0111 09:19:36.733917  4932 solver.cpp:255]     Train net output #0: loss = 0.0124973 (* 1 = 0.0124973 loss)
I0111 09:19:36.733925  4932 solver.cpp:631] Iteration 66840, lr = 1e-08
I0111 09:19:39.293795  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5412 > 20) by scale factor 0.849574
I0111 09:20:21.123828  4932 solver.cpp:240] Iteration 66860, loss = 0.0821933
I0111 09:20:21.123901  4932 solver.cpp:255]     Train net output #0: loss = 0.212318 (* 1 = 0.212318 loss)
I0111 09:20:21.123911  4932 solver.cpp:631] Iteration 66860, lr = 1e-08
I0111 09:20:21.463080  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7974 > 20) by scale factor 0.806535
I0111 09:20:23.685503  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3579 > 20) by scale factor 0.637798
I0111 09:20:32.567919  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8744 > 20) by scale factor 0.837717
I0111 09:21:05.575783  4932 solver.cpp:240] Iteration 66880, loss = 0.0762565
I0111 09:21:05.575892  4932 solver.cpp:255]     Train net output #0: loss = 0.0911553 (* 1 = 0.0911553 loss)
I0111 09:21:05.575907  4932 solver.cpp:631] Iteration 66880, lr = 1e-08
I0111 09:21:12.576583  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.056 > 20) by scale factor 0.798212
I0111 09:21:36.994498  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0049 > 20) by scale factor 0.999756
I0111 09:21:41.434689  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.5125 > 20) by scale factor 0.783929
I0111 09:21:49.975852  4932 solver.cpp:240] Iteration 66900, loss = 0.0639962
I0111 09:21:49.975891  4932 solver.cpp:255]     Train net output #0: loss = 0.00202393 (* 1 = 0.00202393 loss)
I0111 09:21:49.975900  4932 solver.cpp:631] Iteration 66900, lr = 1e-08
I0111 09:22:03.637190  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2627 > 20) by scale factor 0.824312
I0111 09:22:34.353348  4932 solver.cpp:240] Iteration 66920, loss = 0.0513031
I0111 09:22:34.353417  4932 solver.cpp:255]     Train net output #0: loss = 0.00103809 (* 1 = 0.00103809 loss)
I0111 09:22:34.353427  4932 solver.cpp:631] Iteration 66920, lr = 1e-08
I0111 09:23:03.532804  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2936 > 20) by scale factor 0.985531
I0111 09:23:18.726243  4932 solver.cpp:240] Iteration 66940, loss = 0.0554735
I0111 09:23:18.726310  4932 solver.cpp:255]     Train net output #0: loss = 0.00917237 (* 1 = 0.00917237 loss)
I0111 09:23:18.726320  4932 solver.cpp:631] Iteration 66940, lr = 1e-08
I0111 09:23:59.007866  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3762 > 20) by scale factor 0.981537
I0111 09:24:03.107347  4932 solver.cpp:240] Iteration 66960, loss = 0.0485863
I0111 09:24:03.107378  4932 solver.cpp:255]     Train net output #0: loss = 0.0934622 (* 1 = 0.0934622 loss)
I0111 09:24:03.107386  4932 solver.cpp:631] Iteration 66960, lr = 1e-08
I0111 09:24:18.976557  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1375 > 20) by scale factor 0.828586
I0111 09:24:21.196717  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1541 > 20) by scale factor 0.828018
I0111 09:24:45.604537  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.0181 > 20) by scale factor 0.799421
I0111 09:24:47.487428  4932 solver.cpp:240] Iteration 66980, loss = 0.0838528
I0111 09:24:47.487470  4932 solver.cpp:255]     Train net output #0: loss = 0.0045347 (* 1 = 0.0045347 loss)
I0111 09:24:47.487485  4932 solver.cpp:631] Iteration 66980, lr = 1e-08
I0111 09:25:29.989511  4932 solver.cpp:424] Iteration 67000, Testing net (#0)
I0111 09:26:22.055277  4932 solver.cpp:481]     Test net output #0: accuracy = 0.83579
I0111 09:26:22.055373  4932 solver.cpp:481]     Test net output #1: loss = 0.762678 (* 1 = 0.762678 loss)
I0111 09:26:23.921082  4932 solver.cpp:240] Iteration 67000, loss = 0.0389551
I0111 09:26:23.921118  4932 solver.cpp:255]     Train net output #0: loss = 0.0372199 (* 1 = 0.0372199 loss)
I0111 09:26:23.921126  4932 solver.cpp:631] Iteration 67000, lr = 1e-08
I0111 09:27:08.284198  4932 solver.cpp:240] Iteration 67020, loss = 0.0676608
I0111 09:27:08.284284  4932 solver.cpp:255]     Train net output #0: loss = 0.00897815 (* 1 = 0.00897815 loss)
I0111 09:27:08.284296  4932 solver.cpp:631] Iteration 67020, lr = 1e-08
I0111 09:27:15.277950  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8312 > 20) by scale factor 0.693693
I0111 09:27:26.374153  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1246 > 20) by scale factor 0.829031
I0111 09:27:28.595213  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8219 > 20) by scale factor 0.960526
I0111 09:27:52.660151  4932 solver.cpp:240] Iteration 67040, loss = 0.0627599
I0111 09:27:52.660264  4932 solver.cpp:255]     Train net output #0: loss = 0.121854 (* 1 = 0.121854 loss)
I0111 09:27:52.660277  4932 solver.cpp:631] Iteration 67040, lr = 1e-08
I0111 09:28:12.957825  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9662 > 20) by scale factor 0.953914
I0111 09:28:30.710021  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.2932 > 20) by scale factor 0.790726
I0111 09:28:37.028548  4932 solver.cpp:240] Iteration 67060, loss = 0.0740558
I0111 09:28:37.028586  4932 solver.cpp:255]     Train net output #0: loss = 0.0248673 (* 1 = 0.0248673 loss)
I0111 09:28:37.028594  4932 solver.cpp:631] Iteration 67060, lr = 1e-08
I0111 09:29:21.401669  4932 solver.cpp:240] Iteration 67080, loss = 0.0696159
I0111 09:29:21.401743  4932 solver.cpp:255]     Train net output #0: loss = 0.082238 (* 1 = 0.082238 loss)
I0111 09:29:21.401752  4932 solver.cpp:631] Iteration 67080, lr = 1e-08
I0111 09:29:21.740473  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9618 > 20) by scale factor 0.910673
I0111 09:29:41.708256  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0375 > 20) by scale factor 0.998128
I0111 09:30:05.773797  4932 solver.cpp:240] Iteration 67100, loss = 0.0706903
I0111 09:30:05.773860  4932 solver.cpp:255]     Train net output #0: loss = 0.105478 (* 1 = 0.105478 loss)
I0111 09:30:05.773869  4932 solver.cpp:631] Iteration 67100, lr = 1e-08
I0111 09:30:50.138772  4932 solver.cpp:240] Iteration 67120, loss = 0.0417448
I0111 09:30:50.138844  4932 solver.cpp:255]     Train net output #0: loss = 0.219662 (* 1 = 0.219662 loss)
I0111 09:30:50.138854  4932 solver.cpp:631] Iteration 67120, lr = 1e-08
I0111 09:31:34.508668  4932 solver.cpp:240] Iteration 67140, loss = 0.0625016
I0111 09:31:34.508733  4932 solver.cpp:255]     Train net output #0: loss = 0.00416312 (* 1 = 0.00416312 loss)
I0111 09:31:34.508743  4932 solver.cpp:631] Iteration 67140, lr = 1e-08
I0111 09:32:03.691984  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 41.6907 > 20) by scale factor 0.479723
I0111 09:32:10.350284  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0049 > 20) by scale factor 0.952159
I0111 09:32:18.883235  4932 solver.cpp:240] Iteration 67160, loss = 0.0737465
I0111 09:32:18.883275  4932 solver.cpp:255]     Train net output #0: loss = 0.0722333 (* 1 = 0.0722333 loss)
I0111 09:32:18.883283  4932 solver.cpp:631] Iteration 67160, lr = 1e-08
I0111 09:32:56.934131  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7914 > 20) by scale factor 0.961936
I0111 09:33:03.255784  4932 solver.cpp:240] Iteration 67180, loss = 0.0617715
I0111 09:33:03.255836  4932 solver.cpp:255]     Train net output #0: loss = 0.082122 (* 1 = 0.082122 loss)
I0111 09:33:03.255849  4932 solver.cpp:631] Iteration 67180, lr = 1e-08
I0111 09:33:25.795079  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6133 > 20) by scale factor 0.970247
I0111 09:33:45.763245  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6611 > 20) by scale factor 0.810995
I0111 09:33:47.644502  4932 solver.cpp:240] Iteration 67200, loss = 0.0697741
I0111 09:33:47.644538  4932 solver.cpp:255]     Train net output #0: loss = 0.0140169 (* 1 = 0.0140169 loss)
I0111 09:33:47.644551  4932 solver.cpp:631] Iteration 67200, lr = 1e-08
I0111 09:33:59.079684  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9802 > 20) by scale factor 0.909911
I0111 09:34:16.830243  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8982 > 20) by scale factor 0.913319
I0111 09:34:32.026901  4932 solver.cpp:240] Iteration 67220, loss = 0.0494515
I0111 09:34:32.026942  4932 solver.cpp:255]     Train net output #0: loss = 0.00206899 (* 1 = 0.00206899 loss)
I0111 09:34:32.026950  4932 solver.cpp:631] Iteration 67220, lr = 1e-08
I0111 09:34:47.890107  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8242 > 20) by scale factor 0.960423
I0111 09:35:16.392833  4932 solver.cpp:240] Iteration 67240, loss = 0.0486707
I0111 09:35:16.392869  4932 solver.cpp:255]     Train net output #0: loss = 0.0102947 (* 1 = 0.0102947 loss)
I0111 09:35:16.392877  4932 solver.cpp:631] Iteration 67240, lr = 1e-08
I0111 09:35:41.138921  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3837 > 20) by scale factor 0.935293
I0111 09:36:00.771430  4932 solver.cpp:240] Iteration 67260, loss = 0.0666118
I0111 09:36:00.771469  4932 solver.cpp:255]     Train net output #0: loss = 0.231812 (* 1 = 0.231812 loss)
I0111 09:36:00.771478  4932 solver.cpp:631] Iteration 67260, lr = 1e-08
I0111 09:36:45.128012  4932 solver.cpp:240] Iteration 67280, loss = 0.0653157
I0111 09:36:45.128087  4932 solver.cpp:255]     Train net output #0: loss = 0.0429505 (* 1 = 0.0429505 loss)
I0111 09:36:45.128096  4932 solver.cpp:631] Iteration 67280, lr = 1e-08
I0111 09:37:23.177765  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1778 > 20) by scale factor 0.901801
I0111 09:37:29.493757  4932 solver.cpp:240] Iteration 67300, loss = 0.06482
I0111 09:37:29.493793  4932 solver.cpp:255]     Train net output #0: loss = 0.0459687 (* 1 = 0.0459687 loss)
I0111 09:37:29.493801  4932 solver.cpp:631] Iteration 67300, lr = 1e-08
I0111 09:37:58.669981  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7419 > 20) by scale factor 0.964232
I0111 09:38:13.866572  4932 solver.cpp:240] Iteration 67320, loss = 0.0758593
I0111 09:38:13.866614  4932 solver.cpp:255]     Train net output #0: loss = 0.0118127 (* 1 = 0.0118127 loss)
I0111 09:38:13.866623  4932 solver.cpp:631] Iteration 67320, lr = 1e-08
I0111 09:38:58.231947  4932 solver.cpp:240] Iteration 67340, loss = 0.0686996
I0111 09:38:58.232019  4932 solver.cpp:255]     Train net output #0: loss = 0.0218644 (* 1 = 0.0218644 loss)
I0111 09:38:58.232029  4932 solver.cpp:631] Iteration 67340, lr = 1e-08
I0111 09:39:09.665529  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1248 > 20) by scale factor 0.903964
I0111 09:39:22.974802  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5309 > 20) by scale factor 0.974143
I0111 09:39:34.072736  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3876 > 20) by scale factor 0.893352
I0111 09:39:40.726596  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3977 > 20) by scale factor 0.854786
I0111 09:39:42.607923  4932 solver.cpp:240] Iteration 67360, loss = 0.0840316
I0111 09:39:42.607962  4932 solver.cpp:255]     Train net output #0: loss = 0.102796 (* 1 = 0.102796 loss)
I0111 09:39:42.607971  4932 solver.cpp:631] Iteration 67360, lr = 1e-08
I0111 09:39:51.818302  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3702 > 20) by scale factor 0.730722
I0111 09:40:07.349375  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3548 > 20) by scale factor 0.821192
I0111 09:40:14.005240  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3406 > 20) by scale factor 0.895233
I0111 09:40:16.225380  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2189 > 20) by scale factor 0.762808
I0111 09:40:26.984122  4932 solver.cpp:240] Iteration 67380, loss = 0.0984836
I0111 09:40:26.984154  4932 solver.cpp:255]     Train net output #0: loss = 0.0604284 (* 1 = 0.0604284 loss)
I0111 09:40:26.984164  4932 solver.cpp:631] Iteration 67380, lr = 1e-08
I0111 09:40:45.069871  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.843 > 20) by scale factor 0.838821
I0111 09:41:11.355401  4932 solver.cpp:240] Iteration 67400, loss = 0.0569199
I0111 09:41:11.355430  4932 solver.cpp:255]     Train net output #0: loss = 0.0103294 (* 1 = 0.0103294 loss)
I0111 09:41:11.355437  4932 solver.cpp:631] Iteration 67400, lr = 1e-08
I0111 09:41:25.005417  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4225 > 20) by scale factor 0.933597
I0111 09:41:51.628968  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.3534 > 20) by scale factor 0.821242
I0111 09:41:55.727821  4932 solver.cpp:240] Iteration 67420, loss = 0.104331
I0111 09:41:55.727890  4932 solver.cpp:255]     Train net output #0: loss = 0.0881139 (* 1 = 0.0881139 loss)
I0111 09:41:55.727898  4932 solver.cpp:631] Iteration 67420, lr = 1e-08
I0111 09:42:24.907642  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0381 > 20) by scale factor 0.713315
I0111 09:42:40.100877  4932 solver.cpp:240] Iteration 67440, loss = 0.0879028
I0111 09:42:40.100956  4932 solver.cpp:255]     Train net output #0: loss = 0.0282146 (* 1 = 0.0282146 loss)
I0111 09:42:40.100966  4932 solver.cpp:631] Iteration 67440, lr = 1e-08
I0111 09:43:07.062264  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1267 > 20) by scale factor 0.795966
I0111 09:43:24.472646  4932 solver.cpp:240] Iteration 67460, loss = 0.0625132
I0111 09:43:24.472726  4932 solver.cpp:255]     Train net output #0: loss = 0.00283093 (* 1 = 0.00283093 loss)
I0111 09:43:24.472735  4932 solver.cpp:631] Iteration 67460, lr = 1e-08
I0111 09:43:46.994312  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.2121 > 20) by scale factor 0.708915
I0111 09:44:08.840304  4932 solver.cpp:240] Iteration 67480, loss = 0.0525727
I0111 09:44:08.840384  4932 solver.cpp:255]     Train net output #0: loss = 0.0365143 (* 1 = 0.0365143 loss)
I0111 09:44:08.840394  4932 solver.cpp:631] Iteration 67480, lr = 1e-08
I0111 09:44:31.361364  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3987 > 20) by scale factor 0.636969
I0111 09:44:53.209671  4932 solver.cpp:240] Iteration 67500, loss = 0.0708603
I0111 09:44:53.209736  4932 solver.cpp:255]     Train net output #0: loss = 0.229755 (* 1 = 0.229755 loss)
I0111 09:44:53.209746  4932 solver.cpp:631] Iteration 67500, lr = 1e-08
I0111 09:44:55.768682  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5063 > 20) by scale factor 0.929961
I0111 09:45:31.273912  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5613 > 20) by scale factor 0.700249
I0111 09:45:37.592381  4932 solver.cpp:240] Iteration 67520, loss = 0.0658808
I0111 09:45:37.592418  4932 solver.cpp:255]     Train net output #0: loss = 0.16265 (* 1 = 0.16265 loss)
I0111 09:45:37.592427  4932 solver.cpp:631] Iteration 67520, lr = 1e-08
I0111 09:45:44.587553  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5035 > 20) by scale factor 0.850936
I0111 09:45:46.808569  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.85 > 20) by scale factor 0.838575
I0111 09:46:02.341728  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2353 > 20) by scale factor 0.941829
I0111 09:46:21.973951  4932 solver.cpp:240] Iteration 67540, loss = 0.0923907
I0111 09:46:21.973994  4932 solver.cpp:255]     Train net output #0: loss = 0.110241 (* 1 = 0.110241 loss)
I0111 09:46:21.974002  4932 solver.cpp:631] Iteration 67540, lr = 1e-08
I0111 09:47:02.250574  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0029 > 20) by scale factor 0.908973
I0111 09:47:06.350301  4932 solver.cpp:240] Iteration 67560, loss = 0.0520875
I0111 09:47:06.350340  4932 solver.cpp:255]     Train net output #0: loss = 0.078676 (* 1 = 0.078676 loss)
I0111 09:47:06.350348  4932 solver.cpp:631] Iteration 67560, lr = 1e-08
I0111 09:47:24.439077  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5936 > 20) by scale factor 0.847688
I0111 09:47:31.095564  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9888 > 20) by scale factor 0.95289
I0111 09:47:44.410655  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1198 > 20) by scale factor 0.994046
I0111 09:47:50.726622  4932 solver.cpp:240] Iteration 67580, loss = 0.0857319
I0111 09:47:50.726660  4932 solver.cpp:255]     Train net output #0: loss = 0.0357103 (* 1 = 0.0357103 loss)
I0111 09:47:50.726667  4932 solver.cpp:631] Iteration 67580, lr = 1e-08
I0111 09:47:59.940492  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.195 > 20) by scale factor 0.990346
I0111 09:48:02.160786  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 33.4453 > 20) by scale factor 0.597991
I0111 09:48:26.568090  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6411 > 20) by scale factor 0.968941
I0111 09:48:35.103550  4932 solver.cpp:240] Iteration 67600, loss = 0.104682
I0111 09:48:35.103590  4932 solver.cpp:255]     Train net output #0: loss = 0.345937 (* 1 = 0.345937 loss)
I0111 09:48:35.103598  4932 solver.cpp:631] Iteration 67600, lr = 1e-08
I0111 09:48:35.442684  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.5639 > 20) by scale factor 0.6765
I0111 09:48:44.317117  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4408 > 20) by scale factor 0.932803
I0111 09:48:46.536310  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6961 > 20) by scale factor 0.966367
I0111 09:49:19.473228  4932 solver.cpp:240] Iteration 67620, loss = 0.0842634
I0111 09:49:19.473296  4932 solver.cpp:255]     Train net output #0: loss = 0.131099 (* 1 = 0.131099 loss)
I0111 09:49:19.473306  4932 solver.cpp:631] Iteration 67620, lr = 1e-08
I0111 09:50:03.839287  4932 solver.cpp:240] Iteration 67640, loss = 0.0671501
I0111 09:50:03.839360  4932 solver.cpp:255]     Train net output #0: loss = 0.0110718 (* 1 = 0.0110718 loss)
I0111 09:50:03.839370  4932 solver.cpp:631] Iteration 67640, lr = 1e-08
I0111 09:50:48.198801  4932 solver.cpp:240] Iteration 67660, loss = 0.0426137
I0111 09:50:48.198869  4932 solver.cpp:255]     Train net output #0: loss = 0.152473 (* 1 = 0.152473 loss)
I0111 09:50:48.198879  4932 solver.cpp:631] Iteration 67660, lr = 1e-08
I0111 09:50:55.196780  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6545 > 20) by scale factor 0.845507
I0111 09:51:32.566723  4932 solver.cpp:240] Iteration 67680, loss = 0.057982
I0111 09:51:32.566802  4932 solver.cpp:255]     Train net output #0: loss = 0.0549344 (* 1 = 0.0549344 loss)
I0111 09:51:32.566812  4932 solver.cpp:631] Iteration 67680, lr = 1e-08
I0111 09:51:48.438746  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0881 > 20) by scale factor 0.995615
I0111 09:52:06.193866  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8716 > 20) by scale factor 0.804129
I0111 09:52:10.632447  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8448 > 20) by scale factor 0.804999
I0111 09:52:16.949244  4932 solver.cpp:240] Iteration 67700, loss = 0.108168
I0111 09:52:16.949280  4932 solver.cpp:255]     Train net output #0: loss = 0.137324 (* 1 = 0.137324 loss)
I0111 09:52:16.949288  4932 solver.cpp:631] Iteration 67700, lr = 1e-08
I0111 09:52:32.818778  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7067 > 20) by scale factor 0.921375
I0111 09:52:48.348757  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9426 > 20) by scale factor 0.80184
I0111 09:52:55.009249  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.9402 > 20) by scale factor 0.835417
I0111 09:52:59.448182  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1857 > 20) by scale factor 0.826936
I0111 09:53:01.329020  4932 solver.cpp:240] Iteration 67720, loss = 0.102284
I0111 09:53:01.329051  4932 solver.cpp:255]     Train net output #0: loss = 0.00512463 (* 1 = 0.00512463 loss)
I0111 09:53:01.329058  4932 solver.cpp:631] Iteration 67720, lr = 1e-08
I0111 09:53:12.758316  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3918 > 20) by scale factor 0.980786
I0111 09:53:45.700354  4932 solver.cpp:240] Iteration 67740, loss = 0.0553618
I0111 09:53:45.700450  4932 solver.cpp:255]     Train net output #0: loss = 0.0290322 (* 1 = 0.0290322 loss)
I0111 09:53:45.700460  4932 solver.cpp:631] Iteration 67740, lr = 1e-08
I0111 09:54:03.786412  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9649 > 20) by scale factor 0.953975
I0111 09:54:21.542680  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8325 > 20) by scale factor 0.805395
I0111 09:54:30.080004  4932 solver.cpp:240] Iteration 67760, loss = 0.0806836
I0111 09:54:30.080040  4932 solver.cpp:255]     Train net output #0: loss = 0.125785 (* 1 = 0.125785 loss)
I0111 09:54:30.080049  4932 solver.cpp:631] Iteration 67760, lr = 1e-08
I0111 09:55:14.444349  4932 solver.cpp:240] Iteration 67780, loss = 0.0590431
I0111 09:55:14.444416  4932 solver.cpp:255]     Train net output #0: loss = 0.00476921 (* 1 = 0.00476921 loss)
I0111 09:55:14.444425  4932 solver.cpp:631] Iteration 67780, lr = 1e-08
I0111 09:55:17.001768  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1986 > 20) by scale factor 0.94346
I0111 09:55:34.752409  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4899 > 20) by scale factor 0.930671
I0111 09:55:50.289718  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.3552 > 20) by scale factor 0.731122
I0111 09:55:52.510762  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.6241 > 20) by scale factor 0.698711
I0111 09:55:58.827227  4932 solver.cpp:240] Iteration 67800, loss = 0.115158
I0111 09:55:58.827263  4932 solver.cpp:255]     Train net output #0: loss = 0.105966 (* 1 = 0.105966 loss)
I0111 09:55:58.827270  4932 solver.cpp:631] Iteration 67800, lr = 1e-08
I0111 09:56:05.818428  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9135 > 20) by scale factor 0.872847
I0111 09:56:12.480386  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.4058 > 20) by scale factor 0.819478
I0111 09:56:43.204941  4932 solver.cpp:240] Iteration 67820, loss = 0.0704398
I0111 09:56:43.205008  4932 solver.cpp:255]     Train net output #0: loss = 0.066786 (* 1 = 0.066786 loss)
I0111 09:56:43.205018  4932 solver.cpp:631] Iteration 67820, lr = 1e-08
I0111 09:56:45.762290  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8324 > 20) by scale factor 0.718587
I0111 09:57:19.048295  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9921 > 20) by scale factor 0.869866
I0111 09:57:27.585078  4932 solver.cpp:240] Iteration 67840, loss = 0.10055
I0111 09:57:27.585117  4932 solver.cpp:255]     Train net output #0: loss = 0.0823731 (* 1 = 0.0823731 loss)
I0111 09:57:27.585127  4932 solver.cpp:631] Iteration 67840, lr = 1e-08
I0111 09:58:11.961241  4932 solver.cpp:240] Iteration 67860, loss = 0.0532858
I0111 09:58:11.961305  4932 solver.cpp:255]     Train net output #0: loss = 0.00631321 (* 1 = 0.00631321 loss)
I0111 09:58:11.961315  4932 solver.cpp:631] Iteration 67860, lr = 1e-08
I0111 09:58:21.171674  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7381 > 20) by scale factor 0.777057
I0111 09:58:32.267328  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1148 > 20) by scale factor 0.865246
I0111 09:58:52.235560  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9684 > 20) by scale factor 0.690408
I0111 09:58:54.457409  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 35.9659 > 20) by scale factor 0.556082
I0111 09:58:56.338089  4932 solver.cpp:240] Iteration 67880, loss = 0.130131
I0111 09:58:56.338121  4932 solver.cpp:255]     Train net output #0: loss = 0.00874589 (* 1 = 0.00874589 loss)
I0111 09:58:56.338130  4932 solver.cpp:631] Iteration 67880, lr = 1e-08
I0111 09:59:05.554198  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1582 > 20) by scale factor 0.992151
I0111 09:59:12.208801  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4687 > 20) by scale factor 0.931589
I0111 09:59:27.744063  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5528 > 20) by scale factor 0.81457
I0111 09:59:38.833551  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1164 > 20) by scale factor 0.82931
I0111 09:59:40.714581  4932 solver.cpp:240] Iteration 67900, loss = 0.0662483
I0111 09:59:40.714620  4932 solver.cpp:255]     Train net output #0: loss = 0.0700327 (* 1 = 0.0700327 loss)
I0111 09:59:40.714629  4932 solver.cpp:631] Iteration 67900, lr = 1e-08
I0111 10:00:25.084918  4932 solver.cpp:240] Iteration 67920, loss = 0.0756441
I0111 10:00:25.084991  4932 solver.cpp:255]     Train net output #0: loss = 0.0234421 (* 1 = 0.0234421 loss)
I0111 10:00:25.085000  4932 solver.cpp:631] Iteration 67920, lr = 1e-08
I0111 10:01:00.913732  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.827 > 20) by scale factor 0.916296
I0111 10:01:09.450179  4932 solver.cpp:240] Iteration 67940, loss = 0.0581098
I0111 10:01:09.450219  4932 solver.cpp:255]     Train net output #0: loss = 0.0933541 (* 1 = 0.0933541 loss)
I0111 10:01:09.450228  4932 solver.cpp:631] Iteration 67940, lr = 1e-08
I0111 10:01:14.225920  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4891 > 20) by scale factor 0.930702
I0111 10:01:53.826282  4932 solver.cpp:240] Iteration 67960, loss = 0.052766
I0111 10:01:53.826364  4932 solver.cpp:255]     Train net output #0: loss = 0.0354239 (* 1 = 0.0354239 loss)
I0111 10:01:53.826373  4932 solver.cpp:631] Iteration 67960, lr = 1e-08
I0111 10:02:29.657429  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9399 > 20) by scale factor 0.742394
I0111 10:02:38.196192  4932 solver.cpp:240] Iteration 67980, loss = 0.0519011
I0111 10:02:38.196235  4932 solver.cpp:255]     Train net output #0: loss = 0.0692798 (* 1 = 0.0692798 loss)
I0111 10:02:38.196246  4932 solver.cpp:631] Iteration 67980, lr = 1e-08
I0111 10:03:20.684398  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2312 > 20) by scale factor 0.988571
I0111 10:03:20.693156  4932 solver.cpp:424] Iteration 68000, Testing net (#0)
I0111 10:04:09.991690  4932 solver.cpp:481]     Test net output #0: accuracy = 0.825263
I0111 10:04:09.991780  4932 solver.cpp:481]     Test net output #1: loss = 0.92594 (* 1 = 0.92594 loss)
I0111 10:04:11.858100  4932 solver.cpp:240] Iteration 68000, loss = 0.0452846
I0111 10:04:11.858141  4932 solver.cpp:255]     Train net output #0: loss = 0.00703106 (* 1 = 0.00703106 loss)
I0111 10:04:11.858150  4932 solver.cpp:631] Iteration 68000, lr = 1e-08
I0111 10:04:14.416558  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4389 > 20) by scale factor 0.853283
I0111 10:04:56.244629  4932 solver.cpp:240] Iteration 68020, loss = 0.0504362
I0111 10:04:56.244730  4932 solver.cpp:255]     Train net output #0: loss = 0.0555088 (* 1 = 0.0555088 loss)
I0111 10:04:56.244745  4932 solver.cpp:631] Iteration 68020, lr = 1e-08
I0111 10:05:09.898831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.2977 > 20) by scale factor 0.896953
I0111 10:05:20.996984  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.6303 > 20) by scale factor 0.883772
I0111 10:05:25.438807  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7032 > 20) by scale factor 0.966034
I0111 10:05:38.761207  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.1075 > 20) by scale factor 0.664285
I0111 10:05:40.643838  4932 solver.cpp:240] Iteration 68040, loss = 0.111082
I0111 10:05:40.643870  4932 solver.cpp:255]     Train net output #0: loss = 0.00215739 (* 1 = 0.00215739 loss)
I0111 10:05:40.643879  4932 solver.cpp:631] Iteration 68040, lr = 1e-08
I0111 10:05:56.515969  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.1529 > 20) by scale factor 0.795136
I0111 10:06:25.034127  4932 solver.cpp:240] Iteration 68060, loss = 0.0575872
I0111 10:06:25.034236  4932 solver.cpp:255]     Train net output #0: loss = 0.00356585 (* 1 = 0.00356585 loss)
I0111 10:06:25.034250  4932 solver.cpp:631] Iteration 68060, lr = 1e-08
I0111 10:07:03.100594  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8247 > 20) by scale factor 0.916392
I0111 10:07:09.421990  4932 solver.cpp:240] Iteration 68080, loss = 0.0663183
I0111 10:07:09.422027  4932 solver.cpp:255]     Train net output #0: loss = 0.126968 (* 1 = 0.126968 loss)
I0111 10:07:09.422037  4932 solver.cpp:631] Iteration 68080, lr = 1e-08
I0111 10:07:53.800071  4932 solver.cpp:240] Iteration 68100, loss = 0.0494969
I0111 10:07:53.800146  4932 solver.cpp:255]     Train net output #0: loss = 0.00891553 (* 1 = 0.00891553 loss)
I0111 10:07:53.800156  4932 solver.cpp:631] Iteration 68100, lr = 1e-08
I0111 10:08:11.889374  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.6498 > 20) by scale factor 0.811366
I0111 10:08:25.210255  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3732 > 20) by scale factor 0.981683
I0111 10:08:38.186225  4932 solver.cpp:240] Iteration 68120, loss = 0.0617992
I0111 10:08:38.186269  4932 solver.cpp:255]     Train net output #0: loss = 0.272287 (* 1 = 0.272287 loss)
I0111 10:08:38.186280  4932 solver.cpp:631] Iteration 68120, lr = 1e-08
I0111 10:08:49.621359  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1105 > 20) by scale factor 0.765976
I0111 10:09:00.719064  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5911 > 20) by scale factor 0.847779
I0111 10:09:18.474133  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.302 > 20) by scale factor 0.858297
I0111 10:09:22.575012  4932 solver.cpp:240] Iteration 68140, loss = 0.0661144
I0111 10:09:22.575058  4932 solver.cpp:255]     Train net output #0: loss = 0.0025739 (* 1 = 0.0025739 loss)
I0111 10:09:22.575070  4932 solver.cpp:631] Iteration 68140, lr = 1e-08
I0111 10:10:06.963915  4932 solver.cpp:240] Iteration 68160, loss = 0.0511666
I0111 10:10:06.964002  4932 solver.cpp:255]     Train net output #0: loss = 0.0345175 (* 1 = 0.0345175 loss)
I0111 10:10:06.964015  4932 solver.cpp:631] Iteration 68160, lr = 1e-08
I0111 10:10:45.028861  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9073 > 20) by scale factor 0.743294
I0111 10:10:51.348841  4932 solver.cpp:240] Iteration 68180, loss = 0.0625534
I0111 10:10:51.348884  4932 solver.cpp:255]     Train net output #0: loss = 0.00418142 (* 1 = 0.00418142 loss)
I0111 10:10:51.348894  4932 solver.cpp:631] Iteration 68180, lr = 1e-08
I0111 10:11:35.722702  4932 solver.cpp:240] Iteration 68200, loss = 0.0643772
I0111 10:11:35.722795  4932 solver.cpp:255]     Train net output #0: loss = 0.0348838 (* 1 = 0.0348838 loss)
I0111 10:11:35.722807  4932 solver.cpp:631] Iteration 68200, lr = 1e-08
I0111 10:12:20.099702  4932 solver.cpp:240] Iteration 68220, loss = 0.0377596
I0111 10:12:20.099781  4932 solver.cpp:255]     Train net output #0: loss = 0.118073 (* 1 = 0.118073 loss)
I0111 10:12:20.099792  4932 solver.cpp:631] Iteration 68220, lr = 1e-08
I0111 10:13:04.478027  4932 solver.cpp:240] Iteration 68240, loss = 0.0488711
I0111 10:13:04.478111  4932 solver.cpp:255]     Train net output #0: loss = 0.0468106 (* 1 = 0.0468106 loss)
I0111 10:13:04.478124  4932 solver.cpp:631] Iteration 68240, lr = 1e-08
I0111 10:13:48.855007  4932 solver.cpp:240] Iteration 68260, loss = 0.0682602
I0111 10:13:48.855087  4932 solver.cpp:255]     Train net output #0: loss = 0.248913 (* 1 = 0.248913 loss)
I0111 10:13:48.855098  4932 solver.cpp:631] Iteration 68260, lr = 1e-08
I0111 10:13:49.194329  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6764 > 20) by scale factor 0.749728
I0111 10:13:55.851795  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9748 > 20) by scale factor 0.953524
I0111 10:14:33.244323  4932 solver.cpp:240] Iteration 68280, loss = 0.0685114
I0111 10:14:33.244406  4932 solver.cpp:255]     Train net output #0: loss = 0.0158019 (* 1 = 0.0158019 loss)
I0111 10:14:33.244420  4932 solver.cpp:631] Iteration 68280, lr = 1e-08
I0111 10:15:17.620921  4932 solver.cpp:240] Iteration 68300, loss = 0.0684035
I0111 10:15:17.620992  4932 solver.cpp:255]     Train net output #0: loss = 0.0045756 (* 1 = 0.0045756 loss)
I0111 10:15:17.621004  4932 solver.cpp:631] Iteration 68300, lr = 1e-08
I0111 10:15:26.841330  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.611 > 20) by scale factor 0.632692
I0111 10:15:33.499337  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4993 > 20) by scale factor 0.701772
I0111 10:15:42.379289  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.7477 > 20) by scale factor 0.919637
I0111 10:15:46.821303  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9709 > 20) by scale factor 0.690348
I0111 10:16:02.022171  4932 solver.cpp:240] Iteration 68320, loss = 0.115496
I0111 10:16:02.022238  4932 solver.cpp:255]     Train net output #0: loss = 0.00222982 (* 1 = 0.00222982 loss)
I0111 10:16:02.022249  4932 solver.cpp:631] Iteration 68320, lr = 1e-08
I0111 10:16:11.239713  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6642 > 20) by scale factor 0.923182
I0111 10:16:46.403599  4932 solver.cpp:240] Iteration 68340, loss = 0.0660811
I0111 10:16:46.403688  4932 solver.cpp:255]     Train net output #0: loss = 0.0409847 (* 1 = 0.0409847 loss)
I0111 10:16:46.403702  4932 solver.cpp:631] Iteration 68340, lr = 1e-08
I0111 10:17:10.621592  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.5141 > 20) by scale factor 0.850552
I0111 10:17:12.843039  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.1834 > 20) by scale factor 0.641366
I0111 10:17:32.476395  4932 solver.cpp:240] Iteration 68360, loss = 0.0974354
I0111 10:17:32.476496  4932 solver.cpp:255]     Train net output #0: loss = 0.0791238 (* 1 = 0.0791238 loss)
I0111 10:17:32.476511  4932 solver.cpp:631] Iteration 68360, lr = 1e-08
I0111 10:18:12.908056  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.206 > 20) by scale factor 0.989803
I0111 10:18:17.009244  4932 solver.cpp:240] Iteration 68380, loss = 0.0545968
I0111 10:18:17.009277  4932 solver.cpp:255]     Train net output #0: loss = 0.0364828 (* 1 = 0.0364828 loss)
I0111 10:18:17.009287  4932 solver.cpp:631] Iteration 68380, lr = 1e-08
I0111 10:19:01.394598  4932 solver.cpp:240] Iteration 68400, loss = 0.0554783
I0111 10:19:01.394676  4932 solver.cpp:255]     Train net output #0: loss = 0.0513043 (* 1 = 0.0513043 loss)
I0111 10:19:01.394690  4932 solver.cpp:631] Iteration 68400, lr = 1e-08
I0111 10:19:45.776309  4932 solver.cpp:240] Iteration 68420, loss = 0.0551395
I0111 10:19:45.776404  4932 solver.cpp:255]     Train net output #0: loss = 0.016643 (* 1 = 0.016643 loss)
I0111 10:19:45.776418  4932 solver.cpp:631] Iteration 68420, lr = 1e-08
I0111 10:19:50.557687  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4337 > 20) by scale factor 0.978773
I0111 10:19:59.431916  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.9272 > 20) by scale factor 0.626425
I0111 10:20:19.403619  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8252 > 20) by scale factor 0.916374
I0111 10:20:30.158771  4932 solver.cpp:240] Iteration 68440, loss = 0.0815696
I0111 10:20:30.158814  4932 solver.cpp:255]     Train net output #0: loss = 0.286037 (* 1 = 0.286037 loss)
I0111 10:20:30.158828  4932 solver.cpp:631] Iteration 68440, lr = 1e-08
I0111 10:20:41.606472  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1305 > 20) by scale factor 0.903731
I0111 10:20:57.156076  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7669 > 20) by scale factor 0.96307
I0111 10:21:12.682394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9901 > 20) by scale factor 0.869941
I0111 10:21:14.563463  4932 solver.cpp:240] Iteration 68460, loss = 0.0907404
I0111 10:21:14.563509  4932 solver.cpp:255]     Train net output #0: loss = 0.00172797 (* 1 = 0.00172797 loss)
I0111 10:21:14.563520  4932 solver.cpp:631] Iteration 68460, lr = 1e-08
I0111 10:21:58.948004  4932 solver.cpp:240] Iteration 68480, loss = 0.0427188
I0111 10:21:58.948084  4932 solver.cpp:255]     Train net output #0: loss = 0.0203308 (* 1 = 0.0203308 loss)
I0111 10:21:58.948096  4932 solver.cpp:631] Iteration 68480, lr = 1e-08
I0111 10:22:37.014717  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6608 > 20) by scale factor 0.968018
I0111 10:22:43.333513  4932 solver.cpp:240] Iteration 68500, loss = 0.0449369
I0111 10:22:43.333556  4932 solver.cpp:255]     Train net output #0: loss = 0.0121583 (* 1 = 0.0121583 loss)
I0111 10:22:43.333569  4932 solver.cpp:631] Iteration 68500, lr = 1e-08
I0111 10:22:45.889858  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2536 > 20) by scale factor 0.860082
I0111 10:23:27.715600  4932 solver.cpp:240] Iteration 68520, loss = 0.0858189
I0111 10:23:27.715678  4932 solver.cpp:255]     Train net output #0: loss = 0.0958662 (* 1 = 0.0958662 loss)
I0111 10:23:27.715689  4932 solver.cpp:631] Iteration 68520, lr = 1e-08
I0111 10:23:36.931924  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.4396 > 20) by scale factor 0.891282
I0111 10:24:12.102768  4932 solver.cpp:240] Iteration 68540, loss = 0.0460836
I0111 10:24:12.102843  4932 solver.cpp:255]     Train net output #0: loss = 0.0288271 (* 1 = 0.0288271 loss)
I0111 10:24:12.102854  4932 solver.cpp:631] Iteration 68540, lr = 1e-08
I0111 10:24:27.980645  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.925 > 20) by scale factor 0.716205
I0111 10:24:34.637353  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2261 > 20) by scale factor 0.942235
I0111 10:24:36.858702  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.4389 > 20) by scale factor 0.703261
I0111 10:24:56.499773  4932 solver.cpp:240] Iteration 68560, loss = 0.0623492
I0111 10:24:56.499866  4932 solver.cpp:255]     Train net output #0: loss = 0.0778706 (* 1 = 0.0778706 loss)
I0111 10:24:56.499879  4932 solver.cpp:631] Iteration 68560, lr = 1e-08
I0111 10:25:03.495437  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.957 > 20) by scale factor 0.625842
I0111 10:25:40.886873  4932 solver.cpp:240] Iteration 68580, loss = 0.0792133
I0111 10:25:40.886942  4932 solver.cpp:255]     Train net output #0: loss = 0.000809537 (* 1 = 0.000809537 loss)
I0111 10:25:40.886952  4932 solver.cpp:631] Iteration 68580, lr = 1e-08
I0111 10:25:54.544384  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.4213 > 20) by scale factor 0.756964
I0111 10:25:56.766901  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0474 > 20) by scale factor 0.713078
I0111 10:25:58.990216  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.3034 > 20) by scale factor 0.790407
I0111 10:26:25.282915  4932 solver.cpp:240] Iteration 68600, loss = 0.0823149
I0111 10:26:25.282981  4932 solver.cpp:255]     Train net output #0: loss = 0.0178659 (* 1 = 0.0178659 loss)
I0111 10:26:25.282991  4932 solver.cpp:631] Iteration 68600, lr = 1e-08
I0111 10:27:09.662204  4932 solver.cpp:240] Iteration 68620, loss = 0.0246346
I0111 10:27:09.662283  4932 solver.cpp:255]     Train net output #0: loss = 0.0122445 (* 1 = 0.0122445 loss)
I0111 10:27:09.662294  4932 solver.cpp:631] Iteration 68620, lr = 1e-08
I0111 10:27:32.187830  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.0958 > 20) by scale factor 0.766406
I0111 10:27:54.040310  4932 solver.cpp:240] Iteration 68640, loss = 0.0824108
I0111 10:27:54.040383  4932 solver.cpp:255]     Train net output #0: loss = 0.0313644 (* 1 = 0.0313644 loss)
I0111 10:27:54.040393  4932 solver.cpp:631] Iteration 68640, lr = 1e-08
I0111 10:28:38.950618  4932 solver.cpp:240] Iteration 68660, loss = 0.0549401
I0111 10:28:38.950727  4932 solver.cpp:255]     Train net output #0: loss = 0.0521258 (* 1 = 0.0521258 loss)
I0111 10:28:38.950739  4932 solver.cpp:631] Iteration 68660, lr = 1e-08
I0111 10:29:12.571666  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.284 > 20) by scale factor 0.707114
I0111 10:29:23.328160  4932 solver.cpp:240] Iteration 68680, loss = 0.0751608
I0111 10:29:23.328197  4932 solver.cpp:255]     Train net output #0: loss = 0.0140321 (* 1 = 0.0140321 loss)
I0111 10:29:23.328205  4932 solver.cpp:631] Iteration 68680, lr = 1e-08
I0111 10:30:07.724416  4932 solver.cpp:240] Iteration 68700, loss = 0.0407046
I0111 10:30:07.724503  4932 solver.cpp:255]     Train net output #0: loss = 0.216965 (* 1 = 0.216965 loss)
I0111 10:30:07.724514  4932 solver.cpp:631] Iteration 68700, lr = 1e-08
I0111 10:30:10.281435  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3032 > 20) by scale factor 0.985068
I0111 10:30:52.104960  4932 solver.cpp:240] Iteration 68720, loss = 0.0652349
I0111 10:30:52.105039  4932 solver.cpp:255]     Train net output #0: loss = 0.0199085 (* 1 = 0.0199085 loss)
I0111 10:30:52.105049  4932 solver.cpp:631] Iteration 68720, lr = 1e-08
I0111 10:31:07.976075  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7166 > 20) by scale factor 0.880414
I0111 10:31:25.729939  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.4243 > 20) by scale factor 0.786649
I0111 10:31:30.177078  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8859 > 20) by scale factor 0.837315
I0111 10:31:36.499337  4932 solver.cpp:240] Iteration 68740, loss = 0.0676039
I0111 10:31:36.499377  4932 solver.cpp:255]     Train net output #0: loss = 0.0100033 (* 1 = 0.0100033 loss)
I0111 10:31:36.499387  4932 solver.cpp:631] Iteration 68740, lr = 1e-08
I0111 10:31:39.055976  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.8904 > 20) by scale factor 0.87373
I0111 10:32:01.243429  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.4595 > 20) by scale factor 0.977543
I0111 10:32:20.877456  4932 solver.cpp:240] Iteration 68760, loss = 0.0629223
I0111 10:32:20.877497  4932 solver.cpp:255]     Train net output #0: loss = 0.184675 (* 1 = 0.184675 loss)
I0111 10:32:20.877507  4932 solver.cpp:631] Iteration 68760, lr = 1e-08
I0111 10:32:36.749423  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7871 > 20) by scale factor 0.840793
I0111 10:32:43.410887  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5787 > 20) by scale factor 0.926839
I0111 10:33:05.263834  4932 solver.cpp:240] Iteration 68780, loss = 0.0676426
I0111 10:33:05.263875  4932 solver.cpp:255]     Train net output #0: loss = 0.0101198 (* 1 = 0.0101198 loss)
I0111 10:33:05.263885  4932 solver.cpp:631] Iteration 68780, lr = 1e-08
I0111 10:33:36.667508  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.134 > 20) by scale factor 0.86453
I0111 10:33:49.644461  4932 solver.cpp:240] Iteration 68800, loss = 0.0576402
I0111 10:33:49.644506  4932 solver.cpp:255]     Train net output #0: loss = 0.00155533 (* 1 = 0.00155533 loss)
I0111 10:33:49.644518  4932 solver.cpp:631] Iteration 68800, lr = 1e-08
I0111 10:34:34.020757  4932 solver.cpp:240] Iteration 68820, loss = 0.0555312
I0111 10:34:34.020828  4932 solver.cpp:255]     Train net output #0: loss = 0.249266 (* 1 = 0.249266 loss)
I0111 10:34:34.020838  4932 solver.cpp:631] Iteration 68820, lr = 1e-08
I0111 10:35:18.399808  4932 solver.cpp:240] Iteration 68840, loss = 0.0658019
I0111 10:35:18.399878  4932 solver.cpp:255]     Train net output #0: loss = 0.0735288 (* 1 = 0.0735288 loss)
I0111 10:35:18.399888  4932 solver.cpp:631] Iteration 68840, lr = 1e-08
I0111 10:35:52.023988  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7005 > 20) by scale factor 0.966161
I0111 10:36:02.786325  4932 solver.cpp:240] Iteration 68860, loss = 0.0341271
I0111 10:36:02.786375  4932 solver.cpp:255]     Train net output #0: loss = 0.0344494 (* 1 = 0.0344494 loss)
I0111 10:36:02.786386  4932 solver.cpp:631] Iteration 68860, lr = 1e-08
I0111 10:36:14.219501  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.6636 > 20) by scale factor 0.722973
I0111 10:36:16.441534  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9904 > 20) by scale factor 0.909488
I0111 10:36:47.166815  4932 solver.cpp:240] Iteration 68880, loss = 0.0811747
I0111 10:36:47.166890  4932 solver.cpp:255]     Train net output #0: loss = 0.0381121 (* 1 = 0.0381121 loss)
I0111 10:36:47.166901  4932 solver.cpp:631] Iteration 68880, lr = 1e-08
I0111 10:37:31.550005  4932 solver.cpp:240] Iteration 68900, loss = 0.0630698
I0111 10:37:31.550082  4932 solver.cpp:255]     Train net output #0: loss = 0.304749 (* 1 = 0.304749 loss)
I0111 10:37:31.550093  4932 solver.cpp:631] Iteration 68900, lr = 1e-08
I0111 10:37:31.889278  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.8137 > 20) by scale factor 0.960906
I0111 10:38:00.743279  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.479 > 20) by scale factor 0.78496
I0111 10:38:02.964943  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2829 > 20) by scale factor 0.760951
I0111 10:38:15.942806  4932 solver.cpp:240] Iteration 68920, loss = 0.103005
I0111 10:38:15.942844  4932 solver.cpp:255]     Train net output #0: loss = 0.228612 (* 1 = 0.228612 loss)
I0111 10:38:15.942854  4932 solver.cpp:631] Iteration 68920, lr = 1e-08
I0111 10:39:00.319793  4932 solver.cpp:240] Iteration 68940, loss = 0.0330533
I0111 10:39:00.319869  4932 solver.cpp:255]     Train net output #0: loss = 0.0394965 (* 1 = 0.0394965 loss)
I0111 10:39:00.319878  4932 solver.cpp:631] Iteration 68940, lr = 1e-08
I0111 10:39:16.190373  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0747 > 20) by scale factor 0.866748
I0111 10:39:25.067564  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 36.5724 > 20) by scale factor 0.546861
I0111 10:39:40.604732  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.6146 > 20) by scale factor 0.653283
I0111 10:39:44.706714  4932 solver.cpp:240] Iteration 68960, loss = 0.10986
I0111 10:39:44.706758  4932 solver.cpp:255]     Train net output #0: loss = 0.00984643 (* 1 = 0.00984643 loss)
I0111 10:39:44.706770  4932 solver.cpp:631] Iteration 68960, lr = 1e-08
I0111 10:40:29.094960  4932 solver.cpp:240] Iteration 68980, loss = 0.0565699
I0111 10:40:29.095033  4932 solver.cpp:255]     Train net output #0: loss = 0.0373201 (* 1 = 0.0373201 loss)
I0111 10:40:29.095043  4932 solver.cpp:631] Iteration 68980, lr = 1e-08
I0111 10:41:09.380228  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.9298 > 20) by scale factor 0.955576
I0111 10:41:11.610018  4932 solver.cpp:424] Iteration 69000, Testing net (#0)
I0111 10:42:00.967779  4932 solver.cpp:481]     Test net output #0: accuracy = 0.816842
I0111 10:42:00.967864  4932 solver.cpp:481]     Test net output #1: loss = 0.947993 (* 1 = 0.947993 loss)
I0111 10:42:02.836072  4932 solver.cpp:240] Iteration 69000, loss = 0.112393
I0111 10:42:02.836117  4932 solver.cpp:255]     Train net output #0: loss = 0.487175 (* 1 = 0.487175 loss)
I0111 10:42:02.836130  4932 solver.cpp:631] Iteration 69000, lr = 1e-08
I0111 10:42:03.176970  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.6226 > 20) by scale factor 0.75124
I0111 10:42:47.218652  4932 solver.cpp:240] Iteration 69020, loss = 0.0338705
I0111 10:42:47.218731  4932 solver.cpp:255]     Train net output #0: loss = 0.00658407 (* 1 = 0.00658407 loss)
I0111 10:42:47.218741  4932 solver.cpp:631] Iteration 69020, lr = 1e-08
I0111 10:43:07.532747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.938 > 20) by scale factor 0.911658
I0111 10:43:23.071490  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0758 > 20) by scale factor 0.712358
I0111 10:43:31.606884  4932 solver.cpp:240] Iteration 69040, loss = 0.0851583
I0111 10:43:31.606922  4932 solver.cpp:255]     Train net output #0: loss = 0.00398786 (* 1 = 0.00398786 loss)
I0111 10:43:31.606930  4932 solver.cpp:631] Iteration 69040, lr = 1e-08
I0111 10:43:54.134356  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.838 > 20) by scale factor 0.838996
I0111 10:44:15.984552  4932 solver.cpp:240] Iteration 69060, loss = 0.0444134
I0111 10:44:15.984602  4932 solver.cpp:255]     Train net output #0: loss = 0.00273909 (* 1 = 0.00273909 loss)
I0111 10:44:15.984621  4932 solver.cpp:631] Iteration 69060, lr = 1e-08
I0111 10:45:00.360216  4932 solver.cpp:240] Iteration 69080, loss = 0.0685374
I0111 10:45:00.360329  4932 solver.cpp:255]     Train net output #0: loss = 0.00671033 (* 1 = 0.00671033 loss)
I0111 10:45:00.360340  4932 solver.cpp:631] Iteration 69080, lr = 1e-08
I0111 10:45:09.573417  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.8586 > 20) by scale factor 0.773437
I0111 10:45:44.742136  4932 solver.cpp:240] Iteration 69100, loss = 0.0731939
I0111 10:45:44.742210  4932 solver.cpp:255]     Train net output #0: loss = 0.000698053 (* 1 = 0.000698053 loss)
I0111 10:45:44.742221  4932 solver.cpp:631] Iteration 69100, lr = 1e-08
I0111 10:45:58.392231  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.5531 > 20) by scale factor 0.70045
I0111 10:46:29.116163  4932 solver.cpp:240] Iteration 69120, loss = 0.0546799
I0111 10:46:29.116250  4932 solver.cpp:255]     Train net output #0: loss = 0.0730605 (* 1 = 0.0730605 loss)
I0111 10:46:29.116263  4932 solver.cpp:631] Iteration 69120, lr = 1e-08
I0111 10:47:13.497637  4932 solver.cpp:240] Iteration 69140, loss = 0.0483641
I0111 10:47:13.497714  4932 solver.cpp:255]     Train net output #0: loss = 0.175784 (* 1 = 0.175784 loss)
I0111 10:47:13.497725  4932 solver.cpp:631] Iteration 69140, lr = 1e-08
I0111 10:47:13.837198  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1913 > 20) by scale factor 0.826744
I0111 10:47:57.877027  4932 solver.cpp:240] Iteration 69160, loss = 0.0649621
I0111 10:47:57.877120  4932 solver.cpp:255]     Train net output #0: loss = 0.144968 (* 1 = 0.144968 loss)
I0111 10:47:57.877133  4932 solver.cpp:631] Iteration 69160, lr = 1e-08
I0111 10:47:58.217310  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.2607 > 20) by scale factor 0.824379
I0111 10:48:02.658661  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.2251 > 20) by scale factor 0.942282
I0111 10:48:42.259714  4932 solver.cpp:240] Iteration 69180, loss = 0.0679598
I0111 10:48:42.259788  4932 solver.cpp:255]     Train net output #0: loss = 0.257378 (* 1 = 0.257378 loss)
I0111 10:48:42.259799  4932 solver.cpp:631] Iteration 69180, lr = 1e-08
I0111 10:49:26.641098  4932 solver.cpp:240] Iteration 69200, loss = 0.0540677
I0111 10:49:26.641186  4932 solver.cpp:255]     Train net output #0: loss = 0.129631 (* 1 = 0.129631 loss)
I0111 10:49:26.641199  4932 solver.cpp:631] Iteration 69200, lr = 1e-08
I0111 10:50:11.028478  4932 solver.cpp:240] Iteration 69220, loss = 0.0512835
I0111 10:50:11.028564  4932 solver.cpp:255]     Train net output #0: loss = 0.00652818 (* 1 = 0.00652818 loss)
I0111 10:50:11.028574  4932 solver.cpp:631] Iteration 69220, lr = 1e-08
I0111 10:50:15.809641  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9011 > 20) by scale factor 0.913197
I0111 10:50:51.319396  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9626 > 20) by scale factor 0.801198
I0111 10:50:55.421128  4932 solver.cpp:240] Iteration 69240, loss = 0.0670667
I0111 10:50:55.421159  4932 solver.cpp:255]     Train net output #0: loss = 0.0230327 (* 1 = 0.0230327 loss)
I0111 10:50:55.421169  4932 solver.cpp:631] Iteration 69240, lr = 1e-08
I0111 10:51:04.632272  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8106 > 20) by scale factor 0.719149
I0111 10:51:39.801659  4932 solver.cpp:240] Iteration 69260, loss = 0.0401044
I0111 10:51:39.801743  4932 solver.cpp:255]     Train net output #0: loss = 0.00176693 (* 1 = 0.00176693 loss)
I0111 10:51:39.801753  4932 solver.cpp:631] Iteration 69260, lr = 1e-08
I0111 10:51:55.674813  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.9432 > 20) by scale factor 0.742303
I0111 10:52:24.194208  4932 solver.cpp:240] Iteration 69280, loss = 0.0510948
I0111 10:52:24.194281  4932 solver.cpp:255]     Train net output #0: loss = 0.0367149 (* 1 = 0.0367149 loss)
I0111 10:52:24.194291  4932 solver.cpp:631] Iteration 69280, lr = 1e-08
I0111 10:52:46.720394  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.3222 > 20) by scale factor 0.659583
I0111 10:53:08.573084  4932 solver.cpp:240] Iteration 69300, loss = 0.0863885
I0111 10:53:08.573173  4932 solver.cpp:255]     Train net output #0: loss = 0.0149131 (* 1 = 0.0149131 loss)
I0111 10:53:08.573185  4932 solver.cpp:631] Iteration 69300, lr = 1e-08
I0111 10:53:52.955694  4932 solver.cpp:240] Iteration 69320, loss = 0.0587015
I0111 10:53:52.955777  4932 solver.cpp:255]     Train net output #0: loss = 0.104061 (* 1 = 0.104061 loss)
I0111 10:53:52.955788  4932 solver.cpp:631] Iteration 69320, lr = 1e-08
I0111 10:54:26.583994  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8304 > 20) by scale factor 0.805466
I0111 10:54:37.347081  4932 solver.cpp:240] Iteration 69340, loss = 0.0525357
I0111 10:54:37.347122  4932 solver.cpp:255]     Train net output #0: loss = 0.0290006 (* 1 = 0.0290006 loss)
I0111 10:54:37.347138  4932 solver.cpp:631] Iteration 69340, lr = 1e-08
I0111 10:54:46.567291  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 32.1285 > 20) by scale factor 0.6225
I0111 10:55:19.862135  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.8366 > 20) by scale factor 0.718479
I0111 10:55:21.744879  4932 solver.cpp:240] Iteration 69360, loss = 0.0929208
I0111 10:55:21.744918  4932 solver.cpp:255]     Train net output #0: loss = 0.0365959 (* 1 = 0.0365959 loss)
I0111 10:55:21.744927  4932 solver.cpp:631] Iteration 69360, lr = 1e-08
I0111 10:55:42.056803  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0117 > 20) by scale factor 0.869122
I0111 10:56:06.127548  4932 solver.cpp:240] Iteration 69380, loss = 0.0449256
I0111 10:56:06.127640  4932 solver.cpp:255]     Train net output #0: loss = 0.043109 (* 1 = 0.043109 loss)
I0111 10:56:06.127652  4932 solver.cpp:631] Iteration 69380, lr = 1e-08
I0111 10:56:50.514698  4932 solver.cpp:240] Iteration 69400, loss = 0.0456496
I0111 10:56:50.514783  4932 solver.cpp:255]     Train net output #0: loss = 0.00501995 (* 1 = 0.00501995 loss)
I0111 10:56:50.514794  4932 solver.cpp:631] Iteration 69400, lr = 1e-08
I0111 10:56:59.731859  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1924 > 20) by scale factor 0.901208
I0111 10:57:34.898973  4932 solver.cpp:240] Iteration 69420, loss = 0.0683295
I0111 10:57:34.899078  4932 solver.cpp:255]     Train net output #0: loss = 0.035155 (* 1 = 0.035155 loss)
I0111 10:57:34.899094  4932 solver.cpp:631] Iteration 69420, lr = 1e-08
I0111 10:58:12.964937  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.0999 > 20) by scale factor 0.995029
I0111 10:58:19.285001  4932 solver.cpp:240] Iteration 69440, loss = 0.0924068
I0111 10:58:19.285049  4932 solver.cpp:255]     Train net output #0: loss = 0.105825 (* 1 = 0.105825 loss)
I0111 10:58:19.285063  4932 solver.cpp:631] Iteration 69440, lr = 1e-08
I0111 10:58:35.160912  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1599 > 20) by scale factor 0.902533
I0111 10:58:59.573346  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.5741 > 20) by scale factor 0.813864
I0111 10:59:03.673784  4932 solver.cpp:240] Iteration 69460, loss = 0.0788246
I0111 10:59:03.673823  4932 solver.cpp:255]     Train net output #0: loss = 0.00665418 (* 1 = 0.00665418 loss)
I0111 10:59:03.673841  4932 solver.cpp:631] Iteration 69460, lr = 1e-08
I0111 10:59:10.672931  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0525 > 20) by scale factor 0.950005
I0111 10:59:23.988077  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.333 > 20) by scale factor 0.937516
I0111 10:59:48.061285  4932 solver.cpp:240] Iteration 69480, loss = 0.0863613
I0111 10:59:48.061372  4932 solver.cpp:255]     Train net output #0: loss = 0.0900583 (* 1 = 0.0900583 loss)
I0111 10:59:48.061383  4932 solver.cpp:631] Iteration 69480, lr = 1e-08
I0111 11:00:32.449082  4932 solver.cpp:240] Iteration 69500, loss = 0.0611209
I0111 11:00:32.449159  4932 solver.cpp:255]     Train net output #0: loss = 0.0277482 (* 1 = 0.0277482 loss)
I0111 11:00:32.449169  4932 solver.cpp:631] Iteration 69500, lr = 1e-08
I0111 11:00:43.878857  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.4072 > 20) by scale factor 0.934266
I0111 11:01:01.632841  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5385 > 20) by scale factor 0.928571
I0111 11:01:06.073866  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3532 > 20) by scale factor 0.894728
I0111 11:01:16.828755  4932 solver.cpp:240] Iteration 69520, loss = 0.0436696
I0111 11:01:16.828795  4932 solver.cpp:255]     Train net output #0: loss = 0.00686065 (* 1 = 0.00686065 loss)
I0111 11:01:16.828804  4932 solver.cpp:631] Iteration 69520, lr = 1e-08
I0111 11:01:30.482831  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9571 > 20) by scale factor 0.871191
I0111 11:02:01.212157  4932 solver.cpp:240] Iteration 69540, loss = 0.0879963
I0111 11:02:01.212244  4932 solver.cpp:255]     Train net output #0: loss = 0.0131307 (* 1 = 0.0131307 loss)
I0111 11:02:01.212256  4932 solver.cpp:631] Iteration 69540, lr = 1e-08
I0111 11:02:45.590330  4932 solver.cpp:240] Iteration 69560, loss = 0.0398427
I0111 11:02:45.590409  4932 solver.cpp:255]     Train net output #0: loss = 0.172186 (* 1 = 0.172186 loss)
I0111 11:02:45.590420  4932 solver.cpp:631] Iteration 69560, lr = 1e-08
I0111 11:03:25.854465  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.9458 > 20) by scale factor 0.87162
I0111 11:03:29.955029  4932 solver.cpp:240] Iteration 69580, loss = 0.0752697
I0111 11:03:29.955076  4932 solver.cpp:255]     Train net output #0: loss = 0.00138717 (* 1 = 0.00138717 loss)
I0111 11:03:29.955087  4932 solver.cpp:631] Iteration 69580, lr = 1e-08
I0111 11:03:34.734535  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.0529 > 20) by scale factor 0.831501
I0111 11:03:45.830911  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.723 > 20) by scale factor 0.808963
I0111 11:04:14.341603  4932 solver.cpp:240] Iteration 69600, loss = 0.0960828
I0111 11:04:14.341701  4932 solver.cpp:255]     Train net output #0: loss = 0.0590435 (* 1 = 0.0590435 loss)
I0111 11:04:14.341716  4932 solver.cpp:631] Iteration 69600, lr = 1e-08
I0111 11:04:58.721179  4932 solver.cpp:240] Iteration 69620, loss = 0.0337954
I0111 11:04:58.721271  4932 solver.cpp:255]     Train net output #0: loss = 0.0227837 (* 1 = 0.0227837 loss)
I0111 11:04:58.721284  4932 solver.cpp:631] Iteration 69620, lr = 1e-08
I0111 11:05:43.098848  4932 solver.cpp:240] Iteration 69640, loss = 0.0498354
I0111 11:05:43.098956  4932 solver.cpp:255]     Train net output #0: loss = 0.031876 (* 1 = 0.031876 loss)
I0111 11:05:43.098973  4932 solver.cpp:631] Iteration 69640, lr = 1e-08
I0111 11:06:27.483319  4932 solver.cpp:240] Iteration 69660, loss = 0.0435424
I0111 11:06:27.483379  4932 solver.cpp:255]     Train net output #0: loss = 0.00782601 (* 1 = 0.00782601 loss)
I0111 11:06:27.483392  4932 solver.cpp:631] Iteration 69660, lr = 1e-08
I0111 11:07:11.866840  4932 solver.cpp:240] Iteration 69680, loss = 0.0877424
I0111 11:07:11.866952  4932 solver.cpp:255]     Train net output #0: loss = 0.182361 (* 1 = 0.182361 loss)
I0111 11:07:11.866966  4932 solver.cpp:631] Iteration 69680, lr = 1e-08
I0111 11:07:16.645042  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0358 > 20) by scale factor 0.868214
I0111 11:07:45.492079  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 31.3179 > 20) by scale factor 0.638612
I0111 11:07:56.252470  4932 solver.cpp:240] Iteration 69700, loss = 0.0908533
I0111 11:07:56.252511  4932 solver.cpp:255]     Train net output #0: loss = 0.0982058 (* 1 = 0.0982058 loss)
I0111 11:07:56.252521  4932 solver.cpp:631] Iteration 69700, lr = 1e-08
I0111 11:08:40.639914  4932 solver.cpp:240] Iteration 69720, loss = 0.0429838
I0111 11:08:40.639997  4932 solver.cpp:255]     Train net output #0: loss = 0.0176932 (* 1 = 0.0176932 loss)
I0111 11:08:40.640009  4932 solver.cpp:631] Iteration 69720, lr = 1e-08
I0111 11:09:25.027446  4932 solver.cpp:240] Iteration 69740, loss = 0.0757325
I0111 11:09:25.027529  4932 solver.cpp:255]     Train net output #0: loss = 0.138464 (* 1 = 0.138464 loss)
I0111 11:09:25.027540  4932 solver.cpp:631] Iteration 69740, lr = 1e-08
I0111 11:09:47.553978  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3408 > 20) by scale factor 0.937174
I0111 11:09:54.215744  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.3418 > 20) by scale factor 0.937128
I0111 11:09:56.437191  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1513 > 20) by scale factor 0.902883
I0111 11:10:05.312669  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3628 > 20) by scale factor 0.894341
I0111 11:10:09.413144  4932 solver.cpp:240] Iteration 69760, loss = 0.0600649
I0111 11:10:09.413189  4932 solver.cpp:255]     Train net output #0: loss = 0.0688211 (* 1 = 0.0688211 loss)
I0111 11:10:09.413200  4932 solver.cpp:631] Iteration 69760, lr = 1e-08
I0111 11:10:29.725355  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5425 > 20) by scale factor 0.97359
I0111 11:10:38.607779  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3157 > 20) by scale factor 0.984458
I0111 11:10:53.800810  4932 solver.cpp:240] Iteration 69780, loss = 0.0717203
I0111 11:10:53.800858  4932 solver.cpp:255]     Train net output #0: loss = 0.0054146 (* 1 = 0.0054146 loss)
I0111 11:10:53.800869  4932 solver.cpp:631] Iteration 69780, lr = 1e-08
I0111 11:11:22.991832  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.1276 > 20) by scale factor 0.765473
I0111 11:11:27.430930  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6578 > 20) by scale factor 0.968157
I0111 11:11:38.189414  4932 solver.cpp:240] Iteration 69800, loss = 0.0489736
I0111 11:11:38.189457  4932 solver.cpp:255]     Train net output #0: loss = 0.014505 (* 1 = 0.014505 loss)
I0111 11:11:38.189467  4932 solver.cpp:631] Iteration 69800, lr = 1e-08
I0111 11:11:45.189615  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5921 > 20) by scale factor 0.971248
I0111 11:12:22.581750  4932 solver.cpp:240] Iteration 69820, loss = 0.0683631
I0111 11:12:22.581830  4932 solver.cpp:255]     Train net output #0: loss = 0.0925691 (* 1 = 0.0925691 loss)
I0111 11:12:22.581840  4932 solver.cpp:631] Iteration 69820, lr = 1e-08
I0111 11:12:40.674156  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.3112 > 20) by scale factor 0.984679
I0111 11:13:06.965723  4932 solver.cpp:240] Iteration 69840, loss = 0.0743233
I0111 11:13:06.965811  4932 solver.cpp:255]     Train net output #0: loss = 0.239832 (* 1 = 0.239832 loss)
I0111 11:13:06.965822  4932 solver.cpp:631] Iteration 69840, lr = 1e-08
I0111 11:13:33.939797  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.1186 > 20) by scale factor 0.947031
I0111 11:13:51.354514  4932 solver.cpp:240] Iteration 69860, loss = 0.0996683
I0111 11:13:51.354602  4932 solver.cpp:255]     Train net output #0: loss = 0.1167 (* 1 = 0.1167 loss)
I0111 11:13:51.354614  4932 solver.cpp:631] Iteration 69860, lr = 1e-08
I0111 11:13:58.352294  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 29.3819 > 20) by scale factor 0.68069
I0111 11:14:35.750115  4932 solver.cpp:240] Iteration 69880, loss = 0.0866402
I0111 11:14:35.750211  4932 solver.cpp:255]     Train net output #0: loss = 0.0908173 (* 1 = 0.0908173 loss)
I0111 11:14:35.750222  4932 solver.cpp:631] Iteration 69880, lr = 1e-08
I0111 11:15:11.597143  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9166 > 20) by scale factor 0.91255
I0111 11:15:20.134749  4932 solver.cpp:240] Iteration 69900, loss = 0.0546898
I0111 11:15:20.134788  4932 solver.cpp:255]     Train net output #0: loss = 0.056289 (* 1 = 0.056289 loss)
I0111 11:15:20.134796  4932 solver.cpp:631] Iteration 69900, lr = 1e-08
I0111 11:16:04.519757  4932 solver.cpp:240] Iteration 69920, loss = 0.0727732
I0111 11:16:04.519839  4932 solver.cpp:255]     Train net output #0: loss = 0.0438986 (* 1 = 0.0438986 loss)
I0111 11:16:04.519848  4932 solver.cpp:631] Iteration 69920, lr = 1e-08
I0111 11:16:27.048959  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6672 > 20) by scale factor 0.967719
I0111 11:16:48.901841  4932 solver.cpp:240] Iteration 69940, loss = 0.0681958
I0111 11:16:48.901926  4932 solver.cpp:255]     Train net output #0: loss = 0.0988043 (* 1 = 0.0988043 loss)
I0111 11:16:48.901937  4932 solver.cpp:631] Iteration 69940, lr = 1e-08
I0111 11:17:29.185137  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.9508 > 20) by scale factor 0.801576
I0111 11:17:33.282939  4932 solver.cpp:240] Iteration 69960, loss = 0.0475814
I0111 11:17:33.282969  4932 solver.cpp:255]     Train net output #0: loss = 0.0508838 (* 1 = 0.0508838 loss)
I0111 11:17:33.282979  4932 solver.cpp:631] Iteration 69960, lr = 1e-08
I0111 11:17:42.498464  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3274 > 20) by scale factor 0.895761
I0111 11:17:49.161231  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.7869 > 20) by scale factor 0.806877
I0111 11:18:17.667124  4932 solver.cpp:240] Iteration 69980, loss = 0.081954
I0111 11:18:17.667194  4932 solver.cpp:255]     Train net output #0: loss = 0.00106214 (* 1 = 0.00106214 loss)
I0111 11:18:17.667204  4932 solver.cpp:631] Iteration 69980, lr = 1e-08
I0111 11:18:20.225713  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.9989 > 20) by scale factor 0.714314
I0111 11:19:00.168223  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.0431 > 20) by scale factor 0.713188
I0111 11:19:00.177016  4932 solver.cpp:424] Iteration 70000, Testing net (#0)
I0111 11:19:47.865941  4932 solver.cpp:481]     Test net output #0: accuracy = 0.851579
I0111 11:19:47.866027  4932 solver.cpp:481]     Test net output #1: loss = 0.74452 (* 1 = 0.74452 loss)
I0111 11:19:49.732018  4932 solver.cpp:240] Iteration 70000, loss = 0.0706169
I0111 11:19:49.732058  4932 solver.cpp:255]     Train net output #0: loss = 0.013589 (* 1 = 0.013589 loss)
I0111 11:19:49.732069  4932 solver.cpp:631] Iteration 70000, lr = 1e-08
I0111 11:20:34.116963  4932 solver.cpp:240] Iteration 70020, loss = 0.0568975
I0111 11:20:34.117055  4932 solver.cpp:255]     Train net output #0: loss = 0.0231 (* 1 = 0.0231 loss)
I0111 11:20:34.117069  4932 solver.cpp:631] Iteration 70020, lr = 1e-08
I0111 11:21:07.743733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7099 > 20) by scale factor 0.880675
I0111 11:21:18.503778  4932 solver.cpp:240] Iteration 70040, loss = 0.0588553
I0111 11:21:18.503823  4932 solver.cpp:255]     Train net output #0: loss = 0.204997 (* 1 = 0.204997 loss)
I0111 11:21:18.503835  4932 solver.cpp:631] Iteration 70040, lr = 1e-08
I0111 11:22:02.887928  4932 solver.cpp:240] Iteration 70060, loss = 0.0454907
I0111 11:22:02.888022  4932 solver.cpp:255]     Train net output #0: loss = 0.175714 (* 1 = 0.175714 loss)
I0111 11:22:02.888036  4932 solver.cpp:631] Iteration 70060, lr = 1e-08
I0111 11:22:03.227329  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.2385 > 20) by scale factor 0.988217
I0111 11:22:27.635176  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5636 > 20) by scale factor 0.927489
I0111 11:22:40.954630  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.1305 > 20) by scale factor 0.90373
I0111 11:22:47.273676  4932 solver.cpp:240] Iteration 70080, loss = 0.0676179
I0111 11:22:47.273715  4932 solver.cpp:255]     Train net output #0: loss = 0.00404893 (* 1 = 0.00404893 loss)
I0111 11:22:47.273725  4932 solver.cpp:631] Iteration 70080, lr = 1e-08
I0111 11:23:12.027747  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.2078 > 20) by scale factor 0.861777
I0111 11:23:31.665352  4932 solver.cpp:240] Iteration 70100, loss = 0.0721783
I0111 11:23:31.665391  4932 solver.cpp:255]     Train net output #0: loss = 0.0492802 (* 1 = 0.0492802 loss)
I0111 11:23:31.665400  4932 solver.cpp:631] Iteration 70100, lr = 1e-08
I0111 11:24:07.517318  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.0251 > 20) by scale factor 0.868616
I0111 11:24:11.956619  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5173 > 20) by scale factor 0.929485
I0111 11:24:16.058696  4932 solver.cpp:240] Iteration 70120, loss = 0.0755989
I0111 11:24:16.058738  4932 solver.cpp:255]     Train net output #0: loss = 0.0338251 (* 1 = 0.0338251 loss)
I0111 11:24:16.058750  4932 solver.cpp:631] Iteration 70120, lr = 1e-08
I0111 11:24:43.026386  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.756 > 20) by scale factor 0.963575
I0111 11:25:00.447693  4932 solver.cpp:240] Iteration 70140, loss = 0.0693818
I0111 11:25:00.447733  4932 solver.cpp:255]     Train net output #0: loss = 0.0460812 (* 1 = 0.0460812 loss)
I0111 11:25:00.447743  4932 solver.cpp:631] Iteration 70140, lr = 1e-08
I0111 11:25:03.006892  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0016 > 20) by scale factor 0.952311
I0111 11:25:44.840782  4932 solver.cpp:240] Iteration 70160, loss = 0.0862713
I0111 11:25:44.840855  4932 solver.cpp:255]     Train net output #0: loss = 0.0280876 (* 1 = 0.0280876 loss)
I0111 11:25:44.840865  4932 solver.cpp:631] Iteration 70160, lr = 1e-08
I0111 11:26:00.712188  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9457 > 20) by scale factor 0.911341
I0111 11:26:29.220106  4932 solver.cpp:240] Iteration 70180, loss = 0.0781408
I0111 11:26:29.220201  4932 solver.cpp:255]     Train net output #0: loss = 0.15274 (* 1 = 0.15274 loss)
I0111 11:26:29.220213  4932 solver.cpp:631] Iteration 70180, lr = 1e-08
I0111 11:26:40.651988  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.7556 > 20) by scale factor 0.776532
I0111 11:27:09.499706  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0213 > 20) by scale factor 0.951416
I0111 11:27:11.720579  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7526 > 20) by scale factor 0.87902
I0111 11:27:13.601961  4932 solver.cpp:240] Iteration 70200, loss = 0.0968535
I0111 11:27:13.601991  4932 solver.cpp:255]     Train net output #0: loss = 0.001601 (* 1 = 0.001601 loss)
I0111 11:27:13.602000  4932 solver.cpp:631] Iteration 70200, lr = 1e-08
I0111 11:27:25.040781  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5157 > 20) by scale factor 0.974864
I0111 11:27:33.918872  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.1863 > 20) by scale factor 0.99077
I0111 11:27:49.458528  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.857 > 20) by scale factor 0.915038
I0111 11:27:57.999346  4932 solver.cpp:240] Iteration 70220, loss = 0.0656631
I0111 11:27:57.999377  4932 solver.cpp:255]     Train net output #0: loss = 0.00373565 (* 1 = 0.00373565 loss)
I0111 11:27:57.999385  4932 solver.cpp:631] Iteration 70220, lr = 1e-08
I0111 11:28:42.380576  4932 solver.cpp:240] Iteration 70240, loss = 0.045039
I0111 11:28:42.380703  4932 solver.cpp:255]     Train net output #0: loss = 0.0268178 (* 1 = 0.0268178 loss)
I0111 11:28:42.380715  4932 solver.cpp:631] Iteration 70240, lr = 1e-08
I0111 11:28:53.818733  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.7592 > 20) by scale factor 0.841781
I0111 11:28:56.039260  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.8691 > 20) by scale factor 0.804212
I0111 11:29:26.762343  4932 solver.cpp:240] Iteration 70260, loss = 0.0640289
I0111 11:29:26.762454  4932 solver.cpp:255]     Train net output #0: loss = 0.105432 (* 1 = 0.105432 loss)
I0111 11:29:26.762470  4932 solver.cpp:631] Iteration 70260, lr = 1e-08
I0111 11:29:31.543686  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.4511 > 20) by scale factor 0.85284
I0111 11:30:11.152655  4932 solver.cpp:240] Iteration 70280, loss = 0.109092
I0111 11:30:11.152750  4932 solver.cpp:255]     Train net output #0: loss = 0.0794284 (* 1 = 0.0794284 loss)
I0111 11:30:11.152765  4932 solver.cpp:631] Iteration 70280, lr = 1e-08
I0111 11:30:55.536490  4932 solver.cpp:240] Iteration 70300, loss = 0.0556297
I0111 11:30:55.536586  4932 solver.cpp:255]     Train net output #0: loss = 0.0159539 (* 1 = 0.0159539 loss)
I0111 11:30:55.536597  4932 solver.cpp:631] Iteration 70300, lr = 1e-08
I0111 11:31:35.820554  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.5022 > 20) by scale factor 0.930139
I0111 11:31:39.918615  4932 solver.cpp:240] Iteration 70320, loss = 0.0513298
I0111 11:31:39.918654  4932 solver.cpp:255]     Train net output #0: loss = 0.0569493 (* 1 = 0.0569493 loss)
I0111 11:31:39.918663  4932 solver.cpp:631] Iteration 70320, lr = 1e-08
I0111 11:32:24.296128  4932 solver.cpp:240] Iteration 70340, loss = 0.0560908
I0111 11:32:24.296214  4932 solver.cpp:255]     Train net output #0: loss = 0.121333 (* 1 = 0.121333 loss)
I0111 11:32:24.296226  4932 solver.cpp:631] Iteration 70340, lr = 1e-08
I0111 11:32:46.827836  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.3067 > 20) by scale factor 0.896593
I0111 11:32:49.047170  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 26.2812 > 20) by scale factor 0.761001
I0111 11:33:00.138695  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.6328 > 20) by scale factor 0.846281
I0111 11:33:08.678391  4932 solver.cpp:240] Iteration 70360, loss = 0.107032
I0111 11:33:08.678432  4932 solver.cpp:255]     Train net output #0: loss = 0.179529 (* 1 = 0.179529 loss)
I0111 11:33:08.678442  4932 solver.cpp:631] Iteration 70360, lr = 1e-08
I0111 11:33:09.017724  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.7186 > 20) by scale factor 0.965318
I0111 11:33:40.086947  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.6822 > 20) by scale factor 0.651843
I0111 11:33:53.063712  4932 solver.cpp:240] Iteration 70380, loss = 0.069565
I0111 11:33:53.063755  4932 solver.cpp:255]     Train net output #0: loss = 0.0081833 (* 1 = 0.0081833 loss)
I0111 11:33:53.063766  4932 solver.cpp:631] Iteration 70380, lr = 1e-08
I0111 11:34:13.373203  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 30.6395 > 20) by scale factor 0.652753
I0111 11:34:37.439402  4932 solver.cpp:240] Iteration 70400, loss = 0.0447874
I0111 11:34:37.439443  4932 solver.cpp:255]     Train net output #0: loss = 0.119796 (* 1 = 0.119796 loss)
I0111 11:34:37.439455  4932 solver.cpp:631] Iteration 70400, lr = 1e-08
I0111 11:34:46.649014  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.635 > 20) by scale factor 0.969227
I0111 11:34:54.400005  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 27.5865 > 20) by scale factor 0.724992
I0111 11:35:05.497824  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.8174 > 20) by scale factor 0.839723
I0111 11:35:14.374457  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.8613 > 20) by scale factor 0.69297
I0111 11:35:22.911468  4932 solver.cpp:240] Iteration 70420, loss = 0.109216
I0111 11:35:22.911590  4932 solver.cpp:255]     Train net output #0: loss = 0.290018 (* 1 = 0.290018 loss)
I0111 11:35:22.911605  4932 solver.cpp:631] Iteration 70420, lr = 1e-08
I0111 11:35:23.252044  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.6493 > 20) by scale factor 0.923816
I0111 11:36:07.293154  4932 solver.cpp:240] Iteration 70440, loss = 0.0334227
I0111 11:36:07.293252  4932 solver.cpp:255]     Train net output #0: loss = 0.0289739 (* 1 = 0.0289739 loss)
I0111 11:36:07.293265  4932 solver.cpp:631] Iteration 70440, lr = 1e-08
I0111 11:36:51.666257  4932 solver.cpp:240] Iteration 70460, loss = 0.0495271
I0111 11:36:51.666342  4932 solver.cpp:255]     Train net output #0: loss = 0.00907792 (* 1 = 0.00907792 loss)
I0111 11:36:51.666353  4932 solver.cpp:631] Iteration 70460, lr = 1e-08
I0111 11:36:56.442906  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.9997 > 20) by scale factor 0.909105
I0111 11:37:16.413306  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.6932 > 20) by scale factor 0.966502
I0111 11:37:36.046106  4932 solver.cpp:240] Iteration 70480, loss = 0.0775798
I0111 11:37:36.046200  4932 solver.cpp:255]     Train net output #0: loss = 0.0217768 (* 1 = 0.0217768 loss)
I0111 11:37:36.046212  4932 solver.cpp:631] Iteration 70480, lr = 1e-08
I0111 11:38:20.419998  4932 solver.cpp:240] Iteration 70500, loss = 0.0719674
I0111 11:38:20.420074  4932 solver.cpp:255]     Train net output #0: loss = 0.05813 (* 1 = 0.05813 loss)
I0111 11:38:20.420083  4932 solver.cpp:631] Iteration 70500, lr = 1e-08
I0111 11:39:04.799275  4932 solver.cpp:240] Iteration 70520, loss = 0.0560507
I0111 11:39:04.799351  4932 solver.cpp:255]     Train net output #0: loss = 0.0510277 (* 1 = 0.0510277 loss)
I0111 11:39:04.799362  4932 solver.cpp:631] Iteration 70520, lr = 1e-08
I0111 11:39:09.577826  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.8404 > 20) by scale factor 0.915734
I0111 11:39:49.179987  4932 solver.cpp:240] Iteration 70540, loss = 0.0716944
I0111 11:39:49.180073  4932 solver.cpp:255]     Train net output #0: loss = 0.00134168 (* 1 = 0.00134168 loss)
I0111 11:39:49.180086  4932 solver.cpp:631] Iteration 70540, lr = 1e-08
I0111 11:39:58.394789  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 39.4381 > 20) by scale factor 0.507124
I0111 11:40:00.614688  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 28.9073 > 20) by scale factor 0.691867
I0111 11:40:56.130614  4932 solver.cpp:240] Iteration 70560, loss = 0.116204
I0111 11:40:56.130702  4932 solver.cpp:255]     Train net output #0: loss = 0.176621 (* 1 = 0.176621 loss)
I0111 11:40:56.130712  4932 solver.cpp:631] Iteration 70560, lr = 1e-08
I0111 11:41:20.875994  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 20.5558 > 20) by scale factor 0.972962
I0111 11:41:40.505414  4932 solver.cpp:240] Iteration 70580, loss = 0.0580044
I0111 11:41:40.505501  4932 solver.cpp:255]     Train net output #0: loss = 0.0132536 (* 1 = 0.0132536 loss)
I0111 11:41:40.505512  4932 solver.cpp:631] Iteration 70580, lr = 1e-08
I0111 11:42:11.913976  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.1427 > 20) by scale factor 0.864205
I0111 11:42:14.135550  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 21.0949 > 20) by scale factor 0.948098
I0111 11:42:18.577739  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0069 > 20) by scale factor 0.908806
I0111 11:42:24.903264  4932 solver.cpp:240] Iteration 70600, loss = 0.0803474
I0111 11:42:24.903301  4932 solver.cpp:255]     Train net output #0: loss = 0.0335043 (* 1 = 0.0335043 loss)
I0111 11:42:24.903311  4932 solver.cpp:631] Iteration 70600, lr = 1e-08
I0111 11:42:34.116489  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 23.3691 > 20) by scale factor 0.855831
I0111 11:42:38.561136  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.0209 > 20) by scale factor 0.908229
I0111 11:43:07.414454  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6141 > 20) by scale factor 0.78082
I0111 11:43:09.295236  4932 solver.cpp:240] Iteration 70620, loss = 0.0457877
I0111 11:43:09.295274  4932 solver.cpp:255]     Train net output #0: loss = 0.00725719 (* 1 = 0.00725719 loss)
I0111 11:43:09.295284  4932 solver.cpp:631] Iteration 70620, lr = 1e-08
I0111 11:43:36.282541  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 24.1566 > 20) by scale factor 0.82793
I0111 11:44:00.766331  4932 solver.cpp:240] Iteration 70640, loss = 0.0745527
I0111 11:44:00.766409  4932 solver.cpp:255]     Train net output #0: loss = 0.00343043 (* 1 = 0.00343043 loss)
I0111 11:44:00.766420  4932 solver.cpp:631] Iteration 70640, lr = 1e-08
I0111 11:44:03.323801  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 25.6239 > 20) by scale factor 0.780523
I0111 11:44:12.203228  4932 solver.cpp:616] Gradient clipping: scaling down gradients (L2 norm 22.7217 > 20) by scale factor 0.880216
